Pour faire un nuage de mots en python, j'ai utilisé la librairie worldcloud pré-existante. 
La bibliothèque commence par analyser le texte fourni. Elle compte la fréquence de chaque mot dans le texte, on lui donne une liste de mots 'stopwords' qui sont des mots vides qu'on ne veut
pas compter. Les mots les plus fréquents sont généralement mis en évidence dans le nuage de mots en étant plus grand. Une fois les fréquences des mots calculées, la bibliothèque génère une image où la taille de chaque mot est proportionnelle à sa fréquence dans le texte.
Les mots les plus fréquents apparaissent en plus grand, et les moins fréquents en plus petit. On peut également définir une forme pour le nuage de mots, en utilisant une image comme masque.
La bibliothèque utilise des techniques de traitement du langage naturel (NLP) pour analyser le texte. Elle tokenise le texte, c'est-à-dire qu'elle le divise en mots individuels. Le masque est une image binaire où les pixels blancs indiquent les zones où les mots peuvent être placés, et les pixels noirs indiquent les zones vides. La bibliothèque utilise un algorithme de placement pour positionner les mots dans un espace 2D. Cet algorithme essaie de placer les mots de manière à ce qu'ils ne se chevauchent pas trop.