



hal_id    :    hal-04548715



No abstract found in the PDF.



hal_id    :    hal-04038023



—Supervised deep learning approaches to underdeter-
mined audio source separation achieve state-of-the-art perfor-
mance but require a dataset of mixtures along with their corre-
sponding isolated source signals. Such datasets can be extremely
costly to obtain for musical mixtures. This raises a need for unsu-
pervised methods. We propose a novel unsupervised model-based
deep learning approach to musical source separation. Each source
is modelled with a differentiable parametric source-ﬁlter model. A
neural network is trained to reconstruct the observed mixture as
a sum of the sources by estimating the source models’ parameters
given their fundamental frequencies. At test time, soft masks are
obtained from the synthesized source signals. The experimental
evaluation on a vocal ensemble separation task shows that the
proposed method outperforms learning-free methods based on
nonnegative matrix factorization and a supervised deep learning
baseline. Integrating domain knowledge in the form of source
models into a data-driven method leads to high data efﬁciency: the
proposed approach achieves good separation quality even when
trained on less than three minutes of audio. This work makes
powerful deep learning based separation usable in scenarios where
training data with ground truth is expensive or nonexistent.
Index Terms—Unsupervised learning, audio source separation,
signal processing, model-based, deep learning.



hal_id    :    hal-03671851



In the stress-energy tensor formalism, the symmetry between absorption and scattering coefﬁcients, as proven
by measurements combined with simulations, is counter-intuitive. By introducing the wall admittance, we
show that the scattering coefﬁcient is partly created by the real part of the wall admittance combined with the
active intensity, that is, is partly due to absorption. However, it also depends on the imaginary part of the wall
admittance in combination with the reactive intensity, which confers it genuine scattering properties. In the case
of plane waves impinging on planar boundary, the admittance formalism shows that reactive intensity vanishes
in directions parallel to the wall; when the source is at ﬁnite distance from the wall, a residual reactive intensity
subsists. However, for curved boundaries, the velocity in directions parallel to the wall is no longer proportional
to the pressure, and scattering occurs.
Keywords: Energy density, Sound intensity, Absorption coefﬁcient, Scattering coefﬁcient, Wall admittance
1



hal_id    :    hal-03559398



No abstract found in the PDF.



hal_id    :    hal-03790806



—Supervised deep learning approaches to underde-
termined audio source separation achieve state-of-the-art perfor-
mance but require a dataset of mixtures along with their corre-
sponding isolated source signals. Such datasets can be extremely
costly to obtain for musical mixtures. This raises a need for
unsupervised methods. We propose a novel unsupervised model-
based deep learning approach to musical source separation.
Each source is modelled with a differentiable parametric source-
ﬁlter model. A neural network is trained to reconstruct the
observed mixture as a sum of the sources by estimating the
source models’ parameters given their fundamental frequencies.
At test time, soft masks are obtained from the synthesized
source signals. The experimental evaluation on a vocal ensemble
separation task shows that the proposed method outperforms
learning-free methods based on nonnegative matrix factorization
and a supervised deep learning baseline. Integrating domain
knowledge in the form of source models into a data-driven
method leads to high data efﬁciency: the proposed approach
achieves good separation quality even when trained on less than
three minutes of audio. This work makes powerful deep learning
based separation usable in scenarios where training data with
ground truth is expensive or nonexistent.
Index Terms—unsupervised learning, audio source separation,
signal processing, model-based, deep learning.



hal_id    :    hal-03298695



In various audio signal processing applications, such as source sepa-
ration and dereverberation, accurate mathematical modeling of both
source signals and room reverberation is needed to properly describe
the audio data. In a previous paper, we introduced a stochastic room
impulse response model based on the image source principle, and
we proposed an expectation-maximization algorithm that was able
to eﬃciently estimate the model parameters in various experimental
settings. This paper aims to extend the model in order to account for
the dependency of the exponential decay over frequency, due to the
walls usually absorbing less energy at low frequencies than at high
frequencies. Our experimental results show that this reﬁnement of
the model is able to generate realistic room impulse responses, that
are perceptively very close to the original ones.
Index Terms— Reverberation, room impulse response, prob-
abilistic modeling, expectation-maximization algorithm, artiﬁcial
reverberation.



hal_id    :    hal-03255349



Estimating mixtures of damped chirp sinusoids in noise is a
problem that affects audio analysis, coding, and synthesis appli-
cations. Phase-based non-stationary parameter estimators assume
that sinusoids can be resolved in the Fourier transform domain,
whereas high-resolution methods estimate superimposed compo-
nents with accuracy close to the theoretical limits, but only for
sinusoids with constant frequencies. We present a new method
for estimating the parameters of superimposed damped chirps that
has an accuracy competitive with existing non-stationary estima-
tors but also has a high-resolution like subspace techniques. Af-
ter providing the analytical expression for a Gaussian-windowed
damped chirp signal’s Fourier transform, we propose an efficient
variational EM algorithm for nonlinear Bayesian regression that
jointly estimates the amplitudes, phases, frequencies, chirp rates,
and decay rates of multiple non-stationary components that may be
obfuscated under the same local maximum in the frequency spec-
trum. Quantitative results show that the new method not only has
an estimation accuracy that is close to the Cramér-Rao bound, but
also a high resolution that outperforms the state-of-the-art.



hal_id    :    hal-03255319



—State space models have been extensively applied
to model and control dynamical systems in disciplines including
neuroscience, target tracking, and audio processing. A common
modeling assumption is that both the state and data noise are
Gaussian because it simpliﬁes the estimation of the system’s state
and model parameters. However, in many real-world scenarios
where the noise is heavy-tailed or includes outliers, this assump-
tion does not hold, and the performance of the model degrades.
In this paper, we present a new approximate inference algorithm
for state space models with Laplace-distributed multivariate data
that is robust to a wide range of non-Gaussian noise. Locally
exact inference is combined with an expectation propagation
algorithm, leading to ﬁltering and smoothing that outperforms
existing approximate inference methods for Laplace-distributed
data, while retaining a fast speed similar to the Kalman ﬁlter.
Further, we present a maximum posterior expectation maximiza-
tion (EM) algorithm that learns the parameters of the model in
an unsupervised way, automatically avoids over-ﬁtting the data,
and provides better model estimation than existing methods for
the Gaussian model. The quality of the inference and learning
algorithms are exempliﬁed through a diverse set of experiments
and an application to non-linear tracking of audio frequency.
Index Terms—Bayesian inference, time series, heavy-tailed
noise, EM algorithm, machine learning, expectation propagation



hal_id    :    hal-03255334



—The goal of singing voice separation is to recover the
vocals signal from music mixtures. State-of-the-art performance
is achieved by deep neural networks trained in a supervised
fashion. Since training data are scarce and music signals are ex-
tremely diverse, it remains challenging to achieve high separation
quality across various recording and mixing conditions as well
as music styles. In this paper, we investigate to which extent the
separation can be improved when lyrics transcripts are used as
additional information. To this end, we propose a joint approach
to phoneme level lyrics alignment and text-informed singing voice
separation. It is based on DTW-attention, a new monotonic
attention mechanism including a differentiable approximation
of dynamic time warping. Experimental results show that the
method can align phonemes with mixed singing voice with high
precision given accurate transcripts. It also achieves competitive
results on challenging word level alignment test sets using less
training data than state-of-the-art methods. Sequential alignment
and informed separation lead to improved separation quality ac-
cording to objective measures. Text information helps preserving
spectral phoneme properties in the separated voice signals.
Index Terms—Singing voice separation, lyrics alignment,
monotonic attention mechanism



hal_id    :    hal-02932485



Various audio signal processing applications, such as source
separation and dereverberation, require an accurate mathematical
modeling of the input audio data. In the literature, many works
have focused on source signal modeling, while the reverberation
model is often kept very simplistic.
This paper aims to investigate a stochastic room impulse re-
sponse model presented in a previous article: this model is first
adapted to discrete time, then we propose a parametric estimation
algorithm, that we evaluate experimentally. Our results show that
this algorithm is able to efficiently estimate the model parameters,
in various experimental settings (various signal-to-noise ratios and
absorption coefficients of the room walls).



hal_id    :    hal-02457075



Speech separation quality can be improved by exploiting textual
information. However, this usually requires text-to-speech align-
ment at phoneme level. Classical alignment methods are made for
rather clean speech and do not work as well on corrupted speech.
We propose to perform text-informed speech-music separation and
phoneme alignment jointly using recurrent neural networks and the
attention mechanism.
We show that it leads to beneﬁts for both
tasks. In experiments, phoneme transcripts are used to improve the
perceived quality of separated speech over a non-informed baseline.
Moreover, our novel phoneme alignment method based on the at-
tention mechanism achieves state-of-the-art alignment accuracy on
clean and on heavily corrupted speech.
Index Terms— Speech separation, phoneme alignment, atten-
tion, informed source separation



hal_id    :    hal-02456643



We present a Bayesian ﬁlter for state space models with Laplace-
distributed observation noise that is robust to heavy-tailed and
outlier-ridden univariate time-series data. We analytically derive a
closed-form expression of the exact posterior for a Laplace likeli-
hood conditioned on a Gaussian prior. Posterior statistics are prop-
agated forward in time by a proxy Gaussian density. The forward
Kullback-Leibler divergence from the posterior to the Gaussian
is minimized by matching their moments. The proposed method
supports both linear and non-linear systems, and has a fast recur-
sive structure analogous to the Kalman ﬁlter that enables online
inference. Results show that the new method outperforms existing
approximate inference methods, especially in challenging scenarios
where the system’s parameters are uncertain.
Index Terms— heavy-tailed noise, Kalman ﬁlter, state estima-
tion, Laplace distribution, Bayesian inference



hal_id    :    hal-01958485



No abstract found in the PDF.



hal_id    :    hal-02280472



Prior information about the target source can improve audio
source separation quality but is usually not available with the nec-
essary level of audio alignment. This has limited its usability in
the past. We propose a separation model that can nevertheless ex-
ploit such weak information for the separation task while aligning
it on the mixture as a byproduct using an attention mechanism. We
demonstrate the capabilities of the model on a singing voice separa-
tion task exploiting artiﬁcial side information with different levels
of expressiveness. Moreover, we highlight an issue with the com-
mon separation quality assessment procedure regarding parts where
targets or predictions are silent and reﬁne a previous contribution
for a more complete evaluation.
Index Terms— informed source separation, singing voice sep-
aration, weak labels, attention, separation evaluation



hal_id    :    hal-02332689



Prior information about the target source can improve audio source
separation quality but is usually not available with the necessary
level of audio alignment. This has limited its usability in the past.
We propose a separation model that can nevertheless exploit such
weak information for the separation task while aligning it on the
mixture as a byproduct using an attention mechanism. We demon-
strate the capabilities of the model on a singing voice separation task
exploiting artiﬁcial side information with different levels of expres-
siveness. Moreover, we highlight an issue with the common separa-
tion quality assessment procedure regarding parts where targets or
predictions are silent and reﬁne a previous contribution for a more
complete evaluation.
Index Terms— informed source separation, singing voice sep-
aration, weak labels, attention, separation evaluation



hal_id    :    hal-02127799



—In a recent research report, we introduced a general
stochastic reverberation model that aims to represent the statis-
tical properties of reverberation in a broad variety of acoustic
environments. A simpliﬁed version of this model, dedicated
to the particular case of diffuse (i.e. uniform and isotropic)
acoustic ﬁelds, omnidirectional sources and microphones, and
constant attenuation w.r.t frequency, has been investigated both
mathematically and experimentally in a recent research paper.
We showed that this model provides a common mathematical
framework that uniﬁes several well-known results regarding the
statistical properties of reverberation in the space, time and
frequency domains.
In this research report, we aim to extend this mathematical
analysis to uniform and non-diffuse acoustic ﬁelds, and directive
sources and microphones. We show that the predictions of the
general stochastic model experimentally match the observations,
based on both synthetic and real room impulse responses,
measured in various acoustic environments.
Index Terms—Reverberation; Diffusion; Room impulse re-
sponse; Stochastic models.
R´esum´e—Dans un r´ecent rapport de recherche, nous avons
introduit un mod`ele stochastique g´en´eral de r´everb´eration qui
vise `a repr´esenter les propri´et´es statistiques de la r´everb´eration
dans une grande vari´et´e d’environnements acoustiques. Une
version simpliﬁ´ee de ce mod`ele, d´edi´ee au cas particulier de
champs acoustiques diffus (c’est-`a-dire uniformes et isotropes), de
sources et microphones omnidirectionnels, et d’une att´enuation
ind´ependante de la fr´equence, a ´et´e ´etudi´ee math´ematiquement
et exp´erimentalement dans un r´ecent article de



hal_id    :    hal-02049987



—In a recent research paper, we proposed a common
mathematical framework for stochastic reverberation models,
that aimed to unify several well-known results regarding the
statistical properties of reverberation, in the spatial, spectral
and temporal domains. This model was dedicated to diffuse (i.e.
isotropic and uniform) acoustic ﬁelds, omnidirectional sources
and microphones, and constant attenuation coefﬁcients w.r.t.
the frequency. In this technical report, we introduce several
extensions of this model, that aim to model reverberation more
realistically, by considering anisotropic and non-uniform acoustic
ﬁelds, directive sources and microphones, and frequency-varying
attenuation coefﬁcients.
Index Terms—Reverberation; Diffusion; Room impulse re-
sponse; Stochastic models.
Résumé—Dans un récent article de recherche, nous avons
proposé un cadre mathématique commun pour les modèles
stochastiques de réverbération, qui visait à uniﬁer plusieurs
résultats bien connus concernant les propriétés statistiques de
la réverbération, dans les domaines spatial, spectral et temporel.
Ce modèle était dédié aux champs acoustiques diffus (c’est à
dire isotropes et uniformes), à des sources et des microphones
omnidirectionnels, et à des coefﬁcients d’atténuation constants
par rapport à la fréquence. Dans ce rapport technique, nous
introduisons plusieurs extensions de ce modèle, qui visent à mod-
éliser la réverbération de manière plus réaliste, en considérant
des champs acoustiques anisotropes et non uniformes, des sources
et des microphones directifs, et des coefﬁcients d’atténuation
variant en fonction de la fréquence.
Mots clés—Réverbération; Diffusion; Réponse impulsionnelle
de salle; Modèles stochastiques.



hal_id    :    hal-01795319



—In the ﬁeld of room acoustics, it is well known that
reverberation can be characterized statistically in a particular
region of the time-frequency domain (after the transition time
and above Schroeder’s frequency). Since the 1950s, various
formulas have been established, focusing on particular aspects of
reverberation: exponential decay over time, correlations between
frequencies, correlations between sensors at each frequency,
and time-frequency distribution. In this paper, we introduce a
new stochastic reverberation model, that permits us to retrieve
all these well-known results within a common mathematical
framework. To the best of our knowledge, this is the ﬁrst time
that such a uniﬁcation work is presented. The beneﬁts are
multiple: several new formulas generalizing the classical results
are established, that jointly characterize the spatial, temporal
and spectral properties of late reverberation.
Index Terms—Reverberation, room impulse response, room
frequency response, stochastic models, Poisson processes, station-
ary processes, Wigner distribution.



hal_id    :    lirmm-01766795



. This paper introduces a new method for multichannel speech
enhancement based on a versatile modeling of the residual noise spec-
trogram. Such a model has already been presented before in the single
channel case where the noise component is assumed to follow an alpha-
stable distribution for each time-frequency bin, whereas the speech spec-
trogram, supposed to be more regular, is modeled as Gaussian. In this
paper, we describe a multichannel extension of this model, as well as
a Monte Carlo Expectation - Maximisation algorithm for parameter es-
timation. In particular, a multichannel extension of the Itakura-Saito
nonnegative matrix factorization is exploited to estimate the spectral
parameters for speech, and a Metropolis-Hastings algorithm is proposed
to estimate the noise contribution. We evaluate the proposed method in
a challenging multichannel denoising application and compare it to other
state-of-the-art algorithms.
1



hal_id    :    hal-01715431



—In the ﬁeld of room acoustics, it is well known that
reverberation can be characterized statistically in a particular
region of the time-frequency domain (after the transition time
and above Schroeder’s frequency). Since the 1950s, various
formulas have been established, focusing on particular aspects of
reverberation: exponential decay over time, correlations between
frequencies, correlations between sensors at each frequency,
and time-frequency distribution. In this report, we introduce a
new stochastic reverberation model, that permits us to retrieve
all these well-known results within a common mathematical
framework. To the best of our knowledge, this is the ﬁrst time
that such a uniﬁcation work is presented. The beneﬁts are
multiple: several new formulas generalizing the classical results
are established, that jointly characterize the spatial, temporal
and spectral properties of late reverberation.
Index Terms—Reverberation, room impulse response, room
frequency response, stochastic models, Poisson processes, station-
ary processes, Wigner distribution.
Résumé—Dans le domaine de l’acoustique des salles, il est
connu que la réverbération peut être caractérisée statistiquement
dans une région particulière du domaine temps-fréquence (après
le temps de mélange et au-dessus de la fréquence de Schroeder).
Depuis les années 50, diverses formules ont été établies, portant
sur des aspects particuliers de la réverbération : la décrois-
sance exponentielle au cours du temps, les corrélations entre
fréquences, les corrélations entre capteurs à chaque fréquence,
et la distribution temps-fréquence.
Dans ce rapport, nous



hal_id    :    hal-01548508



This paper introduces a new method for single-channel denoising
that sheds new light on classical early developments on this topic
that occurred in the 70’s and 80’s with Wiener ﬁltering and spectral
subtraction. Operating both in the short-time Fourier transform
domain, these methods consist in estimating the power spectral
density (PSD) of the noise without speech. Then, the clean speech
signal is obtained by manipulating the corrupted time-frequency
bins thanks to these noise PSD estimates. Theoretically grounded
when using power spectra, these methods were subsequently gener-
alized to magnitude spectra, or shown to yield better performance
by weighting the PSDs in the so-called parameterized Wiener ﬁlter.
Both these strategies were long considered ad-hoc. To the best
of our knowledge, while we recently proposed an interpretation
of magnitude processing, there is still no theoretical result that
would justify the better performance of parameterized Wiener
ﬁlters. Here, we show how the α-stable probabilistic model for
waveforms naturally leads to these weighted ﬁlters and we provide
a grounded and fast algorithm to enhance corrupted audio that
compares favorably with classical denoising methods.
Index Terms—denoising, Wiener ﬁltering, α-stable processes, prob-
ability theory



hal_id    :    hal-01540479



– La transformée de Mellin est probablement la transformation intégrale la plus méconnue mais aussi une des plus fondamentales dans
de nombreux domaines. Sa genèse a été fort longue, et il est difﬁcile de donner une référence précise de son



hal_id    :    hal-01531252



In this paper, we focus on the problem of sound source localization
and we propose a technique that exploits the known and arbitrary
geometry of the microphone array. While most probabilistic tech-
niques presented in the past rely on Gaussian models, we go further
in this direction and detail a method for source localization that is
based on the recently proposed α-stable harmonizable processes.
They include Cauchy and Gaussian as special cases and their
remarkable feature is to allow a simple modeling of impulsive
and real world sounds with few parameters. The approach we
present builds on the classical convolutive mixing model and has
the particularities of requiring going through the data only once,
to also work in the underdetermined case of more sources than
microphones and to allow massively parallelizable implementations
operating in the time-frequency domain. We show that the method
yields interesting performance for acoustic imaging in realistic
simulations.
Index Terms—source localization, acoustic modeling, α-
stable random variables, spectral measure, sketching



hal_id    :    hal-01401988



. We propose a probabilistic model for acoustic source local-
ization with known but arbitrary geometry of the microphone array. The
approach has several features. First, it relies on a simple nearﬁeld acous-
tic model for wave propagation. Second, it does not require the number
of active sources. On the contrary, it produces a heat map representing
the energy of a large set of candidate locations, thus imaging the acous-
tic ﬁeld. Second, it relies on a heavy-tail α-stable probabilistic model,
whose most important feature is to yield an estimation strategy where
the multichannel signals need to be processed only once in a simple on-
line procedure, called sketching. This sketching produces a ﬁxed-sized
representation of the data that is then analyzed for localization. The
resulting algorithm has a small computational complexity and in this
paper, we demonstrate that it compares favorably with state of the art
for localization in realistic simulations of reverberant environments.
1



hal_id    :    hal-01400965



. In this paper, we consider the underdetermined convolutive
audio source separation (UCASS) problem. In the STFT domain, we con-
sider both source signals and mixing ﬁlters as latent random variables,
and we propose to estimate each source image, i.e. each individual source-
ﬁlter product, by its posterior mean. Although, this is a quite straightfor-
ward application of the Bayesian estimation theory, to our knowledge,
there exist no similar study in the UCASS context. In this paper, we
discuss the interest of this estimator in this context and compare it with
the conventional Wiener ﬁlter in a semi-oracle conﬁguration.3
Keywords: Audio source separation, source image, latent mixing ﬁlters,
MMSE estimator, MCMC sampling.
1



hal_id    :    hal-01248014



We propose a projection-based method for the unmixing of multi-
channel audio signals into their different constituent spatial objects.
Here, spatial objects are modelled using a uniﬁed framework which
handles both point sources and diffuse sources. We then propose
a novel methodology to estimate and take advantage of the spatial
dependencies of an object. Where previous research has processed
the original multichannel mixtures directly and has been principally
focused on the use of inter-channel covariance structures, here we
instead process projections of the multichannel signal on many
different spatial directions. These linear combinations consist of
observations where some spatial objects are cancelled or enhanced.
We then propose an algorithm which takes these projections as
the observations, discarding dependencies between them. Since
each one contains global information regarding all channels of the
original multichannel mixture, this provides an effective means of
learning the parameters of the original audio, while avoiding the
need for joint-processing of all the channels. We further show how
to recover the separated spatial objects and demonstrate the use of
the technique on stereophonic music signals.
Index Terms—Sound Source Separation, α-stable, Spatial
Projection



hal_id    :    hal-01260588



—We propose a method to unmix multichannel audio
signals into their different constitutive spatial objects. To achieve
this, we characterize an audio object through both a spatial and
a spectro-temporal modelling. The particularity of the spatial
model we pick is that it neither assumes an object has only one
underlying source point, nor does it attempt to model the complex
room acoustics. Instead, it focuses on a listener perspective, and
takes each object as the superposition of many contributions
with different incoming directions and inter-channel delays. Our
spectro-temporal probabilistic model is based on the recently
proposed α-harmonisable processes, which are adequate for
signals with large dynamics, such as audio. Then, the main
originality of this work is to provide a new way to estimate and
exploit inter-channel dependences of an object for the purpose
of demixing. In the Gaussian α = 2 case, previous research
focused on covariance structures. This approach is no longer
valid for α < 2 where covariances are not deﬁned. Instead, we
show how simple linear combinations of the mixture channels
can be used to learn the model parameters, and the method
we propose consists in pooling the estimates based on many
projections to correctly account for the original multichannel
audio. Intuitively, each such downmix of the mixture provides a
new perspective where some objects are cancelled or



hal_id    :    hal-01252189



In many signal processing applications, recent techniques often rely on the estimation of a probabilistic model.
Many times, this model does not focus on the observed data itself, but rather on a spectral or time-frequency
transform of this data, such as the discrete Fourier transform (DFT) or the short-time Fourier transform (STFT). A
common statistical assumption regarding these transforms is that all spectral or time-frequency bins are uncorrelated.
However this assumption is generally inaccurate, either because of the intrinsic properties of the data, or because of
the transform itself. In this document, we aim to design transforms from the time domain to the spectral or time-
frequency domain, which best ﬁt this statistical assumption. To formulate this idea, we introduce the concept of
preservation of whiteness, and we characterise the transforms that satisfy this property. We show that several widely
used transforms such as the discrete cosine transform (DCT), DFT, modiﬁed discrete cosine transform (MDCT),
and STFT belong to this class under some conditions.
Index Terms
Second order processes, proper complex processes, spectral transforms, time-frequency transforms, paraunitary
ﬁlter banks.
Résumé
Dans diverses applications de traitement du signal, les techniques récentes s’appuient souvent sur l’estimation
d’un modèle probabiliste. Dans de nombreux cas, le modèle ne représente pas directement les données observées
elles-mêmes, mais plutôt une transformée spectrale



hal_id    :    hal-01170924



Nonnegative matrix factorization (NMF) is an effective and popular
low-rank model for nonnegative data. It enjoys a rich background,
both from an optimization and probabilistic signal processing view-
point. In this study, we propose a new cost-function for NMF ﬁtting,
which is introduced as arising naturally when adopting a Cauchy
process model for audio waveforms. As we recall, this Cauchy
process model is the only probabilistic framework known to date
that is compatible with having additive magnitude spectrograms
for additive independent audio sources. Similarly to the Gaussian
power-spectral density, this Cauchy model features time-frequency
nonnegative scale parameters, on which an NMF structure may be
imposed. The Cauchy cost function we propose is optimal under
that model in a maximum likelihood sense. It thus appears as
an interesting newcomer in the inventory of useful cost-functions
for NMF in audio. We provide multiplicative updates for Cauchy-
NMF and show that they give good performance in audio source
separation as well as in extracting nonnegative low-rank structures
from data buried in very adverse noise.
Index Terms—NMF, audio, Cauchy distribution, robust esti-
mation, probabilistic modeling



hal_id    :    hal-01110035



In this paper, we propose a new method for singing voice detec-
tion based on a Bidirectional Long Short-Term Memory (BLSTM)
Recurrent Neural Network (RNN). This classiﬁer is able to take a
past and future temporal context into account to decide on the pres-
ence/absence of singing voice, thus using the inherent sequential
aspect of a short-term feature extraction in a piece of music. The
BLSTM-RNN contains several hidden layers, so it is able to extract a
simple representation ﬁtted to our task from low-level features. The
results we obtain signiﬁcantly outperform state-of-the-art methods
on a common database.
Index Terms— Singing Voice Detection, Deep Learning, Re-
current Neural Networks, Long Short-Term Memory



hal_id    :    hal-01110028



In the recent years, many studies have focused on the single-
sensor separation of independent waveforms using so-called soft-
masking strategies, where the short term Fourier transform of
the mixture is multiplied element-wise by a ratio of spectrogram
models. When the signals are wide-sense stationary, this strategy
is theoretically justiﬁed as an optimal Wiener ﬁltering: the power
spectrograms of the sources are supposed to add up to yield the
power spectrogram of the mixture. However, experience shows that
using fractional spectrograms instead, such as the amplitude, yields
good performance in practice, because they experimentally better
ﬁt the additivity assumption. To the best of our knowledge, no
probabilistic interpretation of this ﬁltering procedure was available
to date. In this paper, we show that assuming the additivity of frac-
tional spectrograms for the purpose of building soft-masks can be
understood as separating locally stationary α-stable harmonizable
processes, α-harmonizable in short, thus justifying the procedure
theoretically.
Index Terms—audio source separation, probability theory,
harmonizable processes, α-stable random variables, soft-masks



hal_id    :    hal-04768296



In this paper, we propose a novel Self-Supervised-
Learning scheme to train rhythm analysis systems and
instantiate it for few-shot beat tracking.
Taking inspi-
ration from the Contrastive Predictive Coding paradigm,
we propose to train a Log-Mel-Spectrogram-Transformer-
encoder to contrast observations at times separated by hy-
pothesized beat intervals from those that are not. We do
this without the knowledge of ground-truth tempo or beat
positions, as we rely on the local maxima of a Predomi-
nant Local Pulse function, considered as a proxy for Tatum
positions, to define candidate anchors, candidate positives
(located at a distance of a power of two from the anchor)
and negatives (remaining time positions). We show that
a model pre-trained using this approach on the unlabeled
FMA, MTT and MTG-Jamendo datasets can successfully
be fine-tuned in the few-shot regime, i.e. with just a few
annotated examples to get a competitive beat-tracking per-
formance.
1



hal_id    :    hal-04665063



The task of music structure analysis has been mostly
addressed as a sequential problem, by relying on the inter-
nal homogeneity of musical sections or their repetitions.
In this work, we instead regard it as a pairwise link pre-
diction task. If for any pair of time instants in a track, one
can successfully predict whether they belong to the same
structural entity or not, then the underlying structure can
be easily recovered. Building upon this assumption, we
propose a method that first learns to classify pairwise links
between time frames as belonging to the same section (or
segment) or not. The resulting link features, along with
node-specific information, are combined through a graph
attention network. The latter is regularized with a graph
partitioning training objective and outputs boundary loca-
tions between musical segments and section labels. The
overall system is lightweight and performs competitively
with previous methods.
The evaluation is done on two
standard datasets for music structure analysis and an ab-
lation study is conducted in order to gain insight on the
role played by its different components.



hal_id    :    hal-04695595



Machine listening systems often rely on fixed taxonomies to or-
ganize and label audio data, key for training and evaluating deep
neural networks (DNNs) and other supervised algorithms. How-
ever, such taxonomies face significant constraints: they are com-
posed of application-dependent predefined categories, which hin-
ders the integration of new or varied sounds, and exhibits limited
cross-dataset compatibility due to inconsistent labeling standards.
To overcome these limitations, we introduce SALT: Standardized
Audio event Label Taxonomy. Building upon the hierarchical struc-
ture of AudioSet’s ontology, our taxonomy extends and standardizes
labels across 24 publicly available environmental sound datasets, al-
lowing the mapping of class labels from diverse datasets to a unified
system. Our proposal comes with a new Python package designed
for navigating and utilizing this taxonomy, easing cross-dataset la-
bel searching and hierarchical exploration. Notably, our package
allows effortless data aggregation from diverse sources, hence easy
experimentation with combined datasets.
Index Terms— Machine listening, DCASE, sound taxonomy,
sound categorization, data aggregation



hal_id    :    hal-04701759



Audio-text models trained via contrastive learning offer a practical
approach to perform audio classiﬁcation through natural language
prompts, such as “this is a sound of” followed by category names. In
this work, we explore alternative prompt templates for zero-shot au-
dio classiﬁcation, demonstrating the existence of higher-performing
options. First, we ﬁnd that the formatting of the prompts signif-
icantly affects performance so that simply prompting the models
with properly formatted class labels performs competitively with
optimized prompt templates and even prompt ensembling. More-
over, we look into complementing class labels by audio-centric de-
scriptions. By leveraging large language models, we generate tex-
tual descriptions that prioritize acoustic features of sound events
to disambiguate between classes, without extensive prompt engi-
neering. We show that prompting with class descriptions leads to
state-of-the-art results in zero-shot audio classiﬁcation across ma-
jor ambient sound datasets. Remarkably, this method requires no
additional training and remains fully zero-shot.
Index Terms— Zero-shot audio classiﬁcation, audio-text mod-
els, contrastive language-audio pretraining, in-context learning



hal_id    :    hal-04541350



Isolating the desired speaker’s voice amidst multiple
speakers in a noisy acoustic context is a challenging task. Per-
sonalized speech enhancement (PSE) endeavours to achieve
this by leveraging prior knowledge of the speaker’s voice.
Recent research efforts have yielded promising PSE mod-
els, albeit often accompanied by computationally intensive
architectures, unsuitable for resource-constrained embedded
devices. In this paper, we introduce a novel method to per-
sonalize a lightweight dual-stage Speech Enhancement (SE)
model and implement it within DeepFilterNet2, a SE model
renowned for its state-of-the-art performance. We seek an
optimal integration of speaker information within the model,
exploring different positions for the integration of the speaker
embeddings within the dual-stage enhancement architec-
ture. We also investigate a tailored training strategy when
adapting DeepFilterNet2 to a PSE task. We show that our
personalization method greatly improves the performances
of DeepFilterNet2 while preserving minimal computational
overhead.
Index Terms— Target speech extraction, speech en-
hancement, real-time.



hal_id    :    hal-04360221



Current state-of-the-art audio analysis systems rely on pre-
trained embedding models, often used off-the-shelf as (frozen)
feature extractors. Choosing the best one for a set of tasks is the
subject of many recent publications.
However, one aspect often
overlooked in these works is the influence of the duration of audio
input considered to extract an embedding, which we refer to as Tem-
poral Support (TS). In this work, we study the influence of the TS
for well-established or emerging pre-trained embeddings, chosen to
represent different types of architectures and learning paradigms.
We conduct this evaluation using both musical instrument and envi-
ronmental sound datasets, namely OpenMIC, TAU Urban Acoustic
Scenes 2020 Mobile, and ESC-50. We especially highlight that Au-
dio Spectrogram Transformer-based systems (PaSST and BEATs)
remain effective with smaller TS, which therefore allows for a dras-
tic reduction in memory and computational cost.
Moreover, we
show that by choosing the optimal TS we reach competitive results
across all tasks. In particular, we improve the state-of-the-art results
on OpenMIC, using BEATs and PaSST without any fine-tuning.
Index Terms— audio embeddings, acoustic scene classification,
instrument recognition, temporal support, transformers



hal_id    :    hal-04419041



Overlapped speech is notoriously problematic for speaker diarization
systems. Consequently, the use of speech separation has recently
been proposed to improve their performance. Although promising,
speech separation models struggle with realistic data because they
are trained on simulated mixtures with a fixed number of speakers. In
this work, we introduce a new speech separation-guided diarization
scheme suitable for the online speaker diarization of long meeting
recordings with a variable number of speakers, as present in the AMI
corpus. We envisage ConvTasNet and DPRNN as alternatives for the
separation networks, with two or three output sources. To obtain the
speaker diarization result, voice activity detection is applied on each
estimated source. The final model is fine-tuned end-to-end, after first
adapting the separation to real data using AMI. The system operates
on short segments, and inference is performed by stitching the local
predictions using speaker embeddings and incremental clustering.
The results show that our system improves the state-of-the-art on
the AMI headset mix, using no oracle information and under full
evaluation (no collar and including overlapped speech). Finally, we
show the strength of our system particularly on overlapped speech
sections.
Index Terms— online speaker diarization, source separation,
overlapped speech, AMI, speaker embedding



hal_id    :    hal-04729913



Multimodal large language models have fueled progress in image captioning.
These models, fine-tuned on vast image datasets, exhibit a deep understanding
of semantic concepts. In this work, we show that this ability can be re-purposed
for audio captioning, where the joint image-language decoder can be leveraged to
describe auditory content associated with image sequences within videos featuring
audiovisual content. This can be achieved via multimodal alignment. Yet, this
multimodal alignment task is non-trivial due to the inherent disparity between
audible and visible elements in real-world videos. Moreover, multimodal repre-
sentation learning often relies on contrastive learning, facing the challenge of the
so-called modality gap which hinders smooth integration between modalities. In
this work, we introduce a novel methodology for bridging the audiovisual modality
gap by matching the distributions of tokens produced by an audio backbone and
those of an image captioner. Our approach aligns the audio token distribution
with that of the image tokens, enabling the model to perform zero-shot audio
captioning in an unsupervised fashion while keeping the initial image captioning
component unaltered. This alignment allows for the use of either audio or audiovi-
sual input by combining or substituting the image encoder with the aligned audio
encoder. Our method achieves significantly improved performances in zero-shot
audio captioning, compared to existing approaches.1
1



hal_id    :    hal-04216177



Self-Supervised Learning (SSL) has allowed leveraging large
amounts of unlabeled speech data to improve the perfor-
mance of speech recognition models even with small annotated
datasets.
Despite this, speech SSL representations may fail
while facing an acoustic mismatch between the pretraining and
target datasets. To address this issue, we propose a novel super-
vised domain adaptation method, designed for cases exhibiting
such a mismatch in acoustic domains. It consists in applying
properly calibrated data augmentations on a large clean dataset,
bringing it closer to the target domain, and using it as part of
an initial fine-tuning stage. Augmentations are automatically
selected through the minimization of a conditional-dependence
estimator, based on the target dataset. The approach is vali-
dated during an oracle experiment with controlled distortions
and on two amateur-collected low-resource domains, reaching
better performances compared to the baselines in both cases.
Index Terms: self-supervised learning, domain adaptation.



hal_id    :    hal-03817736



Contrastive learning enables learning useful audio and speech
representations without ground-truth labels by maximizing the
similarity between latent representations of similar signal seg-
ments. In this framework various data augmentation techniques
are usually exploited to help enforce desired invariances within
the learned representations, improving performance on various
audio tasks thanks to more robust embeddings. Now, selecting
the most relevant augmentations has proven crucial for better
downstream performances. Thus, this work introduces a condi-
tional independance-based method which allows for automati-
cally selecting a suitable distribution on the choice of augmenta-
tions and their parametrization from a set of predefined ones, for
contrastive self-supervised pre-training. This is performed with
respect to a downstream task of interest, hence saving a costly
hyper-parameter search. Experiments performed on two differ-
ent downstream tasks validate the proposed approach showing
better results than experimenting without augmentation or with
baseline augmentations. We furthermore conduct a qualitative
analysis of the automatically selected augmentations and their
variation according to the considered final downstream dataset.
Index Terms: self-supervised learning, data augmentation.



hal_id    :    hal-04276012



In this paper, we present the process we used in order to collect new annotations of opinions over the multimodal corpus
SEMAINE composed of dyadic interactions. The dataset had already been annotated continuously in two affective dimensions
related to the emotions: Valence and Arousal.
We annotated the part of SEMAINE called Solid SAL composed of 79
interactions between a user and an operator playing the role of a virtual agent designed to engage a person in a sustained,
emotionally colored conversation. We aligned the audio at the word level using the available high-quality manual transcriptions.
The annotated dataset contains 5627 speech turns for a total of 73,944 words, corresponding to 6 hours 20 minutes of dyadic
interactions. Each interaction has been labeled by three annotators at the speech turn level following a three-step process. This
method allows us to obtain a precise annotation regarding the opinion of a speaker. We obtain thus a dataset dense in opinions,
with more than 48% of the annotated speech turns containing at least one opinion. We then propose a new baseline for the
detection of opinions in interactions improving slightly a state of the art model with RoBERTa embeddings. The obtained
results on the database are promising with a F1-score at 0.72.
Keywords: Opinion, Multimodal Machine



hal_id    :    hal-02985794



Speech separation with several speakers is a challenging task be-
cause of the non-stationarity of the speech and the strong signal
similarity between interferent sources. Current state-of-the-art so-
lutions can separate well the different sources using sophisticated
deep neural networks which are very tedious to train. When several
microphones are available, spatial information can be exploited to
design much simpler algorithms to discriminate speakers. We pro-
pose a distributed algorithm that can process spatial information in
a spatially unconstrained microphone array. The algorithm relies on
a convolutional recurrent neural network that can exploit the signal
diversity from the distributed nodes. In a typical case of a meeting
room, this algorithm can capture an estimate of each source in a ﬁrst
step and propagate it over the microphone array in order to increase
the separation performance in a second step. We show that this ap-
proach performs even better when the number of sources and nodes
increases. We also study the inﬂuence of a mismatch in the number
of sources between the training and testing conditions.
Index Terms— Speech separation, microphone arrays, dis-
tributed processing.



hal_id    :    hal-02389159



Multichannel processing is widely used for speech enhancement but
several limitations appear when trying to deploy these solutions in
the real world. Distributed sensor arrays that consider several de-
vices with a few microphones is a viable solution which allows for
exploiting the multiple devices equipped with microphones that we
are using in our everyday life. In this context, we propose to extend
the distributed adaptive node-speciﬁc signal estimation approach to
a neural network framework. At each node, a local ﬁltering is per-
formed to send one signal to the other nodes where a mask is esti-
mated by a neural network in order to compute a global multichan-
nel Wiener ﬁlter. In an array of two nodes, we show that this addi-
tional signal can be leveraged to predict the masks and leads to better
speech enhancement performance than when the mask estimation re-
lies only on the local signals.
Index Terms— Speech enhancement, microphone arrays, dis-
tributed processing.



hal_id    :    hal-02943462



In the last few years, several datasets have been released
to meet the requirements of “hungry” yet promising data-
driven approaches in music technology research. Since,
for historical reasons, most investigations conducted in the
ﬁeld still revolve around music of the so-called “West-
ern” tradition, the corresponding data, methodology and
conclusions carry a strong cultural bias. Music of non-
“Western” background, whenever present, is usually un-
derrepresented, poorly labeled, or even mislabeled, the
exception being projects that aim at speciﬁcally describ-
ing such music. In this paper we present SAMBASET,
a dataset of Brazilian samba music that contains over
40 hours of historical and modern samba de enredo com-
mercial recordings. To the best of our knowledge, this is
the ﬁrst dataset of this genre. We describe the collection of
metadata (e.g. artist, composer, release date) and outline
our semiautomatic approach to the challenging task of an-
notating beats in this large dataset, which includes the as-
sessment of the performance of state-of-the-art beat track-
ing algorithms for this speciﬁc case. Finally, we present
a study on tempo and beat tracking that illustrates SAM-
BASET’s value, and we comment on other tasks for which
it could be used.



hal_id    :    hal-04593480



When deriving contextualized word repre-
sentations from language models, a decision
needs to be made on how to obtain one for
out-of-vocabulary (OOV) words that are seg-
mented into subwords. What is the best way
to represent these words with a single vector,
and are these representations of worse quality
than those of in-vocabulary words? We carry
out an intrinsic evaluation of embeddings from
different models on semantic similarity tasks
involving OOV words. Our analysis reveals,
among other interesting findings, that the qual-
ity of representations of words that are split is
often, but not always, worse than that of the
embeddings of known words. Their similar-
ity values, however, must be interpreted with
caution.
1



hal_id    :    hal-04593478



Dialog participants sometimes align their lin-
guistic styles, e.g., they use the same words
and syntactic constructions as their interlocu-
tors. We propose to investigate the notion of
lexico-semantic alignment: to what extent do
speakers convey the same meaning when they
use the same words? We design measures of
lexico-semantic alignment relying on contextu-
alized word representations. We show that they
reflect interesting semantic differences between
the two sides of a debate and that they can assist
in the task of debate’s winner prediction.
1



hal_id    :    hal-04131585



No abstract found in the PDF.



hal_id    :    hal-04130213



La façon dont nous utilisons les mots est influencée par notre opinion. Nous cherchons à savoir si cela
se reflète dans les plongements de mots contextualisés. Par exemple, la représentation d’ « animal »
est-elle différente pour les gens qui voudraient abolir les zoos et ceux qui ne le voudraient pas? Nous
explorons cette question du point de vue du changement sémantique des mots. Nos expériences avec
des représentations dérivées d’ensembles de données annotés avec les points de vue révèlent des
différences minimes, mais significatives, entre postures opposées 1.
ABSTRACT
One Word, Two Sides : Traces of Stance in Contextualized Word Representations
The way we use words is influenced by our opinion. We investigate whether this is reflected in
contextualized word embeddings. For example, is the representation of “animal” different between
people who would abolish zoos and those who would not? We explore this question from a Lexical
Semantic Change standpoint. Our experiments with BERT embeddings derived from datasets with
stance annotations reveal small but significant differences in word representations between opposing
stances.
MOTS-CLÉS : Représentations contextualisées, changement sémantique, détection de point de vue.
KEYWORDS: Contextualized representations, semantic change, stance detection.
1



hal_id    :    hal-04258177



No abstract found in the PDF.



hal_id    :    hal-03990543



No abstract found in the PDF.



hal_id    :    hal-03860830



The way we use words is influenced by our
opinion.
We investigate whether this is re-
flected in contextualized word embeddings.
For example, is the representation of “animal”
different between people who would abolish
zoos and those who would not? We explore
this question from a Lexical Semantic Change
standpoint. Our experiments with BERT em-
beddings derived from datasets with stance
annotations reveal small but significant differ-
ences in word representations between oppos-
ing stances.
1



hal_id    :    hal-03860827



Our discourses are full of potential lexical ambiguities, due in part to the pervasive use of words having multiple senses.
Sometimes, one word may even be used in more than one sense throughout a text. But, to what extent is this true for different
kinds of texts? Does the use of polysemous words change when a discourse involves two people, or when speakers have time
to plan what to say? We investigate these questions by comparing the polysemy level of texts of different nature, with a focus
on spontaneous spoken dialogs; unlike previous work which examines solely scripted, written, monolog-like data. We compare
multiple metrics that presuppose different conceptualizations of text polysemy, i.e., they consider the observed or the potential
number of senses of words, or their sense distribution in a discourse. We show that the polysemy level of texts varies greatly
depending on the kind of text considered, with dialog and spoken discourses having generally a higher polysemy level than
written monologs. Additionally, our results emphasize the need for relaxing the popular “one sense per discourse” hypothesis.
Keywords: Semantics, Word Sense Disambiguation, Document classification / Text categorisation
1.



hal_id    :    hal-04273536



Users generate content constantly, leading to new data requiring annotation.
Among this data, textual conversations are
created every day and come with some specificities: they are mostly private through instant messaging applications, requiring
the conversational context to be labeled. These specificities led to several annotation tools dedicated to conversation, and
mostly dedicated to dialogue tasks, requiring complex annotation schemata, not always customizable and not taking into
account conversation-level labels.
In this paper, we present EZCAT, an easy-to-use interface to annotate conversations
in a two-level configurable schema, leveraging message-level labels and conversation-level labels at once.
Our interface
is characterized by the voluntary absence of a server and accounts management, enhancing its availability to anyone, and
the control over data, which is crucial to confidential conversations. We also present our first usage of EZCAT along with
our annotation schema we used to annotate confidential customer service conversations.
EZCAT is freely available at
https://gguibon.github.io/ezcat.
Keywords: conversations, annotation tool, text messages
1.



hal_id    :    hal-03701451



Cet article présente l’approche de l’équipe TGV lors de sa participation à la tâche de base de DEFT
2022, dont l’objectif était de prédire automatiquement les notes obtenues par des étudiants sur la
base de leurs réponses à des questionnaires. Notre stratégie s’est focalisée sur la mise au point d’une
méthode de classification des questions en fonction du type de réponse qu’elles attendent, de manière
à pouvoir mener une approche différenciée pour chaque type. Nos trois runs ont consisté en une
approche non différenciée, servant de référence, et deux approches différenciées, la première se basant
sur la constitution d’un jeu de caractéristiques et la seconde sur le calcul de TF-IDF et de la fonction
de hashage. Notre objectif premier était ainsi de vérifier si des approches dédiées à chaque type de
questions sont préférables à une approche globale.
ABSTRACT
Team TGV at DEFT 2022 : automatic prediction of students’ grades according to the different
question types.
In this paper we present the work of the TGV team for the DEFT 2022 challenge. We tackled the
base task only, which consists of automatically grading students based on their answers to several
questions. Our strategy consider this task as a classification task with multiple approaches, each being
specific to a question type leading to different types of



hal_id    :    hal-03574595



Spoken dialog systems need to be able to han-
dle both multiple languages and multilingual-
ity inside a conversation (e.g in case of code-
switching). In this work, we introduce new
pretraining losses tailored to learn multilingual
spoken dialog representations.
The goal of
these losses is to expose the model to code-
switched language. To scale up training, we
automatically build a pretraining corpus com-
posed of multilingual conversations in ﬁve dif-
ferent languages (French, Italian, English, Ger-
man and Spanish) from OpenSubtitles, a
huge multilingual corpus composed of 24.3G
tokens. We test the generic representations on
MIAM, a new benchmark composed of ﬁve di-
alog act corpora on the same aforementioned
languages as well as on two novel multilingual
downstream tasks (i.e multilingual mask utter-
ance retrieval and multilingual inconsistency
identiﬁcation). Our experiments show that our
new code switched-inspired losses achieve a
better performance in both monolingual and
multilingual settings.
1



hal_id    :    hal-03344680



Several recent studies on dyadic human-
human interactions have been done on con-
versations without speciﬁc business objectives.
However, many companies might beneﬁt from
studies dedicated to more precise environ-
ments such as after sales services or customer
satisfaction surveys. In this work, we place
ourselves in the scope of a live chat customer
service in which we want to detect emotions
and their evolution in the conversation ﬂow.
This context leads to multiple challenges that
range from exploiting restricted, small and
mostly unlabeled datasets to ﬁnding and adapt-
ing methods for such context.
We tackle
these challenges by using Few-Shot Learning
while making the hypothesis it can serve con-
versational emotion classiﬁcation for different
languages and sparse labels.
We contribute
by proposing a variation of Prototypical Net-
works for sequence labeling in conversation
that we name ProtoSeq. We test this method
on two datasets with different languages: daily
conversations in English and customer service
chat conversations in French. When applied
to emotion classiﬁcation in conversations, our
method proved to be competitive even when
compared to other ones. The code for Proto-
Seq is available at https://github.com/
gguibon/ProtoSeq.
1



hal_id    :    hal-03574609



Multimodal sentiment analysis is a trending
area of research, and the multimodal fusion
is one of its most active topic. Acknowledg-
ing humans communicate through a variety of
channels (i.e visual, acoustic, linguistic), mul-
timodal systems aim at integrating different
unimodal representations into a synthetic one.
So far, a consequent effort has been made on
developing complex architectures allowing the
fusion of these modalities. However, such sys-
tems are mainly trained by minimising sim-
ple losses such as L1 or cross-entropy.
In
this work, we investigate unexplored penalties
and propose a set of new objectives that mea-
sure the dependency between modalities. We
demonstrate that our new penalties lead to a
consistent improvement (up to 4.3 on accu-
racy) across a large variety of state-of-the-art
models on two well-known sentiment analysis
datasets: CMU-MOSI and CMU-MOSEI. Our
method not only achieves a new SOTA on both
datasets but also produces representations that
are more robust to modality drops. Finally, a
by-product of our methods includes a statisti-
cal network which can be used to interpret the
high dimensional representations learnt by the
model.
1



hal_id    :    hal-03563675



In this paper, we place ourselves in a classi-
ﬁcation scenario in which the target classes
and data type are not accessible during train-
ing. We use a meta-learning approach to de-
termine whether or not meta-trained informa-
tion from common social network data with
ﬁne-grained emotion labels can achieve com-
petitive performance on messages labeled with
different emotion categories. We leverage few-
shot learning to match with the classiﬁcation
scenario and consider metric learning based
meta-learning by setting up Prototypical Net-
works with a Transformer encoder, trained in
an episodic fashion.
This approach proves
to be effective for capturing meta-information
from a source emotional tag set to predict pre-
viously unseen emotional tags. Even though
shifting the data type triggers an expected per-
formance drop, our meta-learning approach
achieves decent results when compared to the
fully supervised one.
1



hal_id    :    hal-03265871



Dans cet article nous reproduisons un scénario d’apprentissage selon lequel les données cibles
ne sont pas accessibles et seules des données connexes le sont. Nous utilisons une approche par
méta-apprentissage aﬁn de déterminer si les méta-informations apprises à partir de messages issus
de médias sociaux, ﬁnement annotés en émotions, peuvent produire de bonnes performances une
fois utilisées sur des messages issus de conversations, étiquetés en émotions avec une granularité
différente. Nous mettons à proﬁt l’apprentissage sur quelques exemples (few-shot learning) pour la
mise en place de ce scénario. Cette approche se montre efﬁcace pour capturer les méta-informations
d’un jeu d’étiquettes émotionnelles pour prédire des étiquettes jusqu’alors inconnues au modèle. Bien
que le fait de varier le type de données engendre une baisse de performance, notre approche par
méta-apprentissage atteint des résultats décents comparés au référentiel d’apprentissage supervisé.
ABSTRACT
Meta-learning : Classifying Messages into Unseen Emotional Categories
In this paper, we place ourselves in a classiﬁcation scenario in which the target data set classes and
data type are not accessible during training. We use a meta-learning approach to determine whether
or not meta-trained information from common social network data with ﬁne-grained emotion labels
can achieve competitive performance on conversation utterances labeled with different, higher level,
emotions. We leverage few-shot learning to concur with the classiﬁcation scenario. This



hal_id    :    hal-03134854



While being an essential component
of spoken language, ﬁllers (e.g. “um”
or “uh”) often remain overlooked in
Spoken Language Understanding (SLU)
tasks.
We explore the possibility of
representing them with deep contex-
tualised embeddings, showing improve-
ments on modelling spoken language
and two downstream tasks — predict-
ing a speaker’s stance and expressed
conﬁdence.
1



hal_id    :    hal-02914840



The principle of compositionality, which enables natural language to represent
complex concepts via a structured combination of simpler ones, allows us to con-
vey an open-ended set of messages using a limited vocabulary. If compositionality
is indeed a natural property of language, we may expect it to appear in commu-
nication protocols that are created by neural agents in language games. In this
paper, we propose an effective neural iterated learning (NIL) algorithm that, when
applied to interacting neural agents, facilitates the emergence of a more structured
type of language. Indeed, these languages provide learning speed advantages to
neural agents during training, which can be incrementally ampliﬁed via NIL. We
provide a probabilistic model of NIL and an explanation of why the advantage
of compositional language exist. Our experiments conﬁrm our analysis, and also
demonstrate that the emerged languages largely improve the generalizing power
of the neural agent communication.
1



hal_id    :    hal-02912385



Noise-Contrastive Estimation (NCE) is a learning criterion that is regularly used to train neural
language models in place of Maximum Likelihood Estimation, since it avoids the computational
bottleneck caused by the output softmax. In this paper, we analyse and explain some of the
weaknesses of this objective function, linked to the mechanism of self-normalization, by closely
monitoring comparative experiments. We then explore several remedies and modiﬁcations to
propose tractable and efﬁcient NCE training strategies. In particular, we propose to make the
scaling factor a trainable parameter of the model, and to use the noise distribution to initialize the
output bias. These solutions, yet simple, yield stable and competitive performances in either small
and large scale language modelling tasks.
1



hal_id    :    hal-02912471



L’estimation contrastive bruitée (NCE) et l’échantillonage par importance (IS) sont des procédures
d’entraînement basées sur l’échantillonage, que l’on utilise habituellement à la place de l’estimation
du maximum de vraisemblance (MLE) pour éviter le calcul du softmax lorsque l’on entraîne des
modèles de langue neuronaux. Dans cet article, nous cherchons à résumer le fonctionnement de ces
algorithmes, et leur utilisation dans la littérature du TAL. Nous les comparons expérimentalement, et
présentons des manières de faciliter l’entraînement du NCE.
ABSTRACT
Here the title in English.
Noise Contrastive Estimation (NCE) and Importance Sampling (IS) are sampling based algorithms
traditionally used to avoid computing the costly output softmax when training neural language models
with Maximum Likelihood Estimation (MLE). In this work, we attempt to summarize how these
procedures work, and how they have been used in the computational linguistics literature. We then
compare them, and experiment with tricks that ease NCE training.
MOTS-CLÉS : Modèle de langue, Estimation contrastive bruitée, Negative Sampling.
KEYWORDS: Neural Language Model, Noise Contrastive Estimation, Negative Sampling.



hal_id    :    hal-02912472



Cet article propose une architecture neuronale pour un modèle de langue à vocabulaire ouvert. Les
représentations continues des mots sont calculées à la volée à partir des caractères les composant,
gràce à une couche convolutionnelle suivie d’une couche de regroupement (pooling). Cela permet
au modèle de représenter n’importe quel mot, qu’il fasse partie du contexte ou soit évalué pour la
prédiction. La fonction objectif est dérivée de l’estimation contrastive bruitée (Noise Contrastive
Estimation, ou NCE), calculable dans notre cas sans vocabulaire. Nous évaluons la capacité de
notre modèle à construire des représentations continues de mots inconnus sur la tâche de traduction
automatique IWSLT-2016, de l’Anglais vers le Tchèque, en ré-évaluant les N meilleures hypothèses
(N-best reranking). Les résultats expérimentaux permettent des gains jusqu’à 0,7 point BLEU. Ils
montrent aussi la difﬁculté d’utiliser des représentations dérivées des caractères pour la prédiction.
ABSTRACT
Opening the vocabulary of neural language models with character-level word representations
This paper introduces an architecture for an open-vocabulary neural language model. Word represen-
tations are computed on-the-ﬂy by a convolution network followed by pooling layer. This allows the
model to consider any word, in the context or for the prediction. The training objective is derived from
the Noise-Contrastive Estimation to adapt it the open vocabulary case. We test the ability of our model
to



hal_id    :    hal-02912384



Noise Contrastive Estimation (NCE) is a
learning procedure that is regularly used
to train neural language models, since
it avoids the computational bottleneck
caused by the output softmax. In this pa-
per, we attempt to explain some of the
weaknesses of this objective function, and
to draw directions for further develop-
ments. Experiments on a small task show
the issues raised by the unigram noise
distribution, and that a context dependent
noise distribution, such as the bigram dis-
tribution, can solve these issues and pro-
vide stable and data-efﬁcient learning.
1



hal_id    :    hal-04702293



This paper addresses the problem of approximating an unknown probability distribution
with density f - which can only be evaluated up to an unknown scaling factor - with the
help of a sequential algorithm that produces at each iteration n ≥1 an estimated density
qn. The proposed method optimizes the Kullback-Leibler divergence using a mirror descent
(MD) algorithm directly on the space of density functions, while a stochastic approximation
technique helps to manage between algorithm complexity and variability.
One of the key
innovations of this work is the theoretical guarantee that is provided for an algorithm with a
fixed MD learning rate η ∈(0, 1). The main result is that the sequence qn converges almost
surely to the target density f uniformly on compact sets. Through numerical experiments, we
show that fixing the learning rate η ∈(0, 1) significantly improves the algorithm’s performance,
particularly in the context of multi-modal target distributions where a small value of η allows
to increase the chance of finding all modes. Additionally, we propose a particle subsampling
method to enhance computational efficiency and compare our method against other approaches
through numerical experiments.
1



hal_id    :    hal-04512759



We consider a discrete-time system of n coupled random vectors, a.k.a. interacting particles.
The dynamics involve a vanishing step size, some random centered perturbations, and a mean
vector ﬁeld which induces the coupling between the particles. We study the doubly asymptotic
regime where both the number of iterations and the number n of particles tend to inﬁnity,
without any constraint on the relative rates of convergence of these two parameters.
We
establish that the empirical measure of the interpolated trajectories of the particles converges
in probability, in an ergodic sense, to the set of recurrent Mc-Kean-Vlasov distributions. We
also consider the pointwise convergence of the empirical measures of the particles. A ﬁrst
application example is the granular media equation, where the particles are shown to converge
to a critical point of the Helmholtz energy. A second example is the convergence of stochastic
gradient descent to the global minimizer of the risk, in a wide two-layer neural networks using
random features.
Contents
1



hal_id    :    hal-03442137



In non-smooth stochastic optimization, we establish the non-convergence of the stochas-
tic subgradient descent (SGD) to the critical points recently called active strict saddles
by Davis and Drusvyatskiy. Such points lie on a manifold M where the function f has a
direction of second-order negative curvature. Off this manifold, the norm of the Clarke
subdifferential of f is lower-bounded. We require two conditions on f. The first assump-
tion is a Verdier stratification condition, which is a refinement of the popular Whitney
stratification. It allows us to establish a strengthened version of the projection formula
of Bolte et al. for Whitney stratifiable functions, and which is of independent interest.
The second assumption, termed the angle condition, allows to control the distance of the
iterates to M. When f is weakly convex, our assumptions are generic. Consequently,
generically in the class of definable weakly convex functions, SGD converges to a local
minimizer.
Keywords.
Non-smooth optimization, stochastic gradient descent, avoidance of traps,
Clarke subdifferential, stratification, weak convexity
1



hal_id    :    hal-04319492



This paper introduces a new method to tackle the issue of the almost sure conver-
gence of stochastic approximation algorithms deﬁned from a diﬀerential inclusion.
Under the assumption of slowly decaying step-sizes, we establish that the set of es-
sential accumulation points of the iterates belongs to the Birkhoﬀcenter associated
with the diﬀerential inclusion. Unlike previous works, our results do not rely on
the notion of asymptotic pseudotrajectories introduced by Bena¨ım–Hofbauer–Sorin,
which is the predominant technique to address the convergence problem. They fol-
low as a consequence of Young’s superposition principle for closed measures. This
perspective bridges the gap between Young’s principle and the notion of invariant
measure of set-valued dynamical systems introduced by Faure and Roth. Also, the
proposed method allows to obtain suﬃcient conditions under which the velocities
locally compensate around any essential accumulation point.
KEYWORDS
Stochastic approximation: Closed measures; Weak convergence; Diﬀerential
inclusions



hal_id    :    hal-02564349



This paper studies the asymptotic behavior of the constant step Stochastic Gradient
Descent for the minimization of an unknown function, deﬁned as the expectation of a
non convex, non smooth, locally Lipschitz random function. As the gradient may not
exist, it is replaced by a certain operator: a reasonable choice is to use an element of
the Clarke subdiﬀerential of the random function; another choice is the output of the
celebrated backpropagation algorithm, which is popular amongst practioners, and whose
properties have recently been studied by Bolte and Pauwels. Since the expectation of the
chosen operator is not in general an element of the Clarke subdiﬀerential of the mean
function, it has been assumed in the literature that an oracle of the Clarke subdiﬀerential
of the mean function is available. As a ﬁrst result, it is shown in this paper that such
an oracle is not needed for almost all initialization points of the algorithm.
Next, in
the small step size regime, it is shown that the interpolated trajectory of the algorithm
converges in probability (in the compact convergence sense) towards the set of solutions
of a particular diﬀerential inclusion: the subgradient ﬂow. Finally, viewing the iterates as
a Markov chain whose transition kernel is indexed by the step size, it is shown that the
invariant



hal_id    :    hal-03860881



Actor-critic methods integrating target net-
works have exhibited a stupendous empirical
success in deep reinforcement learning. How-
ever, a theoretical understanding of the use
of target networks in actor-critic methods is
largely missing in the literature. In this pa-
per, we reduce this gap between theory and
practice by proposing the ﬁrst theoretical anal-
ysis of an online target-based actor-critic al-
gorithm with linear function approximation
in the discounted reward setting. Our algo-
rithm uses three diﬀerent timescales: one for
the actor and two for the critic. Instead of
using the standard single timescale temporal
diﬀerence (TD) learning algorithm as a critic,
we use a two timescales target-based version
of TD learning closely inspired from practical
actor-critic algorithms implementing target
networks. First, we establish asymptotic con-
vergence results for both the critic and the
actor under Markovian sampling. Then, we
provide a ﬁnite-time analysis showing the im-
pact of incorporating a target network into
actor-critic methods.
1



hal_id    :    hal-03310455



: In this paper, a general stochastic optimization procedure is
studied, unifying several variants of the stochastic gradient descent such
as, among others, the stochastic heavy ball method, the Stochastic Nes-
terov Accelerated Gradient algorithm (S-NAG), and the widely used Adam
algorithm. The algorithm is seen as a noisy Euler discretization of a non-
autonomous ordinary diﬀerential equation, recently introduced by Belotto
da Silva and Gazeau, which is analyzed in depth. Assuming that the objec-
tive function is non-convex and diﬀerentiable, the stability and the almost
sure convergence of the iterates to the set of critical points are established.
A noteworthy special case is the convergence proof of S-NAG in a non-
convex setting. Under some assumptions, the convergence rate is provided
under the form of a Central Limit Theorem. Finally, the non-convergence
of the algorithm to undesired critical points, such as local maxima or saddle
points, is established. Here, the main ingredient is a new avoidance of traps
result for non-autonomous settings, which is of independent interest.
MSC2020 subject classiﬁcations: Primary 62L20; secondary 34A12,
68T99, 60F99.
Keywords and phrases: stochastic approximation, dynamical systems,
adaptive gradient methods with momentum, Nesterov accelerated gradient,
ADAM, avoidance of traps.
Contents
1



hal_id    :    hal-02369882



A new stochastic primal-dual algorithm for solving a composite
optimization problem is proposed. It is assumed that all the functions
/ operators that enter the optimization problem are given as statistical
expectations. These expectations are unknown but revealed across
time through i.i.d realizations. The proposed algorithm is proven to
converge to a saddle point of the Lagrangian function. In the frame-
work of the monotone operator theory, the convergence proof relies on
recent results on the stochastic Forward Backward algorithm involving
random monotone operators. An example of convex optimization under
stochastic linear constraints is considered.
1



hal_id    :    hal-02369439



No abstract found in the PDF.



hal_id    :    hal-01725134



A stochastic Forward-Backward algorithm with a constant step is studied. At each time
step, this algorithm involves an independent copy of a couple of random maximal monotone
operators. Deﬁning a mean operator as a selection integral, the diﬀerential inclusion built
from the sum of the two mean operators is considered. As a ﬁrst result, it is shown that the
interpolated process obtained from the iterates converges narrowly in the small step regime
to the solution of this diﬀerential inclusion. In order to control the long term behavior of the
iterates, a stability result is needed in addition. To this end, the sequence of the iterates is
seen as a homogeneous Feller Markov chain whose transition kernel is parameterized by the
algorithm step size. The cluster points of the Markov chains invariant measures in the small
step regime are invariant for the semiﬂow induced by the diﬀerential inclusion. Conclusions
regarding the long run behavior of the iterates for small steps are drawn. It is shown that
when the sum of the mean operators is demipositive, the probabilities that the iterates are
away from the set of zeros of this sum are small in Ces`aro mean. The ergodic behavior of
these iterates is studied as well. Applications of the proposed algorithm are considered. In
particular, a



hal_id    :    hal-02367908



—In this paper, we investigate machine learning
approaches addressing the problem of geolocation. First, we
review some classical learning methods to build a radio map. In
particular, these methods are splitted in two categories, which we
refer to as likelihood-based methods and ﬁngerprinting methods.
Then, we provide a novel geolocation approach in each of
these two categories. The ﬁrst proposed technique relies on a
semi-parametric Nadaraya-Watson estimator of the likelihood,
followed by a maximum a posteriori (MAP) estimator of the
object’s position. The second technique consists in learning a
proper metric on the dataset, constructed by means of a Gradient
boosting regressor: a k-nearest neighbor algorithm is then used
to estimate the position. Finally, all the proposed methods are
compared on a data set originated from Sigfox network. The
experiments show the interest of the proposed methods, both in
terms of location estimation performance, and of ability to build
radio maps.
Keywords: LPWA Network, localization, maximum
likelihood, metric learning



hal_id    :    hal-02369904



The Douglas Rachford algorithm is an algorithm that converges
to a minimizer of a sum of two convex functions. The algo-
rithm consists in ﬁxed point iterations involving computations
of the proximity operators of the two functions separately.
The paper investigates a stochastic version of the algorithm
where both functions are random and the step size is constant.
We establish that the iterates of the algorithm stay close to
the set of solution with high probability when the step size
is small enough. Application to structured regularization is
considered.
Index Terms— Stochastic optimization, proximal me-
thods, Douglas Rachford algorithm, structured regulariza-
tions



hal_id    :    hal-02365695



—This paper introduces a constant step size adaptive
algorithm for distributed optimization on a graph. The algorithm
is of diffusion-adaptation type and is asynchronous: at every iter-
ation, some randomly selected nodes compute some local variable
by means of a proximity operator involving a locally observed
random variable, and share these variable with neighbors. The
algorithm is built upon a stochastic version of the Douglas-
Rachford algorithm. A practical application to target localization
using measurements from multistatic continuous active sonar
systems is investigated at length.
Index Terms—Adaptive algorithms, stochastic approximation,
distributed optimization, proximal operator, target localization.



hal_id    :    hal-01725141



– L’algorithme du gradient proximal permet de trouver les minimiseurs d’une somme F + G de deux fonctions convexes propres et
fermées, l’une étant supposée dérivable. Cet article introduit une version stochastique de cet algorithme. Les itérations font intervenir une suite iid
de deux fonctions aléatoires, dont les espérances coïncident respectivement avec F et G, ainsi que des projections aléatoires sur des ensembles
convexes fermés. L’objectif est de fournir une analyse de convergence, dans un contexte adaptatif où le pas de l’algorithme est supposé constant.
On montre que, en moyenne de Césaro, la probabilité pour que les itérées soient hors d’un voisinage des minimiseurs souhaités est arbitrairement
faible lorsque le nombre d’itérations tend vers l’inﬁni, et dans la limite de pas faibles. Le comportement ergodique des itérées est également
étudié. Enﬁn, l’algorithme est étendu au contexte plus général des opérateurs maximaux monotones aléatoires.
Abstract – The proximal gradient algorithm allows to ﬁnd the minimizers of a sum F + G of two proper closed convex functions, one of them
being differentiable. This paper introduces a stochastic version of the proximal gradient algorithm. The iterations involve an iid sequence of two
random functions, whose expectations coincide with F and G respectively, as well as random projections onto closed convex sets.



hal_id    :    hal-02365713



—Image deblurring techniques are effective tools to
obtain high quality image from acquired image degraded by
blur and noise. In applications such as astronomy and satellite
imaging, size of acquired images can be extremely large (up
to gigapixels) covering a wide ﬁeld-of-view suffering from shift-
variant blur. Most of the existing deblurring techniques are
designed to be cost effective on a centralized computing system
having a shared memory and possibly multicore processor. The
largest image they can handle is then conditioned by the memory
capacity of the system. In this paper, we propose a distributed
shift-variant image deblurring algorithm in which several con-
nected processing units (each with reasonable computational
resources) can deblur simultaneously different portions of a
large image while maintaining a certain coherency among them
to ﬁnally obtain a single crisp image. The proposed algorithm
is based on a distributed Douglas-Rachford splitting algorithm
with a speciﬁc structure of the penalty parameters used in
the proximity operator. Numerical experiments show that the
proposed algorithm produces images of similar quality as the
existing centralized techniques while being distributed and being
cost effective for extremely large images.
Index Terms—Distributed optimization, proximal projection,
shift-variant blur, inverse problems, image deblurring.



hal_id    :    hal-01520266



—Image deblurring is an economic way to reduce
certain degradations (blur and noise) in acquired images. Thus,
it has become essential tool in high resolution imaging in
many applications, e.g., astronomy, microscopy or computational
photography. In applications such as astronomy and satellite
imaging, the size of acquired images can be extremely large (up
to gigapixels) covering wide ﬁeld-of-view suffering from shift-
variant blur. Most of the existing image deblurring techniques
are designed and implemented to work efﬁciently on centralized
computing system having multiple processors and a shared mem-
ory. Thus, the largest image that can be handle is limited by the
size of the physical memory available on the system. In this paper,
we propose a distributed nonblind image deblurring algorithm in
which several connected processing nodes (with reasonable com-
putational resources) process simultaneously different portions of
a large image while maintaining certain coherency among them to
ﬁnally obtain a single crisp image. Unlike the existing centralized
techniques, image deblurring in distributed fashion raises several
issues. To tackle these issues, we consider certain approximations
that trade-offs between the quality of deblurred image and the
computational resources required to achieve it. The experimental
results show that our algorithm produces the similar quality
of images as the existing centralized techniques while allowing
distribution, and thus being cost effective for extremely large
images.
Index Terms—Distributed optimization, Proximal projection,
Consensus,



hal_id    :    hal-01497087



— The V˜u-Condat algorithm is a standard method
for ﬁnding a saddle point of a Lagrangian involving a dif-
ferentiable function. Recent works have tried to adapt the
idea of random coordinate descent to this algorithm, with
the aim to efﬁciently solve some regularized or distributed
optimization problems. A drawback of these approaches is
that the admissible step sizes can be small, leading to slow
convergence. In this paper, we introduce a coordinate descent
primal-dual algorithm which is provably convergent for a wider
range of step size values than previous methods. In particular,
the condition on the step-sizes depends on the coordinate-wise
Lipschitz constant of the differentiable function’s gradient. We
discuss the application of our method to distributed optimiza-
tion and large scale support vector machine problems.



hal_id    :    hal-01237226



— Based on the idea of randomized coordinate descent
of α-averaged operators, a randomized primal-dual optimization
algorithm is introduced, where a random subset of coordinates is
updated at each iteration. The algorithm builds upon a variant
of a recent (deterministic) algorithm proposed by V˜u and Condat
that includes the well known ADMM as a particular case. The
obtained algorithm is used to solve asynchronously a distributed
optimization problem. A network of agents, each having a
separate cost function containing a differentiable term, seek to
ﬁnd a consensus on the minimum of the aggregate objective. The
method yields an algorithm where at each iteration, a random
subset of agents wake up, update their local estimates, exchange
some data with their neighbors, and go idle. Numerical results
demonstrate the attractive performance of the method.
The general approach can be naturally adapted to other situa-
tions where coordinate descent convex optimization algorithms
are used with a random choice of the coordinates.
Index Terms— Distributed Optimization, Coordinate Descent,
Consensus algorithms, Primal-Dual Algorithm.



hal_id    :    hal-01183959



The purpose of this paper is to study the dynamical behavior of the sequence (xn)
produced by the forward-backward algorithm
yn+1 ∈B(un+1, xn),
xn+1 = (I + γn+1A(un+1, ·))−1(xn −γn+1yn+1),
where A(ξ) = A(ξ, ·) and B(ξ) = B(ξ, ·) are two functions valued in the set of maximal
monotone operators on RN, (un) is a sequence of independent and identically distributed
random variables, and (γn) is a sequence of vanishing step sizes. Following the approach of
the recent paper [16], we deﬁne the operators A(x) = E[A(u1, x)] and B(x) = E[B(u1, x)],
where the expectations are the set-valued Aumann integrals with respect to the law of
u1, and assume that the monotone operator A + B is maximal (suﬃcient conditions for
maximality are provided). It is shown that with probability one, the interpolated process
obtained from the iterates xn is an asymptotic pseudo trajectory in the sense of Bena¨ım
and Hirsch of the diﬀerential inclusion ˙z(t) ∈−(A + B)(z(t)). The convergence of the
empirical means of the xn’s towards a zero of A + B follows, as well as the convergence of
the sequence (xn) itself to such a zero under a demipositivity assumption. These results
ﬁnd applications in a wide range of optimization or variational inequality problems in
random environments.
Keywords :
Dynamical systems, Random



hal_id    :    hal-04299756



It is the purpose of this paper to investigate the issue of estimating the regularity
index β > 0 of a discrete heavy-tailed r.v. S, i.e. a r.v. S valued in N∗such that
P(S > n) = L(n) · n−β for all n ≥1, where L : R∗
+ →R+ is a slowly varying
function. Such discrete probability laws, referred to as generalized Zipf’s laws
sometimes, are commonly used to model rank-size distributions after a preliminary
range segmentation in a wide variety of areas such as e.g. quantitative linguistics,
social sciences or information theory. As a first go, we consider the situation where
inference is based on independent copies S1, . . . , Sn of the generic variable S.
Just like the popular Hill estimator in the continuous heavy-tail situation, the
estimator bβ we propose can be derived by means of a suitable reformulation of
the regularly varying condition, replacing S’s survivor function by its empirical
counterpart. Under mild assumptions, a non-asymptotic bound for the deviation
between bβ and β is established, as well as limit results (consistency and asymptotic
normality). Beyond the i.i.d. case, the inference method proposed is extended to the
estimation of the regularity index of a regenerative β-null recurrent Markov chain.
Since the parameter β can be then viewed as the



hal_id    :    hal-03206297



. Cubesats platforms expansion increases the need to simplify pay-
loads and to optimize downlink data capabilities. A promising solution is to en-
hance on-board software, in order to take early decisions automatically. How-
ever, the most efficient methods for data analysis are generally large deep neu-
ral networks (DNN) oversized to be loaded and processed on limited hardware 
capacities of cubesats. To use them, we must reduce the size of DNN while ac-
commodating efficiency in terms of both accuracy and inference cost. In this 
paper, we propose a distillation method which reduces image segmentation 
deep neural network’s size to fit into on board processors. This method is pre-
sented through a ship detection example comparing accuracy and inference 
costs for several networks. 
Keywords: Deep Learning, Deep Neural Networks, distillation, small sats, 
FPGA, image processing on-board.  
1



hal_id    :    hal-04242023



In this paper, we develop an active learning framework for the bipartite ranking
problem. Motivated by numerous applications, ranging from supervised anomaly
detection to credit-scoring through the design of medical diagnosis support systems,
and usually formulated as the problem of optimizing (a scalar summary of) the
ROC curve, bipartite ranking has been the subject of much attention in the passive
context. Various dedicated algorithms have been recently proposed and studied
by the machine-learning community. In contrast, active bipartite ranking rule
is poorly documented in the literature. Due to its global nature, a strategy for
labeling sequentially data points that are difficult to rank w.r.t. to the others is
required. This learning task is much more complex than binary classification, for
which many active algorithms have been designed. It is the goal of this article to
provide a rigorous formulation of such a selective sampling approach. We propose
a dedicated algorithm, referred to as active-rank, which aims to minimise the
distance between the ROC curve of the ranking function built and the optimal one,
w.r.t. the sup norm. We show that, for a fixed confidence level ε and probability δ,
active-rank is PAC(ε, δ). In addition, we provide a problem dependent upper
bound on the expected sampling time of active-rank and also demonstrate a
problem dependent lower bound



hal_id    :    hal-04126067



Athlete’s pose acquisition and analysis is promising to provide coaches with details of athletes
performance and thus help to improve athletes’ performances with more detailed supervision from
coaches. Compared with traditional ways of acquiring an athlete's gesture, such as using wearable
sensors, computer vision technology has advantages of low-cost, high-efficient and non-intrusive.
This paper aims to bridge these two fields, by reconstructing athletes’ trajectory using monocular
(i.e. single-camera-shot) videos. Under a few assumptions that are applicable to most of the sports
of athletics, we proposed a method combining computer vision techniques and physics laws to
reconstruct athletes’ trajectories from monocular videos. The method first estimates 3D pose of
athletes from video inputs, then performs kinematic analysis on estimated poses to reconstruct the
trajectories of athletes. We tested this algorithm on videos from the triple jump finals of the 2016
Olympics in Rio de Janeiro. We achieved a best performance with 9.1% mean average error when
using ground-truth foot-ground contact signal and 21.4% mean average error when using predicted
foot-ground contact signal.



hal_id    :    hal-03920536



No abstract found in the PDF.



hal_id    :    hal-03559365



We consider the classic supervised learning problem where a continuous non-negative
random label Y (e.g. a random duration) is to be predicted based upon observing a random
vector X valued in Rd with d ≥1 by means of a regression rule with minimum least
square error. In various applications, ranging from industrial quality control to public
health through credit risk analysis for instance, training observations can be right censored,
meaning that, rather than on independent copies of (X, Y ), statistical learning relies on
a collection of n ≥1 independent realizations of the triplet (X, min{Y, C}, δ), where
C is a nonnegative random variable with unknown distribution, modelling censoring and
δ = I{Y ≤C} indicates whether the duration is right censored or not. As ignoring censoring
in the risk computation may clearly lead to a severe underestimation of the target duration
and jeopardize prediction, we consider a plug-in estimate of the true risk based on a Kaplan-
Meier estimator of the conditional survival function of the censoring C given X, referred
to as Beran risk, in order to perform empirical risk minimization. It is established, under
mild conditions, that the learning rate of minimizers of this biased/weighted empirical risk
functional is of order OP(
p
log(n)/n) when ignoring model bias issues inherent to plug-in
estimation, as



hal_id    :    hal-04268476



In spite of the high performance and reliability
of deep learning algorithms in a wide range of
everyday applications, many investigations tend
to show that a lot of models exhibit biases, dis-
criminating against speciﬁc subgroups of the pop-
ulation (e.g. gender, ethnicity). This urges the
practitioner to develop fair systems with a uni-
form/comparable performance across sensitive
groups. In this work, we investigate the gender
bias of deep Face Recognition networks. In or-
der to measure this bias, we introduce two new
metrics, BFAR and BFRR, that better reﬂect
the inherent deployment needs of Face Recog-
nition systems. Motivated by geometric consid-
erations, we mitigate gender bias through a new
post-processing methodology which transforms
the deep embeddings of a pre-trained model to
give more representation power to discriminated
subgroups. It consists in training a shallow neural
network by minimizing a Fair von Mises-Fisher
loss whose hyperparameters account for the intra-
class variance of each gender. Interestingly, we
empirically observe that these hyperparameters
are correlated with our fairness metrics. In fact,
extensive numerical experiments on a variety of
datasets show that a careful selection signiﬁcantly
reduces gender bias.



hal_id    :    hal-03537148



The concept of median/consensus has been
widely investigated in order to provide a sta-
tistical summary of ranking data, i.e.
re-
alizations of a random permutation Σ of a
ﬁnite set, {1, . . . , n} with n ≥1 say. As it
sheds light onto only one aspect of Σ’s dis-
tribution P, it may neglect other informative
features. It is the purpose of this paper to
deﬁne analogues of quantiles, ranks and sta-
tistical procedures based on such quantities
for the analysis of ranking data by means of a
metric-based notion of depth function on the
symmetric group. Overcoming the absence
of vector space structure on Sn, the latter
deﬁnes a center-outward ordering of the per-
mutations in the support of P and extends
the classic metric-based formulation of con-
sensus ranking (medians corresponding then
to the deepest permutations). The axiomatic
properties that ranking depths should ideally
possess are listed, while computational and
generalization issues are studied at length.
Beyond the theoretical analysis carried out,
the relevance of the novel concepts and meth-
ods introduced for a wide variety of statistical
tasks are also supported by numerous numer-
ical experiments.
1



hal_id    :    hal-03559370



We consider risk minimization problems where
the (source) distribution PS of the training obser-
vations Z1, . . . , Zn diﬀers from the (target) distri-
bution PT involved in the risk that one seeks to
minimize. Under the natural assumption that PS
dominates PT, i.e. PT << PS , we develop a semi-
parametric framework in the situation where we
do not observe any sample from PT, but rather
have access to some auxiliary information at the
target population scale. More precisely, assuming
that the Radon-Nikodym derivative dPT/dPS (z)
belongs to a parametric class {g(z, α), α ∈A}
and that some (generalized) moments of PT are
available to the learner, we propose a two-step
learning procedure to perform the risk minimiza-
tion task. We ﬁrst select ˆα so as to match the mo-
ment constraints as closely as possible and then
reweight each (biased) training observation Zi by
g(Zi, ˆα) in the ﬁnal Empirical Risk Minimization
(ERM) algorithm. We establish a OP(1/ √n) gen-
eralization bound proving that, remarkably, the
solution to the weighted ERM problem thus con-
structed achieves a learning rate of the same order
as that attained in absence of any sampling bias.
Beyond these theoretical guarantees, numerical
results providing strong empirical evidence of the
relevance of the approach promoted in this article
are displayed.



hal_id    :    hal-03559386



Motivated by a wide variety of applications,
ranging from stochastic optimization to di-
mension reduction through variable selection,
the problem of estimating gradients accurately
is of crucial importance in statistics and learn-
ing theory.
We consider here the classical
regression setup, where a real valued square
integrable r.v. Y is to be predicted upon ob-
serving a (possibly high dimensional) random
vector X by means of a predictive function
f(X) as accurately as possible in the mean-
squared sense and study a nearest-neighbour-
based pointwise estimate of the gradient of
the optimal predictive function, the regression
function m(x) = E[Y | X = x]. Under clas-
sical smoothness conditions combined with
the assumption that the tails of Y −m(X)
are sub-Gaussian, we prove nonasymptotic
bounds improving upon those obtained for
alternative estimation methods. Beyond the
novel theoretical results established, several
illustrative numerical experiments have been
carried out. The latter provide strong em-
pirical evidence that the estimation method
proposed here performs very well for vari-
ous statistical problems involving gradient es-
timation, namely dimensionality reduction,
stochastic gradient descent optimization and
disentanglement quantification.
1



hal_id    :    hal-03190532



The ROC curve is the gold standard for measuring the performance
of a test/scoring statistic regarding its capacity to discriminate between
two statistical populations in a wide variety of applications, ranging from
anomaly detection in signal processing to information retrieval, through
medical diagnosis.
Most practical performance measures used in scor-
ing/ranking applications such as the AUC, the local AUC, the p-norm
push, the DCG and others, can be viewed as summaries of the ROC
curve. In this paper, the fact that most of these empirical criteria can
be expressed as two-sample linear rank statistics is highlighted and con-
centration inequalities for collections of such random variables, referred
to as two-sample rank processes here, are proved, when indexed by VC
classes of scoring functions. Based on these nonasymptotic bounds, the
generalization capacity of empirical maximizers of a wide class of ranking
performance criteria is next investigated from a theoretical perspective.
It is also supported by empirical evidence through convincing numerical
experiments.
1



hal_id    :    hal-02507316



.
We present a framework for deﬁning the “right” level of
explainability based on technical, legal and economic considerations.
Our approach involves three logical steps: First, deﬁne the main con-
textual factors, such as who is the audience of the explanation, the
operational context, the level of harm that the system could cause,
and the legal/regulatory framework. This step will help characterize
the operational and legal needs for explanation, and the correspond-
ing social beneﬁts. Second, examine the technical tools available,
including post-hoc approaches (input perturbation, saliency maps...)
and hybrid AI approaches. Third, as function of the ﬁrst two steps,
choose the right levels of global and local explanation outputs, taking
into the account the costs involved. We identify seven kinds of costs
and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1



hal_id    :    hal-03126870



In multiclass classiﬁcation, the goal is to
learn how to predict a random label Y , val-
ued in Y = {1,
. . . ,
K} with K ≥3,
based upon observing a r.v.
X, taking its
values in Rq with q ≥1 say, by means of
a classiﬁcation rule g : Rq →Y with min-
imum probability of error P{Y
̸= g(X)}.
However, in a wide variety of situations, the
task targeted may be more ambitious, con-
sisting in sorting all the possible label values
y that may be assigned to X by decreasing
order of the posterior probability ηy(X) =
P{Y = y | X}.
This article is devoted to
the analysis of this statistical learning prob-
lem, halfway between multiclass classiﬁcation
and posterior probability estimation (regres-
sion) and referred to as label ranking here.
We highlight the fact that it can be viewed
as a speciﬁc variant of ranking median re-
gression (RMR), where, rather than observ-
ing a random permutation Σ assigned to the
input vector X and drawn from a Bradley-
Terry-Luce-Plackett model with conditional
preference vector (η1(X), . . . , ηK(X)), the
sole information available for training a la-
bel ranking rule is the label Y ranked on
top, namely Σ−1(1). Inspired by recent re-
sults in RMR, we prove that under appro-
priate noise conditions, the One-Versus-One
(OVO) approach to multiclassiﬁcation yields,
as a by-product, an



hal_id    :    hal-03559387



. We consider statistical learning problems, when the distribution P′ of
the training observations Z′
1, . . . , Z′
n diﬀers from the distribution P involved in the
risk one seeks to minimize (referred to as the test distribution) but is still deﬁned on
the same measurable space as P and dominates it. In the unrealistic case where the
likelihood ratio Φ(z) = dP/dP′(z) is known, one may straightforwardly extends the
Empirical Risk Minimization (ERM) approach to this speciﬁc transfer learning setup
using the same idea as that behind Importance Sampling, by minimizing a weighted
version of the empirical risk functional computed from the ’biased’ training data Z′
i
with weights Φ(Z′
i ). Although the importance function Φ(z) is generally unknown in
practice, we show that, in various situations frequently encountered in practice, it
takes a simple form and can be directly estimated from the Z′
i ’s and some auxiliary
information on the statistical population P. By means of linearization techniques,
we then prove that the generalization capacity of the approach aforementioned is
preserved when plugging the resulting estimates of the Φ(Z′
i)’s into the weighted
empirical risk. Beyond these theoretical guarantees, numerical results provide strong
empirical evidence of the relevance of the approach promoted in this article.
1



hal_id    :    hal-02185060



In a wide variety of situations, anomalies in the behaviour of a complex
system, whose health is monitored through the observation of a random
vector X = (X1, . . . , Xd) valued in Rd, correspond to the simultane-
ous occurrence of extreme values for certain subgroups α ⊂{1, . . . , d}
of variables Xj. Under the heavy-tail assumption, which is precisely ap-
propriate for modeling these phenomena, statistical methods relying on
multivariate extreme value theory have been developed in the past few
years for identifying such events/subgroups. This paper exploits this ap-
proach much further by means of a novel mixture model that permits to
describe the distribution of extremal observations and where the anomaly
type α is viewed as a latent variable. One may then take advantage of the
model by assigning to any extreme point a posterior probability for each
anomaly type α, deﬁning implicitly a similarity measure between anoma-
lies. It is explained at length how the latter permits to cluster extreme
observations and obtain an informative planar representation of anomalies
using standard graph-mining tools. The relevance and usefulness of the
clustering and 2-d visual display thus designed is illustrated on simulated
datasets and on real observations as well, in the aeronautics application
domain.
Keywords—
Anomaly detection, clustering, graph-mining, latent
variable analysis, mixture modelling,



hal_id    :    hal-02878302



No abstract found in the PDF.



hal_id    :    hal-02506409



The recent enthusiasm for artiﬁcial intelligence (AI) is due principally to
advances in deep learning. Deep learning methods are remarkably accurate,
but also opaque, which limits their potential use in safety-critical applications.
To achieve trust and accountability, designers and operators of machine learn-
ing algorithms must be able to explain the inner workings, the results and the
causes of failures of algorithms to users, regulators, and citizens. The orig-
inality of this paper is to combine technical, legal and economic aspects of
explainability to develop a framework for deﬁning the ”right” level of explain-
ability in a given context. We propose three logical steps: First, deﬁne the
main contextual factors, such as who the audience of the explanation is, the
operational context, the level of harm that the system could cause, and the
legal/regulatory framework. This step will help characterize the operational
and legal needs for explanation, and the corresponding social beneﬁts. Second,
examine the technical tools available, including post hoc approaches (input
perturbation, saliency maps...) and hybrid AI approaches. Third, as function
of the ﬁrst two steps, choose the right levels of global and local explanation
outputs, taking into the account the costs involved. We identify seven kinds
of costs and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1We would like to



hal_id    :    hal-02077745



No abstract found in the PDF.



hal_id    :    hal-02078108



. Iterative stochastic approximation methods are widely used to solve M-estimation prob-
lems, in the context of predictive learning in particular. In certain situations that shall be undoubtedly
more and more common in the Big Data era, the datasets available are so massive that computing
statistics over the full sample is hardly feasible, if not unfeasible. A natural and popular approach
to gradient descent in this context consists in substituting the “full data” statistics with their coun-
terparts based on subsamples picked at random of manageable size. It is the main purpose of this
paper to investigate the impact of survey sampling with unequal inclusion probabilities on stochastic
gradient descent-based M-estimation methods. Precisely, we prove that, in presence of some a priori
information, one may signiﬁcantly increase statistical accuracy in terms of limit variance, when choos-
ing appropriate ﬁrst order inclusion probabilities. These results are described by asymptotic theorems
and are also supported by illustrative numerical experiments.
Mathematics Subject Classiﬁcation. 62D05.
Received January 3, 2018. Accepted October 22, 2018.



hal_id    :    hal-02369435



For the purpose of monitoring the behavior of complex infrastructures (e.g.
aircrafts,
transport or energy networks), high-rate sensors are deployed to capture multivariate data,
generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anoma-
lies that may jeopardize the smooth operation of the system of interest. The statistical
analysis of such massive data of functional nature raises many challenging methodological
questions. The primary goal of this paper is to extend the popular Isolation Forest (IF)
approach to Anomaly Detection, originally dedicated to ﬁnite dimensional observations, to
functional data. The major diﬃculty lies in the wide variety of topological structures that
may equip a space of functions and the great variety of patterns that may characterize
abnormal curves.
We address the issue of (randomly) splitting the functional space in
a ﬂexible manner in order to isolate progressively any trajectory from the others, a key
ingredient to the eﬃciency of the algorithm. Beyond a detailed description of the algo-
rithm, computational complexity and stability issues are investigated at length. From the
scoring function measuring the degree of abnormality of an observation provided by the
proposed variant of the IF algorithm, a Functional Statistical Depth function is deﬁned and
discussed, as well as a multivariate functional extension. Numerical experiments provide
strong empirical evidence of the accuracy of the extension



hal_id    :    hal-02166428



. The development of cluster computing frameworks has al-
lowed practitioners to scale out various statistical estimation and ma-
chine learning algorithms with minimal programming eﬀort. This is es-
pecially true for machine learning problems whose objective function
is nicely separable across individual data points, such as classiﬁcation
and regression. In contrast, statistical learning tasks involving pairs (or
more generally tuples) of data points — such as metric learning, clus-
tering or ranking — do not lend themselves as easily to data-parallelism
and in-memory computing. In this paper, we investigate how to bal-
ance between statistical performance and computational eﬃciency in
such distributed tuplewise statistical problems. We ﬁrst propose a sim-
ple strategy based on occasionally repartitioning data across workers
between parallel computation stages, where the number of repartition-
ing steps rules the trade-oﬀbetween accuracy and runtime. We then
present some theoretical results highlighting the beneﬁts brought by the
proposed method in terms of variance reduction, and extend our results
to design distributed stochastic gradient descent algorithms for tuplewise
empirical risk minimization. Our results are supported by numerical ex-
periments in pairwise statistical estimation and learning on synthetic and
real-world datasets.
Keywords: Distributed Machine Learning · Distributed Data Process-
ing · U-Statistics · Stochastic Gradient Descent · AUC Optimization
1



hal_id    :    hal-02461801



In many situations, the choice of an adequate similarity measure or
metric on the feature space dramatically determines the performance of
machine learning methods. Building automatically such measures is the
speciﬁc purpose of metric/similarity learning. In [21], similarity learning
is formulated as a pairwise bipartite ranking problem: ideally, the larger
the probability that two observations in the feature space belong to the
same class (or share the same label), the higher the similarity measure
between them. From this perspective, the ROC curve is an appropriate
performance criterion and it is the goal of this article to extend recur-
sive tree-based ROC optimization techniques in order to propose eﬃcient
similarity learning algorithms.
The validity of such iterative partition-
ing procedures in the pairwise setting is established by means of results
pertaining to the theory of U-processes and from a practical angle, it is
discussed at length how to implement them by means of splitting rules
speciﬁcally tailored to the similarity learning task. Beyond these theoret-
ical/methodological contributions, numerical experiments are displayed
and provide strong empirical evidence of the performance of the algorith-
mic approaches we propose.
Keywords: Metric-Learning · Rate Bound Analysis · Similarity Learning
· Tree-based Algorithms · U-processes.
1



hal_id    :    hal-02463910



Tournament procedures, recently introduced in
Lugosi & Mendelson (2016), offer an appealing
alternative, from a theoretical perspective at least,
to the principle of Empirical Risk Minimization in
machine learning. Statistical learning by Median-
of-Means (MoM) basically consists in segmenting
the training data into blocks of equal size and com-
paring the statistical performance of every pair of
candidate decision rules on each data block: that
with highest performance on the majority of the
blocks is declared as the winner. In the context of
nonparametric regression, functions having won
all their duels have been shown to outperform em-
pirical risk minimizers w.r.t. the mean squared
error under minimal assumptions, while exhibit-
ing robustness properties. It is the purpose of this
paper to extend this approach, in order to address
other learning problems in particular, for which
the performance criterion takes the form of an
expectation over pairs of observations rather than
over one single observation, as may be the case
in pairwise ranking, clustering or metric learn-
ing. Precisely, it is proved here that the bounds
achieved by MoM are essentially conserved when
the blocks are built by means of independent sam-
pling without replacement schemes instead of a
simple segmentation. These results are next ex-
tended to situations where the risk is related to a
pairwise loss function and its empirical counter-
part is of the form of a



hal_id    :    hal-02023057



Originally motivated by default risk management applications, this paper investigates a
novel problem, referred to as the proﬁtable bandit problem here. At each step, an agent
chooses a subset of the K ≥1 possible actions. For each action chosen, she then respectively
pays and receives the sum of a random number of costs and rewards. Her objective is
to maximize her cumulated proﬁt.
We adapt and study three well-known strategies in
this purpose, that were proved to be most eﬃcient in other settings: kl-UCB, Bayes-
UCB and Thompson Sampling. For each of them, we prove a ﬁnite time regret bound
which, together with a lower bound we obtain as well, establishes asymptotic optimality
in some cases. Our goal is also to compare these three strategies from a theoretical and
empirical perspective both at the same time. We give simple, self-contained proofs that
emphasize their similarities, as well as their diﬀerences. While both Bayesian strategies are
automatically adapted to the geometry of information, the numerical experiments carried
out show a slight advantage for Thompson Sampling in practice.
Keywords: credit risk, multi-armed bandits, thresholding bandits, index policy, bayesian
policy



hal_id    :    hal-01516919



This paper aims at formulating the issue of ranking multivariate unlabeled observations
depending on their degree of abnormality as an unsupervised statistical learning task. In
the 1-d situation, this problem is usually tackled by means of tail estimation techniques:
univariate observations are viewed as all the more ‘abnormal’ as they are located far in the
tail(s) of the underlying probability distribution. It would be desirable as well to dispose of
a scalar valued ‘scoring’ function allowing for comparing the degree of abnormality of mul-
tivariate observations. Here we formulate the issue of scoring anomalies as a M-estimation
problem by means of a novel functional performance criterion, referred to as the Mass Vol-
ume curve (MV curve in short), whose optimal elements are strictly increasing transforms
of the density almost everywhere on the support of the density. We ﬁrst study the statistical
estimation of the MV curve of a given scoring function and we provide a strategy to build
conﬁdence regions using a smoothed bootstrap approach. Optimization of this functional
criterion over the set of piecewise constant scoring functions is next tackled. This boils
down to estimating a sequence of empirical minimum volume sets whose levels are chosen
adaptively from the data, so as to adjust to the variations of the optimal MV curve, while
controling



hal_id    :    hal-01932813



In pattern recognition, a random label Y is to be predicted based upon observ-
ing a random vector X valued in Rd with d ≥1 by means of a classiﬁcation
rule with minimum probability of error. In a wide variety of applications, ranging
from ﬁnance/insurance to environmental sciences through teletrafﬁc data analysis
for instance, extreme (i.e. very large) observations X are of crucial importance,
while contributing in a negligible manner to the (empirical) error however, simply
because of their rarity. As a consequence, empirical risk minimizers generally
perform very poorly in extreme regions. It is the purpose of this paper to de-
velop a general framework for classiﬁcation in the extremes. Precisely, under
non-parametric heavy-tail assumptions for the class distributions, we prove that
a natural and asymptotic notion of risk, accounting for predictive performance in
extreme regions of the input space, can be deﬁned and show that minimizers of an
empirical version of a non-asymptotic approximant of this dedicated risk, based
on a fraction of the largest observations, lead to classiﬁcation rules with good
generalization capacity, by means of maximal deviation inequalities in low proba-
bility regions. Beyond theoretical results, numerical experiments are presented in
order to illustrate the relevance of the approach developed.
1



hal_id    :    hal-01249862



Though the statistical analysis of ranking data has been a subject of interest over the past
centuries, especially in economics, psychology or social choice theory, it has been revitalized in
the past 15 years by recent applications such as recommender or search engines and is receiving
now increasing interest in the machine learning literature. Numerous modern systems indeed
generate ranking data, representing for instance ordered results to a query or user preferences.
Each such ranking usually involves a small but varying subset of the whole catalog of items
only. The study of the variability of these data, i.e. the statistical analysis of incomplete rank-
ings, is however a great statistical and computational challenge, because of their heterogeneity
and the related combinatorial complexity of the problem. Whereas many statistical methods
for analyzing full rankings (orderings of all the items in the catalog) are documented in the
dedicated literature, partial rankings (full rankings with ties) or pairwise comparisons, only a
few approaches are available today to deal with incomplete ranking, relying each on a strong
speciﬁc assumption.
It is the purpose of this article to introduce a novel general framework for the statistical
analysis of incomplete rankings. It is based on a representation tailored to these speciﬁc data,
whose construction is also explained here, which ﬁts with



hal_id    :    hal-01367546



The problem of predicting connections between a set of data points ﬁnds many
applications, in systems biology and social network analysis among others. This
paper focuses on the graph reconstruction problem, where the prediction rule is
obtained by minimizing the average error over all n(n −1)/2 possible pairs of
the n nodes of a training graph. Our ﬁrst contribution is to derive learning rates of
order OP(log n/n) for this problem, signiﬁcantly improving upon the slow rates
of order OP(1/√n) established in the seminal work of Biau and Bleakley (2006).
Strikingly, these fast rates are universal, in contrast to similar results known for
other statistical learning problems (e.g., classiﬁcation, density level set estimation,
ranking, clustering) which require strong assumptions on the distribution of the
data. Motivated by applications to large graphs, our second contribution deals with
the computational complexity of graph reconstruction. Speciﬁcally, we investigate
to which extent the learning rates can be preserved when replacing the empirical
reconstruction risk by a computationally cheaper Monte-Carlo version, obtained
by sampling with replacement B ≪n2 pairs of nodes. Finally, we illustrate our
theoretical results by numerical experiments on synthetic and real graphs.
1



hal_id    :    hal-01567869



Model selection is a crucial issue in machine-
learning and a wide variety of penalisation methods
(with possibly data dependent complexity penal-
ties) have recently been introduced for this purpose.
However their empirical performance is generally
not well documented in the literature. It is the goal
of this paper to investigate to which extent such
recent techniques can be successfully used for the
tuning of both the regularisation and kernel param-
eters in support vector regression (SVR) and the
complexity measure in regression trees (CART).
This task is traditionally solved via V -fold cross-
validation (VFCV), which gives eﬃcient results for
a reasonable computational cost. A disadvantage
however of VFCV is that the procedure is known
to provide an asymptotically suboptimal risk esti-
mate as the number of examples tends to inﬁnity.
Recently, a penalisation procedure called V -fold pe-
nalisation has been proposed to improve on VFCV,
supported by theoretical arguments. Here we re-
port on an extensive set of experiments comparing
V -fold penalisation and VFCV for SVR/CART cal-
ibration on several benchmark datasets. We high-
light cases in which VFCV and V -fold penalisation
provide poor estimates of the risk respectively and
introduce a modiﬁed penalisation technique to re-
duce the estimation error.
∗Author for correspondence (charanpal.dhanjal@lip6.fr)
1



hal_id    :    hal-01327662



In a wide range of statistical learning problems such as ranking, clustering or metric learning
among others, the risk is accurately estimated by U-statistics of degree d ≥1, i.e. func-
tionals of the training data with low variance that take the form of averages over k-tuples.
From a computational perspective, the calculation of such statistics is highly expensive
even for a moderate sample size n, as it requires averaging O(nd) terms.
This makes
learning procedures relying on the optimization of such data functionals hardly feasible in
practice. It is the major goal of this paper to show that, strikingly, such empirical risks can
be replaced by drastically computationally simpler Monte-Carlo estimates based on O(n)
terms only, usually referred to as incomplete U-statistics, without damaging the OP(1/√n)
learning rate of Empirical Risk Minimization (ERM) procedures. For this purpose, we
establish uniform deviation results describing the error made when approximating a U-
process by its incomplete version under appropriate complexity assumptions. Extensions
to model selection, fast rate situations and various sampling techniques are also consid-
ered, as well as an application to stochastic gradient descent for ERM. Finally, numerical
examples are displayed in order to provide strong empirical evidence that the approach we
promote largely surpasses more naive subsampling techniques.
Keywords:
big data, empirical risk minimization, U-processes, rate bound analysis,
sampling



hal_id    :    hal-00936316



The Cuban contact-tracing detection system set up in 1986 allowed the
reconstruction and analysis of the sexual network underlying the epidemic
(5,389 vertices and 4,073 edges, giant component of 2,386 nodes and 3,168
edges), shedding light onto the spread of HIV and the role of contact-
tracing. Clustering based on modularity optimization provides a better
visualization and understanding of the network, in combination with the
study of covariates.
The graph has a globally low but heterogeneous
density, with clusters of high intraconnectivity but low interconnectivity.
Though descriptive, our results pave the way for incorporating structure
when studying stochastic SIR epidemics spreading on social networks.
Data accessibility:
Data concerning the sex, sexual orientation, mode of
detection of individuals and allowing the reconstruction of the graph, is provided in
the supplementary materials.
Keywords: Cuban HIV/AIDS epidemics; contact-tracing; social network;
graph-mining; clustering.
∗Author for correspondence (stephan.clemencon@telecom-paristech.fr)
†Author for correspondence (chi.tran@math.univ-lille1.fr)
1
1



hal_id    :    hal-00854458



This article focuses, in the context of epidemic models, on rare events that may possibly correspond
to crisis situations from the perspective of Public Health. In general, no close analytic form for their
occurrence probabilities is available and crude Monte-Carlo procedures fail. We show how recent
intensive computer simulation techniques, such as interacting branching particle methods, can be
used for estimation purposes, as well as for generating model paths that correspond to realizations
of such events. Applications of these simulation-based methods to several epidemic models are also
considered and discussed thoroughly.
Keywords: Stochastic epidemic model ; rare event analysis ; Monte-Carlo simulation ; importance
sampling ; interacting branching particle system ; genetic models ; multilevel splitting
AMS Codes: MSC 65C35 ; 62G32 ; MSC 92D30
1



hal_id    :    hal-01214667



In many learning problems, ranging from clustering to ranking through metric
learning, empirical estimates of the risk functional consist of an average over tu-
ples (e.g., pairs or triplets) of observations, rather than over individual observa-
tions. In this paper, we focus on how to best implement a stochastic approximation
approach to solve such risk minimization problems. We argue that in the large-
scale setting, gradient estimates should be obtained by sampling tuples of data
points with replacement (incomplete U-statistics) instead of sampling data points
without replacement (complete U-statistics based on subsamples). We develop a
theoretical framework accounting for the substantial impact of this strategy on the
generalization ability of the prediction model returned by the Stochastic Gradient
Descent (SGD) algorithm. It reveals that the method we promote achieves a much
better trade-off between statistical accuracy and computational cost. Beyond the
rate bound analysis, experiments on AUC maximization and metric learning pro-
vide strong empirical evidence of the superiority of the proposed approach.
1



hal_id    :    hal-01270543



Statistical analysis of rank data describing pref-
erences over small and variable subsets of a po-
tentially large ensemble of items {1, . . . , n} is
a very challenging problem. It is motivated by
a wide variety of modern applications, such as
recommender systems or search engines. How-
ever, very few inference methods have been doc-
umented in the literature to learn a ranking model
from such incomplete rank data. The goal of this
paper is twofold: it develops a rigorous mathe-
matical framework for the problem of learning
a ranking model from incomplete rankings and
introduces a novel general statistical method to
address it. Based on an original concept of multi-
resolution analysis (MRA) of incomplete rank-
ings, it ﬁnely adapts to any observation setting,
leading to a statistical accuracy and an algorith-
mic complexity that depend directly on the com-
plexity of the observed data. Beyond theoretical
guarantees, we also provide experimental results
that show its statistical performance.



hal_id    :    hal-02107483



Efﬁcient and robust algorithms for decentralized estimation in networks are es-
sential to many distributed systems. Whereas distributed estimation of sample
mean statistics has been the subject of a good deal of attention, computation of U-
statistics, relying on more expensive averaging over pairs of observations, is a less
investigated area. Yet, such data functionals are essential to describe global prop-
erties of a statistical population, with important examples including Area Under
the Curve, empirical variance, Gini mean difference and within-cluster point scat-
ter. This paper proposes new synchronous and asynchronous randomized gossip
algorithms which simultaneously propagate data across the network and main-
tain local estimates of the U-statistic of interest. We establish convergence rate
bounds of O(1/t) and O(log t/t) for the synchronous and asynchronous cases
respectively, where t is the number of iterations, with explicit data and network
dependent terms. Beyond favorable comparisons in terms of rate analysis, numer-
ical experiments provide empirical evidence the proposed algorithms surpasses
the previously introduced approach.
1



hal_id    :    hal-02107459



Statistical analysis of rank data describing pref-
erences over small and variable subsets of a po-
tentially large ensemble of items {1, . . . , n} is
a very challenging problem. It is motivated by
a wide variety of modern applications, such as
recommender systems or search engines. How-
ever, very few inference methods have been doc-
umented in the literature to learn a ranking model
from such incomplete rank data. The goal of this
paper is twofold: it develops a rigorous mathe-
matical framework for the problem of learning
a ranking model from incomplete rankings and
introduces a novel general statistical method to
address it. Based on an original concept of multi-
resolution analysis (MRA) of incomplete rank-
ings, it ﬁnely adapts to any observation setting,
leading to a statistical accuracy and an algorith-
mic complexity that depend directly on the com-
plexity of the observed data. Beyond theoretical
guarantees, we also provide experimental results
that show its statistical performance.



hal_id    :    hal-02107492



In many learning problems, ranging from clustering to ranking through metric
learning, empirical estimates of the risk functional consist of an average over tu-
ples (e.g., pairs or triplets) of observations, rather than over individual observa-
tions. In this paper, we focus on how to best implement a stochastic approximation
approach to solve such risk minimization problems. We argue that in the large-
scale setting, gradient estimates should be obtained by sampling tuples of data
points with replacement (incomplete U-statistics) instead of sampling data points
without replacement (complete U-statistics based on subsamples). We develop a
theoretical framework accounting for the substantial impact of this strategy on the
generalization ability of the prediction model returned by the Stochastic Gradient
Descent (SGD) algorithm. It reveals that the method we promote achieves a much
better trade-off between statistical accuracy and computational cost. Beyond the
rate bound analysis, experiments on AUC maximization and metric learning pro-
vide strong empirical evidence of the superiority of the proposed approach.
1



hal_id    :    hal-04254953



We study short-term prediction of wind speed and wind power (every 10 minutes up to 4
hours ahead). Accurate forecasts for these quantities are crucial to mitigate the negative eﬀects of
wind farms’ intermittent production on energy systems and markets. We use machine learning to
combine outputs from numerical weather prediction models with local observations. The former
provide valuable information on higher scales dynamics while the latter gives the model fresher and
location-speciﬁc data. So as to make the results usable for practitioners, we focus on well-known
methods which can handle a high volume of data. We study ﬁrst variable selection using both a
linear technique and a nonlinear one. Then we exploit these results to forecast wind speed and
wind power still with an emphasis on linear models versus nonlinear ones. For the wind power
prediction, we also compare the indirect approach (wind speed predictions passed through a power
curve) and the indirect one (directly predict wind power).
Keywords—Wind speed forecasting, Wind energy forecasting, Machine learning, Numerical weather
prediction, Downscaling
Abbreviations—Numerical weather prediction (NWP); machine learning (ML); European Cen-
tre for Medium-Range Weather Forecasts (ECMWF); parc de Bonneval (BO); parc de Moulin de
Pierre (MP); parc de Beaumont (BM); parc de la Renardi`ere (RE); parc de la V`enerie (VE); ker-
nel ridge regression (KRR); neural



hal_id    :    hal-03341560



One of the challenges in machine learning research is to ensure that presented and published
results are sound and reliable. Reproducibility, that is obtaining similar results as presented
in a paper or talk, using the same code and data (when available), is a necessary step to
verify the reliability of research ﬁndings.
Reproducibility is also an important step to
promote open and accessible research, thereby allowing the scientiﬁc community to quickly
integrate new ﬁndings and convert ideas to practice. Reproducibility also promotes the use
of robust experimental workﬂows, which potentially reduce unintentional errors. In 2019,
the Neural Information Processing Systems (NeurIPS) conference, the premier international
conference for research in machine learning, introduced a reproducibility program, designed
to improve the standards across the community for how we conduct, communicate, and
evaluate machine learning research.
The program contained three components: a code
submission policy, a community-wide reproducibility challenge, and the inclusion of the
c⃝2021 Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, Vincent Larivi`ere, Alina Beygelzimer, Florence
d’Alch´e-Buc, Emily Fox, Hugo Larochelle. Corresponding author: Joelle Pineau (jpineau@cs.mcgill.ca).
License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided
at http://jmlr.org/papers/v22/20-303.html.
Pineau, Vincent-Lamarre, Sinha, Larivi`ere, Beygelzimer, d’Alch´e-Buc, Fox, Larochelle
Machine Learning Reproducibility checklist as part of the paper submission process. In
this paper, we describe each of these components, how it was deployed, as well as what



hal_id    :    hal-02507316



.
We present a framework for deﬁning the “right” level of
explainability based on technical, legal and economic considerations.
Our approach involves three logical steps: First, deﬁne the main con-
textual factors, such as who is the audience of the explanation, the
operational context, the level of harm that the system could cause,
and the legal/regulatory framework. This step will help characterize
the operational and legal needs for explanation, and the correspond-
ing social beneﬁts. Second, examine the technical tools available,
including post-hoc approaches (input perturbation, saliency maps...)
and hybrid AI approaches. Third, as function of the ﬁrst two steps,
choose the right levels of global and local explanation outputs, taking
into the account the costs involved. We identify seven kinds of costs
and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1



hal_id    :    hal-02506409



The recent enthusiasm for artiﬁcial intelligence (AI) is due principally to
advances in deep learning. Deep learning methods are remarkably accurate,
but also opaque, which limits their potential use in safety-critical applications.
To achieve trust and accountability, designers and operators of machine learn-
ing algorithms must be able to explain the inner workings, the results and the
causes of failures of algorithms to users, regulators, and citizens. The orig-
inality of this paper is to combine technical, legal and economic aspects of
explainability to develop a framework for deﬁning the ”right” level of explain-
ability in a given context. We propose three logical steps: First, deﬁne the
main contextual factors, such as who the audience of the explanation is, the
operational context, the level of harm that the system could cause, and the
legal/regulatory framework. This step will help characterize the operational
and legal needs for explanation, and the corresponding social beneﬁts. Second,
examine the technical tools available, including post hoc approaches (input
perturbation, saliency maps...) and hybrid AI approaches. Third, as function
of the ﬁrst two steps, choose the right levels of global and local explanation
outputs, taking into the account the costs involved. We identify seven kinds
of costs and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1We would like to



hal_id    :    hal-02618085



:
In small molecule identiﬁcation from tandem mass (MS/MS) spectra, input–output
kernel regression (IOKR) currently provides the state-of-the-art combination of fast training and
prediction and high identiﬁcation rates. The IOKR approach can be simply understood as predicting
a ﬁngerprint vector from the MS/MS spectrum of the unknown molecule, and solving a pre-image
problem to ﬁnd the molecule with the most similar ﬁngerprint. In this paper, we bring forward the
following improvements to the IOKR framework: ﬁrstly, we formulate the IOKRreverse model that
can be understood as mapping molecular structures into the MS/MS feature space and solving a
pre-image problem to ﬁnd the molecule whose predicted spectrum is the closest to the input MS/MS
spectrum. Secondly, we introduce an approach to combine several IOKR and IOKRreverse models
computed from different input and output kernels, called IOKRfusion. The method is based on
minimizing structured Hinge loss of the combined model using a mini-batch stochastic subgradient
optimization. Our experiments show a consistent improvement of top-k accuracy both in positive
and negative ionization mode data.
Keywords: metabolite identiﬁcation; machine learning; structured prediction; kernel methods



hal_id    :    hal-02371140



The task of predicting ﬁne grained user opin-
ion based on spontaneous spoken language is
a key problem arising in the development of
Computational Agents as well as in the devel-
opment of social network based opinion min-
ers. Unfortunately, gathering reliable data on
which a model can be trained is notoriously dif-
ﬁcult and existing works rely only on coarsely
labeled opinions. In this work we aim at bridg-
ing the gap separating ﬁne grained opinion
models already developed for written language
and coarse grained models developed for spon-
taneous multimodal opinion mining. We take
advantage of the implicit hierarchical structure
of opinions to build a joint ﬁne and coarse
grained opinion model that exploits different
views of the opinion expression. The resulting
model shares some properties with attention-
based models and is shown to provide compet-
itive results on a recently released multimodal
ﬁne grained annotated corpus.
1



hal_id    :    hal-02182244



, full
text). We take a similar approach defining different sets of features. Mining logs offers an exhaustive vision of
all use: the functionalities used, the types of documents consulted, and the sequence of these actions. All these
elements are impossible to obtain through interviews or surveys. Moreover, online surveys, which are among the
tools used by the BnF to gain insight on the use, tend to be answered by regular users close to the institution and
miss newcomers or occasional users.
This paper aims at studying the feasibility and usability of data-mining algorithms on web logs to provide a
better understanding of the behaviors of digital library users. The originality of our research is twofold : first,
web logs are combined with the description of documents to get a better view of the types of documents that
are consulted; second, the modeling of sequences of actions is used to discover usage patterns in the browsing
activity of Gallica’s users.
Among the various clustering approaches able to deal with sequential data, we have chosen a generative
probabilistic approach based on a mixture of Markov models whose main feature is the interpretability of each
class, using the parameters of each component of the mixture. We first instantiate this approach by considering a
mixture of Markov



hal_id    :    hal-02786616



No abstract found in the PDF.



hal_id    :    hal-02881802



The vascular endothelium is considered as a key cell compartment for the response to ioniz-
ing radiation of normal tissues and tumors, and as a promising target to improve the differen-
tial effect of radiotherapy in the future. Following radiation exposure, the global endothelial
cell response covers a wide range of gene, miRNA, protein and metabolite expression modi-
fications. Changes occur at the transcriptional, translational and post-translational levels
and impact cell phenotype as well as the microenvironment by the production and secretion
of soluble factors such as reactive oxygen species, chemokines, cytokines and growth fac-
tors. These radiation-induced dynamic modifications of molecular networks may control the
endothelial cell phenotype and govern recruitment of immune cells, stressing the impor-
tance of clearly understanding the mechanisms which underlie these temporal processes. A
wide variety of time series data is commonly used in bioinformatics studies, including gene
expression, protein concentrations and metabolomics data. The use of clustering of these
data is still an unclear problem. Here, we introduce kernels between Gaussian processes
modeling time series, and subsequently introduce a spectral clustering algorithm. We apply
the methods to the study of human primary endothelial cells (HUVECs) exposed to a radio-
therapy dose fraction (2 Gy). Time windows of differential expressions of 301 genes
involved in key cellular processes such as



hal_id    :    hal-01968742



No abstract found in the PDF.



hal_id    :    hal-01709264



, TeraLab a été choisie pour cette étude puisqu’il s’agit d’une plateforme répondant à
nos attentes en termes de volume de données, volumes de calcul et de sécurité.
2.3.2
Python
Deﬁnition 2.3.2. Python est un langage de programmation objet, multi-paradigme et multiplate-
forme. Il favorise la programmation impérative structurée, fonctionnelle et orientée objet. Il est doté
d’un typage dynamique fort, d’une gestion automatique de la mémoire par ramasse-miettes et d’un
système de gestion d’exceptions. Le langage Python est placé sous une licence libre proche de la
licence BSD3 et fonctionne sur la plupart des plates-formes informatiques, des supercalculateurs aux
ordinateurs centraux, de Windows à Unix en passant par GNU/Linux, Mac OS, ou encore Android,
iOS.
Les algorithmes développés dans le cadre de ce projet ont été intégralement conçus à l’aide du
langage Python (Def. 2.3.2). Il est particulièrement adapté à nos besoins puisqu’il oﬀre des outils de
haut niveau programmés par la communauté des chercheurs (en Machine Learning notamment) et
une syntaxe simple à utiliser.
2.3.3
Elasticsearch
Deﬁnition 2.3.3. Elasticsearch est un serveur utilisant Lucene pour l’indexation et la recherche des
données. Il fournit un moteur de recherche distribué et multi-entité à travers une interface REST.
C’est un logiciel libre écrit en Java et publié en open source sous licence Apache.
L’outil Elasticsearch (subsection 2.3.3) a été choisi comme infrastructure



hal_id    :    hal-02637720



Motivation: An important problematic of metabolomics is to identify metabolites using tandem
mass spectrometry data. Machine learning methods have been proposed recently to solve this
problem by predicting molecular ﬁngerprint vectors and matching these ﬁngerprints against exist-
ing molecular structure databases. In this work we propose to address the metabolite identiﬁcation
problem using a structured output prediction approach. This type of approach is not limited to vec-
tor output space and can handle structured output space such as the molecule space.
Results: We use the Input Output Kernel Regression method to learn the mapping between tandem
mass spectra and molecular structures. The principle of this method is to encode the similarities in
the input (spectra) space and the similarities in the output (molecule) space using two kernel func-
tions. This method approximates the spectra-molecule mapping in two phases. The ﬁrst phase
corresponds to a regression problem from the input space to the feature space associated to the
output kernel. The second phase is a preimage problem, consisting in mapping back the predicted
output feature vectors to the molecule space. We show that our approach achieves state-of-the-art
accuracy in metabolite identiﬁcation. Moreover, our method has the advantage of decreasing
the running times for the training step and the test step by several orders of magnitude



hal_id    :    hal-01216708



In this paper, we introduce a novel approach, called Input Output Kernel Regression
(IOKR), for learning mappings between structured inputs and structured outputs. The
approach belongs to the family of Output Kernel Regression methods devoted to regres-
sion in feature space endowed with some output kernel. In order to take into account
structure in input data and beneﬁt from kernels in the input space as well, we use the
Reproducing Kernel Hilbert Space theory for vector-valued functions. We ﬁrst recall the
ridge solution for supervised learning and then study the regularized hinge loss-based
solution used in Maximum Margin Regression. Both models are also developed in the
context of semi-supervised setting. We also derive an extension of Generalized Cross
Validation for model selection in the case of the least-square model. Finally we show
the versatility of the IOKR framework on two diﬀerent problems: link prediction seen
as a structured output problem and multi-task regression seen as a multiple and inter-
dependent output problem. Eventually, we present a set of detailed numerical results
that shows the relevance of the method on these two tasks.
1



hal_id    :    hal-04762097



We introduce Annealed Multiple Choice Learning (aMCL) which combines simu-
lated annealing with MCL. MCL is a learning framework handling ambiguous tasks
by predicting a small set of plausible hypotheses. These hypotheses are trained
using the Winner-takes-all (WTA) scheme, which promotes the diversity of the
predictions. However, this scheme may converge toward an arbitrarily suboptimal
local minimum, due to the greedy nature of WTA. We overcome this limitation
using annealing, which enhances the exploration of the hypothesis space during
training. We leverage insights from statistical physics and information theory
to provide a detailed description of the model training trajectory. Additionally,
we validate our algorithm by extensive experiments on synthetic datasets, on the
standard UCI benchmark, and on speech separation.
1



hal_id    :    hal-04736454



—This paper describes speech enhancement for real-
time automatic speech recognition (ASR) in real environments.
A standard approach to this task is to use neural beamforming
that can work efficiently in an online manner. It estimates the
masks of clean dry speech from a noisy echoic mixture spectro-
gram with a deep neural network (DNN) and then computes a
enhancement filter used for beamforming. The performance of
such a supervised approach, however, is drastically degraded un-
der mismatched conditions. This calls for run-time adaptation
of the DNN. Although the ground-truth speech spectrogram re-
quired for adaptation is not available at run time, blind dere-
verberation and separation methods such as weighted prediction
error (WPE) and fast multichannel nonnegative matrix factor-
ization (FastMNMF) can be used for generating pseudo ground-
truth data from a mixture. Based on this idea, a prior work pro-
posed a dual-process system based on a cascade of WPE and
minimum variance distortionless response (MVDR) beamform-
ing asynchronously fine-tuned by block-online FastMNMF. To in-
tegrate the dereverberation capability into neural beamforming
and make it fine-tunable at run time, we propose to use weighted
power minimization distortionless response (WPD) beamforming,
a unified version of WPE and minimum power distortionless re-
sponse (MPDR), whose joint dereverberation and denoising filter
is estimated using a DNN. We evaluated the impact of run-time
adaptation under various



hal_id    :    hal-04768296



In this paper, we propose a novel Self-Supervised-
Learning scheme to train rhythm analysis systems and
instantiate it for few-shot beat tracking.
Taking inspi-
ration from the Contrastive Predictive Coding paradigm,
we propose to train a Log-Mel-Spectrogram-Transformer-
encoder to contrast observations at times separated by hy-
pothesized beat intervals from those that are not. We do
this without the knowledge of ground-truth tempo or beat
positions, as we rely on the local maxima of a Predomi-
nant Local Pulse function, considered as a proxy for Tatum
positions, to define candidate anchors, candidate positives
(located at a distance of a power of two from the anchor)
and negatives (remaining time positions). We show that
a model pre-trained using this approach on the unlabeled
FMA, MTT and MTG-Jamendo datasets can successfully
be fine-tuned in the few-shot regime, i.e. with just a few
annotated examples to get a competitive beat-tracking per-
formance.
1



hal_id    :    hal-04665063



The task of music structure analysis has been mostly
addressed as a sequential problem, by relying on the inter-
nal homogeneity of musical sections or their repetitions.
In this work, we instead regard it as a pairwise link pre-
diction task. If for any pair of time instants in a track, one
can successfully predict whether they belong to the same
structural entity or not, then the underlying structure can
be easily recovered. Building upon this assumption, we
propose a method that first learns to classify pairwise links
between time frames as belonging to the same section (or
segment) or not. The resulting link features, along with
node-specific information, are combined through a graph
attention network. The latter is regularized with a graph
partitioning training objective and outputs boundary loca-
tions between musical segments and section labels. The
overall system is lightweight and performs competitively
with previous methods.
The evaluation is done on two
standard datasets for music structure analysis and an ab-
lation study is conducted in order to gain insight on the
role played by its different components.



hal_id    :    hal-04695595



Machine listening systems often rely on fixed taxonomies to or-
ganize and label audio data, key for training and evaluating deep
neural networks (DNNs) and other supervised algorithms. How-
ever, such taxonomies face significant constraints: they are com-
posed of application-dependent predefined categories, which hin-
ders the integration of new or varied sounds, and exhibits limited
cross-dataset compatibility due to inconsistent labeling standards.
To overcome these limitations, we introduce SALT: Standardized
Audio event Label Taxonomy. Building upon the hierarchical struc-
ture of AudioSet’s ontology, our taxonomy extends and standardizes
labels across 24 publicly available environmental sound datasets, al-
lowing the mapping of class labels from diverse datasets to a unified
system. Our proposal comes with a new Python package designed
for navigating and utilizing this taxonomy, easing cross-dataset la-
bel searching and hierarchical exploration. Notably, our package
allows effortless data aggregation from diverse sources, hence easy
experimentation with combined datasets.
Index Terms— Machine listening, DCASE, sound taxonomy,
sound categorization, data aggregation



hal_id    :    hal-04701759



Audio-text models trained via contrastive learning offer a practical
approach to perform audio classiﬁcation through natural language
prompts, such as “this is a sound of” followed by category names. In
this work, we explore alternative prompt templates for zero-shot au-
dio classiﬁcation, demonstrating the existence of higher-performing
options. First, we ﬁnd that the formatting of the prompts signif-
icantly affects performance so that simply prompting the models
with properly formatted class labels performs competitively with
optimized prompt templates and even prompt ensembling. More-
over, we look into complementing class labels by audio-centric de-
scriptions. By leveraging large language models, we generate tex-
tual descriptions that prioritize acoustic features of sound events
to disambiguate between classes, without extensive prompt engi-
neering. We show that prompting with class descriptions leads to
state-of-the-art results in zero-shot audio classiﬁcation across ma-
jor ambient sound datasets. Remarkably, this method requires no
additional training and remains fully zero-shot.
Index Terms— Zero-shot audio classiﬁcation, audio-text mod-
els, contrastive language-audio pretraining, in-context learning



hal_id    :    hal-04720291



The Prototypical Network (ProtoNet) has emerged as a popular
choice in Few-shot Learning (FSL) scenarios due to its remark-
able performance and straightforward implementation.
Building
upon such success, we first propose a simple (yet novel) method
to fine-tune a ProtoNet on the (labeled) support set of the test
episode of a C-way-K-shot test episode (without using the query
set which is only used for evaluation). We then propose an algo-
rithmic framework that combines ProtoNet with optimization-based
FSL algorithms (MAML and Meta-Curvature) to work with such
a fine-tuning method. Since optimization-based algorithms endow
the target learner model with the ability to fast adaption to only a
few samples, we utilize ProtoNet as the target model to enhance
its fine-tuning performance with the help of a specifically designed
episodic fine-tuning strategy. The experimental results confirm that
our proposed models, MAML-Proto and MC-Proto, combined with
our unique fine-tuning method, outperform regular ProtoNet by a
large margin in few-shot audio classification tasks on the ESC-50
and Speech Commands v2 datasets. We note that although we have
only applied our model to the audio domain, it is a general method
and can be easily extended to other domains.
Index Terms— Few-shot learning, Audio classification, Proto-
typical Network, Model-Agnostic Meta-Learning, Meta-Curvature



hal_id    :    hal-04685184



As diffusion-based deep generative models gain prevalence, re-
searchers are actively investigating their potential applications
across various domains, including music synthesis and style al-
teration. Within this work, we are interested in timbre transfer, a
process that involves seamlessly altering the instrumental character-
istics of musical pieces while preserving essential musical elements.
This paper introduces WaveTransfer, an end-to-end diffusion model
designed for timbre transfer. We specifically employ the bilateral
denoising diffusion model (BDDM) for noise scheduling search.
Our model is capable of conducting timbre transfer between audio
mixtures as well as individual instruments. Notably, it exhibits ver-
satility in that it accommodates multiple types of timbre transfer
between unique instrument pairs in a single model, eliminating the
need for separate model training for each pairing.
Furthermore,
unlike recent works limited to 16 kHz, WaveTransfer can be trained
at various sampling rates, including the industry-standard 44.1 kHz,
a feature of particular interest to the music community.
Index Terms— Multi-instrumental timbre transfer, diffusion
models, music transformation, generative AI



hal_id    :    hal-04632526



This paper describes a method for estimating the room impulse
response (RIR) for a microphone and a sound source located at
arbitrary positions from the 3D mesh data of the room. Simulat-
ing realistic RIRs with pure physics-driven methods often fails
the balance between physical consistency and computational ef-
ficiency, hindering application to real-time speech processing.
Alternatively, one can use MESH2IR, a fast black-box estima-
tor that consists of an encoder extracting latent code from mesh
data with a graph convolutional network (GCN) and a decoder
generating the RIR from the latent code. Combining these two
approaches, we propose a fast yet physically coherent estimator
with interpretable latent code based on differentiable digital sig-
nal processing (DDSP). Specifically, the encoder estimates a vir-
tual shoebox room scene that acoustically approximates the real
scene, accelerating physical simulation with the differentiable
image-source model in the decoder. Our experiments showed
that our method outperformed MESH2IR for real mesh data ob-
tained with the depth scanner of Microsoft HoloLens 2, and can
provide correct spatial consistency for binaural RIRs.
Index Terms: Spatial audio, room acoustics, 3D mesh data,
physical models, DDSP



hal_id    :    hal-04640068



Single-channel speech dereverberation aims at extracting a
dry speech signal from a recording affected by the acoustic re-
flections in a room. However, most current deep learning-based
approaches for speech dereverberation are not interpretable for
room acoustics, and can be considered as black-box systems
in that regard. In this work, we address this problem by regu-
larizing the training loss using a novel physical coherence loss
which encourages the room impulse response (RIR) induced by
the dereverberated output of the model to match the acoustic
properties of the room in which the signal was recorded. Our
investigation demonstrates the preservation of the original dere-
verberated signal alongside the provision of a more physically
coherent RIR.
Index Terms: Speech dereverberation, hybrid deep learning,
room acoustics, acoustic matching, speech processing



hal_id    :    hal-04705811



—Latent representation learning has been an active
field of study for decades in numerous applications. Inspired
among others by the tokenization from Natural Language
Processing and motivated by the research of a simple data
representation, recent works have introduced a quantization step
into the feature extraction. In this work, we propose a novel
strategy to build the neural discrete representation by means of
random codebooks. These codebooks are obtained by randomly
sampling a large, predefined fixed codebook. We experimentally
show the merits and potential of our approach in a task of audio
compression and reconstruction.
Index Terms—feature extraction, quantization, random code-
books, audio reconstruction



hal_id    :    hal-04614241



—This paper addresses the challenge of estimating
multiple highly oscillating amplitudes within the nonlinear chirp
signal model. The problem is analogous to the mode detection
task with fixed instantaneous frequencies, where the oscillating
amplitudes signify mechanical vibrations concealing crucial infor-
mation for predictive maintenance. Existing methods often focus
on single-frequency estimation, employ simple amplitude func-
tions, or impose strong noise assumptions. Furthermore, these
methods frequently rely on arbitrarily chosen hyperparameters,
leading to sub-optimal generalization for a diverse range of am-
plitudes. To address these limitations, our approach introduces
two estimators, based on Capon filters and negative log-likelihood
approaches respectively, that leverage locally stationary assump-
tions and incorporate hyperparameters estimation. The results
demonstrate that, even under challenging conditions, these esti-
mators yield competitive outcomes across various noisy scenarios,
mitigating the drawbacks associated with existing methods.
Index Terms—chirp signal, amplitude estimation, locally sta-
tionary process, filtering, hyperparameters estimation



hal_id    :    hal-04574640



Winner-takes-all training is a simple learning
paradigm, which handles ambiguous tasks by pre-
dicting a set of plausible hypotheses. Recently,
a connection was established between Winner-
takes-all training and centroidal Voronoi tessel-
lations, showing that, once trained, hypotheses
should quantize optimally the shape of the condi-
tional distribution to predict. However, the best
use of these hypotheses for uncertainty quantifi-
cation is still an open question. In this work, we
show how to leverage the appealing geometric
properties of the Winner-takes-all learners for con-
ditional density estimation, without modifying its
original training scheme. We theoretically estab-
lish the advantages of our novel estimator both in
terms of quantization and density estimation, and
we demonstrate its competitiveness on synthetic
and real-world datasets, including audio data.



hal_id    :    halshs-04654217



No abstract found in the PDF.



hal_id    :    hal-04602229



In recent years, significant advances have been made in deep learn-
ing models for audio generation, offering promising tools for mu-
sical creation. In this work, we investigate the use of deep audio
generative models in interactive dance/music performance. We
adopted a performance-led research design approach, establish-
ing an art-research collaboration between a researcher/musician
and a dancer. First, we describe our motion-sound interactive sys-
tem integrating deep audio generative model and propose three
methods for embodied exploration of deep latent spaces. Then, we
detail the creative process for building the performance centered
on the co-design of the system. Finally, we report feedback from
the dancer’s interviews and discuss the results and perspectives.
The code implementation is publicly available on our github1.
CCS CONCEPTS
• Human-centered computing →Sound-based input / output;
Gestural input; Auditory feedback; Collaborative interaction;
• Applied computing →Sound and music computing; • Com-
puting methodologies →Machine learning.
KEYWORDS
dance-music-AI performance, HCI, motion-sound interaction, deep
learning, generative models, embodied exploration, latent space
ACM Reference Format:
Sarah Nabi, Philippe Esling, Geoffroy Peeters, and Frédéric Bevilacqua. 2024.
Embodied exploration of deep latent spaces in interactive dance-music
performance. In 9th International Conference on Movement and Computing
(MOCO ’24), May 30-June 2, 2024, Utrecht, Netherlands. ACM, New York, NY,
USA, 9 pages. https://doi.org/10.1145/3658852.3659072
1https://github.com/ircam-ismm/embodied-latent-exploration
Permission to make digital or hard copies of all or part of this work for personal or
classroom



hal_id    :    hal-04541350



Isolating the desired speaker’s voice amidst multiple
speakers in a noisy acoustic context is a challenging task. Per-
sonalized speech enhancement (PSE) endeavours to achieve
this by leveraging prior knowledge of the speaker’s voice.
Recent research efforts have yielded promising PSE mod-
els, albeit often accompanied by computationally intensive
architectures, unsuitable for resource-constrained embedded
devices. In this paper, we introduce a novel method to per-
sonalize a lightweight dual-stage Speech Enhancement (SE)
model and implement it within DeepFilterNet2, a SE model
renowned for its state-of-the-art performance. We seek an
optimal integration of speaker information within the model,
exploring different positions for the integration of the speaker
embeddings within the dual-stage enhancement architec-
ture. We also investigate a tailored training strategy when
adapting DeepFilterNet2 to a PSE task. We show that our
personalization method greatly improves the performances
of DeepFilterNet2 while preserving minimal computational
overhead.
Index Terms— Target speech extraction, speech en-
hancement, real-time.



hal_id    :    hal-04358467



In neural audio signal processing, pitch conditioning has been
used to enhance the performance of synthesizers. However, jointly
training pitch estimators and synthesizers is a challenge when us-
ing standard audio-to-audio reconstruction loss, leading to reliance
on external pitch trackers. To address this issue, we propose us-
ing a spectral loss function inspired by optimal transportation theory
that minimizes the displacement of spectral energy. We validate this
approach through an unsupervised autoencoding task that fits a har-
monic template to harmonic signals. We jointly estimate the funda-
mental frequency and amplitudes of harmonics using a lightweight
encoder and reconstruct the signals using a differentiable harmonic
synthesizer. The proposed approach offers a promising direction for
improving unsupervised parameter estimation in neural audio appli-
cations.
Index Terms— differentiable signal processing, machine learn-
ing, optimal transport, frequency estimation



hal_id    :    hal-04424100



Diffusion models are receiving a growing interest for a variety of
signal generation tasks such as speech or music synthesis. WaveG-
rad, for example, is a successful diffusion model that conditionally
uses the mel spectrogram to guide a diffusion process for the gen-
eration of high-fidelity audio. However, such models face important
challenges concerning the noise diffusion process for training and
inference, and they have difficulty generating high-quality speech
for speakers that were not seen during training. With the aim of
minimizing the conditioning error and increasing the efficiency of
the noise diffusion process, we propose in this paper a new scheme
called GLA-Grad, which consists in introducing a phase recovery al-
gorithm such as the Griffin-Lim algorithm (GLA) at each step of the
regular diffusion process. Furthermore, it can be directly applied to
an already-trained waveform generation model, without additional
training or fine-tuning. We show that our algorithm outperforms
state-of-the-art diffusion models for speech generation, especially
when generating speech for a previously unseen target speaker.
Index Terms— Diffusion models, speech generation, Griffin-
Lim algorithm, domain adaptation



hal_id    :    hal-04360221



Current state-of-the-art audio analysis systems rely on pre-
trained embedding models, often used off-the-shelf as (frozen)
feature extractors. Choosing the best one for a set of tasks is the
subject of many recent publications.
However, one aspect often
overlooked in these works is the influence of the duration of audio
input considered to extract an embedding, which we refer to as Tem-
poral Support (TS). In this work, we study the influence of the TS
for well-established or emerging pre-trained embeddings, chosen to
represent different types of architectures and learning paradigms.
We conduct this evaluation using both musical instrument and envi-
ronmental sound datasets, namely OpenMIC, TAU Urban Acoustic
Scenes 2020 Mobile, and ESC-50. We especially highlight that Au-
dio Spectrogram Transformer-based systems (PaSST and BEATs)
remain effective with smaller TS, which therefore allows for a dras-
tic reduction in memory and computational cost.
Moreover, we
show that by choosing the optimal TS we reach competitive results
across all tasks. In particular, we improve the state-of-the-art results
on OpenMIC, using BEATs and PaSST without any fine-tuning.
Index Terms— audio embeddings, acoustic scene classification,
instrument recognition, temporal support, transformers



hal_id    :    hal-04479188



We address the problem of accurately interpolating measured ane-
choic steering vectors with a deep learning framework called the
neural field. This task plays a pivotal role in reducing the resource-
intensive measurements required for precise sound source separa-
tion and localization, essential as the front-end of speech recogni-
tion. Classical approaches to interpolation rely on linear weighting of
nearby measurements in space on a fixed, discrete set of frequencies.
Drawing inspiration from the success of neural fields for novel view
synthesis in computer vision, we introduce the neural steerer, a con-
tinuous complex-valued function that takes both frequency and direc-
tion as input and produces the corresponding steering vector. Impor-
tantly, it incorporates inter-channel phase difference information and
a regularization term enforcing filter causality, essential for accurate
steering vector modeling. Our experiments, conducted using a dataset
of real measured steering vectors, demonstrate the effectiveness of
our resolution-free model in interpolating such measurements.
Index Terms— Steering vector, neural field, spatial audio, inter-
polation, representation learning



hal_id    :    hal-04423979



Generative adversarial network (GAN) models can synthesize high-
quality audio signals while ensuring fast sample generation. How-
ever, they are difficult to train and are prone to several issues in-
cluding mode collapse and divergence. In this paper, we introduce
SpecDiff-GAN, a neural vocoder based on HiFi-GAN, which was
initially devised for speech synthesis from mel spectrogram. In our
model, the training stability is enhanced by means of a forward dif-
fusion process which consists in injecting noise from a Gaussian
distribution to both real and fake samples before inputting them to
the discriminator. We further improve the model by exploiting a
spectrally-shaped noise distribution with the aim to make the dis-
criminator’s task more challenging. We then show the merits of our
proposed model for speech and music synthesis on several datasets.
Our experiments confirm that our model compares favorably in au-
dio quality and efficiency compared to several baselines.
Index Terms— Generative adversarial network (GAN), diffu-
sion process, deep audio synthesis, spectral envelope



hal_id    :    hal-04419041



Overlapped speech is notoriously problematic for speaker diarization
systems. Consequently, the use of speech separation has recently
been proposed to improve their performance. Although promising,
speech separation models struggle with realistic data because they
are trained on simulated mixtures with a fixed number of speakers. In
this work, we introduce a new speech separation-guided diarization
scheme suitable for the online speaker diarization of long meeting
recordings with a variable number of speakers, as present in the AMI
corpus. We envisage ConvTasNet and DPRNN as alternatives for the
separation networks, with two or three output sources. To obtain the
speaker diarization result, voice activity detection is applied on each
estimated source. The final model is fine-tuned end-to-end, after first
adapting the separation to real data using AMI. The system operates
on short segments, and inference is performed by stitching the local
predictions using speaker embeddings and incremental clustering.
The results show that our system improves the state-of-the-art on
the AMI headset mix, using no oracle information and under full
evaluation (no collar and including overlapped speech). Finally, we
show the strength of our system particularly on overlapped speech
sections.
Index Terms— online speaker diarization, source separation,
overlapped speech, AMI, speaker embedding



hal_id    :    hal-04432659



Music generated by deep learning methods often suffers
from a lack of coherence and long-term organization. Yet,
multi-scale hierarchical structure is a distinctive feature of
music signals. To leverage this information, we propose a
structure-informed positional encoding framework for music
generation with Transformers. We design three variants in
terms of absolute, relative and non-stationary positional in-
formation. We comprehensively test them on two symbolic
music generation tasks: next-timestep prediction and accom-
paniment generation.
As a comparison, we choose multi-
ple baselines from the literature and demonstrate the merits
of our methods using several musically-motivated evaluation
metrics. In particular, our methods improve the melodic and
structural consistency of the generated pieces.
Index Terms— symbolic music generation, Transform-
ers, music structure, positional encoding



hal_id    :    hal-04423348



. With the progress of generative neural models, Hierarchical Text Classification
(HTC) can be cast as a generative task. In this case, given an input text, the model generates
the sequence of predicted class labels taken from a label tree of arbitrary width and depth.
Treating HTC as a generative task introduces multiple modeling choices. These choices vary
from choosing the order for visiting the class tree and therefore defining the order of generat-
ing tokens, choosing either to constrain the decoding to labels that respect the previous level
predictions, up to choosing the pre-trained Language Model itself. Each HTC model therefore
differs from the others from an architectural standpoint, but also from the modeling choices
that were made. Prior contributions lack transparent modeling choices and open implemen-
tations, hindering the assessment of whether model performance stems from architectural or
modeling decisions. For these reasons, we propose with this paper an analysis of the impact
of different modeling choices along with common model errors and successes for this task.
This analysis is based on an open framework coming along this paper that can facilitate the
development of future contributions in the field by providing datasets, metrics, error analysis
toolkit and the capability to readily test various modeling choices for one given model.
Keywords: Hierarchical text



hal_id    :    hal-04604650



. In recent years, there has been a signicant surge in machine
learning techniques, particularly in the domain of deep learning, tailored
for handling attributed graphs. Nevertheless, to work, these methods as-
sume that the attributes values are fully known, which is not realistic
in numerous real-world applications. This paper explores the potential
of Optimal Transport (OT) to impute missing attributes on graphs. To
proceed, we design a novel multi-view OT loss function that can encom-
pass both node feature data and the underlying topological structure of
the graph by utilizing multiple graph representations. We then utilize
this novel loss to train eciently a Graph Convolutional Neural Net-
work (GCN) architecture capable of imputing all missing values over the
graph at once. We evaluate the interest of our approach with experiments
both on synthetic data and real-world graphs, including dierent miss-
ingness mechanisms and a wide range of missing data. These experiments
demonstrate that our method is competitive with the state-of-the-art in
all cases and of particular interest on weakly homophilic graphs.
Keywords: Attributed Graph · Missing Data Imputation · Optimal
Transport
1



hal_id    :    hal-04575332



We consider the statistical seriation problem, where the statistician seeks to recover a
hidden ordering from a noisy observation of a permuted Robinson matrix. In this paper,
we tightly characterize the minimax rate for this problem of matrix reordering when
the Robinson matrix is bi-Lipschitz, and we also provide a polynomial time algorithm
achieving this rate; thereby answering two open questions of [Giraud et al., 2021]. Our
analysis further extends to broader classes of similarity matrices.
1



hal_id    :    hal-04729913



Multimodal large language models have fueled progress in image captioning.
These models, fine-tuned on vast image datasets, exhibit a deep understanding
of semantic concepts. In this work, we show that this ability can be re-purposed
for audio captioning, where the joint image-language decoder can be leveraged to
describe auditory content associated with image sequences within videos featuring
audiovisual content. This can be achieved via multimodal alignment. Yet, this
multimodal alignment task is non-trivial due to the inherent disparity between
audible and visible elements in real-world videos. Moreover, multimodal repre-
sentation learning often relies on contrastive learning, facing the challenge of the
so-called modality gap which hinders smooth integration between modalities. In
this work, we introduce a novel methodology for bridging the audiovisual modality
gap by matching the distributions of tokens produced by an audio backbone and
those of an image captioner. Our approach aligns the audio token distribution
with that of the image tokens, enabling the model to perform zero-shot audio
captioning in an unsupervised fashion while keeping the initial image captioning
component unaltered. This alignment allows for the use of either audio or audiovi-
sual input by combining or substituting the image encoder with the aligned audio
encoder. Our method achieves significantly improved performances in zero-shot
audio captioning, compared to existing approaches.1
1



hal_id    :    hal-04593480



When deriving contextualized word repre-
sentations from language models, a decision
needs to be made on how to obtain one for
out-of-vocabulary (OOV) words that are seg-
mented into subwords. What is the best way
to represent these words with a single vector,
and are these representations of worse quality
than those of in-vocabulary words? We carry
out an intrinsic evaluation of embeddings from
different models on semantic similarity tasks
involving OOV words. Our analysis reveals,
among other interesting findings, that the qual-
ity of representations of words that are split is
often, but not always, worse than that of the
embeddings of known words. Their similar-
ity values, however, must be interpreted with
caution.
1



hal_id    :    hal-04578273



. The pair-matching problem appears in many applications where one wants to discover
matches between pairs of entities or individuals. Formally, the set of individuals is represented by
the nodes of a graph where the edges, unobserved at first, represent the matches. The algorithm
queries pairs of nodes and observes the presence/absence of edges. Its goal is to discover as
many edges as possible with a fixed budget of queries. Pair-matching is a particular instance of
multi-armed bandit problem in which the arms are pairs of individuals and the rewards are edges
linking these pairs. This bandit problem is non-standard though, as each arm can only be played
once.
Given this last constraint, sublinear regret can be expected only if the graph presents some
underlying structure. This paper shows that sublinear regret is achievable in the case where
the graph is generated according to a Stochastic Block Model (SBM) with two communities.
Optimal regret bounds are computed for this pair-matching problem. They exhibit a phase trans-
ition related to the Kesten-Stigum threshold for community detection in SBM. The pair-matching
problem is considered in the case where each node is constrained to be sampled less than a given
amount of times, for example for ensuring individual fairness. We show how optimal regret rates
depend on this



hal_id    :    hal-04539879



—This paper tackles two major problem settings for
interpretability of audio processing networks, post-hoc and by-
design interpretation. For post-hoc interpretation, we aim to in-
terpret decisions of a network in terms of high-level audio objects
that are also listenable for the end-user. This is extended to
present an inherently interpretable model with high performance.
To this end, we propose a novel interpreter design that incor-
porates non-negative matrix factorization (NMF). In particular,
an interpreter is trained to generate a regularized intermediate
embedding from hidden layers of a target network, learnt as time-
activations of a pre-learnt NMF dictionary. Our methodology
allows us to generate intuitive audio-based interpretations that
explicitly enhance parts of the input signal most relevant for a
network’s decision. We demonstrate our method’s applicability
on a variety of classification tasks, including multi-label data for
real-world audio and music.
Index Terms—Audio interpretability, explainability, by-design
interpretable models, audio convolutional networks, non-negative
matrix factorization



hal_id    :    hal-03615137



—Tensor factorization models are widely used in many
applied ﬁelds such as chemometrics, psychometrics, computer
vision or communication networks. Real life data collection is
often subject to errors, resulting in missing data. Here we focus
in understanding how this issue should be dealt with for non-
negative tensor factorization. We investigate several criteria used
for non-negative tensor factorization in the case where some
entries are missing. In particular we show how smoothness
penalties can compensate the presence of missing values in order
to ensure the existence of an optimum. This lead us to propose
new criteria with efﬁcient numerical optimization algorithms.
Numerical experiments are conducted to support our claims.
Index Terms—Non-negative tensor decomposition, missing val-
ues, Tensor completion, smoothness, PARAFAC, CP decomposi-
tion.



hal_id    :    hal-04410338



Seals are small coin-shaped artifacts, mostly made of lead, held with strings to seal letters.
This work presents the first attempt towards automatic reading of text on Byzantine seal
images. Byzantine seals are generally decorated with iconography on the obverse side and
Greek text on the reverse side. Text may include the sender’s name, position in the Byzantine
aristocracy, and elements of prayers. Both text and iconography are precious literary sources
that wait to be exploited electronically, so the development of computerized systems for
interpreting seals images is of paramount importance. This work’s contribution is hence a
deep, two-stages, character reading pipeline for transcribing Byzantine seal images. A first deep
convolutional neural network (CNN) detects characters in the seal (character localization). A
second convolutional network reads the localized characters (character classification). Finally, a
diplomatic transcription of the seal is provided by post-processing the two network outputs. We
provide an experimental evaluation of each CNN in isolation and both CNNs in combination. All
performances are evaluated by cross-validation. Character localization achieves a mean average
precision (mAP@0.5) greater than 0.9. Classification of characters cropped from ground truth
bounding boxes achieves Top-1 accuracy greater than 0.92. End-to-end evaluation shows the
efficiency of the proposed approach when compared to the SoTA for similar tasks.



hal_id    :    hal-04552478



Data augmentation is an essential building block for learning efﬁcient deep learning
models. Among all augmentation techniques proposed so far, linear interpolation
of training data points, also called mixup, has found to be effective for a large
panel of applications. While the majority of works have focused on selecting
the right points to mix, or applying complex non-linear interpolation, we are
interested in mixing similar points more frequently and strongly than less similar
ones. To this end, we propose to dynamically change the underlying distribution of
interpolation coefﬁcients through warping functions, depending on the similarity
between data points to combine. We deﬁne an efﬁcient and ﬂexible framework to do
so without losing in diversity. We provide extensive experiments for classiﬁcation
and regression tasks, showing that our proposed method improves both performance
and calibration of models. Code available in torch-uncertainty.
1



hal_id    :    hal-04390768



Group fairness is a central research topic in
text classification, where reaching fair treat-
ment between sensitive groups (e.g. women
vs. men) remains an open challenge. This
paper presents a novel method for mitigating
biases in neural text classification, agnostic to
the model architecture. Considering the diffi-
culty to distinguish fair from unfair informa-
tion in a text encoder, we take inspiration from
adversarial training to induce Wasserstein in-
dependence between representations learned to
predict our target label and the ones learned to
predict some sensitive attribute. Our approach
provides two significant advantages. Firstly,
it does not require annotations of sensitive at-
tributes in both testing and training data. This is
more suitable for real-life scenarios compared
to existing methods that require annotations
of sensitive attributes at train time. Secondly,
our approach exhibits a comparable or better
fairness-accuracy trade-off compared to exist-
ing methods. Our implementation is available
on Github1.
1



hal_id    :    hal-04216055



We introduce Resilient Multiple Choice Learning (rMCL), an extension of the
MCL approach for conditional distribution estimation in regression settings where
multiple targets may be sampled for each training input. Multiple Choice Learning
is a simple framework to tackle multimodal density estimation, using the Winner-
Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing
MCL variants focus on merging the hypotheses, thereby eventually sacriﬁcing
the diversity of the predictions. In contrast, our method relies on a novel learned
scoring scheme underpinned by a mathematical framework based on Voronoi tessel-
lations of the output space, from which we can derive a probabilistic interpretation.
After empirically validating rMCL with experiments on synthetic data, we further
assess its merits on the sound source localization task, demonstrating its practical
usefulness and the relevance of its interpretation.
1



hal_id    :    hal-04172863



This paper revisits single-channel audio source separation based on
a probabilistic generative model of a mixture signal defined in the
continuous time domain. We assume that each source signal fol-
lows a non-stationary Gaussian process (GP), i.e., any finite set of
sampled points follows a zero-mean multivariate Gaussian distribu-
tion whose covariance matrix is governed by a kernel function over
time-varying latent variables. The mixture signal composed of such
source signals thus follows a GP whose covariance matrix is given
by the sum of the source covariance matrices. To estimate the latent
variables from the mixture signal, we use a deep neural network with
an encoder-separator-decoder architecture (e.g., Conv-TasNet) that
separates the latent variables in a pseudo-time-frequency space. The
key feature of our method is to feed the latent variables into the ker-
nel function for estimating the source covariance matrices, instead
of using the decoder for directly estimating the time-domain source
signals. This enables the decomposition of a mixture signal into the
source signals with a classical yet powerful Wiener filter that consid-
ers the full covariance structure over all samples. The kernel func-
tion and the network are trained jointly in the maximum likelihood
framework. Comparative experiments using two-speech mixtures
under clean, noisy, and noisy-reverberant conditions from the WSJ0-
2mix, WHAM!, and WHAMR! benchmark datasets demonstrated
that the proposed method



hal_id    :    hal-04135264



BHAI 1 (Byzantine Hybrid Artificial Intelligence) is the first project
based on artificial intelligence dedicated to Byzantine seals. The
scientific consortium comprises a multidisciplinary team involving
historians specialized in the Byzantine period, specialists in sig-
illography, and computer science experts. This article describes the
main objectives of this project: data acquisition of seal images, text
and iconography recognition, seal dating, as well as our current
achievements and first results on character recognition and spatial
analysis of personages.
CCS CONCEPTS
• Applied computing →Arts and humanities; • Computing
methodologies →Spatial and physical reasoning; Semantic
networks; Natural language processing.
KEYWORDS
Byzantine Greek, Byzantine history, seal images, deep neural net-
works, character recognition, iconography recognition
ACM Reference Format:
Victoria EYHARABIDE, Laurence LIKFORMAN-SULEM, Lucia ORLANDI,
Alexandre BINOUX, Théophile RAGEAU, Qijia HUANG, Attilio FIAN-
DROTTI, Beatrice CASEAU, and Isabelle BLOCH. 2023. Study of historical
Byzantine seal images: the BHAI project for computer-based sigillography.
In 7th International Workshop on Historical Document Imaging and Processing
(HIP ’23), August 25–26, 2023, San Jose, CA, USA. ACM, New York, NY, USA,
6 pages. https://doi.org/10.1145/3604951.3605523
1



hal_id    :    hal-04216177



Self-Supervised Learning (SSL) has allowed leveraging large
amounts of unlabeled speech data to improve the perfor-
mance of speech recognition models even with small annotated
datasets.
Despite this, speech SSL representations may fail
while facing an acoustic mismatch between the pretraining and
target datasets. To address this issue, we propose a novel super-
vised domain adaptation method, designed for cases exhibiting
such a mismatch in acoustic domains. It consists in applying
properly calibrated data augmentations on a large clean dataset,
bringing it closer to the target domain, and using it as part of
an initial fine-tuning stage. Augmentations are automatically
selected through the minimization of a conditional-dependence
estimator, based on the target dataset. The approach is vali-
dated during an oracle experiment with controlled distortions
and on two amateur-collected low-resource domains, reaching
better performances compared to the baselines in both cases.
Index Terms: self-supervised learning, domain adaptation.



hal_id    :    hal-04593478



Dialog participants sometimes align their lin-
guistic styles, e.g., they use the same words
and syntactic constructions as their interlocu-
tors. We propose to investigate the notion of
lexico-semantic alignment: to what extent do
speakers convey the same meaning when they
use the same words? We design measures of
lexico-semantic alignment relying on contextu-
alized word representations. We show that they
reflect interesting semantic differences between
the two sides of a debate and that they can assist
in the task of debate’s winner prediction.
1



hal_id    :    hal-04131585



No abstract found in the PDF.



hal_id    :    hal-04130213



La façon dont nous utilisons les mots est influencée par notre opinion. Nous cherchons à savoir si cela
se reflète dans les plongements de mots contextualisés. Par exemple, la représentation d’ « animal »
est-elle différente pour les gens qui voudraient abolir les zoos et ceux qui ne le voudraient pas? Nous
explorons cette question du point de vue du changement sémantique des mots. Nos expériences avec
des représentations dérivées d’ensembles de données annotés avec les points de vue révèlent des
différences minimes, mais significatives, entre postures opposées 1.
ABSTRACT
One Word, Two Sides : Traces of Stance in Contextualized Word Representations
The way we use words is influenced by our opinion. We investigate whether this is reflected in
contextualized word embeddings. For example, is the representation of “animal” different between
people who would abolish zoos and those who would not? We explore this question from a Lexical
Semantic Change standpoint. Our experiments with BERT embeddings derived from datasets with
stance annotations reveal small but significant differences in word representations between opposing
stances.
MOTS-CLÉS : Représentations contextualisées, changement sémantique, détection de point de vue.
KEYWORDS: Contextualized representations, semantic change, stance detection.
1



hal_id    :    hal-04093374



Measuring noise in cities and automatically identifying the cor-
responding sound sources are a crucial challenge for policymak-
ers. Indeed, such information helps addressing noise pollution and
improving the well-being of urban dwellers. In recent years, re-
searchers have provided annotated datasets recorded in two ma-
jor cities to foster the development of urban sound event detection
(SED) systems. This paper presents an in-depth study of the be-
haviour of state-of-the-art SED systems well suited to our problem,
combining three far-field real recordings datasets which can be used
jointly during training. In our evaluation, we highlight the perfor-
mance gaps existing between simple and hard recording examples
based on the salience of sound events and the polyphony of the
recordings. We provide new proximity annotations for this anal-
ysis. We evaluate the ability of urban SED systems to generalize
across cities with varying degrees of training supervision. We show
that such generalization is hindered mostly by the difficulties current
urban SED systems have to detect sound events with low salience
along with sound events in highly polyphonic soundscapes.
Index Terms— Sound Event Detection (SED), Far-field urban
audio recordings, urban sound monitoring,



hal_id    :    ujm-04165556



. In contrast to classic autoregressive generation, insertion-
based models can predict in a order-free way multiple tokens at a time,
which make their generation uniquely controllable: it can be constrained
to strictly include an ordered list of tokens. We propose to exploit this
feature in a new diverse paraphrasing framework: ﬁrst, we extract im-
portant tokens or keywords in the source sentence; second, we augment
them; third, we generate new samples around them by using insertion
models. We show that the generated paraphrases are competitive with
state of the art autoregressive paraphrasers, not only in diversity but also
in quality. We further investigate their potential to create new pseudo-
labelled samples for data augmentation, using a meta-learning classiﬁca-
tion framework, and ﬁnd equally competitive result. In addition to prov-
ing non-autoregressive (NAR) viability for paraphrasing, we contribute
our open-source framework as a starting point for further research into
controllable NAR generation.
Keywords: Deep Learning · Natural language processing · Controllable
text generation · Transformers · Non-autoregressive · Insertion models.
1



hal_id    :    hal-04213215



. In recent years, large Transformer-based Pre-trained Lan-
guage Models (PLM) have changed the Natural Language Processing
(NLP) landscape, by pushing the performance boundaries of the state-
of-the-art on a wide variety of tasks. However, this performance gain goes
along with an increase in complexity, and as a result, the size of such
models (up to billions of parameters) represents a constraint for their
deployment on embedded devices or short-inference time tasks. To cope
with this situation, compressed models emerged (e.g. DistilBERT), de-
mocratizing their usage in a growing number of applications that impact
our daily lives. A crucial issue is the fairness of the predictions made by
both PLMs and their distilled counterparts. In this paper, we propose
an empirical exploration of this problem by formalizing two questions:
(1) Can we identify the neural mechanism(s) responsible for gender bias
in BERT (and by extension DistilBERT)? (2) Does distillation tend to
accentuate or mitigate gender bias (e.g. is DistilBERT more prone to
gender bias than its uncompressed version, BERT)? Our findings are the
following: (I) one cannot identify a specific layer that produces bias; (II)
every attention head uniformly encodes bias; except in the context of un-
derrepresented classes with a high imbalance of the sensitive attribute;
(III) this subset of heads is different as we re-fine tune the



hal_id    :    hal-04253752



Non-deterministic measurements are common in real-world scenarios: the performance
of a stochastic optimization algorithm or the total reward of a reinforcement learning agent
in a chaotic environment are just two examples in which unpredictable outcomes are com-
mon. These measures can be modeled as random variables and compared among each other
via their expected values or more sophisticated tools such as null hypothesis statistical
tests. In this paper, we propose an alternative framework to visually compare two sam-
ples according to their estimated cumulative distribution functions. First, we introduce a
dominance measure for two random variables that quantiﬁes the proportion in which the
cumulative distribution function of one of the random variables stochastically dominates
the other one. Then, we present a graphical method that decomposes in quantiles i) the
proposed dominance measure and ii) the probability that one of the random variables takes
lower values than the other. With illustrative purposes, we re-evaluate the experimentation
of an already published work with the proposed methodology and we show that additional
conclusions—missed by the rest of the methods—can be inferred. Additionally, the software
package RVCompare was created as a convenient way of applying and experimenting with
the proposed framework.
Keywords:
Data visualization, Random variables, Cumulative distribution function, First-order
stochastic dominance
1
arXiv:2203.07889v4  [stat.ML]  30 Aug 2022
0.0225 0.0250 0.0275 0.0300 0.0325



hal_id    :    hal-04244852



Handling large datasets and calculating complex statistics on huge datasets require
important computing resources. Using subsampling methods to calculate statistics
of interest on small samples is often used in practice to reduce computational com-
plexity, for instance using the divide and conquer strategy. In this article, we recall
some results on subsampling distributions and derive a precise rate of convergence
for these quantities and the corresponding quantiles. We also develop some standard-
ization techniques based on subsampling unstandardized statistics in the framework
of large datasets. It is argued that using several subsampling distributions with dif-
ferent subsampling sizes brings a lot of information on the behavior of statistical
learning procedures: subsampling allows to estimate the rate of convergence of dif-
ferent algorithms, to estimate the variability of complex statistics, to estimate conﬁ-
dence intervals for out-of-sample errors and interpolate their values at larger scales.
These results are illustrated on simulations, but also on two important datasets,
frequently analyzed in the statistical learning community, EMNIST (recognition of
digits) and VeReMi (analysis of Network Vehicular Reference Misbehavior).
KEYWORDS
Scaling, big data, Subsampling, Convergence rate estimation, Conﬁdence intervals
in statistical learning, Out-of sample error, EMNIST digits VeReMi



hal_id    :    hal-04310171



Argumentation
. . . . .
51
G. Dubuisson Duplessis, M. Richard, A.-L. Guénet (APIA)
Segmentation de phases de dialogue dans des retranscriptions de conversations de centres
d’appels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
A. Ferdjaoui, S. Affeldt, M. Nadif (SFC)
Modèles graphiques causaux interactifs pour les données textuelles . . . . . . . . . . . . .
65
C. Fèvre, H. Zgaya-Biau, P. Mathieu, S. Hammadi (JFSMA)
L’optimisation du covoiturage dynamique multi-saut . . . . . . . . . . . . . . . . . . . . .
71
S. Forest, J.-C. Quinton, M. Lefort (CNIA)
Champ neuronal et apprentissage profond de topologies pour la fusion multimodale . . . .
81
A. Godinot, E. Le Merrer, C. Penzo, F. Taïani, G. Tredan (RJCIA)
Change-Relaxed Active Fairness Auditing . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
K. Le Gall, L. Bellanger, A. Stamm, D.A. Laplaud (SFC)
Génération de données



hal_id    :    hal-04258177



No abstract found in the PDF.



hal_id    :    hal-04390005



Optimal transport (OT) compares probability distributions by
computing a meaningful alignment between their samples. CO-
optimal transport (COOT) takes this comparison further by
inferring an alignment between features as well. While this ap-
proach leads to better alignments and generalizes both OT and
Gromov-Wasserstein distances, we provide a theoretical result
showing that it is sensitive to outliers that are omnipresent
in real-world data. This prompts us to propose unbalanced
COOT for which we provably show its robustness to noise in
the compared datasets. To the best of our knowledge, this is
the ﬁrst such result for OT methods in incomparable spaces.
With this result in hand, we provide empirical evidence of this
robustness for the challenging tasks of heterogeneous domain
adaptation with and without varying proportions of classes
and simultaneous alignment of samples and features across
single-cell measurements.



hal_id    :    hal-03608767



—This paper introduces a theoretically-rigorous sound
source localization (SSL) method based on a robust extension
of the classical multiple signal classification (MUSIC) algorithm.
The original SSL method estimates the noise eigenvectors and the
MUSIC spectrum by computing the spatial covariance matrix of
the observed multichannel signal and then detects the peaks from
the spectrum. In this work, the covariance matrix is replaced with
the positive definite shape matrix originating from the elliptically
contoured α-stable model, which is more suitable under real
noisy high-reverberant conditions. Evaluation on synthetic data
shows that the proposed method outperforms baseline methods
under such adverse conditions, while it is comparable on real
data recorded in a mild acoustic condition.
Index Terms— sound source localization, MUSIC, α-stable
theory, covariation



hal_id    :    hal-03990543



No abstract found in the PDF.



hal_id    :    hal-03821125



—This article describes a computationally-efﬁcient sta-
tistical approach to joint (semi-)blind source separation and dere-
verberation for multichannel noisy reverberant mixture signals. A
standard approach to source separation is to formulate a generative
model of a multichannel mixture spectrogram that consists of
source and spatial models representing the time-frequency power
spectral densities (PSDs) and spatial covariance matrices (SCMs)
of source images, respectively, and ﬁnd the maximum-likelihood
estimates of these parameters. A state-of-the-art blind source sep-
aration method in this thread of research is fast multichannel
nonnegative matrix factorization (FastMNMF) based on the low-
rank PSDs and jointly-diagonalizable full-rank SCMs. To perform
mutually-dependent separation and dereverberation jointly, in this
paper we integrate both moving average (MA) and autoregressive
(AR) models that represent the early reﬂections and late rever-
berations of sources, respectively, into the FastMNMF formalism.
Using a pretrained deep generative model of speech PSDs as a
source model, we realize semi-blind joint speech separation and
dereverberation. We derive an iterative optimization algorithm
based on iterative projection or iterative source steering for jointly
and efﬁciently updating the AR parameters and the SCMs. Our
experimentalresultsshowedthesuperiorityoftheproposedARMA
extensionoveritsAR-orMA-ablatedversioninaspeechseparation
and/or dereverberation task.
Index Terms—Multichannel audio signal processing, source
separation, dereverberation, joint diagonalization.
Manuscript received 4 October 2021; revised 31 March 2022; accepted 18
June2022.Dateofpublication13July2022;dateofcurrentversion28July2022.
This work was supported in part by JSPS KAKENHI under Grants 19H04137,
20K19833, and 20H01159, and in part by NII



hal_id    :    hal-03657196



—This paper describes heavy-tailed extensions of a
state-of-the-art versatile blind source separation method called
fast multichannel nonnegative matrix factorization (FastMNMF)
from a uniﬁed point of view. The common way of deriving such an
extension is to replace the multivariate complex Gaussian distribu-
tion in the likelihood function with its heavy-tailed generalization,
e.g., the multivariate complex Student’s t and leptokurtic gener-
alized Gaussian distributions, and tailor-make the corresponding
parameter optimization algorithm. Using a wider class of heavy-
tailed distributions called a Gaussian scale mixture (GSM), i.e., a
mixture of Gaussian distributions whose variances are perturbed
by positive random scalars called impulse variables, we propose
GSM-FastMNMF and develop an expectation-maximization algo-
rithm that works even when the probability density function of
the impulse variables have no analytical expressions. We show
that existing heavy-tailed FastMNMF extensions are instances of
GSM-FastMNMF and derive a new instance based on the gen-
eralized hyperbolic distribution that include the normal-inverse
Gaussian, Student’s t, and Gaussian distributions as the special
cases. Our experiments show that the normal-inverse Gaussian
FastMNMF outperforms the state-of-the-art FastMNMF exten-
sions and ILRMA model in speech enhancement and separation
in terms of the signal-to-distortion ratio.
Index Terms—Nonnegative matrix factorization, blind source
separation, probabilistic framework, expectation-maximization



hal_id    :    hal-03860497



, ISMIR 2022 Conference
SSM-NET: FEATURE LEARNING FOR MUSIC STRUCTURE ANALYSIS
USING A SELF-SIMILARITY-MATRIX BASED LOSS
Geoffroy Peeters
LTCI, Télécom-Paris, IP-Paris
geoffroy.peeters@telecom-paris.fr
Florian Angulo
LTCI, Télécom-Paris, IP-Paris
florian.angulo@telecom-paris.fr
ABSTRACT
In this paper, we propose a new paradigm to learn au-
dio features for Music Structure Analysis (MSA).
We
train a deep encoder to learn features such that the Self-
Similarity-Matrix (SSM) resulting from those approxi-
mates a ground-truth SSM. This is done by minimizing
a loss between both SSMs.
Since this loss is differen-
tiable w.r.t. its input features we can train the encoder in a
straightforward way. We successfully demonstrate the use
of this training paradigm using the Area Under the Curve
ROC (AUC) on the RWC-Pop dataset.



hal_id    :    hal-03903647



As music has become more available especially on music
streaming platforms, people have started to have distinct
preferences to fit to their varying listening situations, also
known as context. Hence, there has been a growing inter-
est in considering the user’s situation when recommending
music to users. Previous works have proposed user-aware
autotaggers to infer situation-related tags from music con-
tent and user’s global listening preferences. However, in
a practical music retrieval system, the autotagger could be
only used by assuming that the context class is explicitly
provided by the user. In this work, for designing a fully
automatised music retrieval system, we propose to disam-
biguate the user’s listening information from their stream
data. Namely, we propose a system which can generate a
situational playlist for a user at a certain time 1) by leverag-
ing user-aware music autotaggers, and 2) by automatically
inferring the user’s situation from stream data (e.g. device,
network) and user’s general profile information (e.g. age).
Experiments show that such a context-aware personalized
music retrieval system is feasible, but the performance de-
creases in the case of new users, new tracks or when the
number of context classes increases.



hal_id    :    hal-03782827



Invariance-based learning is a promising approach in deep learning.
Among other benefits, it can mitigate the lack of diversity of avail-
able datasets and increase the interpretability of trained models. To
this end, practitioners often use a consistency cost penalizing the
sensitivity of a model to a set of carefully selected data augmen-
tations. However, there is no consensus about how these augmen-
tations should be selected. In this paper, we study the behavior
of several augmentation strategies. We consider the task of sound
event detection and classification for our experiments. In particular,
we show that transformations operating on the internal layers of a
deep neural network are beneficial for this task.
Index Terms— sound event detection, data augmentation, ad-
versarial learning



hal_id    :    hal-03860830



The way we use words is influenced by our
opinion.
We investigate whether this is re-
flected in contextualized word embeddings.
For example, is the representation of “animal”
different between people who would abolish
zoos and those who would not? We explore
this question from a Lexical Semantic Change
standpoint. Our experiments with BERT em-
beddings derived from datasets with stance
annotations reveal small but significant differ-
ences in word representations between oppos-
ing stances.
1



hal_id    :    hal-03817736



Contrastive learning enables learning useful audio and speech
representations without ground-truth labels by maximizing the
similarity between latent representations of similar signal seg-
ments. In this framework various data augmentation techniques
are usually exploited to help enforce desired invariances within
the learned representations, improving performance on various
audio tasks thanks to more robust embeddings. Now, selecting
the most relevant augmentations has proven crucial for better
downstream performances. Thus, this work introduces a condi-
tional independance-based method which allows for automati-
cally selecting a suitable distribution on the choice of augmenta-
tions and their parametrization from a set of predefined ones, for
contrastive self-supervised pre-training. This is performed with
respect to a downstream task of interest, hence saving a costly
hyper-parameter search. Experiments performed on two differ-
ent downstream tasks validate the proposed approach showing
better results than experimenting without augmentation or with
baseline augmentations. We furthermore conduct a qualitative
analysis of the automatically selected augmentations and their
variation according to the considered final downstream dataset.
Index Terms: self-supervised learning, data augmentation.



hal_id    :    hal-03860827



Our discourses are full of potential lexical ambiguities, due in part to the pervasive use of words having multiple senses.
Sometimes, one word may even be used in more than one sense throughout a text. But, to what extent is this true for different
kinds of texts? Does the use of polysemous words change when a discourse involves two people, or when speakers have time
to plan what to say? We investigate these questions by comparing the polysemy level of texts of different nature, with a focus
on spontaneous spoken dialogs; unlike previous work which examines solely scripted, written, monolog-like data. We compare
multiple metrics that presuppose different conceptualizations of text polysemy, i.e., they consider the observed or the potential
number of senses of words, or their sense distribution in a discourse. We show that the polysemy level of texts varies greatly
depending on the kind of text considered, with dialog and spoken discourses having generally a higher polysemy level than
written monologs. Additionally, our results emphasize the need for relaxing the popular “one sense per discourse” hypothesis.
Keywords: Semantics, Word Sense Disambiguation, Document classification / Text categorisation
1.



hal_id    :    hal-04273536



Users generate content constantly, leading to new data requiring annotation.
Among this data, textual conversations are
created every day and come with some specificities: they are mostly private through instant messaging applications, requiring
the conversational context to be labeled. These specificities led to several annotation tools dedicated to conversation, and
mostly dedicated to dialogue tasks, requiring complex annotation schemata, not always customizable and not taking into
account conversation-level labels.
In this paper, we present EZCAT, an easy-to-use interface to annotate conversations
in a two-level configurable schema, leveraging message-level labels and conversation-level labels at once.
Our interface
is characterized by the voluntary absence of a server and accounts management, enhancing its availability to anyone, and
the control over data, which is crucial to confidential conversations. We also present our first usage of EZCAT along with
our annotation schema we used to annotate confidential customer service conversations.
EZCAT is freely available at
https://gguibon.github.io/ezcat.
Keywords: conversations, annotation tool, text messages
1.



hal_id    :    hal-04276012



In this paper, we present the process we used in order to collect new annotations of opinions over the multimodal corpus
SEMAINE composed of dyadic interactions. The dataset had already been annotated continuously in two affective dimensions
related to the emotions: Valence and Arousal.
We annotated the part of SEMAINE called Solid SAL composed of 79
interactions between a user and an operator playing the role of a virtual agent designed to engage a person in a sustained,
emotionally colored conversation. We aligned the audio at the word level using the available high-quality manual transcriptions.
The annotated dataset contains 5627 speech turns for a total of 73,944 words, corresponding to 6 hours 20 minutes of dyadic
interactions. Each interaction has been labeled by three annotators at the speech turn level following a three-step process. This
method allows us to obtain a precise annotation regarding the opinion of a speaker. We obtain thus a dataset dense in opinions,
with more than 48% of the annotated speech turns containing at least one opinion. We then propose a new baseline for the
detection of opinions in interactions improving slightly a state of the art model with RoBERTa embeddings. The obtained
results on the database are promising with a F1-score at 0.72.
Keywords: Opinion, Multimodal Machine



hal_id    :    hal-04166172



. Handwriting is an everyday life human activity. It can be
collected oﬀ-line by scanning sheets of paper. The resulting images can
then be processed by a computer-based system. Thanks to digitizing
tablets, handwriting can also be collected on-line. From the collected raw
signals (pen position, pressure over time), the dynamics of the writing
can be recovered. Since handwriting is unique for each individual, it can
be considered as a biometric modality.
Biometric systems predicting gender from oﬀ-line handwriting, have been
recently proposed. However we observe that, in contrast to other modal-
ities such as speech, it is not straightforward for a human being (even
expert) to predict gender. In this study we explore the limits of auto-
matic gender prediction from on-line handwriting collected from a young
adults population, homogeneous in terms of age and education. In our
previous work [1], a statistical analysis of on-line dynamic features has
shown diﬀerences between male and female groups. In the present study,
we provide these features to a classiﬁer, based on a machine learning ap-
proach (SVMs). Since datasets are relatively small (240 subjects), several
evaluation frameworks are explored: cross validation (CV), bootstrap,
and ﬁxed train/test partitions. Accuracies obtained from ﬁxed partitions
range from 37% to 79%, while those estimated by CV and bootstrap
are around 60%.
This shows to our opinion



hal_id    :    hal-03637425



This paper describes a blind source separation method for multichan-
nel audio signals, called NF-FastMNMF, based on the integration of
the normalizing ﬂow (NF) into the multichannel nonnegative matrix
factorization with jointly-diagonalizable spatial covariance matrices,
a.k.a. FastMNMF. Whereas the NF of ﬂow-based independent vector
analysis, called NF-IVA, acts as the demixing matrices to transform
an M-channel mixture into M independent sources, the NF of NF-
FastMNMF acts as the diagonalization matrices to transform an M-
channel mixture into a spatially-independent M-channel mixture rep-
resented as a weighted sum of N source images. This diagonalization
enables the NF, which has been used only for determined separation
because of its bijective nature, to be applicable to non-determined
separation. NF-FastMNMF has time-varying diagonalization matri-
ces that are potentially better at handling dynamical data variation
than the time-invariant ones in FastMNMF. To have an NF with richer
expression capability, the dimension-wise scalings using diagonal ma-
trices originally used in NF-IVA are replaced with linear transforma-
tions using upper triangular matrices; in both cases, the diagonal and
upper triangular matrices are estimated by neural networks. The eval-
uation shows that NF-FastMNMF performs well for both determined
and non-determined separations of multiple speech utterances by sta-
tionary or non-stationary speakers from a noisy reverberant mixture.
Index Terms— Blind source separation, normalizing ﬂow, joint
diagonalization, multichannel nonnegative matrix factorization



hal_id    :    hal-03602455



This paper introduces a new extragradient-type algorithm for a class of
nonconvex-nonconcave minimax problems. It is well-known that ﬁnding a local
solution for general minimax problems is computationally intractable. This ob-
servation has recently motivated the study of structures suﬃcient for convergence
of ﬁrst order methods in the more general setting of variational inequalities when
the so-called weak Minty variational inequality (MVI) holds. This problem class
captures non-trivial structures as we demonstrate with examples, for which a large
family of existing algorithms provably converge to limit cycles. Our results require
a less restrictive parameter range in the weak MVI compared to what is previously
known, thus extending the applicability of our scheme. The proposed algorithm is
applicable to constrained and regularized problems, and involves an adaptive step-
size allowing for potentially larger stepsizes. Our scheme also converges globally
even in settings where the underlying operator exhibits limit cycles.
1



hal_id    :    hal-03727169



— This paper describes the practical response- and
performance-aware development of online speech enhancement
for an augmented reality (AR) headset that helps a user under-
stand conversations made in real noisy echoic environments (e.g.,
cocktail party). One may use a state-of-the-art blind source sep-
aration method called fast multichannel nonnegative matrix fac-
torization (FastMNMF) that works well in various environments
thanks to its unsupervised nature. Its heavy computational cost,
however, prevents its application to real-time processing. In con-
trast, a supervised beamforming method that uses a deep neural
network (DNN) for estimating spatial information of speech and
noise readily fits real-time processing, but suffers from drastic
performance degradation in mismatched conditions. Given such
complementary characteristics, we propose a dual-process ro-
bust online speech enhancement method based on DNN-based
beamforming with FastMNMF-guided adaptation. FastMNMF
(back end) is performed in a mini-batch style and the noisy and
enhanced speech pairs are used together with the original par-
allel training data for updating the direction-aware DNN (front
end) with backpropagation at a computationally-allowable inter-
val. This method is used with a blind dereverberation method
called weighted prediction error (WPE) for transcribing the
noisy reverberant speech of a speaker, which can be detected
from video or selected by a user’s hand gesture or eye gaze, in
a streaming manner and spatially showing the transcriptions
with an AR technique. Our



hal_id    :    hal-03701451



Cet article présente l’approche de l’équipe TGV lors de sa participation à la tâche de base de DEFT
2022, dont l’objectif était de prédire automatiquement les notes obtenues par des étudiants sur la
base de leurs réponses à des questionnaires. Notre stratégie s’est focalisée sur la mise au point d’une
méthode de classification des questions en fonction du type de réponse qu’elles attendent, de manière
à pouvoir mener une approche différenciée pour chaque type. Nos trois runs ont consisté en une
approche non différenciée, servant de référence, et deux approches différenciées, la première se basant
sur la constitution d’un jeu de caractéristiques et la seconde sur le calcul de TF-IDF et de la fonction
de hashage. Notre objectif premier était ainsi de vérifier si des approches dédiées à chaque type de
questions sont préférables à une approche globale.
ABSTRACT
Team TGV at DEFT 2022 : automatic prediction of students’ grades according to the different
question types.
In this paper we present the work of the TGV team for the DEFT 2022 challenge. We tackled the
base task only, which consists of automatically grading students based on their answers to several
questions. Our strategy consider this task as a classification task with multiple approaches, each being
specific to a question type leading to different types of



hal_id    :    hal-03821095



This paper describes a practical dual-process speech enhance-
ment system that adapts environment-sensitive frame-online
beamforming (front-end) with help from environment-free
block-online source separation (back-end). To use minimum
variance distortionless response (MVDR) beamforming, one
may train a deep neural network (DNN) that estimates time-
frequency masks used for computing the covariance matrices
of sources (speech and noise). Backpropagation-based run-
time adaptation of the DNN was proposed for dealing with the
mismatched training-test conditions. Instead, one may try to
directly estimate the source covariance matrices with a state-of-
the-art blind source separation method called fast multichannel
non-negative matrix factorization (FastMNMF). In practice,
however, neither the DNN nor the FastMNMF can be updated
in a frame-online manner due to its computationally-expensive
iterative nature. Our DNN-free system leverages the posteri-
ors of the latest source spectrograms given by block-online
FastMNMF to derive the current source covariance matrices
for frame-online beamforming. The evaluation shows that our
frame-online system can quickly respond to scene changes
caused by interfering speaker movements and outperformed
an existing block-online system with DNN-based beamform-
ing by 5.0 points in terms of the word error rate.
Index Terms— speech enhancement, beamforming, blind
source separation, automatic speech recognition



hal_id    :    hal-03727181



This paper describes noisy speech recognition for an augmented
reality headset that helps verbal communication with in real mul-
tiparty conversational environments. A major approach that has
actively been studied in simulated environments is to sequentially
perform speech enhancement and automatic speech recognition
(ASR) based on deep neural networks (DNNs) trained in a su-
pervised manner. In our task, however, such a pretrained system
fails to work due to the mismatch between the training and test
conditions and the head movements of the user. To enhance only
the utterances of a target speaker, we use beamforming based on
a DNN-based speech mask estimator that can adaptively extract
the speech components corresponding to a head-relative particu-
lar direction. We propose a semi-supervised adaptation method
that jointly updates the mask estimator and the ASR model at
run-time using clean speech signals with ground-truth transcrip-
tions and noisy speech signals with highly-confident estimated
transcriptions. Comparative experiments using the state-of-the-
art distant speech recognition system show that the proposed
method significantly improves the ASR performance.
Index Terms: speech enhancement, speech recognition, human-
computer interaction, run-time adaptation.



hal_id    :    hal-03574595



Spoken dialog systems need to be able to han-
dle both multiple languages and multilingual-
ity inside a conversation (e.g in case of code-
switching). In this work, we introduce new
pretraining losses tailored to learn multilingual
spoken dialog representations.
The goal of
these losses is to expose the model to code-
switched language. To scale up training, we
automatically build a pretraining corpus com-
posed of multilingual conversations in ﬁve dif-
ferent languages (French, Italian, English, Ger-
man and Spanish) from OpenSubtitles, a
huge multilingual corpus composed of 24.3G
tokens. We test the generic representations on
MIAM, a new benchmark composed of ﬁve di-
alog act corpora on the same aforementioned
languages as well as on two novel multilingual
downstream tasks (i.e multilingual mask utter-
ance retrieval and multilingual inconsistency
identiﬁcation). Our experiments show that our
new code switched-inspired losses achieve a
better performance in both monolingual and
multilingual settings.
1



hal_id    :    hal-03344680



Several recent studies on dyadic human-
human interactions have been done on con-
versations without speciﬁc business objectives.
However, many companies might beneﬁt from
studies dedicated to more precise environ-
ments such as after sales services or customer
satisfaction surveys. In this work, we place
ourselves in the scope of a live chat customer
service in which we want to detect emotions
and their evolution in the conversation ﬂow.
This context leads to multiple challenges that
range from exploiting restricted, small and
mostly unlabeled datasets to ﬁnding and adapt-
ing methods for such context.
We tackle
these challenges by using Few-Shot Learning
while making the hypothesis it can serve con-
versational emotion classiﬁcation for different
languages and sparse labels.
We contribute
by proposing a variation of Prototypical Net-
works for sequence labeling in conversation
that we name ProtoSeq. We test this method
on two datasets with different languages: daily
conversations in English and customer service
chat conversations in French. When applied
to emotion classiﬁcation in conversations, our
method proved to be competitive even when
compared to other ones. The code for Proto-
Seq is available at https://github.com/
gguibon/ProtoSeq.
1



hal_id    :    hal-03574609



Multimodal sentiment analysis is a trending
area of research, and the multimodal fusion
is one of its most active topic. Acknowledg-
ing humans communicate through a variety of
channels (i.e visual, acoustic, linguistic), mul-
timodal systems aim at integrating different
unimodal representations into a synthetic one.
So far, a consequent effort has been made on
developing complex architectures allowing the
fusion of these modalities. However, such sys-
tems are mainly trained by minimising sim-
ple losses such as L1 or cross-entropy.
In
this work, we investigate unexplored penalties
and propose a set of new objectives that mea-
sure the dependency between modalities. We
demonstrate that our new penalties lead to a
consistent improvement (up to 4.3 on accu-
racy) across a large variety of state-of-the-art
models on two well-known sentiment analysis
datasets: CMU-MOSI and CMU-MOSEI. Our
method not only achieves a new SOTA on both
datasets but also produces representations that
are more robust to modality drops. Finally, a
by-product of our methods includes a statisti-
cal network which can be used to interpret the
high dimensional representations learnt by the
model.
1



hal_id    :    hal-03329932



—Analog-to-feature (A2F) conversion is an acquisition
method thought for IoT devices in order to increase wireless
sensor’s battery life. The operating principle of A2F is to
perform classification tasks at sub-Nyquist rate, by extracting
relevant features in the analog domain and then performing
the classification step in the digital domain. We propose to use
non-uniform wavelet sampling (NUWS) combined with feature
selection to find and extract from the signal, a small set of relevant
features for electrocardiogram (ECG) anomalies detection. A
CMOS 0.18 µm mixed architecture for NUWS feature extraction
is proposed, to obtain a power consumption model for A2F.
This model can be taken into account in the feature selection
step by evaluating the energy cost of each wavelet and then
try to maximize classification accuracy while minimizing the
energy needed for extraction. We demonstrate the benefits of A2F
showing that the energy needed can be divided by 15 compared
to classical approach.
Index Terms—Analog-to-Feature converter, Bio-sensing ac-
quisition, Feature selection, Low power, Non-Uniform Wavelet
Sampling.



hal_id    :    hal-03409892



Emergent states are behavioral, cognitive and affective processes ap-
pearing among the members of a group when they interact together.
In the last decade, the development of computational approaches
received a growing interest in building Human-Centered systems.
Such a development is particularly difficult because some of these
states have several dimensions interplaying somehow and some-
where over time. In this paper, we focus on cohesion, its dimensions
and their interplay. Several definitions of cohesion exist, it can be
simply defined as the tendency of a group to stick together to pursue
goals and/or affective needs. This plethora of definitions resulted in
many different cohesion dimensions. Social and Task dimensions
are the most investigated both in Social Sciences and Computer
Science since they both play an important role in a wide range of
contexts and groups. To the best of our knowledge, however, no pre-
vious work on the prediction of cohesion dynamics focused on how
these 2 dimensions interplay. We leverage Social Sciences to address
this issue. In particular, we take advantage of the importance of
Social cohesion for creating flexible and constructive relationships
to reinforce Task cohesion. We describe a Deep Neural Network
architecture (DNN) for predicting the dynamics of Task cohesion
by applying transfer learning from a pre-trained model dedicated
to the prediction of Social cohesion dynamics. Our architecture
is



hal_id    :    hal-03167498



—The analysis of load curves collected
from smart meters is a key step for many energy man-
agement tasks ranging from consumption forecasting
to customers characterization and load monitoring.
In this contribution, we propose a model based on a
functional formulation of nonnegative tensor factor-
ization and derive updates for the corresponding opti-
mization problem. We show on the concrete example
of multi-sites load curves disaggregation how this
formulation is helpful for 1) exhibiting smooth intra-
day consumption patterns and 2) taking into account
external variables such as the outside temperature.
The beneﬁts are demonstrated on simulated and real
data by exhibiting a meaningful clustering of the
observed sites based on the obtained decomposition.



hal_id    :    hal-03563675



In this paper, we place ourselves in a classi-
ﬁcation scenario in which the target classes
and data type are not accessible during train-
ing. We use a meta-learning approach to de-
termine whether or not meta-trained informa-
tion from common social network data with
ﬁne-grained emotion labels can achieve com-
petitive performance on messages labeled with
different emotion categories. We leverage few-
shot learning to match with the classiﬁcation
scenario and consider metric learning based
meta-learning by setting up Prototypical Net-
works with a Transformer encoder, trained in
an episodic fashion.
This approach proves
to be effective for capturing meta-information
from a source emotional tag set to predict pre-
viously unseen emotional tags. Even though
shifting the data type triggers an expected per-
formance drop, our meta-learning approach
achieves decent results when compared to the
fully supervised one.
1



hal_id    :    hal-02985794



Speech separation with several speakers is a challenging task be-
cause of the non-stationarity of the speech and the strong signal
similarity between interferent sources. Current state-of-the-art so-
lutions can separate well the different sources using sophisticated
deep neural networks which are very tedious to train. When several
microphones are available, spatial information can be exploited to
design much simpler algorithms to discriminate speakers. We pro-
pose a distributed algorithm that can process spatial information in
a spatially unconstrained microphone array. The algorithm relies on
a convolutional recurrent neural network that can exploit the signal
diversity from the distributed nodes. In a typical case of a meeting
room, this algorithm can capture an estimate of each source in a ﬁrst
step and propagate it over the microphone array in order to increase
the separation performance in a second step. We show that this ap-
proach performs even better when the number of sources and nodes
increases. We also study the inﬂuence of a mismatch in the number
of sources between the training and testing conditions.
Index Terms— Speech separation, microphone arrays, dis-
tributed processing.



hal_id    :    hal-03265871



Dans cet article nous reproduisons un scénario d’apprentissage selon lequel les données cibles
ne sont pas accessibles et seules des données connexes le sont. Nous utilisons une approche par
méta-apprentissage aﬁn de déterminer si les méta-informations apprises à partir de messages issus
de médias sociaux, ﬁnement annotés en émotions, peuvent produire de bonnes performances une
fois utilisées sur des messages issus de conversations, étiquetés en émotions avec une granularité
différente. Nous mettons à proﬁt l’apprentissage sur quelques exemples (few-shot learning) pour la
mise en place de ce scénario. Cette approche se montre efﬁcace pour capturer les méta-informations
d’un jeu d’étiquettes émotionnelles pour prédire des étiquettes jusqu’alors inconnues au modèle. Bien
que le fait de varier le type de données engendre une baisse de performance, notre approche par
méta-apprentissage atteint des résultats décents comparés au référentiel d’apprentissage supervisé.
ABSTRACT
Meta-learning : Classifying Messages into Unseen Emotional Categories
In this paper, we place ourselves in a classiﬁcation scenario in which the target data set classes and
data type are not accessible during training. We use a meta-learning approach to determine whether
or not meta-trained information from common social network data with ﬁne-grained emotion labels
can achieve competitive performance on conversation utterances labeled with different, higher level,
emotions. We leverage few-shot learning to concur with the classiﬁcation scenario. This



hal_id    :    hal-02429681



Discrete time trawl processes constitute a large class of time series parameterized by a
trawl sequence (aj)j∈N and deﬁned though a sequence of independent and identically
distributed (i.i.d.) copies of a continuous time process (γ(t))t∈R called the seed process.
They provide a general framework for modeling linear or non-linear long range dependent
time series. We investigate the spectral estimation, either pointwise or broadband, of long
range dependent discrete-time trawl processes. The diﬃculty arising from the variety of
seed processes and of trawl sequences is twofold. First, the spectral density may take
diﬀerent forms, often including smooth additive correction terms. Second, trawl processes
with similar spectral densities may exhibit very diﬀerent statistical behaviors. We prove
the consistency of our estimators under very general conditions and we show that a wide
class of trawl processes satisfy them. This is done in particular by introducing a weighted
weak dependence index that can be of independent interest.
The broadband spectral
estimator includes an estimator of the long memory parameter. We complete this work
with numerical experiments to evaluate the ﬁnite sample size performance of this estimator
for various integer valued discrete time trawl processes.
Keywords: trawl processes; integer-valued time series; long memory parameter estimation
MSC: 62M10; 62F12; 60G51;
1



hal_id    :    hal-03189235



Data depth is a concept in multivariate statistics that measures the centrality
of a point in a given data cloud in Rd. If the depth of a point can be represented
as the minimum of the depths with respect to all one-dimensional projections
of the data, then the depth satisﬁes the so-called projection property. Such
depths form an important class that includes many of the depths that have
been proposed in literature. For depths that satisfy the projection property an
approximate algorithm can easily be constructed since taking the minimum of
the depths with respect to only a ﬁnite number of one-dimensional projections
yields an upper bound for the depth with respect to the multivariate data. Such
an algorithm is particularly useful if no exact algorithm exists or if the exact
algorithm has a high computational complexity, as is the case with the halfspace
depth or the projection depth. To compute these depths in high dimensions,
the use of an approximate algorithm with better complexity is surely preferable.
Instead of focusing on a single method we provide a comprehensive and fair
comparison of several methods, both already described in the literature and
original.
Keywords:
data depth, projection property, approximate computation,
∗Corresponding author
Email addresses: rainer.dyckerhoff@statistik.uni-koeln.de (Rainer Dyckerhoﬀ),
pavlo.mozharovskyi@telecom-paris.fr (Pavlo Mozharovskyi), nagy@karlin.mff.cuni.cz
(Stanislav Nagy)
Preprint submitted to Computational Statistics and Data Analysis
November 20,



hal_id    :    hal-02088860



. In this contribution we are interested in proving that a given
observation-driven model is identiﬁable. In the case of a GARCH(p, q) model,
a simple suﬃcient condition has been established in [2] for showing the consis-
tency of the quasi-maximum likelihood estimator. It turns out that this condi-
tion applies for a much larger class of observation-driven models, that we call
the class of linearly observation-driven models. This class includes standard in-
teger valued observation-driven time series such as the Poisson autoregression
model and its numerous extensions. Our results also apply to vector-valued
time series such as the bivariate integer valued GARCH model, to non-linear
models such as the threshold Poisson autoregression or to observation-driven
models with exogenous covariates such as the PARX model.



hal_id    :    hal-03188029



John W. Tukey (1975) deﬁned statistical data depth as a function that determines centrality of
an arbitrary point with respect to a data cloud or to a probability measure. During the last decades,
this seminal idea of data depth evolved into a powerful tool proving to be useful in various ﬁelds
of science. Recently, extending the notion of data depth to the functional setting attracted a lot
of attention among theoretical and applied statisticians. We go further and suggest a notion of
data depth suitable for data represented as curves, or trajectories, which is independent of the
parametrization. We show that our curve depth satisﬁes theoretical requirements of general depth
functions that are meaningful for trajectories. We apply our methodology to diffusion tensor
brain images and also to pattern recognition of hand written digits and letters. Supplementary
Materials are available online.
Keywords: data depth, space of curves, unparametrized curves, nonparametric statistics,
curve registration, DT-MRI ﬁbers, classiﬁcation, DD-plot.
1



hal_id    :    hal-02933051



Screening rules were recently introduced as a technique for explicitly
identifying active structures such as sparsity, in optimization problem
arising in machine learning. This has led to new methods of acceleration
based on a substantial dimension reduction.
We show that screening
rules stem from a combination of natural properties of subdiﬀerential sets
and optimality conditions, and can hence be understood in a uniﬁed way.
Under mild assumptions, we analyze the number of iterations needed to
identify the optimal active set for any converging algorithm. We show that
it only depends on its convergence rate.
1



hal_id    :    hal-03134854



While being an essential component
of spoken language, ﬁllers (e.g. “um”
or “uh”) often remain overlooked in
Spoken Language Understanding (SLU)
tasks.
We explore the possibility of
representing them with deep contex-
tualised embeddings, showing improve-
ments on modelling spoken language
and two downstream tasks — predict-
ing a speaker’s stance and expressed
conﬁdence.
1



hal_id    :    hal-02934433



Music tags are commonly used to describe and catego-
rize music. Various auto-tagging models and datasets have
been proposed for the automatic music annotation with
tags. However, the past approaches often neglect the fact
that many of these tags largely depend on the user, espe-
cially the tags related to the context of music listening. In
this paper, we address this problem by proposing a user-
aware music auto-tagging system and evaluation protocol.
Speciﬁcally, we use both the audio content and user infor-
mation extracted from the user listening history to predict
contextual tags for a given user/track pair. We propose a
new dataset of music tracks annotated with contextual tags
per user. We compare our model to the traditional audio-
based model and study the inﬂuence of user embeddings
on the classiﬁcation quality. Our work shows that explic-
itly modeling the user listening history into the automatic
tagging process could lead to more accurate estimation of
contextual tags.



hal_id    :    hal-02507316



.
We present a framework for deﬁning the “right” level of
explainability based on technical, legal and economic considerations.
Our approach involves three logical steps: First, deﬁne the main con-
textual factors, such as who is the audience of the explanation, the
operational context, the level of harm that the system could cause,
and the legal/regulatory framework. This step will help characterize
the operational and legal needs for explanation, and the correspond-
ing social beneﬁts. Second, examine the technical tools available,
including post-hoc approaches (input perturbation, saliency maps...)
and hybrid AI approaches. Third, as function of the ﬁrst two steps,
choose the right levels of global and local explanation outputs, taking
into the account the costs involved. We identify seven kinds of costs
and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1



hal_id    :    hal-03132996



With the ubiquity of sensors in the IoT era,
statistical observations are becoming increas-
ingly available in the form of massive (multi-
variate) time-series. Formulated as unsuper-
vised anomaly detection tasks, an abundance
of applications like aviation safety manage-
ment, the health monitoring of complex in-
frastructures or fraud detection can now rely
on such functional data, acquired and stored
with an ever ﬁner granularity. The concept
of statistical depth, which reﬂects centrality
of an arbitrary observation w.r.t. a statisti-
cal population may play a crucial role in this
regard, anomalies corresponding to observa-
tions with ’small’ depth. Supported by sound
theoretical and computational developments
in the recent decades, it has proven to be
extremely useful, in particular in functional
spaces.
However, most approaches docu-
mented in the literature consist in evaluat-
ing independently the centrality of each point
forming the time series and consequently ex-
hibit a certain insensitivity to possible shape
changes. In this paper, we propose a novel
notion of functional depth based on the area
of the convex hull of sampled curves, captur-
ing gradual departures from centrality, even
beyond the envelope of the data, in a nat-
ural fashion. We discuss practical relevance
of commonly imposed axioms on functional
depths and investigate which of them are sat-
isﬁed by the notion of depth we promote here.
Estimation and computational issues are also
addressed and various numerical experiments
provide empirical evidence



hal_id    :    hal-02547012



The problem of multi-label classification with missing labels (MLML)
is a common challenge that is prevalent in several domains, e.g.
image annotation and auto-tagging. In multi-label classification,
each instance may belong to multiple class labels simultaneously.
Due to the nature of the dataset collection and labelling proce-
dure, it is common to have incomplete annotations in the dataset,
i.e. not all samples are labelled with all the corresponding labels.
However, the incomplete data labelling hinders the training of clas-
sification models. MLML has received much attention from the
research community. However, in cases where a pre-trained model
is fine-tuned on an MLML dataset, there has been no straightfor-
ward approach to tackle the missing labels, specifically when there
is no information about which are the missing ones. In this paper,
we propose a weighted loss function to account for the confidence
in each label/sample pair that can easily be incorporated to fine-
tune a pre-trained model on an incomplete dataset. Our experiment
results show that using the proposed loss function improves the
performance of the model as the ratio of missing labels increases.
CCS CONCEPTS
• Computing methodologies →Neural networks.
KEYWORDS
Multi-label classification; missing labels; neural networks
ACM Reference Format:
Karim M. Ibrahim, Elena V. Epure, Geoffroy Peeters, and Gaël Richard. 2020.
Confidence-based Weighted Loss for Multi-label Classification with Missing
Labels. In Proceedings of the



hal_id    :    hal-02481374



Music listening context such as location or activity has been shown
to greatly inﬂuence the users’ musical tastes. In this work, we study
the relationship between user context and audio content in order to
enable context-aware music recommendation agnostic to user data.
For that, we propose a semi-automatic procedure to collect track sets
which leverages playlist titles as a proxy for context labelling. Using
this, we create and release a dataset of ∼50k tracks labelled with
15 different contexts. Then, we present benchmark classiﬁcation
results on the created dataset using an audio auto-tagging model. As
the training and evaluation of these models are impacted by missing
negative labels due to incomplete annotations, we propose a sample-
level weighted cross entropy loss to account for the conﬁdence in
missing labels and show improved context prediction results.
Index Terms— music auto-tagging, user context, dataset col-
lection, multi-label classiﬁcation, missing labels.



hal_id    :    hal-02389159



Multichannel processing is widely used for speech enhancement but
several limitations appear when trying to deploy these solutions in
the real world. Distributed sensor arrays that consider several de-
vices with a few microphones is a viable solution which allows for
exploiting the multiple devices equipped with microphones that we
are using in our everyday life. In this context, we propose to extend
the distributed adaptive node-speciﬁc signal estimation approach to
a neural network framework. At each node, a local ﬁltering is per-
formed to send one signal to the other nodes where a mask is esti-
mated by a neural network in order to compute a global multichan-
nel Wiener ﬁlter. In an array of two nodes, we show that this addi-
tional signal can be leveraged to predict the masks and leads to better
speech enhancement performance than when the mask estimation re-
lies only on the local signals.
Index Terms— Speech enhancement, microphone arrays, dis-
tributed processing.



hal_id    :    hal-02914840



The principle of compositionality, which enables natural language to represent
complex concepts via a structured combination of simpler ones, allows us to con-
vey an open-ended set of messages using a limited vocabulary. If compositionality
is indeed a natural property of language, we may expect it to appear in commu-
nication protocols that are created by neural agents in language games. In this
paper, we propose an effective neural iterated learning (NIL) algorithm that, when
applied to interacting neural agents, facilitates the emergence of a more structured
type of language. Indeed, these languages provide learning speed advantages to
neural agents during training, which can be incrementally ampliﬁed via NIL. We
provide a probabilistic model of NIL and an explanation of why the advantage
of compositional language exist. Our experiments conﬁrm our analysis, and also
demonstrate that the emerged languages largely improve the generalizing power
of the neural agent communication.
1



hal_id    :    hal-02506409



The recent enthusiasm for artiﬁcial intelligence (AI) is due principally to
advances in deep learning. Deep learning methods are remarkably accurate,
but also opaque, which limits their potential use in safety-critical applications.
To achieve trust and accountability, designers and operators of machine learn-
ing algorithms must be able to explain the inner workings, the results and the
causes of failures of algorithms to users, regulators, and citizens. The orig-
inality of this paper is to combine technical, legal and economic aspects of
explainability to develop a framework for deﬁning the ”right” level of explain-
ability in a given context. We propose three logical steps: First, deﬁne the
main contextual factors, such as who the audience of the explanation is, the
operational context, the level of harm that the system could cause, and the
legal/regulatory framework. This step will help characterize the operational
and legal needs for explanation, and the corresponding social beneﬁts. Second,
examine the technical tools available, including post hoc approaches (input
perturbation, saliency maps...) and hybrid AI approaches. Third, as function
of the ﬁrst two steps, choose the right levels of global and local explanation
outputs, taking into the account the costs involved. We identify seven kinds
of costs and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1We would like to



hal_id    :    hal-01440269



We present single imputation method for missing values which borrows the idea of data  
depth—a measure of centrality defined for an arbitrary point of a space with respect to a prob- 
ability distribution or data cloud. This consists in iterative maximization of the depth of each 
observation with missing values, and can be employed with any properly defined statistical depth 
function. For each single iteration, imputation reverts to optimization of quadratic, linear, or 
quasiconcave functions that are solved analytically by linear programming or the Nelder-Mead 
method. As it accounts for the underlying data topology, the procedure is distribution free, allows 
imputation close to the data geometry, can make prediction in situations where local imputation 
(k-nearest neighbors, random forest) cannot, and has attractive robustness and asymptotic prop- 
erties under elliptical symmetry. It is shown that a special case—when using the Mahalanobis 
depth—has direct connection to well-known methods for the multivariate normal model, such as 
iterated regression and regularized PCA. The methodology is extended to multiple imputation for 
data stemming from an elliptically symmetric distribution. Simulation and real data studies show 
good results compared with existing popular alternatives. The method has been implemented as 
an R-package. Supplementary materials for the article



hal_id    :    hal-02433213



Source separation aims at decomposing a vector into additive components. This
is often done by ﬁrst estimating source parameters before feeding them into a
ﬁltering method, often based on ratios of covariances. The whole pipeline is
traditionally rooted in some probabilistic framework providing both the likeli-
hood for parameter estimation and the separation method. While Gaussians
are ubiquitous for this purpose, many studies showed the beneﬁt of heavy-tailed
models for estimation. However, there is no counterpart ﬁltering method to date
exploiting such formalism, so that related studies revert to covariance-based ﬁl-
tering after estimation is ﬁnished.
Here, we introduce a new multivariate separation technique, that fully ex-
ploits the ﬂexibility of α-stable heavy-tailed distributions. We show how a spa-
tial representation can be exploited, which decomposes the observation as an
inﬁnite sum of contributions originating from all directions. Two methods for
separation are derived. The ﬁrst one is non-linear and similar to a beamforming
technique, while the second one is linear, but minimizes a covariation criterion,
which is the counterpart of the covariance for α-stable vectors. We evaluate the
proposed techniques in a large number of challenging and adverse situations on
synthetic experiments, demonstrating their performance for the extraction of
signals from strong interferences.
Keywords:
alpha-stable distribution, separation theory, additive models,
measure theory, optimization
$This work was partly supported by the research



hal_id    :    hal-01502252



Locally stationary Hawkes processes have been introduced in order to generalise clas-
sical Hawkes processes away from stationarity by allowing for a time-varying second-order
structure. This class of self-exciting point processes has recently attracted a lot of inter-
est in applications in the life sciences (seismology, genomics, neuro-science,...), but also
in the modeling of high-frequency ﬁnancial data. In this contribution we provide a fully
developed nonparametric estimation theory of both local mean density and local Bartlett
spectra of a locally stationary Hawkes process. In particular we apply our kernel estima-
tion of the spectrum localised both in time and frequency to two data sets of transaction
times revealing pertinent features in the data that had not been made visible by classical
non-localised approaches based on models with constant fertility functions over time.
Keywords: Time frequency analysis; Locally stationary time series; high frequency ﬁ-
nancial data; Non-parametric kernel estimation; Self-exciting point processes.
1



hal_id    :    hal-01497104



This paper introduces a randomized coordinate descent version of the V˜u-Condat algorithm.
By
coordinate descent, we mean that only a subset of the coordinates of the primal and dual iterates is
updated at each iteration, the other coordinates being maintained to their past value.
Our method
allows us to solve optimization problems with a combination of diﬀerentiable functions, constraints as
well as non-separable and non-diﬀerentiable regularizers.
We show that the sequences generated by our algorithm almost surely converge to a saddle point
of the problem at stake, for a wider range of parameter values than previous methods. In particular,
the condition on the step-sizes depends on the coordinate-wise Lipschitz constant of the diﬀerentiable
function’s gradient, which is a major feature allowing classical coordinate descent to perform so well when
it is applicable. We then prove a sublinear rate of convergence in general and a linear rate of convergence
if the objective enjoys strong convexity properties.
We illustrate the performances of the algorithm on a total-variation regularized least squares regression
problem and on large scale support vector machine problems.
1



hal_id    :    hal-02369435



For the purpose of monitoring the behavior of complex infrastructures (e.g.
aircrafts,
transport or energy networks), high-rate sensors are deployed to capture multivariate data,
generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anoma-
lies that may jeopardize the smooth operation of the system of interest. The statistical
analysis of such massive data of functional nature raises many challenging methodological
questions. The primary goal of this paper is to extend the popular Isolation Forest (IF)
approach to Anomaly Detection, originally dedicated to ﬁnite dimensional observations, to
functional data. The major diﬃculty lies in the wide variety of topological structures that
may equip a space of functions and the great variety of patterns that may characterize
abnormal curves.
We address the issue of (randomly) splitting the functional space in
a ﬂexible manner in order to isolate progressively any trajectory from the others, a key
ingredient to the eﬃciency of the algorithm. Beyond a detailed description of the algo-
rithm, computational complexity and stability issues are investigated at length. From the
scoring function measuring the degree of abnormality of an observation provided by the
proposed variant of the IF algorithm, a Functional Statistical Depth function is deﬁned and
discussed, as well as a multivariate functional extension. Numerical experiments provide
strong empirical evidence of the accuracy of the extension



hal_id    :    hal-02420416



In this paper, we address how to evaluate and improve the perfor-
mance of automatic dominant melody extraction systems from a
pattern mining perspective with a focus on jazz improvisations.
Traditionally, dominant melody extraction systems estimate the
melody on the frame-level, but for real-world musicological appli-
cations note-level representations are needed. For the evaluation of
estimated note tracks, the current frame-wise metrics are not fully
suitable and provide at most a first approximation. Furthermore,
mining melodic patterns (n-grams) poses another challenge because
note-wise errors propagate geometrically with increasing length of
the pattern. On the other hand, for certain derived metrics such as
pattern commonalities between performers, extraction errors might
be less critical if at least qualitative rankings can be reproduced.
Finally, while searching for similar patterns in a melody database
the number of irrelevant patterns in the result set increases with
lower similarity thresholds. For reasons of usability, it would be in-
teresting to know the behavior using imperfect automated melody
extractions. We propose three novel evaluation strategies for es-
timated note-tracks based on three application scenarios: Pattern
mining, pattern commonalities, and fuzzy pattern search. We apply
the proposed metrics to one general state-of-the-art melody esti-
mation method (Melodia) and to two variants of an algorithm that
was optimized for the extraction of jazz solos melodies. A subset of
the Weimar Jazz Database



hal_id    :    hal-02943462



In the last few years, several datasets have been released
to meet the requirements of “hungry” yet promising data-
driven approaches in music technology research. Since,
for historical reasons, most investigations conducted in the
ﬁeld still revolve around music of the so-called “West-
ern” tradition, the corresponding data, methodology and
conclusions carry a strong cultural bias. Music of non-
“Western” background, whenever present, is usually un-
derrepresented, poorly labeled, or even mislabeled, the
exception being projects that aim at speciﬁcally describ-
ing such music. In this paper we present SAMBASET,
a dataset of Brazilian samba music that contains over
40 hours of historical and modern samba de enredo com-
mercial recordings. To the best of our knowledge, this is
the ﬁrst dataset of this genre. We describe the collection of
metadata (e.g. artist, composer, release date) and outline
our semiautomatic approach to the challenging task of an-
notating beats in this large dataset, which includes the as-
sessment of the performance of state-of-the-art beat track-
ing algorithms for this speciﬁc case. Finally, we present
a study on tempo and beat tracking that illustrates SAM-
BASET’s value, and we comment on other tasks for which
it could be used.



hal_id    :    hal-02166428



. The development of cluster computing frameworks has al-
lowed practitioners to scale out various statistical estimation and ma-
chine learning algorithms with minimal programming eﬀort. This is es-
pecially true for machine learning problems whose objective function
is nicely separable across individual data points, such as classiﬁcation
and regression. In contrast, statistical learning tasks involving pairs (or
more generally tuples) of data points — such as metric learning, clus-
tering or ranking — do not lend themselves as easily to data-parallelism
and in-memory computing. In this paper, we investigate how to bal-
ance between statistical performance and computational eﬃciency in
such distributed tuplewise statistical problems. We ﬁrst propose a sim-
ple strategy based on occasionally repartitioning data across workers
between parallel computation stages, where the number of repartition-
ing steps rules the trade-oﬀbetween accuracy and runtime. We then
present some theoretical results highlighting the beneﬁts brought by the
proposed method in terms of variance reduction, and extend our results
to design distributed stochastic gradient descent algorithms for tuplewise
empirical risk minimization. Our results are supported by numerical ex-
periments in pairwise statistical estimation and learning on synthetic and
real-world datasets.
Keywords: Distributed Machine Learning · Distributed Data Process-
ing · U-Statistics · Stochastic Gradient Descent · AUC Optimization
1



hal_id    :    hal-02288063



—We propose a semi-supervised multichannel speech
enhancement system based on a probabilistic model which as-
sumes that both speech and noise follow the heavy-tailed multi-
variate complex Cauchy distribution. As we advocate, this allows
handling strong and adverse noisy conditions. Consequently, the
model is parameterized by the source magnitude spectrograms
and the source spatial scatter matrices. To deal with the non-
additivity of scatter matrices, our ﬁrst contribution is to perform
the enhancement on a projected space. Then, our second contri-
bution is to combine a latent variable model for speech, which
is trained by following the variational autoencoder framework,
with a low-rank model for the noise source. At test time, an it-
erative inference algorithm is applied, which produces estimated
parameters to use for separation. The speech latent variables are
estimated ﬁrst from the noisy speech and then updated by a gra-
dient descent method, while a majorization-equalization strategy
is used to update both the noise and the spatial parameters of
both sources. Our experimental results show that the Cauchy
model outperforms the state-of-art methods. The standard devi-
ation scores also reveal that the proposed method is more robust
against non-stationary noise.
Index Terms—Multichannel speech enhancement, multivariate
complex Cauchy distribution, variational autoencoder, nonnega-
tive matrix factorization



hal_id    :    hal-01900037



Popular machine learning estimators involve
regularization parameters that can be chal-
lenging to tune, and standard strategies rely
on grid search for this task. In this paper,
we revisit the techniques of approximating
the regularization path up to predeﬁned tol-
erance ϵ in a uniﬁed framework and show
that its complexity is O(1/ d√ϵ) for uniformly
convex loss of order d > 0 and O(1/√ϵ)
for Generalized Self-Concordant functions.
This framework encompasses least-squares
but also logistic regression (a case that as far
as we know was not handled as precisely by
previous works). We leverage our technique
to provide reﬁned bounds on the validation
error as well as a practical algorithm for hy-
perparameter tuning.
The later has global
convergence guarantee when targeting a pre-
scribed accuracy on the validation set. Last
but not least, our approach helps relieving
the practitioner from the (often neglected)
task of selecting a stopping criterion when
optimizing over the training set: our method
automatically calibrates it based on the tar-
geted accuracy on the validation set.
1



hal_id    :    hal-02303823



No abstract found in the PDF.



hal_id    :    hal-02912385



Noise-Contrastive Estimation (NCE) is a learning criterion that is regularly used to train neural
language models in place of Maximum Likelihood Estimation, since it avoids the computational
bottleneck caused by the output softmax. In this paper, we analyse and explain some of the
weaknesses of this objective function, linked to the mechanism of self-normalization, by closely
monitoring comparative experiments. We then explore several remedies and modiﬁcations to
propose tractable and efﬁcient NCE training strategies. In particular, we propose to make the
scaling factor a trainable parameter of the model, and to use the noise distribution to initialize the
output bias. These solutions, yet simple, yield stable and competitive performances in either small
and large scale language modelling tasks.
1



hal_id    :    lirmm-01766795



. This paper introduces a new method for multichannel speech
enhancement based on a versatile modeling of the residual noise spec-
trogram. Such a model has already been presented before in the single
channel case where the noise component is assumed to follow an alpha-
stable distribution for each time-frequency bin, whereas the speech spec-
trogram, supposed to be more regular, is modeled as Gaussian. In this
paper, we describe a multichannel extension of this model, as well as
a Monte Carlo Expectation - Maximisation algorithm for parameter es-
timation. In particular, a multichannel extension of the Itakura-Saito
nonnegative matrix factorization is exploited to estimate the spectral
parameters for speech, and a Metropolis-Hastings algorithm is proposed
to estimate the noise contribution. We evaluate the proposed method in
a challenging multichannel denoising application and compare it to other
state-of-the-art algorithms.
1



hal_id    :    hal-02912471



L’estimation contrastive bruitée (NCE) et l’échantillonage par importance (IS) sont des procédures
d’entraînement basées sur l’échantillonage, que l’on utilise habituellement à la place de l’estimation
du maximum de vraisemblance (MLE) pour éviter le calcul du softmax lorsque l’on entraîne des
modèles de langue neuronaux. Dans cet article, nous cherchons à résumer le fonctionnement de ces
algorithmes, et leur utilisation dans la littérature du TAL. Nous les comparons expérimentalement, et
présentons des manières de faciliter l’entraînement du NCE.
ABSTRACT
Here the title in English.
Noise Contrastive Estimation (NCE) and Importance Sampling (IS) are sampling based algorithms
traditionally used to avoid computing the costly output softmax when training neural language models
with Maximum Likelihood Estimation (MLE). In this work, we attempt to summarize how these
procedures work, and how they have been used in the computational linguistics literature. We then
compare them, and experiment with tricks that ease NCE training.
MOTS-CLÉS : Modèle de langue, Estimation contrastive bruitée, Negative Sampling.
KEYWORDS: Neural Language Model, Noise Contrastive Estimation, Negative Sampling.



hal_id    :    hal-01812011



In high dimension, it is customary to consider
Lasso-type estimators to enforce sparsity. For
standard Lasso theory to hold, the regulariza-
tion parameter should be proportional to the
noise level, which is often unknown in prac-
tice. A remedy is to consider estimators such
as the Concomitant Lasso, which jointly opti-
mize over the regression coeﬃcients and the
noise level. However, when data from diﬀer-
ent sources are pooled to increase sample size,
noise levels diﬀer and new dedicated estima-
tors are needed. We provide new statistical
and computational solutions to perform het-
eroscedastic regression, with an emphasis on
brain imaging with magneto- and electroen-
cephalography (M/EEG). When instantiated
to de-correlated noise, our framework leads to
an eﬃcient algorithm whose computational
cost is not higher than for the Lasso, but ad-
dresses more complex noise structures. Ex-
periments demonstrate improved prediction
and support identiﬁcation with correct esti-
mation of noise levels.
1



hal_id    :    hal-01269137



. In this contribution we introduce weakly locally stationary time series through
the local approximation of the non-stationary covariance structure by a stationary one.
This allows us to deﬁne autoregression coeﬃcients in a non-stationary context, which, in
the particular case of a locally stationary Time Varying Autoregressive (TVAR) process,
coincide with the generating coeﬃcients. We provide and study an estimator of the time
varying autoregression coeﬃcients in a general setting. The proposed estimator of these
coeﬃcients enjoys an optimal minimax convergence rate under limited smoothness condi-
tions. In a second step, using a bias reduction technique, we derive a minimax-rate estima-
tor for arbitrarily smooth time-evolving coeﬃcients, which outperforms the previous one
for large data sets. In turn, for TVAR processes, the predictor derived from the estimator
exhibits an optimal minimax prediction rate.



hal_id    :    hal-01679078



We address the issue of reliably detecting and quantifying cross-frequency coupling (CFC)
in neural time series. Based on non-linear auto-regressive models, the proposed method
provides a generative and parametric model of the time-varying spectral content of the
signals. As this method models the entire spectrum simultaneously, it avoids the pitfalls
related to incorrect filtering or the use of the Hilbert transform on wide-band signals. As the
model is probabilistic, it also provides a score of the model “goodness of fit” via the likeli-
hood, enabling easy and legitimate model selection and parameter comparison; this data-
driven feature is unique to our model-based approach. Using three datasets obtained with
invasive neurophysiological recordings in humans and rodents, we demonstrate that these
models are able to replicate previous results obtained with other metrics, but also reveal
new insights such as the influence of the amplitude of the slow oscillation. Using simulations,
we demonstrate that our parametric method can reveal neural couplings with shorter signals
than non-parametric methods. We also show how the likelihood can be used to find optimal
filtering parameters, suggesting new properties on the spectrum of the driving signal, but
also to estimate the optimal delay between the coupled signals, enabling a directionality esti-
mation in the coupling.
Author summary
Neural oscillations synchronize information across brain areas at



hal_id    :    hal-01404966



No abstract found in the PDF.



hal_id    :    hal-01593459



Leveraging the celebrated support vector regression (SVR) method, we propose a unifying
framework in order to deliver regression machines in reproducing kernel Hilbert spaces
(RKHSs) with data sparsity. The central point is a new deﬁnition of ϵ-insensitivity, valid for
many regression losses (including quantile and expectile regression) and their multivariate
extensions. We show that the dual optimization problem to empirical risk minimization
with ϵ-insensitivity involves a data sparse regularization. We also provide an analysis of
the excess of risk as well as a randomized coordinate descent algorithm for solving the dual.
Numerical experiments validate our approach.
Keywords: Quantile regression, Expectile regression, Operator-valued kernel.



hal_id    :    hal-01548475



While most dereverberation methods focus on how to estimate the
magnitude of an anechoic signal in the time-frequency domain, we
propose a method which also takes the phase into account. By ap-
plying a harmonic model to the anechoic signal, we derive a formu-
lation to compute the amplitude and phase of each harmonic. These
parameters are then estimated by our method in presence of rever-
beration. As we jointly estimate the amplitude and phase of the
clean signal, we achieve a very strong dereverberation on synthetic
harmonic signals, resulting in a signiﬁcant improvement of standard
dereverberation objective measures over the state-of-the-art.
Index Terms— dereverberation, phase, sinusoidal modeling,



hal_id    :    hal-01548508



This paper introduces a new method for single-channel denoising
that sheds new light on classical early developments on this topic
that occurred in the 70’s and 80’s with Wiener ﬁltering and spectral
subtraction. Operating both in the short-time Fourier transform
domain, these methods consist in estimating the power spectral
density (PSD) of the noise without speech. Then, the clean speech
signal is obtained by manipulating the corrupted time-frequency
bins thanks to these noise PSD estimates. Theoretically grounded
when using power spectra, these methods were subsequently gener-
alized to magnitude spectra, or shown to yield better performance
by weighting the PSDs in the so-called parameterized Wiener ﬁlter.
Both these strategies were long considered ad-hoc. To the best
of our knowledge, while we recently proposed an interpretation
of magnitude processing, there is still no theoretical result that
would justify the better performance of parameterized Wiener
ﬁlters. Here, we show how the α-stable probabilistic model for
waveforms naturally leads to these weighted ﬁlters and we provide
a grounded and fast algorithm to enhance corrupted audio that
compares favorably with classical denoising methods.
Index Terms—denoising, Wiener ﬁltering, α-stable processes, prob-
ability theory



hal_id    :    hal-01531259



—While most dereverberation methods focus on how
to estimate the amplitude of an anechoic signal, we propose a
method which also takes the phase into account. By applying a
sinusoidal model to the anechoic signal, we derive a formulation
to compute the amplitude and phase of each sinusoid. These
parameters are then estimated by our method in the reverberant
case. As we jointly estimate the amplitude and phase of the clean
signal, we achieve a very strong dereverberation, resulting in a
signiﬁcant improvement of objective dereverberation measures
over the state-of-the-art.



hal_id    :    hal-01531252



In this paper, we focus on the problem of sound source localization
and we propose a technique that exploits the known and arbitrary
geometry of the microphone array. While most probabilistic tech-
niques presented in the past rely on Gaussian models, we go further
in this direction and detail a method for source localization that is
based on the recently proposed α-stable harmonizable processes.
They include Cauchy and Gaussian as special cases and their
remarkable feature is to allow a simple modeling of impulsive
and real world sounds with few parameters. The approach we
present builds on the classical convolutive mixing model and has
the particularities of requiring going through the data only once,
to also work in the underdetermined case of more sources than
microphones and to allow massively parallelizable implementations
operating in the time-frequency domain. We show that the method
yields interesting performance for acoustic imaging in realistic
simulations.
Index Terms—source localization, acoustic modeling, α-
stable random variables, spectral measure, sketching



hal_id    :    hal-02912472



Cet article propose une architecture neuronale pour un modèle de langue à vocabulaire ouvert. Les
représentations continues des mots sont calculées à la volée à partir des caractères les composant,
gràce à une couche convolutionnelle suivie d’une couche de regroupement (pooling). Cela permet
au modèle de représenter n’importe quel mot, qu’il fasse partie du contexte ou soit évalué pour la
prédiction. La fonction objectif est dérivée de l’estimation contrastive bruitée (Noise Contrastive
Estimation, ou NCE), calculable dans notre cas sans vocabulaire. Nous évaluons la capacité de
notre modèle à construire des représentations continues de mots inconnus sur la tâche de traduction
automatique IWSLT-2016, de l’Anglais vers le Tchèque, en ré-évaluant les N meilleures hypothèses
(N-best reranking). Les résultats expérimentaux permettent des gains jusqu’à 0,7 point BLEU. Ils
montrent aussi la difﬁculté d’utiliser des représentations dérivées des caractères pour la prédiction.
ABSTRACT
Opening the vocabulary of neural language models with character-level word representations
This paper introduces an architecture for an open-vocabulary neural language model. Word represen-
tations are computed on-the-ﬂy by a convolution network followed by pooling layer. This allows the
model to consider any word, in the context or for the prediction. The training objective is derived from
the Noise-Contrastive Estimation to adapt it the open vocabulary case. We test the ability of our model
to



hal_id    :    hal-02395677



- Parkinson’s disease (PD) is a neurological disorder associated 
with a progressive decline in motor skills, speech, and cognitive processes. 
Since the diagnosis of Parkinson’s disease is difficult, researchers have 
worked to develop a support tool based on algorithms to differentiate 
healthy controls from PD patients. Online handwriting analysis is one of 
the methods that can be used to diagnose PD. The aim of this study is to 
find a subset of handwriting features suitable for efficiently identifying 
subjects with PD. Data was taken from PDMultiMC database collected in 
Lebanon, and consisting of 16 medicated PD patients and 16 age matched 
controls. Seven handwriting tasks were collected such as copying patterns, 
copying words in Arabic, and writing full names. For each task kinematic 
and spatio-temporal, pressure, energy, entropy, and intrinsic features were 
extracted. Feature selection was done in two stages, the first stage selected 
a subset using statistical analysis, and the second step select the most 
relevant features of this subset, by a suboptimal approach. The selected 
features were fed to a support vector machine classifier with RBF kernel, 
whose aim is to identify the subjects suffering from PD. The accuracy of 
the classification of PD was as high as



hal_id    :    hal-02912384



Noise Contrastive Estimation (NCE) is a
learning procedure that is regularly used
to train neural language models, since
it avoids the computational bottleneck
caused by the output softmax. In this pa-
per, we attempt to explain some of the
weaknesses of this objective function, and
to draw directions for further develop-
ments. Experiments on a small task show
the issues raised by the unigram noise
distribution, and that a context dependent
noise distribution, such as the bigram dis-
tribution, can solve these issues and pro-
vide stable and data-efﬁcient learning.
1



hal_id    :    hal-01401988



. We propose a probabilistic model for acoustic source local-
ization with known but arbitrary geometry of the microphone array. The
approach has several features. First, it relies on a simple nearﬁeld acous-
tic model for wave propagation. Second, it does not require the number
of active sources. On the contrary, it produces a heat map representing
the energy of a large set of candidate locations, thus imaging the acous-
tic ﬁeld. Second, it relies on a heavy-tail α-stable probabilistic model,
whose most important feature is to yield an estimation strategy where
the multichannel signals need to be processed only once in a simple on-
line procedure, called sketching. This sketching produces a ﬁxed-sized
representation of the data that is then analyzed for localization. The
resulting algorithm has a small computational complexity and in this
paper, we demonstrate that it compares favorably with state of the art
for localization in realistic simulations of reverberant environments.
1



hal_id    :    hal-01272327



Addressing the will to give a more complete picture than an average relationship provided
by standard regression, a novel framework for estimating and predicting simultaneously several
conditional quantiles is introduced. The proposed methodology leverages kernel-based multi-task
learning to curb the embarrassing phenomenon of quantile crossing, with a one-step estimation
procedure and no post-processing. Moreover, this framework comes along with theoretical guaran-
tees and an eﬃcient coordinate descent learning algorithm. Numerical experiments on benchmark
and real datasets highlight the enhancements of our approach regarding the prediction error, the
crossing occurrences and the training time.
1



hal_id    :    hal-01337860



Most dereverberation methods aim to reconstruct the ane-
choic magnitude spectrogram, given a reverberant signal.
Regardless of the method, the dereverberated signal is sys-
tematically synthesized with the reverberant phase.
This
corrupted phase reintroduces reverberation and distortion in
the signal. This is why we intend to also reconstruct the ane-
choic phase, given a reverberant signal. Before processing
speech signals, we propose in this paper a method for esti-
mating the anechoic phase of reverberant chirp signals. Our
method presents an accurate estimation of the instantaneous
phase and improves objective measures of dereverberation.
Index Terms— Dereverberation, phase, reassignment, si-
nusoidal modeling.



hal_id    :    hal-01418963



We propose an efﬁcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in
presence of pileup from a sample of low-frequency observa-
tions. Based on a functional equation linking the marks’ den-
sity to the characteristic function of the observations and its
derivative, we propose a new time-efﬁcient method using B-
splines to estimate the density of the underlying γ-ray spec-
trum which is able to handle large datasets used in nuclear
physics. A discussion on the numerical computation of the al-
gorithm and its performances on simulated data are provided
to support our ﬁndings.
Index Terms— Shot-noise, nonparametric estimation, B-
splines, γ-spectroscopy, pile-up correction



hal_id    :    hal-01347167



We propose a method that performs anomaly
detection and localisation within heterogeneous
data using a pairwise undirected mixed graphical
model. The data are a mixture of categorical and
quantitative variables, and the model is learned
over a dataset that is supposed not to contain any
anomaly. We then use the model over temporal
data, potentially a data stream, using a version of
the two-sided CUSUM algorithm. The proposed
decision statistic is based on a conditional likeli-
hood ratio computed for each variable given the
others. Our results show that this function allows
to detect anomalies variable by variable, and thus
to localise the variables involved in the anomalies
more precisely than univariate methods based on
simple marginals.



hal_id    :    hal-02287434



. In this paper, we propose an eﬃcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in presence of pileup from a
sample of low-frequency observations. Based on a functional equation linking the marks’
density to the characteristic function of the observations and its derivative, we propose a
new time-eﬃcient method using B-splines to estimate the density of the underlying γ-ray
spectrum, which is able to handle large datasets used in nuclear physics. A discussion on
the numerical computation of the algorithm and its performances on simulated data are
provided to support our ﬁndings.
Keywords. Shot-noise, B-splines, inverse problem, γ spectrometry



hal_id    :    hal-01248010



Room acoustic parameters are key information for dereverberation or speech recognition. Usually, when
one needs to assess the level of reverberation, only the reverberation time RT60 or a direct to reverberant
sounds index Dτ is estimated. Yet, methods which blindly estimate the reverberation time from reverberant
recorded speech do not always diﬀerentiate the RT60 from the Dτ to evaluate the level of reverberation. That
is why we propose a method to jointly blindly estimate these parameters, from the signal energy decay rate
distribution, by means of kernel regression. Evaluation is carried out with real and simulated room impulse
responses to generate noise-free reverberant speech signals. The results show this new method outperforms
baseline approaches in our evaluation.
1.



hal_id    :    hal-01153882



This paper addresses the generalisation of stationary Hawkes processes in order to allow
for a time-evolving second-order analysis.
Motivated by the concept of locally stationary
autoregressive processes, we apply however inherently diﬀerent techniques to describe the
time-varying dynamics of self-exciting point processes. In particular we derive a stationary
approximation of the Laplace transform of a locally stationary Hawkes process. This allows
us to deﬁne a local intensity function and a local Bartlett spectrum which can be used to
compute approximations of ﬁrst and second order moments of the process. We complete the
paper by some insightful simulation studies.
Keywords:
Locally stationary processes, Hawkes processes, Bartlett spectrum, time
frequency analysis, point processes
2000 MSC: 60G55, 62M15, 46N30



hal_id    :    hal-01080955



. This paper deals with a parametrized family of partially
observed bivariate Markov chains. We establish that, under very mild
assumptions, the limit of the normalized log-likelihood function is max-
imized when the parameters belong to the equivalence class of the true
parameter, which is a key feature for obtaining the consistency of the
maximum likelihood estimators (MLEs) in well-speciﬁed models. This
result is obtained in the general framework of partially dominated mod-
els. We examine two speciﬁc cases of interest, namely, hidden Markov
models (HMMs) and observation-driven time series models. In contrast
with previous approaches, the identiﬁability is addressed by relying on
the uniqueness of the invariant distribution of the Markov chain asso-
ciated to the complete data, regardless its rate of convergence to the
equilibrium.



hal_id    :    hal-01078073



This paper generalizes asymptotic properties obtained in the
observation-driven times series models considered by [7] in the sense
that the conditional law of each observation is also permitted to depend
on the parameter. The existence of ergodic solutions and the consis-
tency of the Maximum Likelihood Estimator (MLE) are derived under
easy-to-check conditions. The obtained conditions appear to apply for a
wide class of models. We illustrate our results with speciﬁc observation-
driven times series, including the recently introduced NBIN-GARCH
and NM-GARCH models, demonstrating the consistency of the MLE
for these two models.
MSC: Primary: 62F12; Secondary: 60J05.
Keywords: consistency, ergodicity, maximum likelihood, observation-driven
models, time series of counts.
1



hal_id    :    hal-01030799



. Consider a non–linear function G(Xt) where Xt is a stationary Gaussian se-
quence with long–range dependence. The usual reduction principle states that the partial
sums of G(Xt) behave asymptotically like the partial sums of the ﬁrst term in the expansion
of G in Hermite polynomials. In the context of the wavelet estimation of the long–range
dependence parameter, one replaces the partial sums of G(Xt) by the wavelet scalogram,
namely the partial sum of squares of the wavelet coeﬃcients. Is there a reduction principle
in the wavelet setting, namely is the asymptotic behavior of the scalogram for G(Xt) the
same as that for the ﬁrst term in the expansion of G in Hermite polynomial? The answer
is negative in general. This paper provides a minimal growth condition on the scales of the
wavelet coeﬃcients which ensures that the reduction principle also holds for the scalogram.
The results are applied to testing the hypothesis that the long-range dependence parameter
takes a speciﬁc value.
Contents
1.



hal_id    :    hal-01164121



In this paper, we consider a nonlinear inverse problem occuring in nu-
clear science. Gamma rays randomly hit a semiconductor detector which
produces an impulse response of electric current. Because the sampling
period of the measured current is larger than the mean interarrival time
of photons, the impulse responses associated to diﬀerent gamma rays can
overlap: this phenomenon is known as pileup.
In this work, it is as-
sumed that the impulse response is an exponentially decaying function.
We propose a novel method to infer the distribution of gamma photon en-
ergies from the indirect measurements obtained from the detector. This
technique is based on a formula linking the characteristic function of the
photon density to a function involving the characteristic function and its
derivative of the observations. We establish that our estimator converges
to the mark density in uniform norm at a polynomial rate.
A limited
Monte-Carlo experiment is provided to support our ﬁndings.
1



hal_id    :    hal-00984064



In this work, we study the problem of aggregating a ﬁnite number of predic-
tors for non stationary sub-linear processes. We provide oracle inequalities relying
essentially on three ingredients: 1) a uniform bound of the ℓ1 norm of the time-
varying sub-linear coeﬃcients, 2) a Lipschitz assumption on the predictors and
3) moment conditions on the noise appearing in the linear representation. Two
kinds of aggregations are considered giving rise to diﬀerent moment conditions
on the noise and more or less sharp oracle inequalities. We apply this approach
for deriving an adaptive predictor for locally stationary time varying autoregres-
sive (TVAR) processes.
It is obtained by aggregating a ﬁnite number of well
chosen predictors, each of them enjoying an optimal minimax convergence rate
under speciﬁc smoothness conditions on the TVAR coeﬃcients. We show that
the obtained aggregated predictor achieves a minimax rate while adapting to the
unknown smoothness. To prove this result, a lower bound is established for the
minimax rate of the prediction risk for the TVAR process. Numerical experiments
complete this study. An important feature of this approach is that the aggregated
predictor can be computed recursively and is thus applicable in an online predic-
tion context.
1



hal_id    :    hal-00755255



We study the convergence of centered and normalized sums of i.i.d. random elements
of the space D of c`adl`ag functions endowed with Skorohod’s J1 topology, to stable distri-
butions in D. Our results are based on the concept of regular variation on metric spaces
and on point process convergence. We provide some applications, in particular to the
empirical process of the renewal-reward process.
1



hal_id    :    hal-02437193



– We propose an eﬃcient method to estimate in a nonparametric fashion the marks’ density of a shot-noise process
subject to a high pile-up eﬀect. Based on a formula linking the characteristic function of the mark density to a function involving
the shot-noise characteristic function and its derivative, we construct a “plug-in” estimator which converges to the mark density
in uniform norm at a logarithmic speed. Two limited Monte-Carlo experiments are provided to support our ﬁndings.
1



hal_id    :    hal-01167391



An important challenge in the aeronautic industry is to cope with maintenance issues of the prod-
ucts, notably detection and localization of components breakdowns. Modern equipments enjoy better
recording and processing capacities, allowing the storage of a large amount of data, on which better
maintenance systems are expected to be built. Eﬃcient probabilistic models able to represent the
statistic distribution of the collected variables in the “normal state” of the system are needed in order
to derive anomaly detection algorithms. Graphical models constitute a rich class of models and are
natural candidates to address this task. This article proposes a method for learning undirected hy-
brid graphical models from heterogeneous data. The data are heterogeneous as they include physical
(quantitative) measures as well as a collection of inherently discrete variables for instance describing
the state of electronic devices. The model we propose is adapted from the Ising and Gaussian models
so that the data don’t require to be translated from their original space, allowing the user to easily
interpret the dependency graph learned from data. The learning step is carried out by minimizing
the negative pseudo-log-likelihood using a proximal gradient algorithm with Lasso and group Lasso
penalization for addressing the high dimension of variables. Once the model is learned, we use the
penalized negative



hal_id    :    hal-04762097



We introduce Annealed Multiple Choice Learning (aMCL) which combines simu-
lated annealing with MCL. MCL is a learning framework handling ambiguous tasks
by predicting a small set of plausible hypotheses. These hypotheses are trained
using the Winner-takes-all (WTA) scheme, which promotes the diversity of the
predictions. However, this scheme may converge toward an arbitrarily suboptimal
local minimum, due to the greedy nature of WTA. We overcome this limitation
using annealing, which enhances the exploration of the hypothesis space during
training. We leverage insights from statistical physics and information theory
to provide a detailed description of the model training trajectory. Additionally,
we validate our algorithm by extensive experiments on synthetic datasets, on the
standard UCI benchmark, and on speech separation.
1



hal_id    :    hal-04736454



—This paper describes speech enhancement for real-
time automatic speech recognition (ASR) in real environments.
A standard approach to this task is to use neural beamforming
that can work efficiently in an online manner. It estimates the
masks of clean dry speech from a noisy echoic mixture spectro-
gram with a deep neural network (DNN) and then computes a
enhancement filter used for beamforming. The performance of
such a supervised approach, however, is drastically degraded un-
der mismatched conditions. This calls for run-time adaptation
of the DNN. Although the ground-truth speech spectrogram re-
quired for adaptation is not available at run time, blind dere-
verberation and separation methods such as weighted prediction
error (WPE) and fast multichannel nonnegative matrix factor-
ization (FastMNMF) can be used for generating pseudo ground-
truth data from a mixture. Based on this idea, a prior work pro-
posed a dual-process system based on a cascade of WPE and
minimum variance distortionless response (MVDR) beamform-
ing asynchronously fine-tuned by block-online FastMNMF. To in-
tegrate the dereverberation capability into neural beamforming
and make it fine-tunable at run time, we propose to use weighted
power minimization distortionless response (WPD) beamforming,
a unified version of WPE and minimum power distortionless re-
sponse (MPDR), whose joint dereverberation and denoising filter
is estimated using a DNN. We evaluated the impact of run-time
adaptation under various



hal_id    :    hal-04768296



In this paper, we propose a novel Self-Supervised-
Learning scheme to train rhythm analysis systems and
instantiate it for few-shot beat tracking.
Taking inspi-
ration from the Contrastive Predictive Coding paradigm,
we propose to train a Log-Mel-Spectrogram-Transformer-
encoder to contrast observations at times separated by hy-
pothesized beat intervals from those that are not. We do
this without the knowledge of ground-truth tempo or beat
positions, as we rely on the local maxima of a Predomi-
nant Local Pulse function, considered as a proxy for Tatum
positions, to define candidate anchors, candidate positives
(located at a distance of a power of two from the anchor)
and negatives (remaining time positions). We show that
a model pre-trained using this approach on the unlabeled
FMA, MTT and MTG-Jamendo datasets can successfully
be fine-tuned in the few-shot regime, i.e. with just a few
annotated examples to get a competitive beat-tracking per-
formance.
1



hal_id    :    hal-04665063



The task of music structure analysis has been mostly
addressed as a sequential problem, by relying on the inter-
nal homogeneity of musical sections or their repetitions.
In this work, we instead regard it as a pairwise link pre-
diction task. If for any pair of time instants in a track, one
can successfully predict whether they belong to the same
structural entity or not, then the underlying structure can
be easily recovered. Building upon this assumption, we
propose a method that first learns to classify pairwise links
between time frames as belonging to the same section (or
segment) or not. The resulting link features, along with
node-specific information, are combined through a graph
attention network. The latter is regularized with a graph
partitioning training objective and outputs boundary loca-
tions between musical segments and section labels. The
overall system is lightweight and performs competitively
with previous methods.
The evaluation is done on two
standard datasets for music structure analysis and an ab-
lation study is conducted in order to gain insight on the
role played by its different components.



hal_id    :    hal-04695595



Machine listening systems often rely on fixed taxonomies to or-
ganize and label audio data, key for training and evaluating deep
neural networks (DNNs) and other supervised algorithms. How-
ever, such taxonomies face significant constraints: they are com-
posed of application-dependent predefined categories, which hin-
ders the integration of new or varied sounds, and exhibits limited
cross-dataset compatibility due to inconsistent labeling standards.
To overcome these limitations, we introduce SALT: Standardized
Audio event Label Taxonomy. Building upon the hierarchical struc-
ture of AudioSet’s ontology, our taxonomy extends and standardizes
labels across 24 publicly available environmental sound datasets, al-
lowing the mapping of class labels from diverse datasets to a unified
system. Our proposal comes with a new Python package designed
for navigating and utilizing this taxonomy, easing cross-dataset la-
bel searching and hierarchical exploration. Notably, our package
allows effortless data aggregation from diverse sources, hence easy
experimentation with combined datasets.
Index Terms— Machine listening, DCASE, sound taxonomy,
sound categorization, data aggregation



hal_id    :    hal-04701759



Audio-text models trained via contrastive learning offer a practical
approach to perform audio classiﬁcation through natural language
prompts, such as “this is a sound of” followed by category names. In
this work, we explore alternative prompt templates for zero-shot au-
dio classiﬁcation, demonstrating the existence of higher-performing
options. First, we ﬁnd that the formatting of the prompts signif-
icantly affects performance so that simply prompting the models
with properly formatted class labels performs competitively with
optimized prompt templates and even prompt ensembling. More-
over, we look into complementing class labels by audio-centric de-
scriptions. By leveraging large language models, we generate tex-
tual descriptions that prioritize acoustic features of sound events
to disambiguate between classes, without extensive prompt engi-
neering. We show that prompting with class descriptions leads to
state-of-the-art results in zero-shot audio classiﬁcation across ma-
jor ambient sound datasets. Remarkably, this method requires no
additional training and remains fully zero-shot.
Index Terms— Zero-shot audio classiﬁcation, audio-text mod-
els, contrastive language-audio pretraining, in-context learning



hal_id    :    hal-04720291



The Prototypical Network (ProtoNet) has emerged as a popular
choice in Few-shot Learning (FSL) scenarios due to its remark-
able performance and straightforward implementation.
Building
upon such success, we first propose a simple (yet novel) method
to fine-tune a ProtoNet on the (labeled) support set of the test
episode of a C-way-K-shot test episode (without using the query
set which is only used for evaluation). We then propose an algo-
rithmic framework that combines ProtoNet with optimization-based
FSL algorithms (MAML and Meta-Curvature) to work with such
a fine-tuning method. Since optimization-based algorithms endow
the target learner model with the ability to fast adaption to only a
few samples, we utilize ProtoNet as the target model to enhance
its fine-tuning performance with the help of a specifically designed
episodic fine-tuning strategy. The experimental results confirm that
our proposed models, MAML-Proto and MC-Proto, combined with
our unique fine-tuning method, outperform regular ProtoNet by a
large margin in few-shot audio classification tasks on the ESC-50
and Speech Commands v2 datasets. We note that although we have
only applied our model to the audio domain, it is a general method
and can be easily extended to other domains.
Index Terms— Few-shot learning, Audio classification, Proto-
typical Network, Model-Agnostic Meta-Learning, Meta-Curvature



hal_id    :    hal-04685184



As diffusion-based deep generative models gain prevalence, re-
searchers are actively investigating their potential applications
across various domains, including music synthesis and style al-
teration. Within this work, we are interested in timbre transfer, a
process that involves seamlessly altering the instrumental character-
istics of musical pieces while preserving essential musical elements.
This paper introduces WaveTransfer, an end-to-end diffusion model
designed for timbre transfer. We specifically employ the bilateral
denoising diffusion model (BDDM) for noise scheduling search.
Our model is capable of conducting timbre transfer between audio
mixtures as well as individual instruments. Notably, it exhibits ver-
satility in that it accommodates multiple types of timbre transfer
between unique instrument pairs in a single model, eliminating the
need for separate model training for each pairing.
Furthermore,
unlike recent works limited to 16 kHz, WaveTransfer can be trained
at various sampling rates, including the industry-standard 44.1 kHz,
a feature of particular interest to the music community.
Index Terms— Multi-instrumental timbre transfer, diffusion
models, music transformation, generative AI



hal_id    :    hal-04632526



This paper describes a method for estimating the room impulse
response (RIR) for a microphone and a sound source located at
arbitrary positions from the 3D mesh data of the room. Simulat-
ing realistic RIRs with pure physics-driven methods often fails
the balance between physical consistency and computational ef-
ficiency, hindering application to real-time speech processing.
Alternatively, one can use MESH2IR, a fast black-box estima-
tor that consists of an encoder extracting latent code from mesh
data with a graph convolutional network (GCN) and a decoder
generating the RIR from the latent code. Combining these two
approaches, we propose a fast yet physically coherent estimator
with interpretable latent code based on differentiable digital sig-
nal processing (DDSP). Specifically, the encoder estimates a vir-
tual shoebox room scene that acoustically approximates the real
scene, accelerating physical simulation with the differentiable
image-source model in the decoder. Our experiments showed
that our method outperformed MESH2IR for real mesh data ob-
tained with the depth scanner of Microsoft HoloLens 2, and can
provide correct spatial consistency for binaural RIRs.
Index Terms: Spatial audio, room acoustics, 3D mesh data,
physical models, DDSP



hal_id    :    hal-04640068



Single-channel speech dereverberation aims at extracting a
dry speech signal from a recording affected by the acoustic re-
flections in a room. However, most current deep learning-based
approaches for speech dereverberation are not interpretable for
room acoustics, and can be considered as black-box systems
in that regard. In this work, we address this problem by regu-
larizing the training loss using a novel physical coherence loss
which encourages the room impulse response (RIR) induced by
the dereverberated output of the model to match the acoustic
properties of the room in which the signal was recorded. Our
investigation demonstrates the preservation of the original dere-
verberated signal alongside the provision of a more physically
coherent RIR.
Index Terms: Speech dereverberation, hybrid deep learning,
room acoustics, acoustic matching, speech processing



hal_id    :    hal-04705811



—Latent representation learning has been an active
field of study for decades in numerous applications. Inspired
among others by the tokenization from Natural Language
Processing and motivated by the research of a simple data
representation, recent works have introduced a quantization step
into the feature extraction. In this work, we propose a novel
strategy to build the neural discrete representation by means of
random codebooks. These codebooks are obtained by randomly
sampling a large, predefined fixed codebook. We experimentally
show the merits and potential of our approach in a task of audio
compression and reconstruction.
Index Terms—feature extraction, quantization, random code-
books, audio reconstruction



hal_id    :    hal-04614241



—This paper addresses the challenge of estimating
multiple highly oscillating amplitudes within the nonlinear chirp
signal model. The problem is analogous to the mode detection
task with fixed instantaneous frequencies, where the oscillating
amplitudes signify mechanical vibrations concealing crucial infor-
mation for predictive maintenance. Existing methods often focus
on single-frequency estimation, employ simple amplitude func-
tions, or impose strong noise assumptions. Furthermore, these
methods frequently rely on arbitrarily chosen hyperparameters,
leading to sub-optimal generalization for a diverse range of am-
plitudes. To address these limitations, our approach introduces
two estimators, based on Capon filters and negative log-likelihood
approaches respectively, that leverage locally stationary assump-
tions and incorporate hyperparameters estimation. The results
demonstrate that, even under challenging conditions, these esti-
mators yield competitive outcomes across various noisy scenarios,
mitigating the drawbacks associated with existing methods.
Index Terms—chirp signal, amplitude estimation, locally sta-
tionary process, filtering, hyperparameters estimation



hal_id    :    hal-04574640



Winner-takes-all training is a simple learning
paradigm, which handles ambiguous tasks by pre-
dicting a set of plausible hypotheses. Recently,
a connection was established between Winner-
takes-all training and centroidal Voronoi tessel-
lations, showing that, once trained, hypotheses
should quantize optimally the shape of the condi-
tional distribution to predict. However, the best
use of these hypotheses for uncertainty quantifi-
cation is still an open question. In this work, we
show how to leverage the appealing geometric
properties of the Winner-takes-all learners for con-
ditional density estimation, without modifying its
original training scheme. We theoretically estab-
lish the advantages of our novel estimator both in
terms of quantization and density estimation, and
we demonstrate its competitiveness on synthetic
and real-world datasets, including audio data.



hal_id    :    halshs-04654217



No abstract found in the PDF.



hal_id    :    hal-04602229



In recent years, significant advances have been made in deep learn-
ing models for audio generation, offering promising tools for mu-
sical creation. In this work, we investigate the use of deep audio
generative models in interactive dance/music performance. We
adopted a performance-led research design approach, establish-
ing an art-research collaboration between a researcher/musician
and a dancer. First, we describe our motion-sound interactive sys-
tem integrating deep audio generative model and propose three
methods for embodied exploration of deep latent spaces. Then, we
detail the creative process for building the performance centered
on the co-design of the system. Finally, we report feedback from
the dancer’s interviews and discuss the results and perspectives.
The code implementation is publicly available on our github1.
CCS CONCEPTS
• Human-centered computing →Sound-based input / output;
Gestural input; Auditory feedback; Collaborative interaction;
• Applied computing →Sound and music computing; • Com-
puting methodologies →Machine learning.
KEYWORDS
dance-music-AI performance, HCI, motion-sound interaction, deep
learning, generative models, embodied exploration, latent space
ACM Reference Format:
Sarah Nabi, Philippe Esling, Geoffroy Peeters, and Frédéric Bevilacqua. 2024.
Embodied exploration of deep latent spaces in interactive dance-music
performance. In 9th International Conference on Movement and Computing
(MOCO ’24), May 30-June 2, 2024, Utrecht, Netherlands. ACM, New York, NY,
USA, 9 pages. https://doi.org/10.1145/3658852.3659072
1https://github.com/ircam-ismm/embodied-latent-exploration
Permission to make digital or hard copies of all or part of this work for personal or
classroom



hal_id    :    hal-04541350



Isolating the desired speaker’s voice amidst multiple
speakers in a noisy acoustic context is a challenging task. Per-
sonalized speech enhancement (PSE) endeavours to achieve
this by leveraging prior knowledge of the speaker’s voice.
Recent research efforts have yielded promising PSE mod-
els, albeit often accompanied by computationally intensive
architectures, unsuitable for resource-constrained embedded
devices. In this paper, we introduce a novel method to per-
sonalize a lightweight dual-stage Speech Enhancement (SE)
model and implement it within DeepFilterNet2, a SE model
renowned for its state-of-the-art performance. We seek an
optimal integration of speaker information within the model,
exploring different positions for the integration of the speaker
embeddings within the dual-stage enhancement architec-
ture. We also investigate a tailored training strategy when
adapting DeepFilterNet2 to a PSE task. We show that our
personalization method greatly improves the performances
of DeepFilterNet2 while preserving minimal computational
overhead.
Index Terms— Target speech extraction, speech en-
hancement, real-time.



hal_id    :    hal-04358467



In neural audio signal processing, pitch conditioning has been
used to enhance the performance of synthesizers. However, jointly
training pitch estimators and synthesizers is a challenge when us-
ing standard audio-to-audio reconstruction loss, leading to reliance
on external pitch trackers. To address this issue, we propose us-
ing a spectral loss function inspired by optimal transportation theory
that minimizes the displacement of spectral energy. We validate this
approach through an unsupervised autoencoding task that fits a har-
monic template to harmonic signals. We jointly estimate the funda-
mental frequency and amplitudes of harmonics using a lightweight
encoder and reconstruct the signals using a differentiable harmonic
synthesizer. The proposed approach offers a promising direction for
improving unsupervised parameter estimation in neural audio appli-
cations.
Index Terms— differentiable signal processing, machine learn-
ing, optimal transport, frequency estimation



hal_id    :    hal-04424100



Diffusion models are receiving a growing interest for a variety of
signal generation tasks such as speech or music synthesis. WaveG-
rad, for example, is a successful diffusion model that conditionally
uses the mel spectrogram to guide a diffusion process for the gen-
eration of high-fidelity audio. However, such models face important
challenges concerning the noise diffusion process for training and
inference, and they have difficulty generating high-quality speech
for speakers that were not seen during training. With the aim of
minimizing the conditioning error and increasing the efficiency of
the noise diffusion process, we propose in this paper a new scheme
called GLA-Grad, which consists in introducing a phase recovery al-
gorithm such as the Griffin-Lim algorithm (GLA) at each step of the
regular diffusion process. Furthermore, it can be directly applied to
an already-trained waveform generation model, without additional
training or fine-tuning. We show that our algorithm outperforms
state-of-the-art diffusion models for speech generation, especially
when generating speech for a previously unseen target speaker.
Index Terms— Diffusion models, speech generation, Griffin-
Lim algorithm, domain adaptation



hal_id    :    hal-04360221



Current state-of-the-art audio analysis systems rely on pre-
trained embedding models, often used off-the-shelf as (frozen)
feature extractors. Choosing the best one for a set of tasks is the
subject of many recent publications.
However, one aspect often
overlooked in these works is the influence of the duration of audio
input considered to extract an embedding, which we refer to as Tem-
poral Support (TS). In this work, we study the influence of the TS
for well-established or emerging pre-trained embeddings, chosen to
represent different types of architectures and learning paradigms.
We conduct this evaluation using both musical instrument and envi-
ronmental sound datasets, namely OpenMIC, TAU Urban Acoustic
Scenes 2020 Mobile, and ESC-50. We especially highlight that Au-
dio Spectrogram Transformer-based systems (PaSST and BEATs)
remain effective with smaller TS, which therefore allows for a dras-
tic reduction in memory and computational cost.
Moreover, we
show that by choosing the optimal TS we reach competitive results
across all tasks. In particular, we improve the state-of-the-art results
on OpenMIC, using BEATs and PaSST without any fine-tuning.
Index Terms— audio embeddings, acoustic scene classification,
instrument recognition, temporal support, transformers



hal_id    :    hal-04479188



We address the problem of accurately interpolating measured ane-
choic steering vectors with a deep learning framework called the
neural field. This task plays a pivotal role in reducing the resource-
intensive measurements required for precise sound source separa-
tion and localization, essential as the front-end of speech recogni-
tion. Classical approaches to interpolation rely on linear weighting of
nearby measurements in space on a fixed, discrete set of frequencies.
Drawing inspiration from the success of neural fields for novel view
synthesis in computer vision, we introduce the neural steerer, a con-
tinuous complex-valued function that takes both frequency and direc-
tion as input and produces the corresponding steering vector. Impor-
tantly, it incorporates inter-channel phase difference information and
a regularization term enforcing filter causality, essential for accurate
steering vector modeling. Our experiments, conducted using a dataset
of real measured steering vectors, demonstrate the effectiveness of
our resolution-free model in interpolating such measurements.
Index Terms— Steering vector, neural field, spatial audio, inter-
polation, representation learning



hal_id    :    hal-04423979



Generative adversarial network (GAN) models can synthesize high-
quality audio signals while ensuring fast sample generation. How-
ever, they are difficult to train and are prone to several issues in-
cluding mode collapse and divergence. In this paper, we introduce
SpecDiff-GAN, a neural vocoder based on HiFi-GAN, which was
initially devised for speech synthesis from mel spectrogram. In our
model, the training stability is enhanced by means of a forward dif-
fusion process which consists in injecting noise from a Gaussian
distribution to both real and fake samples before inputting them to
the discriminator. We further improve the model by exploiting a
spectrally-shaped noise distribution with the aim to make the dis-
criminator’s task more challenging. We then show the merits of our
proposed model for speech and music synthesis on several datasets.
Our experiments confirm that our model compares favorably in au-
dio quality and efficiency compared to several baselines.
Index Terms— Generative adversarial network (GAN), diffu-
sion process, deep audio synthesis, spectral envelope



hal_id    :    hal-04419041



Overlapped speech is notoriously problematic for speaker diarization
systems. Consequently, the use of speech separation has recently
been proposed to improve their performance. Although promising,
speech separation models struggle with realistic data because they
are trained on simulated mixtures with a fixed number of speakers. In
this work, we introduce a new speech separation-guided diarization
scheme suitable for the online speaker diarization of long meeting
recordings with a variable number of speakers, as present in the AMI
corpus. We envisage ConvTasNet and DPRNN as alternatives for the
separation networks, with two or three output sources. To obtain the
speaker diarization result, voice activity detection is applied on each
estimated source. The final model is fine-tuned end-to-end, after first
adapting the separation to real data using AMI. The system operates
on short segments, and inference is performed by stitching the local
predictions using speaker embeddings and incremental clustering.
The results show that our system improves the state-of-the-art on
the AMI headset mix, using no oracle information and under full
evaluation (no collar and including overlapped speech). Finally, we
show the strength of our system particularly on overlapped speech
sections.
Index Terms— online speaker diarization, source separation,
overlapped speech, AMI, speaker embedding



hal_id    :    hal-04432659



Music generated by deep learning methods often suffers
from a lack of coherence and long-term organization. Yet,
multi-scale hierarchical structure is a distinctive feature of
music signals. To leverage this information, we propose a
structure-informed positional encoding framework for music
generation with Transformers. We design three variants in
terms of absolute, relative and non-stationary positional in-
formation. We comprehensively test them on two symbolic
music generation tasks: next-timestep prediction and accom-
paniment generation.
As a comparison, we choose multi-
ple baselines from the literature and demonstrate the merits
of our methods using several musically-motivated evaluation
metrics. In particular, our methods improve the melodic and
structural consistency of the generated pieces.
Index Terms— symbolic music generation, Transform-
ers, music structure, positional encoding



hal_id    :    hal-04423348



. With the progress of generative neural models, Hierarchical Text Classification
(HTC) can be cast as a generative task. In this case, given an input text, the model generates
the sequence of predicted class labels taken from a label tree of arbitrary width and depth.
Treating HTC as a generative task introduces multiple modeling choices. These choices vary
from choosing the order for visiting the class tree and therefore defining the order of generat-
ing tokens, choosing either to constrain the decoding to labels that respect the previous level
predictions, up to choosing the pre-trained Language Model itself. Each HTC model therefore
differs from the others from an architectural standpoint, but also from the modeling choices
that were made. Prior contributions lack transparent modeling choices and open implemen-
tations, hindering the assessment of whether model performance stems from architectural or
modeling decisions. For these reasons, we propose with this paper an analysis of the impact
of different modeling choices along with common model errors and successes for this task.
This analysis is based on an open framework coming along this paper that can facilitate the
development of future contributions in the field by providing datasets, metrics, error analysis
toolkit and the capability to readily test various modeling choices for one given model.
Keywords: Hierarchical text



hal_id    :    hal-04604650



. In recent years, there has been a signicant surge in machine
learning techniques, particularly in the domain of deep learning, tailored
for handling attributed graphs. Nevertheless, to work, these methods as-
sume that the attributes values are fully known, which is not realistic
in numerous real-world applications. This paper explores the potential
of Optimal Transport (OT) to impute missing attributes on graphs. To
proceed, we design a novel multi-view OT loss function that can encom-
pass both node feature data and the underlying topological structure of
the graph by utilizing multiple graph representations. We then utilize
this novel loss to train eciently a Graph Convolutional Neural Net-
work (GCN) architecture capable of imputing all missing values over the
graph at once. We evaluate the interest of our approach with experiments
both on synthetic data and real-world graphs, including dierent miss-
ingness mechanisms and a wide range of missing data. These experiments
demonstrate that our method is competitive with the state-of-the-art in
all cases and of particular interest on weakly homophilic graphs.
Keywords: Attributed Graph · Missing Data Imputation · Optimal
Transport
1



hal_id    :    hal-04575332



We consider the statistical seriation problem, where the statistician seeks to recover a
hidden ordering from a noisy observation of a permuted Robinson matrix. In this paper,
we tightly characterize the minimax rate for this problem of matrix reordering when
the Robinson matrix is bi-Lipschitz, and we also provide a polynomial time algorithm
achieving this rate; thereby answering two open questions of [Giraud et al., 2021]. Our
analysis further extends to broader classes of similarity matrices.
1



hal_id    :    hal-04729913



Multimodal large language models have fueled progress in image captioning.
These models, fine-tuned on vast image datasets, exhibit a deep understanding
of semantic concepts. In this work, we show that this ability can be re-purposed
for audio captioning, where the joint image-language decoder can be leveraged to
describe auditory content associated with image sequences within videos featuring
audiovisual content. This can be achieved via multimodal alignment. Yet, this
multimodal alignment task is non-trivial due to the inherent disparity between
audible and visible elements in real-world videos. Moreover, multimodal repre-
sentation learning often relies on contrastive learning, facing the challenge of the
so-called modality gap which hinders smooth integration between modalities. In
this work, we introduce a novel methodology for bridging the audiovisual modality
gap by matching the distributions of tokens produced by an audio backbone and
those of an image captioner. Our approach aligns the audio token distribution
with that of the image tokens, enabling the model to perform zero-shot audio
captioning in an unsupervised fashion while keeping the initial image captioning
component unaltered. This alignment allows for the use of either audio or audiovi-
sual input by combining or substituting the image encoder with the aligned audio
encoder. Our method achieves significantly improved performances in zero-shot
audio captioning, compared to existing approaches.1
1



hal_id    :    hal-04593480



When deriving contextualized word repre-
sentations from language models, a decision
needs to be made on how to obtain one for
out-of-vocabulary (OOV) words that are seg-
mented into subwords. What is the best way
to represent these words with a single vector,
and are these representations of worse quality
than those of in-vocabulary words? We carry
out an intrinsic evaluation of embeddings from
different models on semantic similarity tasks
involving OOV words. Our analysis reveals,
among other interesting findings, that the qual-
ity of representations of words that are split is
often, but not always, worse than that of the
embeddings of known words. Their similar-
ity values, however, must be interpreted with
caution.
1



hal_id    :    hal-04578273



. The pair-matching problem appears in many applications where one wants to discover
matches between pairs of entities or individuals. Formally, the set of individuals is represented by
the nodes of a graph where the edges, unobserved at first, represent the matches. The algorithm
queries pairs of nodes and observes the presence/absence of edges. Its goal is to discover as
many edges as possible with a fixed budget of queries. Pair-matching is a particular instance of
multi-armed bandit problem in which the arms are pairs of individuals and the rewards are edges
linking these pairs. This bandit problem is non-standard though, as each arm can only be played
once.
Given this last constraint, sublinear regret can be expected only if the graph presents some
underlying structure. This paper shows that sublinear regret is achievable in the case where
the graph is generated according to a Stochastic Block Model (SBM) with two communities.
Optimal regret bounds are computed for this pair-matching problem. They exhibit a phase trans-
ition related to the Kesten-Stigum threshold for community detection in SBM. The pair-matching
problem is considered in the case where each node is constrained to be sampled less than a given
amount of times, for example for ensuring individual fairness. We show how optimal regret rates
depend on this



hal_id    :    hal-04539879



—This paper tackles two major problem settings for
interpretability of audio processing networks, post-hoc and by-
design interpretation. For post-hoc interpretation, we aim to in-
terpret decisions of a network in terms of high-level audio objects
that are also listenable for the end-user. This is extended to
present an inherently interpretable model with high performance.
To this end, we propose a novel interpreter design that incor-
porates non-negative matrix factorization (NMF). In particular,
an interpreter is trained to generate a regularized intermediate
embedding from hidden layers of a target network, learnt as time-
activations of a pre-learnt NMF dictionary. Our methodology
allows us to generate intuitive audio-based interpretations that
explicitly enhance parts of the input signal most relevant for a
network’s decision. We demonstrate our method’s applicability
on a variety of classification tasks, including multi-label data for
real-world audio and music.
Index Terms—Audio interpretability, explainability, by-design
interpretable models, audio convolutional networks, non-negative
matrix factorization



hal_id    :    hal-03615137



—Tensor factorization models are widely used in many
applied ﬁelds such as chemometrics, psychometrics, computer
vision or communication networks. Real life data collection is
often subject to errors, resulting in missing data. Here we focus
in understanding how this issue should be dealt with for non-
negative tensor factorization. We investigate several criteria used
for non-negative tensor factorization in the case where some
entries are missing. In particular we show how smoothness
penalties can compensate the presence of missing values in order
to ensure the existence of an optimum. This lead us to propose
new criteria with efﬁcient numerical optimization algorithms.
Numerical experiments are conducted to support our claims.
Index Terms—Non-negative tensor decomposition, missing val-
ues, Tensor completion, smoothness, PARAFAC, CP decomposi-
tion.



hal_id    :    hal-04410338



Seals are small coin-shaped artifacts, mostly made of lead, held with strings to seal letters.
This work presents the first attempt towards automatic reading of text on Byzantine seal
images. Byzantine seals are generally decorated with iconography on the obverse side and
Greek text on the reverse side. Text may include the sender’s name, position in the Byzantine
aristocracy, and elements of prayers. Both text and iconography are precious literary sources
that wait to be exploited electronically, so the development of computerized systems for
interpreting seals images is of paramount importance. This work’s contribution is hence a
deep, two-stages, character reading pipeline for transcribing Byzantine seal images. A first deep
convolutional neural network (CNN) detects characters in the seal (character localization). A
second convolutional network reads the localized characters (character classification). Finally, a
diplomatic transcription of the seal is provided by post-processing the two network outputs. We
provide an experimental evaluation of each CNN in isolation and both CNNs in combination. All
performances are evaluated by cross-validation. Character localization achieves a mean average
precision (mAP@0.5) greater than 0.9. Classification of characters cropped from ground truth
bounding boxes achieves Top-1 accuracy greater than 0.92. End-to-end evaluation shows the
efficiency of the proposed approach when compared to the SoTA for similar tasks.



hal_id    :    hal-04552478



Data augmentation is an essential building block for learning efﬁcient deep learning
models. Among all augmentation techniques proposed so far, linear interpolation
of training data points, also called mixup, has found to be effective for a large
panel of applications. While the majority of works have focused on selecting
the right points to mix, or applying complex non-linear interpolation, we are
interested in mixing similar points more frequently and strongly than less similar
ones. To this end, we propose to dynamically change the underlying distribution of
interpolation coefﬁcients through warping functions, depending on the similarity
between data points to combine. We deﬁne an efﬁcient and ﬂexible framework to do
so without losing in diversity. We provide extensive experiments for classiﬁcation
and regression tasks, showing that our proposed method improves both performance
and calibration of models. Code available in torch-uncertainty.
1



hal_id    :    hal-04390768



Group fairness is a central research topic in
text classification, where reaching fair treat-
ment between sensitive groups (e.g. women
vs. men) remains an open challenge. This
paper presents a novel method for mitigating
biases in neural text classification, agnostic to
the model architecture. Considering the diffi-
culty to distinguish fair from unfair informa-
tion in a text encoder, we take inspiration from
adversarial training to induce Wasserstein in-
dependence between representations learned to
predict our target label and the ones learned to
predict some sensitive attribute. Our approach
provides two significant advantages. Firstly,
it does not require annotations of sensitive at-
tributes in both testing and training data. This is
more suitable for real-life scenarios compared
to existing methods that require annotations
of sensitive attributes at train time. Secondly,
our approach exhibits a comparable or better
fairness-accuracy trade-off compared to exist-
ing methods. Our implementation is available
on Github1.
1



hal_id    :    hal-04216055



We introduce Resilient Multiple Choice Learning (rMCL), an extension of the
MCL approach for conditional distribution estimation in regression settings where
multiple targets may be sampled for each training input. Multiple Choice Learning
is a simple framework to tackle multimodal density estimation, using the Winner-
Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing
MCL variants focus on merging the hypotheses, thereby eventually sacriﬁcing
the diversity of the predictions. In contrast, our method relies on a novel learned
scoring scheme underpinned by a mathematical framework based on Voronoi tessel-
lations of the output space, from which we can derive a probabilistic interpretation.
After empirically validating rMCL with experiments on synthetic data, we further
assess its merits on the sound source localization task, demonstrating its practical
usefulness and the relevance of its interpretation.
1



hal_id    :    hal-04172863



This paper revisits single-channel audio source separation based on
a probabilistic generative model of a mixture signal defined in the
continuous time domain. We assume that each source signal fol-
lows a non-stationary Gaussian process (GP), i.e., any finite set of
sampled points follows a zero-mean multivariate Gaussian distribu-
tion whose covariance matrix is governed by a kernel function over
time-varying latent variables. The mixture signal composed of such
source signals thus follows a GP whose covariance matrix is given
by the sum of the source covariance matrices. To estimate the latent
variables from the mixture signal, we use a deep neural network with
an encoder-separator-decoder architecture (e.g., Conv-TasNet) that
separates the latent variables in a pseudo-time-frequency space. The
key feature of our method is to feed the latent variables into the ker-
nel function for estimating the source covariance matrices, instead
of using the decoder for directly estimating the time-domain source
signals. This enables the decomposition of a mixture signal into the
source signals with a classical yet powerful Wiener filter that consid-
ers the full covariance structure over all samples. The kernel func-
tion and the network are trained jointly in the maximum likelihood
framework. Comparative experiments using two-speech mixtures
under clean, noisy, and noisy-reverberant conditions from the WSJ0-
2mix, WHAM!, and WHAMR! benchmark datasets demonstrated
that the proposed method



hal_id    :    hal-04135264



BHAI 1 (Byzantine Hybrid Artificial Intelligence) is the first project
based on artificial intelligence dedicated to Byzantine seals. The
scientific consortium comprises a multidisciplinary team involving
historians specialized in the Byzantine period, specialists in sig-
illography, and computer science experts. This article describes the
main objectives of this project: data acquisition of seal images, text
and iconography recognition, seal dating, as well as our current
achievements and first results on character recognition and spatial
analysis of personages.
CCS CONCEPTS
• Applied computing →Arts and humanities; • Computing
methodologies →Spatial and physical reasoning; Semantic
networks; Natural language processing.
KEYWORDS
Byzantine Greek, Byzantine history, seal images, deep neural net-
works, character recognition, iconography recognition
ACM Reference Format:
Victoria EYHARABIDE, Laurence LIKFORMAN-SULEM, Lucia ORLANDI,
Alexandre BINOUX, Théophile RAGEAU, Qijia HUANG, Attilio FIAN-
DROTTI, Beatrice CASEAU, and Isabelle BLOCH. 2023. Study of historical
Byzantine seal images: the BHAI project for computer-based sigillography.
In 7th International Workshop on Historical Document Imaging and Processing
(HIP ’23), August 25–26, 2023, San Jose, CA, USA. ACM, New York, NY, USA,
6 pages. https://doi.org/10.1145/3604951.3605523
1



hal_id    :    hal-04216177



Self-Supervised Learning (SSL) has allowed leveraging large
amounts of unlabeled speech data to improve the perfor-
mance of speech recognition models even with small annotated
datasets.
Despite this, speech SSL representations may fail
while facing an acoustic mismatch between the pretraining and
target datasets. To address this issue, we propose a novel super-
vised domain adaptation method, designed for cases exhibiting
such a mismatch in acoustic domains. It consists in applying
properly calibrated data augmentations on a large clean dataset,
bringing it closer to the target domain, and using it as part of
an initial fine-tuning stage. Augmentations are automatically
selected through the minimization of a conditional-dependence
estimator, based on the target dataset. The approach is vali-
dated during an oracle experiment with controlled distortions
and on two amateur-collected low-resource domains, reaching
better performances compared to the baselines in both cases.
Index Terms: self-supervised learning, domain adaptation.



hal_id    :    hal-04593478



Dialog participants sometimes align their lin-
guistic styles, e.g., they use the same words
and syntactic constructions as their interlocu-
tors. We propose to investigate the notion of
lexico-semantic alignment: to what extent do
speakers convey the same meaning when they
use the same words? We design measures of
lexico-semantic alignment relying on contextu-
alized word representations. We show that they
reflect interesting semantic differences between
the two sides of a debate and that they can assist
in the task of debate’s winner prediction.
1



hal_id    :    hal-04131585



No abstract found in the PDF.



hal_id    :    hal-04130213



La façon dont nous utilisons les mots est influencée par notre opinion. Nous cherchons à savoir si cela
se reflète dans les plongements de mots contextualisés. Par exemple, la représentation d’ « animal »
est-elle différente pour les gens qui voudraient abolir les zoos et ceux qui ne le voudraient pas? Nous
explorons cette question du point de vue du changement sémantique des mots. Nos expériences avec
des représentations dérivées d’ensembles de données annotés avec les points de vue révèlent des
différences minimes, mais significatives, entre postures opposées 1.
ABSTRACT
One Word, Two Sides : Traces of Stance in Contextualized Word Representations
The way we use words is influenced by our opinion. We investigate whether this is reflected in
contextualized word embeddings. For example, is the representation of “animal” different between
people who would abolish zoos and those who would not? We explore this question from a Lexical
Semantic Change standpoint. Our experiments with BERT embeddings derived from datasets with
stance annotations reveal small but significant differences in word representations between opposing
stances.
MOTS-CLÉS : Représentations contextualisées, changement sémantique, détection de point de vue.
KEYWORDS: Contextualized representations, semantic change, stance detection.
1



hal_id    :    hal-04093374



Measuring noise in cities and automatically identifying the cor-
responding sound sources are a crucial challenge for policymak-
ers. Indeed, such information helps addressing noise pollution and
improving the well-being of urban dwellers. In recent years, re-
searchers have provided annotated datasets recorded in two ma-
jor cities to foster the development of urban sound event detection
(SED) systems. This paper presents an in-depth study of the be-
haviour of state-of-the-art SED systems well suited to our problem,
combining three far-field real recordings datasets which can be used
jointly during training. In our evaluation, we highlight the perfor-
mance gaps existing between simple and hard recording examples
based on the salience of sound events and the polyphony of the
recordings. We provide new proximity annotations for this anal-
ysis. We evaluate the ability of urban SED systems to generalize
across cities with varying degrees of training supervision. We show
that such generalization is hindered mostly by the difficulties current
urban SED systems have to detect sound events with low salience
along with sound events in highly polyphonic soundscapes.
Index Terms— Sound Event Detection (SED), Far-field urban
audio recordings, urban sound monitoring,



hal_id    :    ujm-04165556



. In contrast to classic autoregressive generation, insertion-
based models can predict in a order-free way multiple tokens at a time,
which make their generation uniquely controllable: it can be constrained
to strictly include an ordered list of tokens. We propose to exploit this
feature in a new diverse paraphrasing framework: ﬁrst, we extract im-
portant tokens or keywords in the source sentence; second, we augment
them; third, we generate new samples around them by using insertion
models. We show that the generated paraphrases are competitive with
state of the art autoregressive paraphrasers, not only in diversity but also
in quality. We further investigate their potential to create new pseudo-
labelled samples for data augmentation, using a meta-learning classiﬁca-
tion framework, and ﬁnd equally competitive result. In addition to prov-
ing non-autoregressive (NAR) viability for paraphrasing, we contribute
our open-source framework as a starting point for further research into
controllable NAR generation.
Keywords: Deep Learning · Natural language processing · Controllable
text generation · Transformers · Non-autoregressive · Insertion models.
1



hal_id    :    hal-04213215



. In recent years, large Transformer-based Pre-trained Lan-
guage Models (PLM) have changed the Natural Language Processing
(NLP) landscape, by pushing the performance boundaries of the state-
of-the-art on a wide variety of tasks. However, this performance gain goes
along with an increase in complexity, and as a result, the size of such
models (up to billions of parameters) represents a constraint for their
deployment on embedded devices or short-inference time tasks. To cope
with this situation, compressed models emerged (e.g. DistilBERT), de-
mocratizing their usage in a growing number of applications that impact
our daily lives. A crucial issue is the fairness of the predictions made by
both PLMs and their distilled counterparts. In this paper, we propose
an empirical exploration of this problem by formalizing two questions:
(1) Can we identify the neural mechanism(s) responsible for gender bias
in BERT (and by extension DistilBERT)? (2) Does distillation tend to
accentuate or mitigate gender bias (e.g. is DistilBERT more prone to
gender bias than its uncompressed version, BERT)? Our findings are the
following: (I) one cannot identify a specific layer that produces bias; (II)
every attention head uniformly encodes bias; except in the context of un-
derrepresented classes with a high imbalance of the sensitive attribute;
(III) this subset of heads is different as we re-fine tune the



hal_id    :    hal-04253752



Non-deterministic measurements are common in real-world scenarios: the performance
of a stochastic optimization algorithm or the total reward of a reinforcement learning agent
in a chaotic environment are just two examples in which unpredictable outcomes are com-
mon. These measures can be modeled as random variables and compared among each other
via their expected values or more sophisticated tools such as null hypothesis statistical
tests. In this paper, we propose an alternative framework to visually compare two sam-
ples according to their estimated cumulative distribution functions. First, we introduce a
dominance measure for two random variables that quantiﬁes the proportion in which the
cumulative distribution function of one of the random variables stochastically dominates
the other one. Then, we present a graphical method that decomposes in quantiles i) the
proposed dominance measure and ii) the probability that one of the random variables takes
lower values than the other. With illustrative purposes, we re-evaluate the experimentation
of an already published work with the proposed methodology and we show that additional
conclusions—missed by the rest of the methods—can be inferred. Additionally, the software
package RVCompare was created as a convenient way of applying and experimenting with
the proposed framework.
Keywords:
Data visualization, Random variables, Cumulative distribution function, First-order
stochastic dominance
1
arXiv:2203.07889v4  [stat.ML]  30 Aug 2022
0.0225 0.0250 0.0275 0.0300 0.0325



hal_id    :    hal-04244852



Handling large datasets and calculating complex statistics on huge datasets require
important computing resources. Using subsampling methods to calculate statistics
of interest on small samples is often used in practice to reduce computational com-
plexity, for instance using the divide and conquer strategy. In this article, we recall
some results on subsampling distributions and derive a precise rate of convergence
for these quantities and the corresponding quantiles. We also develop some standard-
ization techniques based on subsampling unstandardized statistics in the framework
of large datasets. It is argued that using several subsampling distributions with dif-
ferent subsampling sizes brings a lot of information on the behavior of statistical
learning procedures: subsampling allows to estimate the rate of convergence of dif-
ferent algorithms, to estimate the variability of complex statistics, to estimate conﬁ-
dence intervals for out-of-sample errors and interpolate their values at larger scales.
These results are illustrated on simulations, but also on two important datasets,
frequently analyzed in the statistical learning community, EMNIST (recognition of
digits) and VeReMi (analysis of Network Vehicular Reference Misbehavior).
KEYWORDS
Scaling, big data, Subsampling, Convergence rate estimation, Conﬁdence intervals
in statistical learning, Out-of sample error, EMNIST digits VeReMi



hal_id    :    hal-04310171



Argumentation
. . . . .
51
G. Dubuisson Duplessis, M. Richard, A.-L. Guénet (APIA)
Segmentation de phases de dialogue dans des retranscriptions de conversations de centres
d’appels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
A. Ferdjaoui, S. Affeldt, M. Nadif (SFC)
Modèles graphiques causaux interactifs pour les données textuelles . . . . . . . . . . . . .
65
C. Fèvre, H. Zgaya-Biau, P. Mathieu, S. Hammadi (JFSMA)
L’optimisation du covoiturage dynamique multi-saut . . . . . . . . . . . . . . . . . . . . .
71
S. Forest, J.-C. Quinton, M. Lefort (CNIA)
Champ neuronal et apprentissage profond de topologies pour la fusion multimodale . . . .
81
A. Godinot, E. Le Merrer, C. Penzo, F. Taïani, G. Tredan (RJCIA)
Change-Relaxed Active Fairness Auditing . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
K. Le Gall, L. Bellanger, A. Stamm, D.A. Laplaud (SFC)
Génération de données



hal_id    :    hal-04258177



No abstract found in the PDF.



hal_id    :    hal-04390005



Optimal transport (OT) compares probability distributions by
computing a meaningful alignment between their samples. CO-
optimal transport (COOT) takes this comparison further by
inferring an alignment between features as well. While this ap-
proach leads to better alignments and generalizes both OT and
Gromov-Wasserstein distances, we provide a theoretical result
showing that it is sensitive to outliers that are omnipresent
in real-world data. This prompts us to propose unbalanced
COOT for which we provably show its robustness to noise in
the compared datasets. To the best of our knowledge, this is
the ﬁrst such result for OT methods in incomparable spaces.
With this result in hand, we provide empirical evidence of this
robustness for the challenging tasks of heterogeneous domain
adaptation with and without varying proportions of classes
and simultaneous alignment of samples and features across
single-cell measurements.



hal_id    :    hal-03608767



—This paper introduces a theoretically-rigorous sound
source localization (SSL) method based on a robust extension
of the classical multiple signal classification (MUSIC) algorithm.
The original SSL method estimates the noise eigenvectors and the
MUSIC spectrum by computing the spatial covariance matrix of
the observed multichannel signal and then detects the peaks from
the spectrum. In this work, the covariance matrix is replaced with
the positive definite shape matrix originating from the elliptically
contoured α-stable model, which is more suitable under real
noisy high-reverberant conditions. Evaluation on synthetic data
shows that the proposed method outperforms baseline methods
under such adverse conditions, while it is comparable on real
data recorded in a mild acoustic condition.
Index Terms— sound source localization, MUSIC, α-stable
theory, covariation



hal_id    :    hal-03990543



No abstract found in the PDF.



hal_id    :    hal-03821125



—This article describes a computationally-efﬁcient sta-
tistical approach to joint (semi-)blind source separation and dere-
verberation for multichannel noisy reverberant mixture signals. A
standard approach to source separation is to formulate a generative
model of a multichannel mixture spectrogram that consists of
source and spatial models representing the time-frequency power
spectral densities (PSDs) and spatial covariance matrices (SCMs)
of source images, respectively, and ﬁnd the maximum-likelihood
estimates of these parameters. A state-of-the-art blind source sep-
aration method in this thread of research is fast multichannel
nonnegative matrix factorization (FastMNMF) based on the low-
rank PSDs and jointly-diagonalizable full-rank SCMs. To perform
mutually-dependent separation and dereverberation jointly, in this
paper we integrate both moving average (MA) and autoregressive
(AR) models that represent the early reﬂections and late rever-
berations of sources, respectively, into the FastMNMF formalism.
Using a pretrained deep generative model of speech PSDs as a
source model, we realize semi-blind joint speech separation and
dereverberation. We derive an iterative optimization algorithm
based on iterative projection or iterative source steering for jointly
and efﬁciently updating the AR parameters and the SCMs. Our
experimentalresultsshowedthesuperiorityoftheproposedARMA
extensionoveritsAR-orMA-ablatedversioninaspeechseparation
and/or dereverberation task.
Index Terms—Multichannel audio signal processing, source
separation, dereverberation, joint diagonalization.
Manuscript received 4 October 2021; revised 31 March 2022; accepted 18
June2022.Dateofpublication13July2022;dateofcurrentversion28July2022.
This work was supported in part by JSPS KAKENHI under Grants 19H04137,
20K19833, and 20H01159, and in part by NII



hal_id    :    hal-03657196



—This paper describes heavy-tailed extensions of a
state-of-the-art versatile blind source separation method called
fast multichannel nonnegative matrix factorization (FastMNMF)
from a uniﬁed point of view. The common way of deriving such an
extension is to replace the multivariate complex Gaussian distribu-
tion in the likelihood function with its heavy-tailed generalization,
e.g., the multivariate complex Student’s t and leptokurtic gener-
alized Gaussian distributions, and tailor-make the corresponding
parameter optimization algorithm. Using a wider class of heavy-
tailed distributions called a Gaussian scale mixture (GSM), i.e., a
mixture of Gaussian distributions whose variances are perturbed
by positive random scalars called impulse variables, we propose
GSM-FastMNMF and develop an expectation-maximization algo-
rithm that works even when the probability density function of
the impulse variables have no analytical expressions. We show
that existing heavy-tailed FastMNMF extensions are instances of
GSM-FastMNMF and derive a new instance based on the gen-
eralized hyperbolic distribution that include the normal-inverse
Gaussian, Student’s t, and Gaussian distributions as the special
cases. Our experiments show that the normal-inverse Gaussian
FastMNMF outperforms the state-of-the-art FastMNMF exten-
sions and ILRMA model in speech enhancement and separation
in terms of the signal-to-distortion ratio.
Index Terms—Nonnegative matrix factorization, blind source
separation, probabilistic framework, expectation-maximization



hal_id    :    hal-03860497



, ISMIR 2022 Conference
SSM-NET: FEATURE LEARNING FOR MUSIC STRUCTURE ANALYSIS
USING A SELF-SIMILARITY-MATRIX BASED LOSS
Geoffroy Peeters
LTCI, Télécom-Paris, IP-Paris
geoffroy.peeters@telecom-paris.fr
Florian Angulo
LTCI, Télécom-Paris, IP-Paris
florian.angulo@telecom-paris.fr
ABSTRACT
In this paper, we propose a new paradigm to learn au-
dio features for Music Structure Analysis (MSA).
We
train a deep encoder to learn features such that the Self-
Similarity-Matrix (SSM) resulting from those approxi-
mates a ground-truth SSM. This is done by minimizing
a loss between both SSMs.
Since this loss is differen-
tiable w.r.t. its input features we can train the encoder in a
straightforward way. We successfully demonstrate the use
of this training paradigm using the Area Under the Curve
ROC (AUC) on the RWC-Pop dataset.



hal_id    :    hal-03903647



As music has become more available especially on music
streaming platforms, people have started to have distinct
preferences to fit to their varying listening situations, also
known as context. Hence, there has been a growing inter-
est in considering the user’s situation when recommending
music to users. Previous works have proposed user-aware
autotaggers to infer situation-related tags from music con-
tent and user’s global listening preferences. However, in
a practical music retrieval system, the autotagger could be
only used by assuming that the context class is explicitly
provided by the user. In this work, for designing a fully
automatised music retrieval system, we propose to disam-
biguate the user’s listening information from their stream
data. Namely, we propose a system which can generate a
situational playlist for a user at a certain time 1) by leverag-
ing user-aware music autotaggers, and 2) by automatically
inferring the user’s situation from stream data (e.g. device,
network) and user’s general profile information (e.g. age).
Experiments show that such a context-aware personalized
music retrieval system is feasible, but the performance de-
creases in the case of new users, new tracks or when the
number of context classes increases.



hal_id    :    hal-03782827



Invariance-based learning is a promising approach in deep learning.
Among other benefits, it can mitigate the lack of diversity of avail-
able datasets and increase the interpretability of trained models. To
this end, practitioners often use a consistency cost penalizing the
sensitivity of a model to a set of carefully selected data augmen-
tations. However, there is no consensus about how these augmen-
tations should be selected. In this paper, we study the behavior
of several augmentation strategies. We consider the task of sound
event detection and classification for our experiments. In particular,
we show that transformations operating on the internal layers of a
deep neural network are beneficial for this task.
Index Terms— sound event detection, data augmentation, ad-
versarial learning



hal_id    :    hal-03860830



The way we use words is influenced by our
opinion.
We investigate whether this is re-
flected in contextualized word embeddings.
For example, is the representation of “animal”
different between people who would abolish
zoos and those who would not? We explore
this question from a Lexical Semantic Change
standpoint. Our experiments with BERT em-
beddings derived from datasets with stance
annotations reveal small but significant differ-
ences in word representations between oppos-
ing stances.
1



hal_id    :    hal-03817736



Contrastive learning enables learning useful audio and speech
representations without ground-truth labels by maximizing the
similarity between latent representations of similar signal seg-
ments. In this framework various data augmentation techniques
are usually exploited to help enforce desired invariances within
the learned representations, improving performance on various
audio tasks thanks to more robust embeddings. Now, selecting
the most relevant augmentations has proven crucial for better
downstream performances. Thus, this work introduces a condi-
tional independance-based method which allows for automati-
cally selecting a suitable distribution on the choice of augmenta-
tions and their parametrization from a set of predefined ones, for
contrastive self-supervised pre-training. This is performed with
respect to a downstream task of interest, hence saving a costly
hyper-parameter search. Experiments performed on two differ-
ent downstream tasks validate the proposed approach showing
better results than experimenting without augmentation or with
baseline augmentations. We furthermore conduct a qualitative
analysis of the automatically selected augmentations and their
variation according to the considered final downstream dataset.
Index Terms: self-supervised learning, data augmentation.



hal_id    :    hal-03860827



Our discourses are full of potential lexical ambiguities, due in part to the pervasive use of words having multiple senses.
Sometimes, one word may even be used in more than one sense throughout a text. But, to what extent is this true for different
kinds of texts? Does the use of polysemous words change when a discourse involves two people, or when speakers have time
to plan what to say? We investigate these questions by comparing the polysemy level of texts of different nature, with a focus
on spontaneous spoken dialogs; unlike previous work which examines solely scripted, written, monolog-like data. We compare
multiple metrics that presuppose different conceptualizations of text polysemy, i.e., they consider the observed or the potential
number of senses of words, or their sense distribution in a discourse. We show that the polysemy level of texts varies greatly
depending on the kind of text considered, with dialog and spoken discourses having generally a higher polysemy level than
written monologs. Additionally, our results emphasize the need for relaxing the popular “one sense per discourse” hypothesis.
Keywords: Semantics, Word Sense Disambiguation, Document classification / Text categorisation
1.



hal_id    :    hal-04273536



Users generate content constantly, leading to new data requiring annotation.
Among this data, textual conversations are
created every day and come with some specificities: they are mostly private through instant messaging applications, requiring
the conversational context to be labeled. These specificities led to several annotation tools dedicated to conversation, and
mostly dedicated to dialogue tasks, requiring complex annotation schemata, not always customizable and not taking into
account conversation-level labels.
In this paper, we present EZCAT, an easy-to-use interface to annotate conversations
in a two-level configurable schema, leveraging message-level labels and conversation-level labels at once.
Our interface
is characterized by the voluntary absence of a server and accounts management, enhancing its availability to anyone, and
the control over data, which is crucial to confidential conversations. We also present our first usage of EZCAT along with
our annotation schema we used to annotate confidential customer service conversations.
EZCAT is freely available at
https://gguibon.github.io/ezcat.
Keywords: conversations, annotation tool, text messages
1.



hal_id    :    hal-04276012



In this paper, we present the process we used in order to collect new annotations of opinions over the multimodal corpus
SEMAINE composed of dyadic interactions. The dataset had already been annotated continuously in two affective dimensions
related to the emotions: Valence and Arousal.
We annotated the part of SEMAINE called Solid SAL composed of 79
interactions between a user and an operator playing the role of a virtual agent designed to engage a person in a sustained,
emotionally colored conversation. We aligned the audio at the word level using the available high-quality manual transcriptions.
The annotated dataset contains 5627 speech turns for a total of 73,944 words, corresponding to 6 hours 20 minutes of dyadic
interactions. Each interaction has been labeled by three annotators at the speech turn level following a three-step process. This
method allows us to obtain a precise annotation regarding the opinion of a speaker. We obtain thus a dataset dense in opinions,
with more than 48% of the annotated speech turns containing at least one opinion. We then propose a new baseline for the
detection of opinions in interactions improving slightly a state of the art model with RoBERTa embeddings. The obtained
results on the database are promising with a F1-score at 0.72.
Keywords: Opinion, Multimodal Machine



hal_id    :    hal-04166172



. Handwriting is an everyday life human activity. It can be
collected oﬀ-line by scanning sheets of paper. The resulting images can
then be processed by a computer-based system. Thanks to digitizing
tablets, handwriting can also be collected on-line. From the collected raw
signals (pen position, pressure over time), the dynamics of the writing
can be recovered. Since handwriting is unique for each individual, it can
be considered as a biometric modality.
Biometric systems predicting gender from oﬀ-line handwriting, have been
recently proposed. However we observe that, in contrast to other modal-
ities such as speech, it is not straightforward for a human being (even
expert) to predict gender. In this study we explore the limits of auto-
matic gender prediction from on-line handwriting collected from a young
adults population, homogeneous in terms of age and education. In our
previous work [1], a statistical analysis of on-line dynamic features has
shown diﬀerences between male and female groups. In the present study,
we provide these features to a classiﬁer, based on a machine learning ap-
proach (SVMs). Since datasets are relatively small (240 subjects), several
evaluation frameworks are explored: cross validation (CV), bootstrap,
and ﬁxed train/test partitions. Accuracies obtained from ﬁxed partitions
range from 37% to 79%, while those estimated by CV and bootstrap
are around 60%.
This shows to our opinion



hal_id    :    hal-03637425



This paper describes a blind source separation method for multichan-
nel audio signals, called NF-FastMNMF, based on the integration of
the normalizing ﬂow (NF) into the multichannel nonnegative matrix
factorization with jointly-diagonalizable spatial covariance matrices,
a.k.a. FastMNMF. Whereas the NF of ﬂow-based independent vector
analysis, called NF-IVA, acts as the demixing matrices to transform
an M-channel mixture into M independent sources, the NF of NF-
FastMNMF acts as the diagonalization matrices to transform an M-
channel mixture into a spatially-independent M-channel mixture rep-
resented as a weighted sum of N source images. This diagonalization
enables the NF, which has been used only for determined separation
because of its bijective nature, to be applicable to non-determined
separation. NF-FastMNMF has time-varying diagonalization matri-
ces that are potentially better at handling dynamical data variation
than the time-invariant ones in FastMNMF. To have an NF with richer
expression capability, the dimension-wise scalings using diagonal ma-
trices originally used in NF-IVA are replaced with linear transforma-
tions using upper triangular matrices; in both cases, the diagonal and
upper triangular matrices are estimated by neural networks. The eval-
uation shows that NF-FastMNMF performs well for both determined
and non-determined separations of multiple speech utterances by sta-
tionary or non-stationary speakers from a noisy reverberant mixture.
Index Terms— Blind source separation, normalizing ﬂow, joint
diagonalization, multichannel nonnegative matrix factorization



hal_id    :    hal-03602455



This paper introduces a new extragradient-type algorithm for a class of
nonconvex-nonconcave minimax problems. It is well-known that ﬁnding a local
solution for general minimax problems is computationally intractable. This ob-
servation has recently motivated the study of structures suﬃcient for convergence
of ﬁrst order methods in the more general setting of variational inequalities when
the so-called weak Minty variational inequality (MVI) holds. This problem class
captures non-trivial structures as we demonstrate with examples, for which a large
family of existing algorithms provably converge to limit cycles. Our results require
a less restrictive parameter range in the weak MVI compared to what is previously
known, thus extending the applicability of our scheme. The proposed algorithm is
applicable to constrained and regularized problems, and involves an adaptive step-
size allowing for potentially larger stepsizes. Our scheme also converges globally
even in settings where the underlying operator exhibits limit cycles.
1



hal_id    :    hal-03727169



— This paper describes the practical response- and
performance-aware development of online speech enhancement
for an augmented reality (AR) headset that helps a user under-
stand conversations made in real noisy echoic environments (e.g.,
cocktail party). One may use a state-of-the-art blind source sep-
aration method called fast multichannel nonnegative matrix fac-
torization (FastMNMF) that works well in various environments
thanks to its unsupervised nature. Its heavy computational cost,
however, prevents its application to real-time processing. In con-
trast, a supervised beamforming method that uses a deep neural
network (DNN) for estimating spatial information of speech and
noise readily fits real-time processing, but suffers from drastic
performance degradation in mismatched conditions. Given such
complementary characteristics, we propose a dual-process ro-
bust online speech enhancement method based on DNN-based
beamforming with FastMNMF-guided adaptation. FastMNMF
(back end) is performed in a mini-batch style and the noisy and
enhanced speech pairs are used together with the original par-
allel training data for updating the direction-aware DNN (front
end) with backpropagation at a computationally-allowable inter-
val. This method is used with a blind dereverberation method
called weighted prediction error (WPE) for transcribing the
noisy reverberant speech of a speaker, which can be detected
from video or selected by a user’s hand gesture or eye gaze, in
a streaming manner and spatially showing the transcriptions
with an AR technique. Our



hal_id    :    hal-03701451



Cet article présente l’approche de l’équipe TGV lors de sa participation à la tâche de base de DEFT
2022, dont l’objectif était de prédire automatiquement les notes obtenues par des étudiants sur la
base de leurs réponses à des questionnaires. Notre stratégie s’est focalisée sur la mise au point d’une
méthode de classification des questions en fonction du type de réponse qu’elles attendent, de manière
à pouvoir mener une approche différenciée pour chaque type. Nos trois runs ont consisté en une
approche non différenciée, servant de référence, et deux approches différenciées, la première se basant
sur la constitution d’un jeu de caractéristiques et la seconde sur le calcul de TF-IDF et de la fonction
de hashage. Notre objectif premier était ainsi de vérifier si des approches dédiées à chaque type de
questions sont préférables à une approche globale.
ABSTRACT
Team TGV at DEFT 2022 : automatic prediction of students’ grades according to the different
question types.
In this paper we present the work of the TGV team for the DEFT 2022 challenge. We tackled the
base task only, which consists of automatically grading students based on their answers to several
questions. Our strategy consider this task as a classification task with multiple approaches, each being
specific to a question type leading to different types of



hal_id    :    hal-03821095



This paper describes a practical dual-process speech enhance-
ment system that adapts environment-sensitive frame-online
beamforming (front-end) with help from environment-free
block-online source separation (back-end). To use minimum
variance distortionless response (MVDR) beamforming, one
may train a deep neural network (DNN) that estimates time-
frequency masks used for computing the covariance matrices
of sources (speech and noise). Backpropagation-based run-
time adaptation of the DNN was proposed for dealing with the
mismatched training-test conditions. Instead, one may try to
directly estimate the source covariance matrices with a state-of-
the-art blind source separation method called fast multichannel
non-negative matrix factorization (FastMNMF). In practice,
however, neither the DNN nor the FastMNMF can be updated
in a frame-online manner due to its computationally-expensive
iterative nature. Our DNN-free system leverages the posteri-
ors of the latest source spectrograms given by block-online
FastMNMF to derive the current source covariance matrices
for frame-online beamforming. The evaluation shows that our
frame-online system can quickly respond to scene changes
caused by interfering speaker movements and outperformed
an existing block-online system with DNN-based beamform-
ing by 5.0 points in terms of the word error rate.
Index Terms— speech enhancement, beamforming, blind
source separation, automatic speech recognition



hal_id    :    hal-03727181



This paper describes noisy speech recognition for an augmented
reality headset that helps verbal communication with in real mul-
tiparty conversational environments. A major approach that has
actively been studied in simulated environments is to sequentially
perform speech enhancement and automatic speech recognition
(ASR) based on deep neural networks (DNNs) trained in a su-
pervised manner. In our task, however, such a pretrained system
fails to work due to the mismatch between the training and test
conditions and the head movements of the user. To enhance only
the utterances of a target speaker, we use beamforming based on
a DNN-based speech mask estimator that can adaptively extract
the speech components corresponding to a head-relative particu-
lar direction. We propose a semi-supervised adaptation method
that jointly updates the mask estimator and the ASR model at
run-time using clean speech signals with ground-truth transcrip-
tions and noisy speech signals with highly-confident estimated
transcriptions. Comparative experiments using the state-of-the-
art distant speech recognition system show that the proposed
method significantly improves the ASR performance.
Index Terms: speech enhancement, speech recognition, human-
computer interaction, run-time adaptation.



hal_id    :    hal-03574595



Spoken dialog systems need to be able to han-
dle both multiple languages and multilingual-
ity inside a conversation (e.g in case of code-
switching). In this work, we introduce new
pretraining losses tailored to learn multilingual
spoken dialog representations.
The goal of
these losses is to expose the model to code-
switched language. To scale up training, we
automatically build a pretraining corpus com-
posed of multilingual conversations in ﬁve dif-
ferent languages (French, Italian, English, Ger-
man and Spanish) from OpenSubtitles, a
huge multilingual corpus composed of 24.3G
tokens. We test the generic representations on
MIAM, a new benchmark composed of ﬁve di-
alog act corpora on the same aforementioned
languages as well as on two novel multilingual
downstream tasks (i.e multilingual mask utter-
ance retrieval and multilingual inconsistency
identiﬁcation). Our experiments show that our
new code switched-inspired losses achieve a
better performance in both monolingual and
multilingual settings.
1



hal_id    :    hal-03344680



Several recent studies on dyadic human-
human interactions have been done on con-
versations without speciﬁc business objectives.
However, many companies might beneﬁt from
studies dedicated to more precise environ-
ments such as after sales services or customer
satisfaction surveys. In this work, we place
ourselves in the scope of a live chat customer
service in which we want to detect emotions
and their evolution in the conversation ﬂow.
This context leads to multiple challenges that
range from exploiting restricted, small and
mostly unlabeled datasets to ﬁnding and adapt-
ing methods for such context.
We tackle
these challenges by using Few-Shot Learning
while making the hypothesis it can serve con-
versational emotion classiﬁcation for different
languages and sparse labels.
We contribute
by proposing a variation of Prototypical Net-
works for sequence labeling in conversation
that we name ProtoSeq. We test this method
on two datasets with different languages: daily
conversations in English and customer service
chat conversations in French. When applied
to emotion classiﬁcation in conversations, our
method proved to be competitive even when
compared to other ones. The code for Proto-
Seq is available at https://github.com/
gguibon/ProtoSeq.
1



hal_id    :    hal-03574609



Multimodal sentiment analysis is a trending
area of research, and the multimodal fusion
is one of its most active topic. Acknowledg-
ing humans communicate through a variety of
channels (i.e visual, acoustic, linguistic), mul-
timodal systems aim at integrating different
unimodal representations into a synthetic one.
So far, a consequent effort has been made on
developing complex architectures allowing the
fusion of these modalities. However, such sys-
tems are mainly trained by minimising sim-
ple losses such as L1 or cross-entropy.
In
this work, we investigate unexplored penalties
and propose a set of new objectives that mea-
sure the dependency between modalities. We
demonstrate that our new penalties lead to a
consistent improvement (up to 4.3 on accu-
racy) across a large variety of state-of-the-art
models on two well-known sentiment analysis
datasets: CMU-MOSI and CMU-MOSEI. Our
method not only achieves a new SOTA on both
datasets but also produces representations that
are more robust to modality drops. Finally, a
by-product of our methods includes a statisti-
cal network which can be used to interpret the
high dimensional representations learnt by the
model.
1



hal_id    :    hal-03329932



—Analog-to-feature (A2F) conversion is an acquisition
method thought for IoT devices in order to increase wireless
sensor’s battery life. The operating principle of A2F is to
perform classification tasks at sub-Nyquist rate, by extracting
relevant features in the analog domain and then performing
the classification step in the digital domain. We propose to use
non-uniform wavelet sampling (NUWS) combined with feature
selection to find and extract from the signal, a small set of relevant
features for electrocardiogram (ECG) anomalies detection. A
CMOS 0.18 µm mixed architecture for NUWS feature extraction
is proposed, to obtain a power consumption model for A2F.
This model can be taken into account in the feature selection
step by evaluating the energy cost of each wavelet and then
try to maximize classification accuracy while minimizing the
energy needed for extraction. We demonstrate the benefits of A2F
showing that the energy needed can be divided by 15 compared
to classical approach.
Index Terms—Analog-to-Feature converter, Bio-sensing ac-
quisition, Feature selection, Low power, Non-Uniform Wavelet
Sampling.



hal_id    :    hal-03409892



Emergent states are behavioral, cognitive and affective processes ap-
pearing among the members of a group when they interact together.
In the last decade, the development of computational approaches
received a growing interest in building Human-Centered systems.
Such a development is particularly difficult because some of these
states have several dimensions interplaying somehow and some-
where over time. In this paper, we focus on cohesion, its dimensions
and their interplay. Several definitions of cohesion exist, it can be
simply defined as the tendency of a group to stick together to pursue
goals and/or affective needs. This plethora of definitions resulted in
many different cohesion dimensions. Social and Task dimensions
are the most investigated both in Social Sciences and Computer
Science since they both play an important role in a wide range of
contexts and groups. To the best of our knowledge, however, no pre-
vious work on the prediction of cohesion dynamics focused on how
these 2 dimensions interplay. We leverage Social Sciences to address
this issue. In particular, we take advantage of the importance of
Social cohesion for creating flexible and constructive relationships
to reinforce Task cohesion. We describe a Deep Neural Network
architecture (DNN) for predicting the dynamics of Task cohesion
by applying transfer learning from a pre-trained model dedicated
to the prediction of Social cohesion dynamics. Our architecture
is



hal_id    :    hal-03167498



—The analysis of load curves collected
from smart meters is a key step for many energy man-
agement tasks ranging from consumption forecasting
to customers characterization and load monitoring.
In this contribution, we propose a model based on a
functional formulation of nonnegative tensor factor-
ization and derive updates for the corresponding opti-
mization problem. We show on the concrete example
of multi-sites load curves disaggregation how this
formulation is helpful for 1) exhibiting smooth intra-
day consumption patterns and 2) taking into account
external variables such as the outside temperature.
The beneﬁts are demonstrated on simulated and real
data by exhibiting a meaningful clustering of the
observed sites based on the obtained decomposition.



hal_id    :    hal-03563675



In this paper, we place ourselves in a classi-
ﬁcation scenario in which the target classes
and data type are not accessible during train-
ing. We use a meta-learning approach to de-
termine whether or not meta-trained informa-
tion from common social network data with
ﬁne-grained emotion labels can achieve com-
petitive performance on messages labeled with
different emotion categories. We leverage few-
shot learning to match with the classiﬁcation
scenario and consider metric learning based
meta-learning by setting up Prototypical Net-
works with a Transformer encoder, trained in
an episodic fashion.
This approach proves
to be effective for capturing meta-information
from a source emotional tag set to predict pre-
viously unseen emotional tags. Even though
shifting the data type triggers an expected per-
formance drop, our meta-learning approach
achieves decent results when compared to the
fully supervised one.
1



hal_id    :    hal-02985794



Speech separation with several speakers is a challenging task be-
cause of the non-stationarity of the speech and the strong signal
similarity between interferent sources. Current state-of-the-art so-
lutions can separate well the different sources using sophisticated
deep neural networks which are very tedious to train. When several
microphones are available, spatial information can be exploited to
design much simpler algorithms to discriminate speakers. We pro-
pose a distributed algorithm that can process spatial information in
a spatially unconstrained microphone array. The algorithm relies on
a convolutional recurrent neural network that can exploit the signal
diversity from the distributed nodes. In a typical case of a meeting
room, this algorithm can capture an estimate of each source in a ﬁrst
step and propagate it over the microphone array in order to increase
the separation performance in a second step. We show that this ap-
proach performs even better when the number of sources and nodes
increases. We also study the inﬂuence of a mismatch in the number
of sources between the training and testing conditions.
Index Terms— Speech separation, microphone arrays, dis-
tributed processing.



hal_id    :    hal-03265871



Dans cet article nous reproduisons un scénario d’apprentissage selon lequel les données cibles
ne sont pas accessibles et seules des données connexes le sont. Nous utilisons une approche par
méta-apprentissage aﬁn de déterminer si les méta-informations apprises à partir de messages issus
de médias sociaux, ﬁnement annotés en émotions, peuvent produire de bonnes performances une
fois utilisées sur des messages issus de conversations, étiquetés en émotions avec une granularité
différente. Nous mettons à proﬁt l’apprentissage sur quelques exemples (few-shot learning) pour la
mise en place de ce scénario. Cette approche se montre efﬁcace pour capturer les méta-informations
d’un jeu d’étiquettes émotionnelles pour prédire des étiquettes jusqu’alors inconnues au modèle. Bien
que le fait de varier le type de données engendre une baisse de performance, notre approche par
méta-apprentissage atteint des résultats décents comparés au référentiel d’apprentissage supervisé.
ABSTRACT
Meta-learning : Classifying Messages into Unseen Emotional Categories
In this paper, we place ourselves in a classiﬁcation scenario in which the target data set classes and
data type are not accessible during training. We use a meta-learning approach to determine whether
or not meta-trained information from common social network data with ﬁne-grained emotion labels
can achieve competitive performance on conversation utterances labeled with different, higher level,
emotions. We leverage few-shot learning to concur with the classiﬁcation scenario. This



hal_id    :    hal-02429681



Discrete time trawl processes constitute a large class of time series parameterized by a
trawl sequence (aj)j∈N and deﬁned though a sequence of independent and identically
distributed (i.i.d.) copies of a continuous time process (γ(t))t∈R called the seed process.
They provide a general framework for modeling linear or non-linear long range dependent
time series. We investigate the spectral estimation, either pointwise or broadband, of long
range dependent discrete-time trawl processes. The diﬃculty arising from the variety of
seed processes and of trawl sequences is twofold. First, the spectral density may take
diﬀerent forms, often including smooth additive correction terms. Second, trawl processes
with similar spectral densities may exhibit very diﬀerent statistical behaviors. We prove
the consistency of our estimators under very general conditions and we show that a wide
class of trawl processes satisfy them. This is done in particular by introducing a weighted
weak dependence index that can be of independent interest.
The broadband spectral
estimator includes an estimator of the long memory parameter. We complete this work
with numerical experiments to evaluate the ﬁnite sample size performance of this estimator
for various integer valued discrete time trawl processes.
Keywords: trawl processes; integer-valued time series; long memory parameter estimation
MSC: 62M10; 62F12; 60G51;
1



hal_id    :    hal-03189235



Data depth is a concept in multivariate statistics that measures the centrality
of a point in a given data cloud in Rd. If the depth of a point can be represented
as the minimum of the depths with respect to all one-dimensional projections
of the data, then the depth satisﬁes the so-called projection property. Such
depths form an important class that includes many of the depths that have
been proposed in literature. For depths that satisfy the projection property an
approximate algorithm can easily be constructed since taking the minimum of
the depths with respect to only a ﬁnite number of one-dimensional projections
yields an upper bound for the depth with respect to the multivariate data. Such
an algorithm is particularly useful if no exact algorithm exists or if the exact
algorithm has a high computational complexity, as is the case with the halfspace
depth or the projection depth. To compute these depths in high dimensions,
the use of an approximate algorithm with better complexity is surely preferable.
Instead of focusing on a single method we provide a comprehensive and fair
comparison of several methods, both already described in the literature and
original.
Keywords:
data depth, projection property, approximate computation,
∗Corresponding author
Email addresses: rainer.dyckerhoff@statistik.uni-koeln.de (Rainer Dyckerhoﬀ),
pavlo.mozharovskyi@telecom-paris.fr (Pavlo Mozharovskyi), nagy@karlin.mff.cuni.cz
(Stanislav Nagy)
Preprint submitted to Computational Statistics and Data Analysis
November 20,



hal_id    :    hal-02088860



. In this contribution we are interested in proving that a given
observation-driven model is identiﬁable. In the case of a GARCH(p, q) model,
a simple suﬃcient condition has been established in [2] for showing the consis-
tency of the quasi-maximum likelihood estimator. It turns out that this condi-
tion applies for a much larger class of observation-driven models, that we call
the class of linearly observation-driven models. This class includes standard in-
teger valued observation-driven time series such as the Poisson autoregression
model and its numerous extensions. Our results also apply to vector-valued
time series such as the bivariate integer valued GARCH model, to non-linear
models such as the threshold Poisson autoregression or to observation-driven
models with exogenous covariates such as the PARX model.



hal_id    :    hal-03188029



John W. Tukey (1975) deﬁned statistical data depth as a function that determines centrality of
an arbitrary point with respect to a data cloud or to a probability measure. During the last decades,
this seminal idea of data depth evolved into a powerful tool proving to be useful in various ﬁelds
of science. Recently, extending the notion of data depth to the functional setting attracted a lot
of attention among theoretical and applied statisticians. We go further and suggest a notion of
data depth suitable for data represented as curves, or trajectories, which is independent of the
parametrization. We show that our curve depth satisﬁes theoretical requirements of general depth
functions that are meaningful for trajectories. We apply our methodology to diffusion tensor
brain images and also to pattern recognition of hand written digits and letters. Supplementary
Materials are available online.
Keywords: data depth, space of curves, unparametrized curves, nonparametric statistics,
curve registration, DT-MRI ﬁbers, classiﬁcation, DD-plot.
1



hal_id    :    hal-02933051



Screening rules were recently introduced as a technique for explicitly
identifying active structures such as sparsity, in optimization problem
arising in machine learning. This has led to new methods of acceleration
based on a substantial dimension reduction.
We show that screening
rules stem from a combination of natural properties of subdiﬀerential sets
and optimality conditions, and can hence be understood in a uniﬁed way.
Under mild assumptions, we analyze the number of iterations needed to
identify the optimal active set for any converging algorithm. We show that
it only depends on its convergence rate.
1



hal_id    :    hal-03134854



While being an essential component
of spoken language, ﬁllers (e.g. “um”
or “uh”) often remain overlooked in
Spoken Language Understanding (SLU)
tasks.
We explore the possibility of
representing them with deep contex-
tualised embeddings, showing improve-
ments on modelling spoken language
and two downstream tasks — predict-
ing a speaker’s stance and expressed
conﬁdence.
1



hal_id    :    hal-02934433



Music tags are commonly used to describe and catego-
rize music. Various auto-tagging models and datasets have
been proposed for the automatic music annotation with
tags. However, the past approaches often neglect the fact
that many of these tags largely depend on the user, espe-
cially the tags related to the context of music listening. In
this paper, we address this problem by proposing a user-
aware music auto-tagging system and evaluation protocol.
Speciﬁcally, we use both the audio content and user infor-
mation extracted from the user listening history to predict
contextual tags for a given user/track pair. We propose a
new dataset of music tracks annotated with contextual tags
per user. We compare our model to the traditional audio-
based model and study the inﬂuence of user embeddings
on the classiﬁcation quality. Our work shows that explic-
itly modeling the user listening history into the automatic
tagging process could lead to more accurate estimation of
contextual tags.



hal_id    :    hal-02507316



.
We present a framework for deﬁning the “right” level of
explainability based on technical, legal and economic considerations.
Our approach involves three logical steps: First, deﬁne the main con-
textual factors, such as who is the audience of the explanation, the
operational context, the level of harm that the system could cause,
and the legal/regulatory framework. This step will help characterize
the operational and legal needs for explanation, and the correspond-
ing social beneﬁts. Second, examine the technical tools available,
including post-hoc approaches (input perturbation, saliency maps...)
and hybrid AI approaches. Third, as function of the ﬁrst two steps,
choose the right levels of global and local explanation outputs, taking
into the account the costs involved. We identify seven kinds of costs
and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1



hal_id    :    hal-03132996



With the ubiquity of sensors in the IoT era,
statistical observations are becoming increas-
ingly available in the form of massive (multi-
variate) time-series. Formulated as unsuper-
vised anomaly detection tasks, an abundance
of applications like aviation safety manage-
ment, the health monitoring of complex in-
frastructures or fraud detection can now rely
on such functional data, acquired and stored
with an ever ﬁner granularity. The concept
of statistical depth, which reﬂects centrality
of an arbitrary observation w.r.t. a statisti-
cal population may play a crucial role in this
regard, anomalies corresponding to observa-
tions with ’small’ depth. Supported by sound
theoretical and computational developments
in the recent decades, it has proven to be
extremely useful, in particular in functional
spaces.
However, most approaches docu-
mented in the literature consist in evaluat-
ing independently the centrality of each point
forming the time series and consequently ex-
hibit a certain insensitivity to possible shape
changes. In this paper, we propose a novel
notion of functional depth based on the area
of the convex hull of sampled curves, captur-
ing gradual departures from centrality, even
beyond the envelope of the data, in a nat-
ural fashion. We discuss practical relevance
of commonly imposed axioms on functional
depths and investigate which of them are sat-
isﬁed by the notion of depth we promote here.
Estimation and computational issues are also
addressed and various numerical experiments
provide empirical evidence



hal_id    :    hal-02547012



The problem of multi-label classification with missing labels (MLML)
is a common challenge that is prevalent in several domains, e.g.
image annotation and auto-tagging. In multi-label classification,
each instance may belong to multiple class labels simultaneously.
Due to the nature of the dataset collection and labelling proce-
dure, it is common to have incomplete annotations in the dataset,
i.e. not all samples are labelled with all the corresponding labels.
However, the incomplete data labelling hinders the training of clas-
sification models. MLML has received much attention from the
research community. However, in cases where a pre-trained model
is fine-tuned on an MLML dataset, there has been no straightfor-
ward approach to tackle the missing labels, specifically when there
is no information about which are the missing ones. In this paper,
we propose a weighted loss function to account for the confidence
in each label/sample pair that can easily be incorporated to fine-
tune a pre-trained model on an incomplete dataset. Our experiment
results show that using the proposed loss function improves the
performance of the model as the ratio of missing labels increases.
CCS CONCEPTS
• Computing methodologies →Neural networks.
KEYWORDS
Multi-label classification; missing labels; neural networks
ACM Reference Format:
Karim M. Ibrahim, Elena V. Epure, Geoffroy Peeters, and Gaël Richard. 2020.
Confidence-based Weighted Loss for Multi-label Classification with Missing
Labels. In Proceedings of the



hal_id    :    hal-02481374



Music listening context such as location or activity has been shown
to greatly inﬂuence the users’ musical tastes. In this work, we study
the relationship between user context and audio content in order to
enable context-aware music recommendation agnostic to user data.
For that, we propose a semi-automatic procedure to collect track sets
which leverages playlist titles as a proxy for context labelling. Using
this, we create and release a dataset of ∼50k tracks labelled with
15 different contexts. Then, we present benchmark classiﬁcation
results on the created dataset using an audio auto-tagging model. As
the training and evaluation of these models are impacted by missing
negative labels due to incomplete annotations, we propose a sample-
level weighted cross entropy loss to account for the conﬁdence in
missing labels and show improved context prediction results.
Index Terms— music auto-tagging, user context, dataset col-
lection, multi-label classiﬁcation, missing labels.



hal_id    :    hal-02389159



Multichannel processing is widely used for speech enhancement but
several limitations appear when trying to deploy these solutions in
the real world. Distributed sensor arrays that consider several de-
vices with a few microphones is a viable solution which allows for
exploiting the multiple devices equipped with microphones that we
are using in our everyday life. In this context, we propose to extend
the distributed adaptive node-speciﬁc signal estimation approach to
a neural network framework. At each node, a local ﬁltering is per-
formed to send one signal to the other nodes where a mask is esti-
mated by a neural network in order to compute a global multichan-
nel Wiener ﬁlter. In an array of two nodes, we show that this addi-
tional signal can be leveraged to predict the masks and leads to better
speech enhancement performance than when the mask estimation re-
lies only on the local signals.
Index Terms— Speech enhancement, microphone arrays, dis-
tributed processing.



hal_id    :    hal-02914840



The principle of compositionality, which enables natural language to represent
complex concepts via a structured combination of simpler ones, allows us to con-
vey an open-ended set of messages using a limited vocabulary. If compositionality
is indeed a natural property of language, we may expect it to appear in commu-
nication protocols that are created by neural agents in language games. In this
paper, we propose an effective neural iterated learning (NIL) algorithm that, when
applied to interacting neural agents, facilitates the emergence of a more structured
type of language. Indeed, these languages provide learning speed advantages to
neural agents during training, which can be incrementally ampliﬁed via NIL. We
provide a probabilistic model of NIL and an explanation of why the advantage
of compositional language exist. Our experiments conﬁrm our analysis, and also
demonstrate that the emerged languages largely improve the generalizing power
of the neural agent communication.
1



hal_id    :    hal-02506409



The recent enthusiasm for artiﬁcial intelligence (AI) is due principally to
advances in deep learning. Deep learning methods are remarkably accurate,
but also opaque, which limits their potential use in safety-critical applications.
To achieve trust and accountability, designers and operators of machine learn-
ing algorithms must be able to explain the inner workings, the results and the
causes of failures of algorithms to users, regulators, and citizens. The orig-
inality of this paper is to combine technical, legal and economic aspects of
explainability to develop a framework for deﬁning the ”right” level of explain-
ability in a given context. We propose three logical steps: First, deﬁne the
main contextual factors, such as who the audience of the explanation is, the
operational context, the level of harm that the system could cause, and the
legal/regulatory framework. This step will help characterize the operational
and legal needs for explanation, and the corresponding social beneﬁts. Second,
examine the technical tools available, including post hoc approaches (input
perturbation, saliency maps...) and hybrid AI approaches. Third, as function
of the ﬁrst two steps, choose the right levels of global and local explanation
outputs, taking into the account the costs involved. We identify seven kinds
of costs and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1We would like to



hal_id    :    hal-01440269



We present single imputation method for missing values which borrows the idea of data  
depth—a measure of centrality defined for an arbitrary point of a space with respect to a prob- 
ability distribution or data cloud. This consists in iterative maximization of the depth of each 
observation with missing values, and can be employed with any properly defined statistical depth 
function. For each single iteration, imputation reverts to optimization of quadratic, linear, or 
quasiconcave functions that are solved analytically by linear programming or the Nelder-Mead 
method. As it accounts for the underlying data topology, the procedure is distribution free, allows 
imputation close to the data geometry, can make prediction in situations where local imputation 
(k-nearest neighbors, random forest) cannot, and has attractive robustness and asymptotic prop- 
erties under elliptical symmetry. It is shown that a special case—when using the Mahalanobis 
depth—has direct connection to well-known methods for the multivariate normal model, such as 
iterated regression and regularized PCA. The methodology is extended to multiple imputation for 
data stemming from an elliptically symmetric distribution. Simulation and real data studies show 
good results compared with existing popular alternatives. The method has been implemented as 
an R-package. Supplementary materials for the article



hal_id    :    hal-02433213



Source separation aims at decomposing a vector into additive components. This
is often done by ﬁrst estimating source parameters before feeding them into a
ﬁltering method, often based on ratios of covariances. The whole pipeline is
traditionally rooted in some probabilistic framework providing both the likeli-
hood for parameter estimation and the separation method. While Gaussians
are ubiquitous for this purpose, many studies showed the beneﬁt of heavy-tailed
models for estimation. However, there is no counterpart ﬁltering method to date
exploiting such formalism, so that related studies revert to covariance-based ﬁl-
tering after estimation is ﬁnished.
Here, we introduce a new multivariate separation technique, that fully ex-
ploits the ﬂexibility of α-stable heavy-tailed distributions. We show how a spa-
tial representation can be exploited, which decomposes the observation as an
inﬁnite sum of contributions originating from all directions. Two methods for
separation are derived. The ﬁrst one is non-linear and similar to a beamforming
technique, while the second one is linear, but minimizes a covariation criterion,
which is the counterpart of the covariance for α-stable vectors. We evaluate the
proposed techniques in a large number of challenging and adverse situations on
synthetic experiments, demonstrating their performance for the extraction of
signals from strong interferences.
Keywords:
alpha-stable distribution, separation theory, additive models,
measure theory, optimization
$This work was partly supported by the research



hal_id    :    hal-01502252



Locally stationary Hawkes processes have been introduced in order to generalise clas-
sical Hawkes processes away from stationarity by allowing for a time-varying second-order
structure. This class of self-exciting point processes has recently attracted a lot of inter-
est in applications in the life sciences (seismology, genomics, neuro-science,...), but also
in the modeling of high-frequency ﬁnancial data. In this contribution we provide a fully
developed nonparametric estimation theory of both local mean density and local Bartlett
spectra of a locally stationary Hawkes process. In particular we apply our kernel estima-
tion of the spectrum localised both in time and frequency to two data sets of transaction
times revealing pertinent features in the data that had not been made visible by classical
non-localised approaches based on models with constant fertility functions over time.
Keywords: Time frequency analysis; Locally stationary time series; high frequency ﬁ-
nancial data; Non-parametric kernel estimation; Self-exciting point processes.
1



hal_id    :    hal-01497104



This paper introduces a randomized coordinate descent version of the V˜u-Condat algorithm.
By
coordinate descent, we mean that only a subset of the coordinates of the primal and dual iterates is
updated at each iteration, the other coordinates being maintained to their past value.
Our method
allows us to solve optimization problems with a combination of diﬀerentiable functions, constraints as
well as non-separable and non-diﬀerentiable regularizers.
We show that the sequences generated by our algorithm almost surely converge to a saddle point
of the problem at stake, for a wider range of parameter values than previous methods. In particular,
the condition on the step-sizes depends on the coordinate-wise Lipschitz constant of the diﬀerentiable
function’s gradient, which is a major feature allowing classical coordinate descent to perform so well when
it is applicable. We then prove a sublinear rate of convergence in general and a linear rate of convergence
if the objective enjoys strong convexity properties.
We illustrate the performances of the algorithm on a total-variation regularized least squares regression
problem and on large scale support vector machine problems.
1



hal_id    :    hal-02369435



For the purpose of monitoring the behavior of complex infrastructures (e.g.
aircrafts,
transport or energy networks), high-rate sensors are deployed to capture multivariate data,
generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anoma-
lies that may jeopardize the smooth operation of the system of interest. The statistical
analysis of such massive data of functional nature raises many challenging methodological
questions. The primary goal of this paper is to extend the popular Isolation Forest (IF)
approach to Anomaly Detection, originally dedicated to ﬁnite dimensional observations, to
functional data. The major diﬃculty lies in the wide variety of topological structures that
may equip a space of functions and the great variety of patterns that may characterize
abnormal curves.
We address the issue of (randomly) splitting the functional space in
a ﬂexible manner in order to isolate progressively any trajectory from the others, a key
ingredient to the eﬃciency of the algorithm. Beyond a detailed description of the algo-
rithm, computational complexity and stability issues are investigated at length. From the
scoring function measuring the degree of abnormality of an observation provided by the
proposed variant of the IF algorithm, a Functional Statistical Depth function is deﬁned and
discussed, as well as a multivariate functional extension. Numerical experiments provide
strong empirical evidence of the accuracy of the extension



hal_id    :    hal-02420416



In this paper, we address how to evaluate and improve the perfor-
mance of automatic dominant melody extraction systems from a
pattern mining perspective with a focus on jazz improvisations.
Traditionally, dominant melody extraction systems estimate the
melody on the frame-level, but for real-world musicological appli-
cations note-level representations are needed. For the evaluation of
estimated note tracks, the current frame-wise metrics are not fully
suitable and provide at most a first approximation. Furthermore,
mining melodic patterns (n-grams) poses another challenge because
note-wise errors propagate geometrically with increasing length of
the pattern. On the other hand, for certain derived metrics such as
pattern commonalities between performers, extraction errors might
be less critical if at least qualitative rankings can be reproduced.
Finally, while searching for similar patterns in a melody database
the number of irrelevant patterns in the result set increases with
lower similarity thresholds. For reasons of usability, it would be in-
teresting to know the behavior using imperfect automated melody
extractions. We propose three novel evaluation strategies for es-
timated note-tracks based on three application scenarios: Pattern
mining, pattern commonalities, and fuzzy pattern search. We apply
the proposed metrics to one general state-of-the-art melody esti-
mation method (Melodia) and to two variants of an algorithm that
was optimized for the extraction of jazz solos melodies. A subset of
the Weimar Jazz Database



hal_id    :    hal-02943462



In the last few years, several datasets have been released
to meet the requirements of “hungry” yet promising data-
driven approaches in music technology research. Since,
for historical reasons, most investigations conducted in the
ﬁeld still revolve around music of the so-called “West-
ern” tradition, the corresponding data, methodology and
conclusions carry a strong cultural bias. Music of non-
“Western” background, whenever present, is usually un-
derrepresented, poorly labeled, or even mislabeled, the
exception being projects that aim at speciﬁcally describ-
ing such music. In this paper we present SAMBASET,
a dataset of Brazilian samba music that contains over
40 hours of historical and modern samba de enredo com-
mercial recordings. To the best of our knowledge, this is
the ﬁrst dataset of this genre. We describe the collection of
metadata (e.g. artist, composer, release date) and outline
our semiautomatic approach to the challenging task of an-
notating beats in this large dataset, which includes the as-
sessment of the performance of state-of-the-art beat track-
ing algorithms for this speciﬁc case. Finally, we present
a study on tempo and beat tracking that illustrates SAM-
BASET’s value, and we comment on other tasks for which
it could be used.



hal_id    :    hal-02166428



. The development of cluster computing frameworks has al-
lowed practitioners to scale out various statistical estimation and ma-
chine learning algorithms with minimal programming eﬀort. This is es-
pecially true for machine learning problems whose objective function
is nicely separable across individual data points, such as classiﬁcation
and regression. In contrast, statistical learning tasks involving pairs (or
more generally tuples) of data points — such as metric learning, clus-
tering or ranking — do not lend themselves as easily to data-parallelism
and in-memory computing. In this paper, we investigate how to bal-
ance between statistical performance and computational eﬃciency in
such distributed tuplewise statistical problems. We ﬁrst propose a sim-
ple strategy based on occasionally repartitioning data across workers
between parallel computation stages, where the number of repartition-
ing steps rules the trade-oﬀbetween accuracy and runtime. We then
present some theoretical results highlighting the beneﬁts brought by the
proposed method in terms of variance reduction, and extend our results
to design distributed stochastic gradient descent algorithms for tuplewise
empirical risk minimization. Our results are supported by numerical ex-
periments in pairwise statistical estimation and learning on synthetic and
real-world datasets.
Keywords: Distributed Machine Learning · Distributed Data Process-
ing · U-Statistics · Stochastic Gradient Descent · AUC Optimization
1



hal_id    :    hal-02288063



—We propose a semi-supervised multichannel speech
enhancement system based on a probabilistic model which as-
sumes that both speech and noise follow the heavy-tailed multi-
variate complex Cauchy distribution. As we advocate, this allows
handling strong and adverse noisy conditions. Consequently, the
model is parameterized by the source magnitude spectrograms
and the source spatial scatter matrices. To deal with the non-
additivity of scatter matrices, our ﬁrst contribution is to perform
the enhancement on a projected space. Then, our second contri-
bution is to combine a latent variable model for speech, which
is trained by following the variational autoencoder framework,
with a low-rank model for the noise source. At test time, an it-
erative inference algorithm is applied, which produces estimated
parameters to use for separation. The speech latent variables are
estimated ﬁrst from the noisy speech and then updated by a gra-
dient descent method, while a majorization-equalization strategy
is used to update both the noise and the spatial parameters of
both sources. Our experimental results show that the Cauchy
model outperforms the state-of-art methods. The standard devi-
ation scores also reveal that the proposed method is more robust
against non-stationary noise.
Index Terms—Multichannel speech enhancement, multivariate
complex Cauchy distribution, variational autoencoder, nonnega-
tive matrix factorization



hal_id    :    hal-01900037



Popular machine learning estimators involve
regularization parameters that can be chal-
lenging to tune, and standard strategies rely
on grid search for this task. In this paper,
we revisit the techniques of approximating
the regularization path up to predeﬁned tol-
erance ϵ in a uniﬁed framework and show
that its complexity is O(1/ d√ϵ) for uniformly
convex loss of order d > 0 and O(1/√ϵ)
for Generalized Self-Concordant functions.
This framework encompasses least-squares
but also logistic regression (a case that as far
as we know was not handled as precisely by
previous works). We leverage our technique
to provide reﬁned bounds on the validation
error as well as a practical algorithm for hy-
perparameter tuning.
The later has global
convergence guarantee when targeting a pre-
scribed accuracy on the validation set. Last
but not least, our approach helps relieving
the practitioner from the (often neglected)
task of selecting a stopping criterion when
optimizing over the training set: our method
automatically calibrates it based on the tar-
geted accuracy on the validation set.
1



hal_id    :    hal-02303823



No abstract found in the PDF.



hal_id    :    hal-02912385



Noise-Contrastive Estimation (NCE) is a learning criterion that is regularly used to train neural
language models in place of Maximum Likelihood Estimation, since it avoids the computational
bottleneck caused by the output softmax. In this paper, we analyse and explain some of the
weaknesses of this objective function, linked to the mechanism of self-normalization, by closely
monitoring comparative experiments. We then explore several remedies and modiﬁcations to
propose tractable and efﬁcient NCE training strategies. In particular, we propose to make the
scaling factor a trainable parameter of the model, and to use the noise distribution to initialize the
output bias. These solutions, yet simple, yield stable and competitive performances in either small
and large scale language modelling tasks.
1



hal_id    :    lirmm-01766795



. This paper introduces a new method for multichannel speech
enhancement based on a versatile modeling of the residual noise spec-
trogram. Such a model has already been presented before in the single
channel case where the noise component is assumed to follow an alpha-
stable distribution for each time-frequency bin, whereas the speech spec-
trogram, supposed to be more regular, is modeled as Gaussian. In this
paper, we describe a multichannel extension of this model, as well as
a Monte Carlo Expectation - Maximisation algorithm for parameter es-
timation. In particular, a multichannel extension of the Itakura-Saito
nonnegative matrix factorization is exploited to estimate the spectral
parameters for speech, and a Metropolis-Hastings algorithm is proposed
to estimate the noise contribution. We evaluate the proposed method in
a challenging multichannel denoising application and compare it to other
state-of-the-art algorithms.
1



hal_id    :    hal-02912471



L’estimation contrastive bruitée (NCE) et l’échantillonage par importance (IS) sont des procédures
d’entraînement basées sur l’échantillonage, que l’on utilise habituellement à la place de l’estimation
du maximum de vraisemblance (MLE) pour éviter le calcul du softmax lorsque l’on entraîne des
modèles de langue neuronaux. Dans cet article, nous cherchons à résumer le fonctionnement de ces
algorithmes, et leur utilisation dans la littérature du TAL. Nous les comparons expérimentalement, et
présentons des manières de faciliter l’entraînement du NCE.
ABSTRACT
Here the title in English.
Noise Contrastive Estimation (NCE) and Importance Sampling (IS) are sampling based algorithms
traditionally used to avoid computing the costly output softmax when training neural language models
with Maximum Likelihood Estimation (MLE). In this work, we attempt to summarize how these
procedures work, and how they have been used in the computational linguistics literature. We then
compare them, and experiment with tricks that ease NCE training.
MOTS-CLÉS : Modèle de langue, Estimation contrastive bruitée, Negative Sampling.
KEYWORDS: Neural Language Model, Noise Contrastive Estimation, Negative Sampling.



hal_id    :    hal-01812011



In high dimension, it is customary to consider
Lasso-type estimators to enforce sparsity. For
standard Lasso theory to hold, the regulariza-
tion parameter should be proportional to the
noise level, which is often unknown in prac-
tice. A remedy is to consider estimators such
as the Concomitant Lasso, which jointly opti-
mize over the regression coeﬃcients and the
noise level. However, when data from diﬀer-
ent sources are pooled to increase sample size,
noise levels diﬀer and new dedicated estima-
tors are needed. We provide new statistical
and computational solutions to perform het-
eroscedastic regression, with an emphasis on
brain imaging with magneto- and electroen-
cephalography (M/EEG). When instantiated
to de-correlated noise, our framework leads to
an eﬃcient algorithm whose computational
cost is not higher than for the Lasso, but ad-
dresses more complex noise structures. Ex-
periments demonstrate improved prediction
and support identiﬁcation with correct esti-
mation of noise levels.
1



hal_id    :    hal-01269137



. In this contribution we introduce weakly locally stationary time series through
the local approximation of the non-stationary covariance structure by a stationary one.
This allows us to deﬁne autoregression coeﬃcients in a non-stationary context, which, in
the particular case of a locally stationary Time Varying Autoregressive (TVAR) process,
coincide with the generating coeﬃcients. We provide and study an estimator of the time
varying autoregression coeﬃcients in a general setting. The proposed estimator of these
coeﬃcients enjoys an optimal minimax convergence rate under limited smoothness condi-
tions. In a second step, using a bias reduction technique, we derive a minimax-rate estima-
tor for arbitrarily smooth time-evolving coeﬃcients, which outperforms the previous one
for large data sets. In turn, for TVAR processes, the predictor derived from the estimator
exhibits an optimal minimax prediction rate.



hal_id    :    hal-01679078



We address the issue of reliably detecting and quantifying cross-frequency coupling (CFC)
in neural time series. Based on non-linear auto-regressive models, the proposed method
provides a generative and parametric model of the time-varying spectral content of the
signals. As this method models the entire spectrum simultaneously, it avoids the pitfalls
related to incorrect filtering or the use of the Hilbert transform on wide-band signals. As the
model is probabilistic, it also provides a score of the model “goodness of fit” via the likeli-
hood, enabling easy and legitimate model selection and parameter comparison; this data-
driven feature is unique to our model-based approach. Using three datasets obtained with
invasive neurophysiological recordings in humans and rodents, we demonstrate that these
models are able to replicate previous results obtained with other metrics, but also reveal
new insights such as the influence of the amplitude of the slow oscillation. Using simulations,
we demonstrate that our parametric method can reveal neural couplings with shorter signals
than non-parametric methods. We also show how the likelihood can be used to find optimal
filtering parameters, suggesting new properties on the spectrum of the driving signal, but
also to estimate the optimal delay between the coupled signals, enabling a directionality esti-
mation in the coupling.
Author summary
Neural oscillations synchronize information across brain areas at



hal_id    :    hal-01404966



No abstract found in the PDF.



hal_id    :    hal-01593459



Leveraging the celebrated support vector regression (SVR) method, we propose a unifying
framework in order to deliver regression machines in reproducing kernel Hilbert spaces
(RKHSs) with data sparsity. The central point is a new deﬁnition of ϵ-insensitivity, valid for
many regression losses (including quantile and expectile regression) and their multivariate
extensions. We show that the dual optimization problem to empirical risk minimization
with ϵ-insensitivity involves a data sparse regularization. We also provide an analysis of
the excess of risk as well as a randomized coordinate descent algorithm for solving the dual.
Numerical experiments validate our approach.
Keywords: Quantile regression, Expectile regression, Operator-valued kernel.



hal_id    :    hal-01548475



While most dereverberation methods focus on how to estimate the
magnitude of an anechoic signal in the time-frequency domain, we
propose a method which also takes the phase into account. By ap-
plying a harmonic model to the anechoic signal, we derive a formu-
lation to compute the amplitude and phase of each harmonic. These
parameters are then estimated by our method in presence of rever-
beration. As we jointly estimate the amplitude and phase of the
clean signal, we achieve a very strong dereverberation on synthetic
harmonic signals, resulting in a signiﬁcant improvement of standard
dereverberation objective measures over the state-of-the-art.
Index Terms— dereverberation, phase, sinusoidal modeling,



hal_id    :    hal-01548508



This paper introduces a new method for single-channel denoising
that sheds new light on classical early developments on this topic
that occurred in the 70’s and 80’s with Wiener ﬁltering and spectral
subtraction. Operating both in the short-time Fourier transform
domain, these methods consist in estimating the power spectral
density (PSD) of the noise without speech. Then, the clean speech
signal is obtained by manipulating the corrupted time-frequency
bins thanks to these noise PSD estimates. Theoretically grounded
when using power spectra, these methods were subsequently gener-
alized to magnitude spectra, or shown to yield better performance
by weighting the PSDs in the so-called parameterized Wiener ﬁlter.
Both these strategies were long considered ad-hoc. To the best
of our knowledge, while we recently proposed an interpretation
of magnitude processing, there is still no theoretical result that
would justify the better performance of parameterized Wiener
ﬁlters. Here, we show how the α-stable probabilistic model for
waveforms naturally leads to these weighted ﬁlters and we provide
a grounded and fast algorithm to enhance corrupted audio that
compares favorably with classical denoising methods.
Index Terms—denoising, Wiener ﬁltering, α-stable processes, prob-
ability theory



hal_id    :    hal-01531259



—While most dereverberation methods focus on how
to estimate the amplitude of an anechoic signal, we propose a
method which also takes the phase into account. By applying a
sinusoidal model to the anechoic signal, we derive a formulation
to compute the amplitude and phase of each sinusoid. These
parameters are then estimated by our method in the reverberant
case. As we jointly estimate the amplitude and phase of the clean
signal, we achieve a very strong dereverberation, resulting in a
signiﬁcant improvement of objective dereverberation measures
over the state-of-the-art.



hal_id    :    hal-01531252



In this paper, we focus on the problem of sound source localization
and we propose a technique that exploits the known and arbitrary
geometry of the microphone array. While most probabilistic tech-
niques presented in the past rely on Gaussian models, we go further
in this direction and detail a method for source localization that is
based on the recently proposed α-stable harmonizable processes.
They include Cauchy and Gaussian as special cases and their
remarkable feature is to allow a simple modeling of impulsive
and real world sounds with few parameters. The approach we
present builds on the classical convolutive mixing model and has
the particularities of requiring going through the data only once,
to also work in the underdetermined case of more sources than
microphones and to allow massively parallelizable implementations
operating in the time-frequency domain. We show that the method
yields interesting performance for acoustic imaging in realistic
simulations.
Index Terms—source localization, acoustic modeling, α-
stable random variables, spectral measure, sketching



hal_id    :    hal-02912472



Cet article propose une architecture neuronale pour un modèle de langue à vocabulaire ouvert. Les
représentations continues des mots sont calculées à la volée à partir des caractères les composant,
gràce à une couche convolutionnelle suivie d’une couche de regroupement (pooling). Cela permet
au modèle de représenter n’importe quel mot, qu’il fasse partie du contexte ou soit évalué pour la
prédiction. La fonction objectif est dérivée de l’estimation contrastive bruitée (Noise Contrastive
Estimation, ou NCE), calculable dans notre cas sans vocabulaire. Nous évaluons la capacité de
notre modèle à construire des représentations continues de mots inconnus sur la tâche de traduction
automatique IWSLT-2016, de l’Anglais vers le Tchèque, en ré-évaluant les N meilleures hypothèses
(N-best reranking). Les résultats expérimentaux permettent des gains jusqu’à 0,7 point BLEU. Ils
montrent aussi la difﬁculté d’utiliser des représentations dérivées des caractères pour la prédiction.
ABSTRACT
Opening the vocabulary of neural language models with character-level word representations
This paper introduces an architecture for an open-vocabulary neural language model. Word represen-
tations are computed on-the-ﬂy by a convolution network followed by pooling layer. This allows the
model to consider any word, in the context or for the prediction. The training objective is derived from
the Noise-Contrastive Estimation to adapt it the open vocabulary case. We test the ability of our model
to



hal_id    :    hal-02395677



- Parkinson’s disease (PD) is a neurological disorder associated 
with a progressive decline in motor skills, speech, and cognitive processes. 
Since the diagnosis of Parkinson’s disease is difficult, researchers have 
worked to develop a support tool based on algorithms to differentiate 
healthy controls from PD patients. Online handwriting analysis is one of 
the methods that can be used to diagnose PD. The aim of this study is to 
find a subset of handwriting features suitable for efficiently identifying 
subjects with PD. Data was taken from PDMultiMC database collected in 
Lebanon, and consisting of 16 medicated PD patients and 16 age matched 
controls. Seven handwriting tasks were collected such as copying patterns, 
copying words in Arabic, and writing full names. For each task kinematic 
and spatio-temporal, pressure, energy, entropy, and intrinsic features were 
extracted. Feature selection was done in two stages, the first stage selected 
a subset using statistical analysis, and the second step select the most 
relevant features of this subset, by a suboptimal approach. The selected 
features were fed to a support vector machine classifier with RBF kernel, 
whose aim is to identify the subjects suffering from PD. The accuracy of 
the classification of PD was as high as



hal_id    :    hal-02912384



Noise Contrastive Estimation (NCE) is a
learning procedure that is regularly used
to train neural language models, since
it avoids the computational bottleneck
caused by the output softmax. In this pa-
per, we attempt to explain some of the
weaknesses of this objective function, and
to draw directions for further develop-
ments. Experiments on a small task show
the issues raised by the unigram noise
distribution, and that a context dependent
noise distribution, such as the bigram dis-
tribution, can solve these issues and pro-
vide stable and data-efﬁcient learning.
1



hal_id    :    hal-01401988



. We propose a probabilistic model for acoustic source local-
ization with known but arbitrary geometry of the microphone array. The
approach has several features. First, it relies on a simple nearﬁeld acous-
tic model for wave propagation. Second, it does not require the number
of active sources. On the contrary, it produces a heat map representing
the energy of a large set of candidate locations, thus imaging the acous-
tic ﬁeld. Second, it relies on a heavy-tail α-stable probabilistic model,
whose most important feature is to yield an estimation strategy where
the multichannel signals need to be processed only once in a simple on-
line procedure, called sketching. This sketching produces a ﬁxed-sized
representation of the data that is then analyzed for localization. The
resulting algorithm has a small computational complexity and in this
paper, we demonstrate that it compares favorably with state of the art
for localization in realistic simulations of reverberant environments.
1



hal_id    :    hal-01272327



Addressing the will to give a more complete picture than an average relationship provided
by standard regression, a novel framework for estimating and predicting simultaneously several
conditional quantiles is introduced. The proposed methodology leverages kernel-based multi-task
learning to curb the embarrassing phenomenon of quantile crossing, with a one-step estimation
procedure and no post-processing. Moreover, this framework comes along with theoretical guaran-
tees and an eﬃcient coordinate descent learning algorithm. Numerical experiments on benchmark
and real datasets highlight the enhancements of our approach regarding the prediction error, the
crossing occurrences and the training time.
1



hal_id    :    hal-01337860



Most dereverberation methods aim to reconstruct the ane-
choic magnitude spectrogram, given a reverberant signal.
Regardless of the method, the dereverberated signal is sys-
tematically synthesized with the reverberant phase.
This
corrupted phase reintroduces reverberation and distortion in
the signal. This is why we intend to also reconstruct the ane-
choic phase, given a reverberant signal. Before processing
speech signals, we propose in this paper a method for esti-
mating the anechoic phase of reverberant chirp signals. Our
method presents an accurate estimation of the instantaneous
phase and improves objective measures of dereverberation.
Index Terms— Dereverberation, phase, reassignment, si-
nusoidal modeling.



hal_id    :    hal-01418963



We propose an efﬁcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in
presence of pileup from a sample of low-frequency observa-
tions. Based on a functional equation linking the marks’ den-
sity to the characteristic function of the observations and its
derivative, we propose a new time-efﬁcient method using B-
splines to estimate the density of the underlying γ-ray spec-
trum which is able to handle large datasets used in nuclear
physics. A discussion on the numerical computation of the al-
gorithm and its performances on simulated data are provided
to support our ﬁndings.
Index Terms— Shot-noise, nonparametric estimation, B-
splines, γ-spectroscopy, pile-up correction



hal_id    :    hal-01347167



We propose a method that performs anomaly
detection and localisation within heterogeneous
data using a pairwise undirected mixed graphical
model. The data are a mixture of categorical and
quantitative variables, and the model is learned
over a dataset that is supposed not to contain any
anomaly. We then use the model over temporal
data, potentially a data stream, using a version of
the two-sided CUSUM algorithm. The proposed
decision statistic is based on a conditional likeli-
hood ratio computed for each variable given the
others. Our results show that this function allows
to detect anomalies variable by variable, and thus
to localise the variables involved in the anomalies
more precisely than univariate methods based on
simple marginals.



hal_id    :    hal-02287434



. In this paper, we propose an eﬃcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in presence of pileup from a
sample of low-frequency observations. Based on a functional equation linking the marks’
density to the characteristic function of the observations and its derivative, we propose a
new time-eﬃcient method using B-splines to estimate the density of the underlying γ-ray
spectrum, which is able to handle large datasets used in nuclear physics. A discussion on
the numerical computation of the algorithm and its performances on simulated data are
provided to support our ﬁndings.
Keywords. Shot-noise, B-splines, inverse problem, γ spectrometry



hal_id    :    hal-01248010



Room acoustic parameters are key information for dereverberation or speech recognition. Usually, when
one needs to assess the level of reverberation, only the reverberation time RT60 or a direct to reverberant
sounds index Dτ is estimated. Yet, methods which blindly estimate the reverberation time from reverberant
recorded speech do not always diﬀerentiate the RT60 from the Dτ to evaluate the level of reverberation. That
is why we propose a method to jointly blindly estimate these parameters, from the signal energy decay rate
distribution, by means of kernel regression. Evaluation is carried out with real and simulated room impulse
responses to generate noise-free reverberant speech signals. The results show this new method outperforms
baseline approaches in our evaluation.
1.



hal_id    :    hal-01153882



This paper addresses the generalisation of stationary Hawkes processes in order to allow
for a time-evolving second-order analysis.
Motivated by the concept of locally stationary
autoregressive processes, we apply however inherently diﬀerent techniques to describe the
time-varying dynamics of self-exciting point processes. In particular we derive a stationary
approximation of the Laplace transform of a locally stationary Hawkes process. This allows
us to deﬁne a local intensity function and a local Bartlett spectrum which can be used to
compute approximations of ﬁrst and second order moments of the process. We complete the
paper by some insightful simulation studies.
Keywords:
Locally stationary processes, Hawkes processes, Bartlett spectrum, time
frequency analysis, point processes
2000 MSC: 60G55, 62M15, 46N30



hal_id    :    hal-01080955



. This paper deals with a parametrized family of partially
observed bivariate Markov chains. We establish that, under very mild
assumptions, the limit of the normalized log-likelihood function is max-
imized when the parameters belong to the equivalence class of the true
parameter, which is a key feature for obtaining the consistency of the
maximum likelihood estimators (MLEs) in well-speciﬁed models. This
result is obtained in the general framework of partially dominated mod-
els. We examine two speciﬁc cases of interest, namely, hidden Markov
models (HMMs) and observation-driven time series models. In contrast
with previous approaches, the identiﬁability is addressed by relying on
the uniqueness of the invariant distribution of the Markov chain asso-
ciated to the complete data, regardless its rate of convergence to the
equilibrium.



hal_id    :    hal-01078073



This paper generalizes asymptotic properties obtained in the
observation-driven times series models considered by [7] in the sense
that the conditional law of each observation is also permitted to depend
on the parameter. The existence of ergodic solutions and the consis-
tency of the Maximum Likelihood Estimator (MLE) are derived under
easy-to-check conditions. The obtained conditions appear to apply for a
wide class of models. We illustrate our results with speciﬁc observation-
driven times series, including the recently introduced NBIN-GARCH
and NM-GARCH models, demonstrating the consistency of the MLE
for these two models.
MSC: Primary: 62F12; Secondary: 60J05.
Keywords: consistency, ergodicity, maximum likelihood, observation-driven
models, time series of counts.
1



hal_id    :    hal-01030799



. Consider a non–linear function G(Xt) where Xt is a stationary Gaussian se-
quence with long–range dependence. The usual reduction principle states that the partial
sums of G(Xt) behave asymptotically like the partial sums of the ﬁrst term in the expansion
of G in Hermite polynomials. In the context of the wavelet estimation of the long–range
dependence parameter, one replaces the partial sums of G(Xt) by the wavelet scalogram,
namely the partial sum of squares of the wavelet coeﬃcients. Is there a reduction principle
in the wavelet setting, namely is the asymptotic behavior of the scalogram for G(Xt) the
same as that for the ﬁrst term in the expansion of G in Hermite polynomial? The answer
is negative in general. This paper provides a minimal growth condition on the scales of the
wavelet coeﬃcients which ensures that the reduction principle also holds for the scalogram.
The results are applied to testing the hypothesis that the long-range dependence parameter
takes a speciﬁc value.
Contents
1.



hal_id    :    hal-01164121



In this paper, we consider a nonlinear inverse problem occuring in nu-
clear science. Gamma rays randomly hit a semiconductor detector which
produces an impulse response of electric current. Because the sampling
period of the measured current is larger than the mean interarrival time
of photons, the impulse responses associated to diﬀerent gamma rays can
overlap: this phenomenon is known as pileup.
In this work, it is as-
sumed that the impulse response is an exponentially decaying function.
We propose a novel method to infer the distribution of gamma photon en-
ergies from the indirect measurements obtained from the detector. This
technique is based on a formula linking the characteristic function of the
photon density to a function involving the characteristic function and its
derivative of the observations. We establish that our estimator converges
to the mark density in uniform norm at a polynomial rate.
A limited
Monte-Carlo experiment is provided to support our ﬁndings.
1



hal_id    :    hal-00984064



In this work, we study the problem of aggregating a ﬁnite number of predic-
tors for non stationary sub-linear processes. We provide oracle inequalities relying
essentially on three ingredients: 1) a uniform bound of the ℓ1 norm of the time-
varying sub-linear coeﬃcients, 2) a Lipschitz assumption on the predictors and
3) moment conditions on the noise appearing in the linear representation. Two
kinds of aggregations are considered giving rise to diﬀerent moment conditions
on the noise and more or less sharp oracle inequalities. We apply this approach
for deriving an adaptive predictor for locally stationary time varying autoregres-
sive (TVAR) processes.
It is obtained by aggregating a ﬁnite number of well
chosen predictors, each of them enjoying an optimal minimax convergence rate
under speciﬁc smoothness conditions on the TVAR coeﬃcients. We show that
the obtained aggregated predictor achieves a minimax rate while adapting to the
unknown smoothness. To prove this result, a lower bound is established for the
minimax rate of the prediction risk for the TVAR process. Numerical experiments
complete this study. An important feature of this approach is that the aggregated
predictor can be computed recursively and is thus applicable in an online predic-
tion context.
1



hal_id    :    hal-00755255



We study the convergence of centered and normalized sums of i.i.d. random elements
of the space D of c`adl`ag functions endowed with Skorohod’s J1 topology, to stable distri-
butions in D. Our results are based on the concept of regular variation on metric spaces
and on point process convergence. We provide some applications, in particular to the
empirical process of the renewal-reward process.
1



hal_id    :    hal-02437193



– We propose an eﬃcient method to estimate in a nonparametric fashion the marks’ density of a shot-noise process
subject to a high pile-up eﬀect. Based on a formula linking the characteristic function of the mark density to a function involving
the shot-noise characteristic function and its derivative, we construct a “plug-in” estimator which converges to the mark density
in uniform norm at a logarithmic speed. Two limited Monte-Carlo experiments are provided to support our ﬁndings.
1



hal_id    :    hal-01167391



An important challenge in the aeronautic industry is to cope with maintenance issues of the prod-
ucts, notably detection and localization of components breakdowns. Modern equipments enjoy better
recording and processing capacities, allowing the storage of a large amount of data, on which better
maintenance systems are expected to be built. Eﬃcient probabilistic models able to represent the
statistic distribution of the collected variables in the “normal state” of the system are needed in order
to derive anomaly detection algorithms. Graphical models constitute a rich class of models and are
natural candidates to address this task. This article proposes a method for learning undirected hy-
brid graphical models from heterogeneous data. The data are heterogeneous as they include physical
(quantitative) measures as well as a collection of inherently discrete variables for instance describing
the state of electronic devices. The model we propose is adapted from the Ising and Gaussian models
so that the data don’t require to be translated from their original space, allowing the user to easily
interpret the dependency graph learned from data. The learning step is carried out by minimizing
the negative pseudo-log-likelihood using a proximal gradient algorithm with Lasso and group Lasso
penalization for addressing the high dimension of variables. Once the model is learned, we use the
penalized negative



hal_id    :    hal-04762097



We introduce Annealed Multiple Choice Learning (aMCL) which combines simu-
lated annealing with MCL. MCL is a learning framework handling ambiguous tasks
by predicting a small set of plausible hypotheses. These hypotheses are trained
using the Winner-takes-all (WTA) scheme, which promotes the diversity of the
predictions. However, this scheme may converge toward an arbitrarily suboptimal
local minimum, due to the greedy nature of WTA. We overcome this limitation
using annealing, which enhances the exploration of the hypothesis space during
training. We leverage insights from statistical physics and information theory
to provide a detailed description of the model training trajectory. Additionally,
we validate our algorithm by extensive experiments on synthetic datasets, on the
standard UCI benchmark, and on speech separation.
1



hal_id    :    hal-04736454



—This paper describes speech enhancement for real-
time automatic speech recognition (ASR) in real environments.
A standard approach to this task is to use neural beamforming
that can work efficiently in an online manner. It estimates the
masks of clean dry speech from a noisy echoic mixture spectro-
gram with a deep neural network (DNN) and then computes a
enhancement filter used for beamforming. The performance of
such a supervised approach, however, is drastically degraded un-
der mismatched conditions. This calls for run-time adaptation
of the DNN. Although the ground-truth speech spectrogram re-
quired for adaptation is not available at run time, blind dere-
verberation and separation methods such as weighted prediction
error (WPE) and fast multichannel nonnegative matrix factor-
ization (FastMNMF) can be used for generating pseudo ground-
truth data from a mixture. Based on this idea, a prior work pro-
posed a dual-process system based on a cascade of WPE and
minimum variance distortionless response (MVDR) beamform-
ing asynchronously fine-tuned by block-online FastMNMF. To in-
tegrate the dereverberation capability into neural beamforming
and make it fine-tunable at run time, we propose to use weighted
power minimization distortionless response (WPD) beamforming,
a unified version of WPE and minimum power distortionless re-
sponse (MPDR), whose joint dereverberation and denoising filter
is estimated using a DNN. We evaluated the impact of run-time
adaptation under various



hal_id    :    hal-04768296



In this paper, we propose a novel Self-Supervised-
Learning scheme to train rhythm analysis systems and
instantiate it for few-shot beat tracking.
Taking inspi-
ration from the Contrastive Predictive Coding paradigm,
we propose to train a Log-Mel-Spectrogram-Transformer-
encoder to contrast observations at times separated by hy-
pothesized beat intervals from those that are not. We do
this without the knowledge of ground-truth tempo or beat
positions, as we rely on the local maxima of a Predomi-
nant Local Pulse function, considered as a proxy for Tatum
positions, to define candidate anchors, candidate positives
(located at a distance of a power of two from the anchor)
and negatives (remaining time positions). We show that
a model pre-trained using this approach on the unlabeled
FMA, MTT and MTG-Jamendo datasets can successfully
be fine-tuned in the few-shot regime, i.e. with just a few
annotated examples to get a competitive beat-tracking per-
formance.
1



hal_id    :    hal-04665063



The task of music structure analysis has been mostly
addressed as a sequential problem, by relying on the inter-
nal homogeneity of musical sections or their repetitions.
In this work, we instead regard it as a pairwise link pre-
diction task. If for any pair of time instants in a track, one
can successfully predict whether they belong to the same
structural entity or not, then the underlying structure can
be easily recovered. Building upon this assumption, we
propose a method that first learns to classify pairwise links
between time frames as belonging to the same section (or
segment) or not. The resulting link features, along with
node-specific information, are combined through a graph
attention network. The latter is regularized with a graph
partitioning training objective and outputs boundary loca-
tions between musical segments and section labels. The
overall system is lightweight and performs competitively
with previous methods.
The evaluation is done on two
standard datasets for music structure analysis and an ab-
lation study is conducted in order to gain insight on the
role played by its different components.



hal_id    :    hal-04695595



Machine listening systems often rely on fixed taxonomies to or-
ganize and label audio data, key for training and evaluating deep
neural networks (DNNs) and other supervised algorithms. How-
ever, such taxonomies face significant constraints: they are com-
posed of application-dependent predefined categories, which hin-
ders the integration of new or varied sounds, and exhibits limited
cross-dataset compatibility due to inconsistent labeling standards.
To overcome these limitations, we introduce SALT: Standardized
Audio event Label Taxonomy. Building upon the hierarchical struc-
ture of AudioSet’s ontology, our taxonomy extends and standardizes
labels across 24 publicly available environmental sound datasets, al-
lowing the mapping of class labels from diverse datasets to a unified
system. Our proposal comes with a new Python package designed
for navigating and utilizing this taxonomy, easing cross-dataset la-
bel searching and hierarchical exploration. Notably, our package
allows effortless data aggregation from diverse sources, hence easy
experimentation with combined datasets.
Index Terms— Machine listening, DCASE, sound taxonomy,
sound categorization, data aggregation



hal_id    :    hal-04701759



Audio-text models trained via contrastive learning offer a practical
approach to perform audio classiﬁcation through natural language
prompts, such as “this is a sound of” followed by category names. In
this work, we explore alternative prompt templates for zero-shot au-
dio classiﬁcation, demonstrating the existence of higher-performing
options. First, we ﬁnd that the formatting of the prompts signif-
icantly affects performance so that simply prompting the models
with properly formatted class labels performs competitively with
optimized prompt templates and even prompt ensembling. More-
over, we look into complementing class labels by audio-centric de-
scriptions. By leveraging large language models, we generate tex-
tual descriptions that prioritize acoustic features of sound events
to disambiguate between classes, without extensive prompt engi-
neering. We show that prompting with class descriptions leads to
state-of-the-art results in zero-shot audio classiﬁcation across ma-
jor ambient sound datasets. Remarkably, this method requires no
additional training and remains fully zero-shot.
Index Terms— Zero-shot audio classiﬁcation, audio-text mod-
els, contrastive language-audio pretraining, in-context learning



hal_id    :    hal-04720291



The Prototypical Network (ProtoNet) has emerged as a popular
choice in Few-shot Learning (FSL) scenarios due to its remark-
able performance and straightforward implementation.
Building
upon such success, we first propose a simple (yet novel) method
to fine-tune a ProtoNet on the (labeled) support set of the test
episode of a C-way-K-shot test episode (without using the query
set which is only used for evaluation). We then propose an algo-
rithmic framework that combines ProtoNet with optimization-based
FSL algorithms (MAML and Meta-Curvature) to work with such
a fine-tuning method. Since optimization-based algorithms endow
the target learner model with the ability to fast adaption to only a
few samples, we utilize ProtoNet as the target model to enhance
its fine-tuning performance with the help of a specifically designed
episodic fine-tuning strategy. The experimental results confirm that
our proposed models, MAML-Proto and MC-Proto, combined with
our unique fine-tuning method, outperform regular ProtoNet by a
large margin in few-shot audio classification tasks on the ESC-50
and Speech Commands v2 datasets. We note that although we have
only applied our model to the audio domain, it is a general method
and can be easily extended to other domains.
Index Terms— Few-shot learning, Audio classification, Proto-
typical Network, Model-Agnostic Meta-Learning, Meta-Curvature



hal_id    :    hal-04685184



As diffusion-based deep generative models gain prevalence, re-
searchers are actively investigating their potential applications
across various domains, including music synthesis and style al-
teration. Within this work, we are interested in timbre transfer, a
process that involves seamlessly altering the instrumental character-
istics of musical pieces while preserving essential musical elements.
This paper introduces WaveTransfer, an end-to-end diffusion model
designed for timbre transfer. We specifically employ the bilateral
denoising diffusion model (BDDM) for noise scheduling search.
Our model is capable of conducting timbre transfer between audio
mixtures as well as individual instruments. Notably, it exhibits ver-
satility in that it accommodates multiple types of timbre transfer
between unique instrument pairs in a single model, eliminating the
need for separate model training for each pairing.
Furthermore,
unlike recent works limited to 16 kHz, WaveTransfer can be trained
at various sampling rates, including the industry-standard 44.1 kHz,
a feature of particular interest to the music community.
Index Terms— Multi-instrumental timbre transfer, diffusion
models, music transformation, generative AI



hal_id    :    hal-04632526



This paper describes a method for estimating the room impulse
response (RIR) for a microphone and a sound source located at
arbitrary positions from the 3D mesh data of the room. Simulat-
ing realistic RIRs with pure physics-driven methods often fails
the balance between physical consistency and computational ef-
ficiency, hindering application to real-time speech processing.
Alternatively, one can use MESH2IR, a fast black-box estima-
tor that consists of an encoder extracting latent code from mesh
data with a graph convolutional network (GCN) and a decoder
generating the RIR from the latent code. Combining these two
approaches, we propose a fast yet physically coherent estimator
with interpretable latent code based on differentiable digital sig-
nal processing (DDSP). Specifically, the encoder estimates a vir-
tual shoebox room scene that acoustically approximates the real
scene, accelerating physical simulation with the differentiable
image-source model in the decoder. Our experiments showed
that our method outperformed MESH2IR for real mesh data ob-
tained with the depth scanner of Microsoft HoloLens 2, and can
provide correct spatial consistency for binaural RIRs.
Index Terms: Spatial audio, room acoustics, 3D mesh data,
physical models, DDSP



hal_id    :    hal-04640068



Single-channel speech dereverberation aims at extracting a
dry speech signal from a recording affected by the acoustic re-
flections in a room. However, most current deep learning-based
approaches for speech dereverberation are not interpretable for
room acoustics, and can be considered as black-box systems
in that regard. In this work, we address this problem by regu-
larizing the training loss using a novel physical coherence loss
which encourages the room impulse response (RIR) induced by
the dereverberated output of the model to match the acoustic
properties of the room in which the signal was recorded. Our
investigation demonstrates the preservation of the original dere-
verberated signal alongside the provision of a more physically
coherent RIR.
Index Terms: Speech dereverberation, hybrid deep learning,
room acoustics, acoustic matching, speech processing



hal_id    :    hal-04705811



—Latent representation learning has been an active
field of study for decades in numerous applications. Inspired
among others by the tokenization from Natural Language
Processing and motivated by the research of a simple data
representation, recent works have introduced a quantization step
into the feature extraction. In this work, we propose a novel
strategy to build the neural discrete representation by means of
random codebooks. These codebooks are obtained by randomly
sampling a large, predefined fixed codebook. We experimentally
show the merits and potential of our approach in a task of audio
compression and reconstruction.
Index Terms—feature extraction, quantization, random code-
books, audio reconstruction



hal_id    :    hal-04614241



—This paper addresses the challenge of estimating
multiple highly oscillating amplitudes within the nonlinear chirp
signal model. The problem is analogous to the mode detection
task with fixed instantaneous frequencies, where the oscillating
amplitudes signify mechanical vibrations concealing crucial infor-
mation for predictive maintenance. Existing methods often focus
on single-frequency estimation, employ simple amplitude func-
tions, or impose strong noise assumptions. Furthermore, these
methods frequently rely on arbitrarily chosen hyperparameters,
leading to sub-optimal generalization for a diverse range of am-
plitudes. To address these limitations, our approach introduces
two estimators, based on Capon filters and negative log-likelihood
approaches respectively, that leverage locally stationary assump-
tions and incorporate hyperparameters estimation. The results
demonstrate that, even under challenging conditions, these esti-
mators yield competitive outcomes across various noisy scenarios,
mitigating the drawbacks associated with existing methods.
Index Terms—chirp signal, amplitude estimation, locally sta-
tionary process, filtering, hyperparameters estimation



hal_id    :    hal-04574640



Winner-takes-all training is a simple learning
paradigm, which handles ambiguous tasks by pre-
dicting a set of plausible hypotheses. Recently,
a connection was established between Winner-
takes-all training and centroidal Voronoi tessel-
lations, showing that, once trained, hypotheses
should quantize optimally the shape of the condi-
tional distribution to predict. However, the best
use of these hypotheses for uncertainty quantifi-
cation is still an open question. In this work, we
show how to leverage the appealing geometric
properties of the Winner-takes-all learners for con-
ditional density estimation, without modifying its
original training scheme. We theoretically estab-
lish the advantages of our novel estimator both in
terms of quantization and density estimation, and
we demonstrate its competitiveness on synthetic
and real-world datasets, including audio data.



hal_id    :    halshs-04654217



No abstract found in the PDF.



hal_id    :    hal-04602229



In recent years, significant advances have been made in deep learn-
ing models for audio generation, offering promising tools for mu-
sical creation. In this work, we investigate the use of deep audio
generative models in interactive dance/music performance. We
adopted a performance-led research design approach, establish-
ing an art-research collaboration between a researcher/musician
and a dancer. First, we describe our motion-sound interactive sys-
tem integrating deep audio generative model and propose three
methods for embodied exploration of deep latent spaces. Then, we
detail the creative process for building the performance centered
on the co-design of the system. Finally, we report feedback from
the dancer’s interviews and discuss the results and perspectives.
The code implementation is publicly available on our github1.
CCS CONCEPTS
• Human-centered computing →Sound-based input / output;
Gestural input; Auditory feedback; Collaborative interaction;
• Applied computing →Sound and music computing; • Com-
puting methodologies →Machine learning.
KEYWORDS
dance-music-AI performance, HCI, motion-sound interaction, deep
learning, generative models, embodied exploration, latent space
ACM Reference Format:
Sarah Nabi, Philippe Esling, Geoffroy Peeters, and Frédéric Bevilacqua. 2024.
Embodied exploration of deep latent spaces in interactive dance-music
performance. In 9th International Conference on Movement and Computing
(MOCO ’24), May 30-June 2, 2024, Utrecht, Netherlands. ACM, New York, NY,
USA, 9 pages. https://doi.org/10.1145/3658852.3659072
1https://github.com/ircam-ismm/embodied-latent-exploration
Permission to make digital or hard copies of all or part of this work for personal or
classroom



hal_id    :    hal-04541350



Isolating the desired speaker’s voice amidst multiple
speakers in a noisy acoustic context is a challenging task. Per-
sonalized speech enhancement (PSE) endeavours to achieve
this by leveraging prior knowledge of the speaker’s voice.
Recent research efforts have yielded promising PSE mod-
els, albeit often accompanied by computationally intensive
architectures, unsuitable for resource-constrained embedded
devices. In this paper, we introduce a novel method to per-
sonalize a lightweight dual-stage Speech Enhancement (SE)
model and implement it within DeepFilterNet2, a SE model
renowned for its state-of-the-art performance. We seek an
optimal integration of speaker information within the model,
exploring different positions for the integration of the speaker
embeddings within the dual-stage enhancement architec-
ture. We also investigate a tailored training strategy when
adapting DeepFilterNet2 to a PSE task. We show that our
personalization method greatly improves the performances
of DeepFilterNet2 while preserving minimal computational
overhead.
Index Terms— Target speech extraction, speech en-
hancement, real-time.



hal_id    :    hal-04358467



In neural audio signal processing, pitch conditioning has been
used to enhance the performance of synthesizers. However, jointly
training pitch estimators and synthesizers is a challenge when us-
ing standard audio-to-audio reconstruction loss, leading to reliance
on external pitch trackers. To address this issue, we propose us-
ing a spectral loss function inspired by optimal transportation theory
that minimizes the displacement of spectral energy. We validate this
approach through an unsupervised autoencoding task that fits a har-
monic template to harmonic signals. We jointly estimate the funda-
mental frequency and amplitudes of harmonics using a lightweight
encoder and reconstruct the signals using a differentiable harmonic
synthesizer. The proposed approach offers a promising direction for
improving unsupervised parameter estimation in neural audio appli-
cations.
Index Terms— differentiable signal processing, machine learn-
ing, optimal transport, frequency estimation



hal_id    :    hal-04424100



Diffusion models are receiving a growing interest for a variety of
signal generation tasks such as speech or music synthesis. WaveG-
rad, for example, is a successful diffusion model that conditionally
uses the mel spectrogram to guide a diffusion process for the gen-
eration of high-fidelity audio. However, such models face important
challenges concerning the noise diffusion process for training and
inference, and they have difficulty generating high-quality speech
for speakers that were not seen during training. With the aim of
minimizing the conditioning error and increasing the efficiency of
the noise diffusion process, we propose in this paper a new scheme
called GLA-Grad, which consists in introducing a phase recovery al-
gorithm such as the Griffin-Lim algorithm (GLA) at each step of the
regular diffusion process. Furthermore, it can be directly applied to
an already-trained waveform generation model, without additional
training or fine-tuning. We show that our algorithm outperforms
state-of-the-art diffusion models for speech generation, especially
when generating speech for a previously unseen target speaker.
Index Terms— Diffusion models, speech generation, Griffin-
Lim algorithm, domain adaptation



hal_id    :    hal-04360221



Current state-of-the-art audio analysis systems rely on pre-
trained embedding models, often used off-the-shelf as (frozen)
feature extractors. Choosing the best one for a set of tasks is the
subject of many recent publications.
However, one aspect often
overlooked in these works is the influence of the duration of audio
input considered to extract an embedding, which we refer to as Tem-
poral Support (TS). In this work, we study the influence of the TS
for well-established or emerging pre-trained embeddings, chosen to
represent different types of architectures and learning paradigms.
We conduct this evaluation using both musical instrument and envi-
ronmental sound datasets, namely OpenMIC, TAU Urban Acoustic
Scenes 2020 Mobile, and ESC-50. We especially highlight that Au-
dio Spectrogram Transformer-based systems (PaSST and BEATs)
remain effective with smaller TS, which therefore allows for a dras-
tic reduction in memory and computational cost.
Moreover, we
show that by choosing the optimal TS we reach competitive results
across all tasks. In particular, we improve the state-of-the-art results
on OpenMIC, using BEATs and PaSST without any fine-tuning.
Index Terms— audio embeddings, acoustic scene classification,
instrument recognition, temporal support, transformers



hal_id    :    hal-04479188



We address the problem of accurately interpolating measured ane-
choic steering vectors with a deep learning framework called the
neural field. This task plays a pivotal role in reducing the resource-
intensive measurements required for precise sound source separa-
tion and localization, essential as the front-end of speech recogni-
tion. Classical approaches to interpolation rely on linear weighting of
nearby measurements in space on a fixed, discrete set of frequencies.
Drawing inspiration from the success of neural fields for novel view
synthesis in computer vision, we introduce the neural steerer, a con-
tinuous complex-valued function that takes both frequency and direc-
tion as input and produces the corresponding steering vector. Impor-
tantly, it incorporates inter-channel phase difference information and
a regularization term enforcing filter causality, essential for accurate
steering vector modeling. Our experiments, conducted using a dataset
of real measured steering vectors, demonstrate the effectiveness of
our resolution-free model in interpolating such measurements.
Index Terms— Steering vector, neural field, spatial audio, inter-
polation, representation learning



hal_id    :    hal-04423979



Generative adversarial network (GAN) models can synthesize high-
quality audio signals while ensuring fast sample generation. How-
ever, they are difficult to train and are prone to several issues in-
cluding mode collapse and divergence. In this paper, we introduce
SpecDiff-GAN, a neural vocoder based on HiFi-GAN, which was
initially devised for speech synthesis from mel spectrogram. In our
model, the training stability is enhanced by means of a forward dif-
fusion process which consists in injecting noise from a Gaussian
distribution to both real and fake samples before inputting them to
the discriminator. We further improve the model by exploiting a
spectrally-shaped noise distribution with the aim to make the dis-
criminator’s task more challenging. We then show the merits of our
proposed model for speech and music synthesis on several datasets.
Our experiments confirm that our model compares favorably in au-
dio quality and efficiency compared to several baselines.
Index Terms— Generative adversarial network (GAN), diffu-
sion process, deep audio synthesis, spectral envelope



hal_id    :    hal-04419041



Overlapped speech is notoriously problematic for speaker diarization
systems. Consequently, the use of speech separation has recently
been proposed to improve their performance. Although promising,
speech separation models struggle with realistic data because they
are trained on simulated mixtures with a fixed number of speakers. In
this work, we introduce a new speech separation-guided diarization
scheme suitable for the online speaker diarization of long meeting
recordings with a variable number of speakers, as present in the AMI
corpus. We envisage ConvTasNet and DPRNN as alternatives for the
separation networks, with two or three output sources. To obtain the
speaker diarization result, voice activity detection is applied on each
estimated source. The final model is fine-tuned end-to-end, after first
adapting the separation to real data using AMI. The system operates
on short segments, and inference is performed by stitching the local
predictions using speaker embeddings and incremental clustering.
The results show that our system improves the state-of-the-art on
the AMI headset mix, using no oracle information and under full
evaluation (no collar and including overlapped speech). Finally, we
show the strength of our system particularly on overlapped speech
sections.
Index Terms— online speaker diarization, source separation,
overlapped speech, AMI, speaker embedding



hal_id    :    hal-04432659



Music generated by deep learning methods often suffers
from a lack of coherence and long-term organization. Yet,
multi-scale hierarchical structure is a distinctive feature of
music signals. To leverage this information, we propose a
structure-informed positional encoding framework for music
generation with Transformers. We design three variants in
terms of absolute, relative and non-stationary positional in-
formation. We comprehensively test them on two symbolic
music generation tasks: next-timestep prediction and accom-
paniment generation.
As a comparison, we choose multi-
ple baselines from the literature and demonstrate the merits
of our methods using several musically-motivated evaluation
metrics. In particular, our methods improve the melodic and
structural consistency of the generated pieces.
Index Terms— symbolic music generation, Transform-
ers, music structure, positional encoding



hal_id    :    hal-04423348



. With the progress of generative neural models, Hierarchical Text Classification
(HTC) can be cast as a generative task. In this case, given an input text, the model generates
the sequence of predicted class labels taken from a label tree of arbitrary width and depth.
Treating HTC as a generative task introduces multiple modeling choices. These choices vary
from choosing the order for visiting the class tree and therefore defining the order of generat-
ing tokens, choosing either to constrain the decoding to labels that respect the previous level
predictions, up to choosing the pre-trained Language Model itself. Each HTC model therefore
differs from the others from an architectural standpoint, but also from the modeling choices
that were made. Prior contributions lack transparent modeling choices and open implemen-
tations, hindering the assessment of whether model performance stems from architectural or
modeling decisions. For these reasons, we propose with this paper an analysis of the impact
of different modeling choices along with common model errors and successes for this task.
This analysis is based on an open framework coming along this paper that can facilitate the
development of future contributions in the field by providing datasets, metrics, error analysis
toolkit and the capability to readily test various modeling choices for one given model.
Keywords: Hierarchical text



hal_id    :    hal-04604650



. In recent years, there has been a signicant surge in machine
learning techniques, particularly in the domain of deep learning, tailored
for handling attributed graphs. Nevertheless, to work, these methods as-
sume that the attributes values are fully known, which is not realistic
in numerous real-world applications. This paper explores the potential
of Optimal Transport (OT) to impute missing attributes on graphs. To
proceed, we design a novel multi-view OT loss function that can encom-
pass both node feature data and the underlying topological structure of
the graph by utilizing multiple graph representations. We then utilize
this novel loss to train eciently a Graph Convolutional Neural Net-
work (GCN) architecture capable of imputing all missing values over the
graph at once. We evaluate the interest of our approach with experiments
both on synthetic data and real-world graphs, including dierent miss-
ingness mechanisms and a wide range of missing data. These experiments
demonstrate that our method is competitive with the state-of-the-art in
all cases and of particular interest on weakly homophilic graphs.
Keywords: Attributed Graph · Missing Data Imputation · Optimal
Transport
1



hal_id    :    hal-04575332



We consider the statistical seriation problem, where the statistician seeks to recover a
hidden ordering from a noisy observation of a permuted Robinson matrix. In this paper,
we tightly characterize the minimax rate for this problem of matrix reordering when
the Robinson matrix is bi-Lipschitz, and we also provide a polynomial time algorithm
achieving this rate; thereby answering two open questions of [Giraud et al., 2021]. Our
analysis further extends to broader classes of similarity matrices.
1



hal_id    :    hal-04729913



Multimodal large language models have fueled progress in image captioning.
These models, fine-tuned on vast image datasets, exhibit a deep understanding
of semantic concepts. In this work, we show that this ability can be re-purposed
for audio captioning, where the joint image-language decoder can be leveraged to
describe auditory content associated with image sequences within videos featuring
audiovisual content. This can be achieved via multimodal alignment. Yet, this
multimodal alignment task is non-trivial due to the inherent disparity between
audible and visible elements in real-world videos. Moreover, multimodal repre-
sentation learning often relies on contrastive learning, facing the challenge of the
so-called modality gap which hinders smooth integration between modalities. In
this work, we introduce a novel methodology for bridging the audiovisual modality
gap by matching the distributions of tokens produced by an audio backbone and
those of an image captioner. Our approach aligns the audio token distribution
with that of the image tokens, enabling the model to perform zero-shot audio
captioning in an unsupervised fashion while keeping the initial image captioning
component unaltered. This alignment allows for the use of either audio or audiovi-
sual input by combining or substituting the image encoder with the aligned audio
encoder. Our method achieves significantly improved performances in zero-shot
audio captioning, compared to existing approaches.1
1



hal_id    :    hal-04593480



When deriving contextualized word repre-
sentations from language models, a decision
needs to be made on how to obtain one for
out-of-vocabulary (OOV) words that are seg-
mented into subwords. What is the best way
to represent these words with a single vector,
and are these representations of worse quality
than those of in-vocabulary words? We carry
out an intrinsic evaluation of embeddings from
different models on semantic similarity tasks
involving OOV words. Our analysis reveals,
among other interesting findings, that the qual-
ity of representations of words that are split is
often, but not always, worse than that of the
embeddings of known words. Their similar-
ity values, however, must be interpreted with
caution.
1



hal_id    :    hal-04578273



. The pair-matching problem appears in many applications where one wants to discover
matches between pairs of entities or individuals. Formally, the set of individuals is represented by
the nodes of a graph where the edges, unobserved at first, represent the matches. The algorithm
queries pairs of nodes and observes the presence/absence of edges. Its goal is to discover as
many edges as possible with a fixed budget of queries. Pair-matching is a particular instance of
multi-armed bandit problem in which the arms are pairs of individuals and the rewards are edges
linking these pairs. This bandit problem is non-standard though, as each arm can only be played
once.
Given this last constraint, sublinear regret can be expected only if the graph presents some
underlying structure. This paper shows that sublinear regret is achievable in the case where
the graph is generated according to a Stochastic Block Model (SBM) with two communities.
Optimal regret bounds are computed for this pair-matching problem. They exhibit a phase trans-
ition related to the Kesten-Stigum threshold for community detection in SBM. The pair-matching
problem is considered in the case where each node is constrained to be sampled less than a given
amount of times, for example for ensuring individual fairness. We show how optimal regret rates
depend on this



hal_id    :    hal-04539879



—This paper tackles two major problem settings for
interpretability of audio processing networks, post-hoc and by-
design interpretation. For post-hoc interpretation, we aim to in-
terpret decisions of a network in terms of high-level audio objects
that are also listenable for the end-user. This is extended to
present an inherently interpretable model with high performance.
To this end, we propose a novel interpreter design that incor-
porates non-negative matrix factorization (NMF). In particular,
an interpreter is trained to generate a regularized intermediate
embedding from hidden layers of a target network, learnt as time-
activations of a pre-learnt NMF dictionary. Our methodology
allows us to generate intuitive audio-based interpretations that
explicitly enhance parts of the input signal most relevant for a
network’s decision. We demonstrate our method’s applicability
on a variety of classification tasks, including multi-label data for
real-world audio and music.
Index Terms—Audio interpretability, explainability, by-design
interpretable models, audio convolutional networks, non-negative
matrix factorization



hal_id    :    hal-03615137



—Tensor factorization models are widely used in many
applied ﬁelds such as chemometrics, psychometrics, computer
vision or communication networks. Real life data collection is
often subject to errors, resulting in missing data. Here we focus
in understanding how this issue should be dealt with for non-
negative tensor factorization. We investigate several criteria used
for non-negative tensor factorization in the case where some
entries are missing. In particular we show how smoothness
penalties can compensate the presence of missing values in order
to ensure the existence of an optimum. This lead us to propose
new criteria with efﬁcient numerical optimization algorithms.
Numerical experiments are conducted to support our claims.
Index Terms—Non-negative tensor decomposition, missing val-
ues, Tensor completion, smoothness, PARAFAC, CP decomposi-
tion.



hal_id    :    hal-04410338



Seals are small coin-shaped artifacts, mostly made of lead, held with strings to seal letters.
This work presents the first attempt towards automatic reading of text on Byzantine seal
images. Byzantine seals are generally decorated with iconography on the obverse side and
Greek text on the reverse side. Text may include the sender’s name, position in the Byzantine
aristocracy, and elements of prayers. Both text and iconography are precious literary sources
that wait to be exploited electronically, so the development of computerized systems for
interpreting seals images is of paramount importance. This work’s contribution is hence a
deep, two-stages, character reading pipeline for transcribing Byzantine seal images. A first deep
convolutional neural network (CNN) detects characters in the seal (character localization). A
second convolutional network reads the localized characters (character classification). Finally, a
diplomatic transcription of the seal is provided by post-processing the two network outputs. We
provide an experimental evaluation of each CNN in isolation and both CNNs in combination. All
performances are evaluated by cross-validation. Character localization achieves a mean average
precision (mAP@0.5) greater than 0.9. Classification of characters cropped from ground truth
bounding boxes achieves Top-1 accuracy greater than 0.92. End-to-end evaluation shows the
efficiency of the proposed approach when compared to the SoTA for similar tasks.



hal_id    :    hal-04552478



Data augmentation is an essential building block for learning efﬁcient deep learning
models. Among all augmentation techniques proposed so far, linear interpolation
of training data points, also called mixup, has found to be effective for a large
panel of applications. While the majority of works have focused on selecting
the right points to mix, or applying complex non-linear interpolation, we are
interested in mixing similar points more frequently and strongly than less similar
ones. To this end, we propose to dynamically change the underlying distribution of
interpolation coefﬁcients through warping functions, depending on the similarity
between data points to combine. We deﬁne an efﬁcient and ﬂexible framework to do
so without losing in diversity. We provide extensive experiments for classiﬁcation
and regression tasks, showing that our proposed method improves both performance
and calibration of models. Code available in torch-uncertainty.
1



hal_id    :    hal-04390768



Group fairness is a central research topic in
text classification, where reaching fair treat-
ment between sensitive groups (e.g. women
vs. men) remains an open challenge. This
paper presents a novel method for mitigating
biases in neural text classification, agnostic to
the model architecture. Considering the diffi-
culty to distinguish fair from unfair informa-
tion in a text encoder, we take inspiration from
adversarial training to induce Wasserstein in-
dependence between representations learned to
predict our target label and the ones learned to
predict some sensitive attribute. Our approach
provides two significant advantages. Firstly,
it does not require annotations of sensitive at-
tributes in both testing and training data. This is
more suitable for real-life scenarios compared
to existing methods that require annotations
of sensitive attributes at train time. Secondly,
our approach exhibits a comparable or better
fairness-accuracy trade-off compared to exist-
ing methods. Our implementation is available
on Github1.
1



hal_id    :    hal-04216055



We introduce Resilient Multiple Choice Learning (rMCL), an extension of the
MCL approach for conditional distribution estimation in regression settings where
multiple targets may be sampled for each training input. Multiple Choice Learning
is a simple framework to tackle multimodal density estimation, using the Winner-
Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing
MCL variants focus on merging the hypotheses, thereby eventually sacriﬁcing
the diversity of the predictions. In contrast, our method relies on a novel learned
scoring scheme underpinned by a mathematical framework based on Voronoi tessel-
lations of the output space, from which we can derive a probabilistic interpretation.
After empirically validating rMCL with experiments on synthetic data, we further
assess its merits on the sound source localization task, demonstrating its practical
usefulness and the relevance of its interpretation.
1



hal_id    :    hal-04172863



This paper revisits single-channel audio source separation based on
a probabilistic generative model of a mixture signal defined in the
continuous time domain. We assume that each source signal fol-
lows a non-stationary Gaussian process (GP), i.e., any finite set of
sampled points follows a zero-mean multivariate Gaussian distribu-
tion whose covariance matrix is governed by a kernel function over
time-varying latent variables. The mixture signal composed of such
source signals thus follows a GP whose covariance matrix is given
by the sum of the source covariance matrices. To estimate the latent
variables from the mixture signal, we use a deep neural network with
an encoder-separator-decoder architecture (e.g., Conv-TasNet) that
separates the latent variables in a pseudo-time-frequency space. The
key feature of our method is to feed the latent variables into the ker-
nel function for estimating the source covariance matrices, instead
of using the decoder for directly estimating the time-domain source
signals. This enables the decomposition of a mixture signal into the
source signals with a classical yet powerful Wiener filter that consid-
ers the full covariance structure over all samples. The kernel func-
tion and the network are trained jointly in the maximum likelihood
framework. Comparative experiments using two-speech mixtures
under clean, noisy, and noisy-reverberant conditions from the WSJ0-
2mix, WHAM!, and WHAMR! benchmark datasets demonstrated
that the proposed method



hal_id    :    hal-04135264



BHAI 1 (Byzantine Hybrid Artificial Intelligence) is the first project
based on artificial intelligence dedicated to Byzantine seals. The
scientific consortium comprises a multidisciplinary team involving
historians specialized in the Byzantine period, specialists in sig-
illography, and computer science experts. This article describes the
main objectives of this project: data acquisition of seal images, text
and iconography recognition, seal dating, as well as our current
achievements and first results on character recognition and spatial
analysis of personages.
CCS CONCEPTS
• Applied computing →Arts and humanities; • Computing
methodologies →Spatial and physical reasoning; Semantic
networks; Natural language processing.
KEYWORDS
Byzantine Greek, Byzantine history, seal images, deep neural net-
works, character recognition, iconography recognition
ACM Reference Format:
Victoria EYHARABIDE, Laurence LIKFORMAN-SULEM, Lucia ORLANDI,
Alexandre BINOUX, Théophile RAGEAU, Qijia HUANG, Attilio FIAN-
DROTTI, Beatrice CASEAU, and Isabelle BLOCH. 2023. Study of historical
Byzantine seal images: the BHAI project for computer-based sigillography.
In 7th International Workshop on Historical Document Imaging and Processing
(HIP ’23), August 25–26, 2023, San Jose, CA, USA. ACM, New York, NY, USA,
6 pages. https://doi.org/10.1145/3604951.3605523
1



hal_id    :    hal-04216177



Self-Supervised Learning (SSL) has allowed leveraging large
amounts of unlabeled speech data to improve the perfor-
mance of speech recognition models even with small annotated
datasets.
Despite this, speech SSL representations may fail
while facing an acoustic mismatch between the pretraining and
target datasets. To address this issue, we propose a novel super-
vised domain adaptation method, designed for cases exhibiting
such a mismatch in acoustic domains. It consists in applying
properly calibrated data augmentations on a large clean dataset,
bringing it closer to the target domain, and using it as part of
an initial fine-tuning stage. Augmentations are automatically
selected through the minimization of a conditional-dependence
estimator, based on the target dataset. The approach is vali-
dated during an oracle experiment with controlled distortions
and on two amateur-collected low-resource domains, reaching
better performances compared to the baselines in both cases.
Index Terms: self-supervised learning, domain adaptation.



hal_id    :    hal-04593478



Dialog participants sometimes align their lin-
guistic styles, e.g., they use the same words
and syntactic constructions as their interlocu-
tors. We propose to investigate the notion of
lexico-semantic alignment: to what extent do
speakers convey the same meaning when they
use the same words? We design measures of
lexico-semantic alignment relying on contextu-
alized word representations. We show that they
reflect interesting semantic differences between
the two sides of a debate and that they can assist
in the task of debate’s winner prediction.
1



hal_id    :    hal-04131585



No abstract found in the PDF.



hal_id    :    hal-04130213



La façon dont nous utilisons les mots est influencée par notre opinion. Nous cherchons à savoir si cela
se reflète dans les plongements de mots contextualisés. Par exemple, la représentation d’ « animal »
est-elle différente pour les gens qui voudraient abolir les zoos et ceux qui ne le voudraient pas? Nous
explorons cette question du point de vue du changement sémantique des mots. Nos expériences avec
des représentations dérivées d’ensembles de données annotés avec les points de vue révèlent des
différences minimes, mais significatives, entre postures opposées 1.
ABSTRACT
One Word, Two Sides : Traces of Stance in Contextualized Word Representations
The way we use words is influenced by our opinion. We investigate whether this is reflected in
contextualized word embeddings. For example, is the representation of “animal” different between
people who would abolish zoos and those who would not? We explore this question from a Lexical
Semantic Change standpoint. Our experiments with BERT embeddings derived from datasets with
stance annotations reveal small but significant differences in word representations between opposing
stances.
MOTS-CLÉS : Représentations contextualisées, changement sémantique, détection de point de vue.
KEYWORDS: Contextualized representations, semantic change, stance detection.
1



hal_id    :    hal-04093374



Measuring noise in cities and automatically identifying the cor-
responding sound sources are a crucial challenge for policymak-
ers. Indeed, such information helps addressing noise pollution and
improving the well-being of urban dwellers. In recent years, re-
searchers have provided annotated datasets recorded in two ma-
jor cities to foster the development of urban sound event detection
(SED) systems. This paper presents an in-depth study of the be-
haviour of state-of-the-art SED systems well suited to our problem,
combining three far-field real recordings datasets which can be used
jointly during training. In our evaluation, we highlight the perfor-
mance gaps existing between simple and hard recording examples
based on the salience of sound events and the polyphony of the
recordings. We provide new proximity annotations for this anal-
ysis. We evaluate the ability of urban SED systems to generalize
across cities with varying degrees of training supervision. We show
that such generalization is hindered mostly by the difficulties current
urban SED systems have to detect sound events with low salience
along with sound events in highly polyphonic soundscapes.
Index Terms— Sound Event Detection (SED), Far-field urban
audio recordings, urban sound monitoring,



hal_id    :    ujm-04165556



. In contrast to classic autoregressive generation, insertion-
based models can predict in a order-free way multiple tokens at a time,
which make their generation uniquely controllable: it can be constrained
to strictly include an ordered list of tokens. We propose to exploit this
feature in a new diverse paraphrasing framework: ﬁrst, we extract im-
portant tokens or keywords in the source sentence; second, we augment
them; third, we generate new samples around them by using insertion
models. We show that the generated paraphrases are competitive with
state of the art autoregressive paraphrasers, not only in diversity but also
in quality. We further investigate their potential to create new pseudo-
labelled samples for data augmentation, using a meta-learning classiﬁca-
tion framework, and ﬁnd equally competitive result. In addition to prov-
ing non-autoregressive (NAR) viability for paraphrasing, we contribute
our open-source framework as a starting point for further research into
controllable NAR generation.
Keywords: Deep Learning · Natural language processing · Controllable
text generation · Transformers · Non-autoregressive · Insertion models.
1



hal_id    :    hal-04213215



. In recent years, large Transformer-based Pre-trained Lan-
guage Models (PLM) have changed the Natural Language Processing
(NLP) landscape, by pushing the performance boundaries of the state-
of-the-art on a wide variety of tasks. However, this performance gain goes
along with an increase in complexity, and as a result, the size of such
models (up to billions of parameters) represents a constraint for their
deployment on embedded devices or short-inference time tasks. To cope
with this situation, compressed models emerged (e.g. DistilBERT), de-
mocratizing their usage in a growing number of applications that impact
our daily lives. A crucial issue is the fairness of the predictions made by
both PLMs and their distilled counterparts. In this paper, we propose
an empirical exploration of this problem by formalizing two questions:
(1) Can we identify the neural mechanism(s) responsible for gender bias
in BERT (and by extension DistilBERT)? (2) Does distillation tend to
accentuate or mitigate gender bias (e.g. is DistilBERT more prone to
gender bias than its uncompressed version, BERT)? Our findings are the
following: (I) one cannot identify a specific layer that produces bias; (II)
every attention head uniformly encodes bias; except in the context of un-
derrepresented classes with a high imbalance of the sensitive attribute;
(III) this subset of heads is different as we re-fine tune the



hal_id    :    hal-04253752



Non-deterministic measurements are common in real-world scenarios: the performance
of a stochastic optimization algorithm or the total reward of a reinforcement learning agent
in a chaotic environment are just two examples in which unpredictable outcomes are com-
mon. These measures can be modeled as random variables and compared among each other
via their expected values or more sophisticated tools such as null hypothesis statistical
tests. In this paper, we propose an alternative framework to visually compare two sam-
ples according to their estimated cumulative distribution functions. First, we introduce a
dominance measure for two random variables that quantiﬁes the proportion in which the
cumulative distribution function of one of the random variables stochastically dominates
the other one. Then, we present a graphical method that decomposes in quantiles i) the
proposed dominance measure and ii) the probability that one of the random variables takes
lower values than the other. With illustrative purposes, we re-evaluate the experimentation
of an already published work with the proposed methodology and we show that additional
conclusions—missed by the rest of the methods—can be inferred. Additionally, the software
package RVCompare was created as a convenient way of applying and experimenting with
the proposed framework.
Keywords:
Data visualization, Random variables, Cumulative distribution function, First-order
stochastic dominance
1
arXiv:2203.07889v4  [stat.ML]  30 Aug 2022
0.0225 0.0250 0.0275 0.0300 0.0325



hal_id    :    hal-04244852



Handling large datasets and calculating complex statistics on huge datasets require
important computing resources. Using subsampling methods to calculate statistics
of interest on small samples is often used in practice to reduce computational com-
plexity, for instance using the divide and conquer strategy. In this article, we recall
some results on subsampling distributions and derive a precise rate of convergence
for these quantities and the corresponding quantiles. We also develop some standard-
ization techniques based on subsampling unstandardized statistics in the framework
of large datasets. It is argued that using several subsampling distributions with dif-
ferent subsampling sizes brings a lot of information on the behavior of statistical
learning procedures: subsampling allows to estimate the rate of convergence of dif-
ferent algorithms, to estimate the variability of complex statistics, to estimate conﬁ-
dence intervals for out-of-sample errors and interpolate their values at larger scales.
These results are illustrated on simulations, but also on two important datasets,
frequently analyzed in the statistical learning community, EMNIST (recognition of
digits) and VeReMi (analysis of Network Vehicular Reference Misbehavior).
KEYWORDS
Scaling, big data, Subsampling, Convergence rate estimation, Conﬁdence intervals
in statistical learning, Out-of sample error, EMNIST digits VeReMi



hal_id    :    hal-04310171



Argumentation
. . . . .
51
G. Dubuisson Duplessis, M. Richard, A.-L. Guénet (APIA)
Segmentation de phases de dialogue dans des retranscriptions de conversations de centres
d’appels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
A. Ferdjaoui, S. Affeldt, M. Nadif (SFC)
Modèles graphiques causaux interactifs pour les données textuelles . . . . . . . . . . . . .
65
C. Fèvre, H. Zgaya-Biau, P. Mathieu, S. Hammadi (JFSMA)
L’optimisation du covoiturage dynamique multi-saut . . . . . . . . . . . . . . . . . . . . .
71
S. Forest, J.-C. Quinton, M. Lefort (CNIA)
Champ neuronal et apprentissage profond de topologies pour la fusion multimodale . . . .
81
A. Godinot, E. Le Merrer, C. Penzo, F. Taïani, G. Tredan (RJCIA)
Change-Relaxed Active Fairness Auditing . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
K. Le Gall, L. Bellanger, A. Stamm, D.A. Laplaud (SFC)
Génération de données



hal_id    :    hal-04258177



No abstract found in the PDF.



hal_id    :    hal-04390005



Optimal transport (OT) compares probability distributions by
computing a meaningful alignment between their samples. CO-
optimal transport (COOT) takes this comparison further by
inferring an alignment between features as well. While this ap-
proach leads to better alignments and generalizes both OT and
Gromov-Wasserstein distances, we provide a theoretical result
showing that it is sensitive to outliers that are omnipresent
in real-world data. This prompts us to propose unbalanced
COOT for which we provably show its robustness to noise in
the compared datasets. To the best of our knowledge, this is
the ﬁrst such result for OT methods in incomparable spaces.
With this result in hand, we provide empirical evidence of this
robustness for the challenging tasks of heterogeneous domain
adaptation with and without varying proportions of classes
and simultaneous alignment of samples and features across
single-cell measurements.



hal_id    :    hal-03608767



—This paper introduces a theoretically-rigorous sound
source localization (SSL) method based on a robust extension
of the classical multiple signal classification (MUSIC) algorithm.
The original SSL method estimates the noise eigenvectors and the
MUSIC spectrum by computing the spatial covariance matrix of
the observed multichannel signal and then detects the peaks from
the spectrum. In this work, the covariance matrix is replaced with
the positive definite shape matrix originating from the elliptically
contoured α-stable model, which is more suitable under real
noisy high-reverberant conditions. Evaluation on synthetic data
shows that the proposed method outperforms baseline methods
under such adverse conditions, while it is comparable on real
data recorded in a mild acoustic condition.
Index Terms— sound source localization, MUSIC, α-stable
theory, covariation



hal_id    :    hal-03990543



No abstract found in the PDF.



hal_id    :    hal-03821125



—This article describes a computationally-efﬁcient sta-
tistical approach to joint (semi-)blind source separation and dere-
verberation for multichannel noisy reverberant mixture signals. A
standard approach to source separation is to formulate a generative
model of a multichannel mixture spectrogram that consists of
source and spatial models representing the time-frequency power
spectral densities (PSDs) and spatial covariance matrices (SCMs)
of source images, respectively, and ﬁnd the maximum-likelihood
estimates of these parameters. A state-of-the-art blind source sep-
aration method in this thread of research is fast multichannel
nonnegative matrix factorization (FastMNMF) based on the low-
rank PSDs and jointly-diagonalizable full-rank SCMs. To perform
mutually-dependent separation and dereverberation jointly, in this
paper we integrate both moving average (MA) and autoregressive
(AR) models that represent the early reﬂections and late rever-
berations of sources, respectively, into the FastMNMF formalism.
Using a pretrained deep generative model of speech PSDs as a
source model, we realize semi-blind joint speech separation and
dereverberation. We derive an iterative optimization algorithm
based on iterative projection or iterative source steering for jointly
and efﬁciently updating the AR parameters and the SCMs. Our
experimentalresultsshowedthesuperiorityoftheproposedARMA
extensionoveritsAR-orMA-ablatedversioninaspeechseparation
and/or dereverberation task.
Index Terms—Multichannel audio signal processing, source
separation, dereverberation, joint diagonalization.
Manuscript received 4 October 2021; revised 31 March 2022; accepted 18
June2022.Dateofpublication13July2022;dateofcurrentversion28July2022.
This work was supported in part by JSPS KAKENHI under Grants 19H04137,
20K19833, and 20H01159, and in part by NII



hal_id    :    hal-03657196



—This paper describes heavy-tailed extensions of a
state-of-the-art versatile blind source separation method called
fast multichannel nonnegative matrix factorization (FastMNMF)
from a uniﬁed point of view. The common way of deriving such an
extension is to replace the multivariate complex Gaussian distribu-
tion in the likelihood function with its heavy-tailed generalization,
e.g., the multivariate complex Student’s t and leptokurtic gener-
alized Gaussian distributions, and tailor-make the corresponding
parameter optimization algorithm. Using a wider class of heavy-
tailed distributions called a Gaussian scale mixture (GSM), i.e., a
mixture of Gaussian distributions whose variances are perturbed
by positive random scalars called impulse variables, we propose
GSM-FastMNMF and develop an expectation-maximization algo-
rithm that works even when the probability density function of
the impulse variables have no analytical expressions. We show
that existing heavy-tailed FastMNMF extensions are instances of
GSM-FastMNMF and derive a new instance based on the gen-
eralized hyperbolic distribution that include the normal-inverse
Gaussian, Student’s t, and Gaussian distributions as the special
cases. Our experiments show that the normal-inverse Gaussian
FastMNMF outperforms the state-of-the-art FastMNMF exten-
sions and ILRMA model in speech enhancement and separation
in terms of the signal-to-distortion ratio.
Index Terms—Nonnegative matrix factorization, blind source
separation, probabilistic framework, expectation-maximization



hal_id    :    hal-03860497



, ISMIR 2022 Conference
SSM-NET: FEATURE LEARNING FOR MUSIC STRUCTURE ANALYSIS
USING A SELF-SIMILARITY-MATRIX BASED LOSS
Geoffroy Peeters
LTCI, Télécom-Paris, IP-Paris
geoffroy.peeters@telecom-paris.fr
Florian Angulo
LTCI, Télécom-Paris, IP-Paris
florian.angulo@telecom-paris.fr
ABSTRACT
In this paper, we propose a new paradigm to learn au-
dio features for Music Structure Analysis (MSA).
We
train a deep encoder to learn features such that the Self-
Similarity-Matrix (SSM) resulting from those approxi-
mates a ground-truth SSM. This is done by minimizing
a loss between both SSMs.
Since this loss is differen-
tiable w.r.t. its input features we can train the encoder in a
straightforward way. We successfully demonstrate the use
of this training paradigm using the Area Under the Curve
ROC (AUC) on the RWC-Pop dataset.



hal_id    :    hal-03903647



As music has become more available especially on music
streaming platforms, people have started to have distinct
preferences to fit to their varying listening situations, also
known as context. Hence, there has been a growing inter-
est in considering the user’s situation when recommending
music to users. Previous works have proposed user-aware
autotaggers to infer situation-related tags from music con-
tent and user’s global listening preferences. However, in
a practical music retrieval system, the autotagger could be
only used by assuming that the context class is explicitly
provided by the user. In this work, for designing a fully
automatised music retrieval system, we propose to disam-
biguate the user’s listening information from their stream
data. Namely, we propose a system which can generate a
situational playlist for a user at a certain time 1) by leverag-
ing user-aware music autotaggers, and 2) by automatically
inferring the user’s situation from stream data (e.g. device,
network) and user’s general profile information (e.g. age).
Experiments show that such a context-aware personalized
music retrieval system is feasible, but the performance de-
creases in the case of new users, new tracks or when the
number of context classes increases.



hal_id    :    hal-03782827



Invariance-based learning is a promising approach in deep learning.
Among other benefits, it can mitigate the lack of diversity of avail-
able datasets and increase the interpretability of trained models. To
this end, practitioners often use a consistency cost penalizing the
sensitivity of a model to a set of carefully selected data augmen-
tations. However, there is no consensus about how these augmen-
tations should be selected. In this paper, we study the behavior
of several augmentation strategies. We consider the task of sound
event detection and classification for our experiments. In particular,
we show that transformations operating on the internal layers of a
deep neural network are beneficial for this task.
Index Terms— sound event detection, data augmentation, ad-
versarial learning



hal_id    :    hal-03860830



The way we use words is influenced by our
opinion.
We investigate whether this is re-
flected in contextualized word embeddings.
For example, is the representation of “animal”
different between people who would abolish
zoos and those who would not? We explore
this question from a Lexical Semantic Change
standpoint. Our experiments with BERT em-
beddings derived from datasets with stance
annotations reveal small but significant differ-
ences in word representations between oppos-
ing stances.
1



hal_id    :    hal-03817736



Contrastive learning enables learning useful audio and speech
representations without ground-truth labels by maximizing the
similarity between latent representations of similar signal seg-
ments. In this framework various data augmentation techniques
are usually exploited to help enforce desired invariances within
the learned representations, improving performance on various
audio tasks thanks to more robust embeddings. Now, selecting
the most relevant augmentations has proven crucial for better
downstream performances. Thus, this work introduces a condi-
tional independance-based method which allows for automati-
cally selecting a suitable distribution on the choice of augmenta-
tions and their parametrization from a set of predefined ones, for
contrastive self-supervised pre-training. This is performed with
respect to a downstream task of interest, hence saving a costly
hyper-parameter search. Experiments performed on two differ-
ent downstream tasks validate the proposed approach showing
better results than experimenting without augmentation or with
baseline augmentations. We furthermore conduct a qualitative
analysis of the automatically selected augmentations and their
variation according to the considered final downstream dataset.
Index Terms: self-supervised learning, data augmentation.



hal_id    :    hal-03860827



Our discourses are full of potential lexical ambiguities, due in part to the pervasive use of words having multiple senses.
Sometimes, one word may even be used in more than one sense throughout a text. But, to what extent is this true for different
kinds of texts? Does the use of polysemous words change when a discourse involves two people, or when speakers have time
to plan what to say? We investigate these questions by comparing the polysemy level of texts of different nature, with a focus
on spontaneous spoken dialogs; unlike previous work which examines solely scripted, written, monolog-like data. We compare
multiple metrics that presuppose different conceptualizations of text polysemy, i.e., they consider the observed or the potential
number of senses of words, or their sense distribution in a discourse. We show that the polysemy level of texts varies greatly
depending on the kind of text considered, with dialog and spoken discourses having generally a higher polysemy level than
written monologs. Additionally, our results emphasize the need for relaxing the popular “one sense per discourse” hypothesis.
Keywords: Semantics, Word Sense Disambiguation, Document classification / Text categorisation
1.



hal_id    :    hal-04273536



Users generate content constantly, leading to new data requiring annotation.
Among this data, textual conversations are
created every day and come with some specificities: they are mostly private through instant messaging applications, requiring
the conversational context to be labeled. These specificities led to several annotation tools dedicated to conversation, and
mostly dedicated to dialogue tasks, requiring complex annotation schemata, not always customizable and not taking into
account conversation-level labels.
In this paper, we present EZCAT, an easy-to-use interface to annotate conversations
in a two-level configurable schema, leveraging message-level labels and conversation-level labels at once.
Our interface
is characterized by the voluntary absence of a server and accounts management, enhancing its availability to anyone, and
the control over data, which is crucial to confidential conversations. We also present our first usage of EZCAT along with
our annotation schema we used to annotate confidential customer service conversations.
EZCAT is freely available at
https://gguibon.github.io/ezcat.
Keywords: conversations, annotation tool, text messages
1.



hal_id    :    hal-04276012



In this paper, we present the process we used in order to collect new annotations of opinions over the multimodal corpus
SEMAINE composed of dyadic interactions. The dataset had already been annotated continuously in two affective dimensions
related to the emotions: Valence and Arousal.
We annotated the part of SEMAINE called Solid SAL composed of 79
interactions between a user and an operator playing the role of a virtual agent designed to engage a person in a sustained,
emotionally colored conversation. We aligned the audio at the word level using the available high-quality manual transcriptions.
The annotated dataset contains 5627 speech turns for a total of 73,944 words, corresponding to 6 hours 20 minutes of dyadic
interactions. Each interaction has been labeled by three annotators at the speech turn level following a three-step process. This
method allows us to obtain a precise annotation regarding the opinion of a speaker. We obtain thus a dataset dense in opinions,
with more than 48% of the annotated speech turns containing at least one opinion. We then propose a new baseline for the
detection of opinions in interactions improving slightly a state of the art model with RoBERTa embeddings. The obtained
results on the database are promising with a F1-score at 0.72.
Keywords: Opinion, Multimodal Machine



hal_id    :    hal-04166172



. Handwriting is an everyday life human activity. It can be
collected oﬀ-line by scanning sheets of paper. The resulting images can
then be processed by a computer-based system. Thanks to digitizing
tablets, handwriting can also be collected on-line. From the collected raw
signals (pen position, pressure over time), the dynamics of the writing
can be recovered. Since handwriting is unique for each individual, it can
be considered as a biometric modality.
Biometric systems predicting gender from oﬀ-line handwriting, have been
recently proposed. However we observe that, in contrast to other modal-
ities such as speech, it is not straightforward for a human being (even
expert) to predict gender. In this study we explore the limits of auto-
matic gender prediction from on-line handwriting collected from a young
adults population, homogeneous in terms of age and education. In our
previous work [1], a statistical analysis of on-line dynamic features has
shown diﬀerences between male and female groups. In the present study,
we provide these features to a classiﬁer, based on a machine learning ap-
proach (SVMs). Since datasets are relatively small (240 subjects), several
evaluation frameworks are explored: cross validation (CV), bootstrap,
and ﬁxed train/test partitions. Accuracies obtained from ﬁxed partitions
range from 37% to 79%, while those estimated by CV and bootstrap
are around 60%.
This shows to our opinion



hal_id    :    hal-03637425



This paper describes a blind source separation method for multichan-
nel audio signals, called NF-FastMNMF, based on the integration of
the normalizing ﬂow (NF) into the multichannel nonnegative matrix
factorization with jointly-diagonalizable spatial covariance matrices,
a.k.a. FastMNMF. Whereas the NF of ﬂow-based independent vector
analysis, called NF-IVA, acts as the demixing matrices to transform
an M-channel mixture into M independent sources, the NF of NF-
FastMNMF acts as the diagonalization matrices to transform an M-
channel mixture into a spatially-independent M-channel mixture rep-
resented as a weighted sum of N source images. This diagonalization
enables the NF, which has been used only for determined separation
because of its bijective nature, to be applicable to non-determined
separation. NF-FastMNMF has time-varying diagonalization matri-
ces that are potentially better at handling dynamical data variation
than the time-invariant ones in FastMNMF. To have an NF with richer
expression capability, the dimension-wise scalings using diagonal ma-
trices originally used in NF-IVA are replaced with linear transforma-
tions using upper triangular matrices; in both cases, the diagonal and
upper triangular matrices are estimated by neural networks. The eval-
uation shows that NF-FastMNMF performs well for both determined
and non-determined separations of multiple speech utterances by sta-
tionary or non-stationary speakers from a noisy reverberant mixture.
Index Terms— Blind source separation, normalizing ﬂow, joint
diagonalization, multichannel nonnegative matrix factorization



hal_id    :    hal-03602455



This paper introduces a new extragradient-type algorithm for a class of
nonconvex-nonconcave minimax problems. It is well-known that ﬁnding a local
solution for general minimax problems is computationally intractable. This ob-
servation has recently motivated the study of structures suﬃcient for convergence
of ﬁrst order methods in the more general setting of variational inequalities when
the so-called weak Minty variational inequality (MVI) holds. This problem class
captures non-trivial structures as we demonstrate with examples, for which a large
family of existing algorithms provably converge to limit cycles. Our results require
a less restrictive parameter range in the weak MVI compared to what is previously
known, thus extending the applicability of our scheme. The proposed algorithm is
applicable to constrained and regularized problems, and involves an adaptive step-
size allowing for potentially larger stepsizes. Our scheme also converges globally
even in settings where the underlying operator exhibits limit cycles.
1



hal_id    :    hal-03727169



— This paper describes the practical response- and
performance-aware development of online speech enhancement
for an augmented reality (AR) headset that helps a user under-
stand conversations made in real noisy echoic environments (e.g.,
cocktail party). One may use a state-of-the-art blind source sep-
aration method called fast multichannel nonnegative matrix fac-
torization (FastMNMF) that works well in various environments
thanks to its unsupervised nature. Its heavy computational cost,
however, prevents its application to real-time processing. In con-
trast, a supervised beamforming method that uses a deep neural
network (DNN) for estimating spatial information of speech and
noise readily fits real-time processing, but suffers from drastic
performance degradation in mismatched conditions. Given such
complementary characteristics, we propose a dual-process ro-
bust online speech enhancement method based on DNN-based
beamforming with FastMNMF-guided adaptation. FastMNMF
(back end) is performed in a mini-batch style and the noisy and
enhanced speech pairs are used together with the original par-
allel training data for updating the direction-aware DNN (front
end) with backpropagation at a computationally-allowable inter-
val. This method is used with a blind dereverberation method
called weighted prediction error (WPE) for transcribing the
noisy reverberant speech of a speaker, which can be detected
from video or selected by a user’s hand gesture or eye gaze, in
a streaming manner and spatially showing the transcriptions
with an AR technique. Our



hal_id    :    hal-03701451



Cet article présente l’approche de l’équipe TGV lors de sa participation à la tâche de base de DEFT
2022, dont l’objectif était de prédire automatiquement les notes obtenues par des étudiants sur la
base de leurs réponses à des questionnaires. Notre stratégie s’est focalisée sur la mise au point d’une
méthode de classification des questions en fonction du type de réponse qu’elles attendent, de manière
à pouvoir mener une approche différenciée pour chaque type. Nos trois runs ont consisté en une
approche non différenciée, servant de référence, et deux approches différenciées, la première se basant
sur la constitution d’un jeu de caractéristiques et la seconde sur le calcul de TF-IDF et de la fonction
de hashage. Notre objectif premier était ainsi de vérifier si des approches dédiées à chaque type de
questions sont préférables à une approche globale.
ABSTRACT
Team TGV at DEFT 2022 : automatic prediction of students’ grades according to the different
question types.
In this paper we present the work of the TGV team for the DEFT 2022 challenge. We tackled the
base task only, which consists of automatically grading students based on their answers to several
questions. Our strategy consider this task as a classification task with multiple approaches, each being
specific to a question type leading to different types of



hal_id    :    hal-03821095



This paper describes a practical dual-process speech enhance-
ment system that adapts environment-sensitive frame-online
beamforming (front-end) with help from environment-free
block-online source separation (back-end). To use minimum
variance distortionless response (MVDR) beamforming, one
may train a deep neural network (DNN) that estimates time-
frequency masks used for computing the covariance matrices
of sources (speech and noise). Backpropagation-based run-
time adaptation of the DNN was proposed for dealing with the
mismatched training-test conditions. Instead, one may try to
directly estimate the source covariance matrices with a state-of-
the-art blind source separation method called fast multichannel
non-negative matrix factorization (FastMNMF). In practice,
however, neither the DNN nor the FastMNMF can be updated
in a frame-online manner due to its computationally-expensive
iterative nature. Our DNN-free system leverages the posteri-
ors of the latest source spectrograms given by block-online
FastMNMF to derive the current source covariance matrices
for frame-online beamforming. The evaluation shows that our
frame-online system can quickly respond to scene changes
caused by interfering speaker movements and outperformed
an existing block-online system with DNN-based beamform-
ing by 5.0 points in terms of the word error rate.
Index Terms— speech enhancement, beamforming, blind
source separation, automatic speech recognition



hal_id    :    hal-03727181



This paper describes noisy speech recognition for an augmented
reality headset that helps verbal communication with in real mul-
tiparty conversational environments. A major approach that has
actively been studied in simulated environments is to sequentially
perform speech enhancement and automatic speech recognition
(ASR) based on deep neural networks (DNNs) trained in a su-
pervised manner. In our task, however, such a pretrained system
fails to work due to the mismatch between the training and test
conditions and the head movements of the user. To enhance only
the utterances of a target speaker, we use beamforming based on
a DNN-based speech mask estimator that can adaptively extract
the speech components corresponding to a head-relative particu-
lar direction. We propose a semi-supervised adaptation method
that jointly updates the mask estimator and the ASR model at
run-time using clean speech signals with ground-truth transcrip-
tions and noisy speech signals with highly-confident estimated
transcriptions. Comparative experiments using the state-of-the-
art distant speech recognition system show that the proposed
method significantly improves the ASR performance.
Index Terms: speech enhancement, speech recognition, human-
computer interaction, run-time adaptation.



hal_id    :    hal-03574595



Spoken dialog systems need to be able to han-
dle both multiple languages and multilingual-
ity inside a conversation (e.g in case of code-
switching). In this work, we introduce new
pretraining losses tailored to learn multilingual
spoken dialog representations.
The goal of
these losses is to expose the model to code-
switched language. To scale up training, we
automatically build a pretraining corpus com-
posed of multilingual conversations in ﬁve dif-
ferent languages (French, Italian, English, Ger-
man and Spanish) from OpenSubtitles, a
huge multilingual corpus composed of 24.3G
tokens. We test the generic representations on
MIAM, a new benchmark composed of ﬁve di-
alog act corpora on the same aforementioned
languages as well as on two novel multilingual
downstream tasks (i.e multilingual mask utter-
ance retrieval and multilingual inconsistency
identiﬁcation). Our experiments show that our
new code switched-inspired losses achieve a
better performance in both monolingual and
multilingual settings.
1



hal_id    :    hal-03344680



Several recent studies on dyadic human-
human interactions have been done on con-
versations without speciﬁc business objectives.
However, many companies might beneﬁt from
studies dedicated to more precise environ-
ments such as after sales services or customer
satisfaction surveys. In this work, we place
ourselves in the scope of a live chat customer
service in which we want to detect emotions
and their evolution in the conversation ﬂow.
This context leads to multiple challenges that
range from exploiting restricted, small and
mostly unlabeled datasets to ﬁnding and adapt-
ing methods for such context.
We tackle
these challenges by using Few-Shot Learning
while making the hypothesis it can serve con-
versational emotion classiﬁcation for different
languages and sparse labels.
We contribute
by proposing a variation of Prototypical Net-
works for sequence labeling in conversation
that we name ProtoSeq. We test this method
on two datasets with different languages: daily
conversations in English and customer service
chat conversations in French. When applied
to emotion classiﬁcation in conversations, our
method proved to be competitive even when
compared to other ones. The code for Proto-
Seq is available at https://github.com/
gguibon/ProtoSeq.
1



hal_id    :    hal-03574609



Multimodal sentiment analysis is a trending
area of research, and the multimodal fusion
is one of its most active topic. Acknowledg-
ing humans communicate through a variety of
channels (i.e visual, acoustic, linguistic), mul-
timodal systems aim at integrating different
unimodal representations into a synthetic one.
So far, a consequent effort has been made on
developing complex architectures allowing the
fusion of these modalities. However, such sys-
tems are mainly trained by minimising sim-
ple losses such as L1 or cross-entropy.
In
this work, we investigate unexplored penalties
and propose a set of new objectives that mea-
sure the dependency between modalities. We
demonstrate that our new penalties lead to a
consistent improvement (up to 4.3 on accu-
racy) across a large variety of state-of-the-art
models on two well-known sentiment analysis
datasets: CMU-MOSI and CMU-MOSEI. Our
method not only achieves a new SOTA on both
datasets but also produces representations that
are more robust to modality drops. Finally, a
by-product of our methods includes a statisti-
cal network which can be used to interpret the
high dimensional representations learnt by the
model.
1



hal_id    :    hal-03329932



—Analog-to-feature (A2F) conversion is an acquisition
method thought for IoT devices in order to increase wireless
sensor’s battery life. The operating principle of A2F is to
perform classification tasks at sub-Nyquist rate, by extracting
relevant features in the analog domain and then performing
the classification step in the digital domain. We propose to use
non-uniform wavelet sampling (NUWS) combined with feature
selection to find and extract from the signal, a small set of relevant
features for electrocardiogram (ECG) anomalies detection. A
CMOS 0.18 µm mixed architecture for NUWS feature extraction
is proposed, to obtain a power consumption model for A2F.
This model can be taken into account in the feature selection
step by evaluating the energy cost of each wavelet and then
try to maximize classification accuracy while minimizing the
energy needed for extraction. We demonstrate the benefits of A2F
showing that the energy needed can be divided by 15 compared
to classical approach.
Index Terms—Analog-to-Feature converter, Bio-sensing ac-
quisition, Feature selection, Low power, Non-Uniform Wavelet
Sampling.



hal_id    :    hal-03409892



Emergent states are behavioral, cognitive and affective processes ap-
pearing among the members of a group when they interact together.
In the last decade, the development of computational approaches
received a growing interest in building Human-Centered systems.
Such a development is particularly difficult because some of these
states have several dimensions interplaying somehow and some-
where over time. In this paper, we focus on cohesion, its dimensions
and their interplay. Several definitions of cohesion exist, it can be
simply defined as the tendency of a group to stick together to pursue
goals and/or affective needs. This plethora of definitions resulted in
many different cohesion dimensions. Social and Task dimensions
are the most investigated both in Social Sciences and Computer
Science since they both play an important role in a wide range of
contexts and groups. To the best of our knowledge, however, no pre-
vious work on the prediction of cohesion dynamics focused on how
these 2 dimensions interplay. We leverage Social Sciences to address
this issue. In particular, we take advantage of the importance of
Social cohesion for creating flexible and constructive relationships
to reinforce Task cohesion. We describe a Deep Neural Network
architecture (DNN) for predicting the dynamics of Task cohesion
by applying transfer learning from a pre-trained model dedicated
to the prediction of Social cohesion dynamics. Our architecture
is



hal_id    :    hal-03167498



—The analysis of load curves collected
from smart meters is a key step for many energy man-
agement tasks ranging from consumption forecasting
to customers characterization and load monitoring.
In this contribution, we propose a model based on a
functional formulation of nonnegative tensor factor-
ization and derive updates for the corresponding opti-
mization problem. We show on the concrete example
of multi-sites load curves disaggregation how this
formulation is helpful for 1) exhibiting smooth intra-
day consumption patterns and 2) taking into account
external variables such as the outside temperature.
The beneﬁts are demonstrated on simulated and real
data by exhibiting a meaningful clustering of the
observed sites based on the obtained decomposition.



hal_id    :    hal-03563675



In this paper, we place ourselves in a classi-
ﬁcation scenario in which the target classes
and data type are not accessible during train-
ing. We use a meta-learning approach to de-
termine whether or not meta-trained informa-
tion from common social network data with
ﬁne-grained emotion labels can achieve com-
petitive performance on messages labeled with
different emotion categories. We leverage few-
shot learning to match with the classiﬁcation
scenario and consider metric learning based
meta-learning by setting up Prototypical Net-
works with a Transformer encoder, trained in
an episodic fashion.
This approach proves
to be effective for capturing meta-information
from a source emotional tag set to predict pre-
viously unseen emotional tags. Even though
shifting the data type triggers an expected per-
formance drop, our meta-learning approach
achieves decent results when compared to the
fully supervised one.
1



hal_id    :    hal-02985794



Speech separation with several speakers is a challenging task be-
cause of the non-stationarity of the speech and the strong signal
similarity between interferent sources. Current state-of-the-art so-
lutions can separate well the different sources using sophisticated
deep neural networks which are very tedious to train. When several
microphones are available, spatial information can be exploited to
design much simpler algorithms to discriminate speakers. We pro-
pose a distributed algorithm that can process spatial information in
a spatially unconstrained microphone array. The algorithm relies on
a convolutional recurrent neural network that can exploit the signal
diversity from the distributed nodes. In a typical case of a meeting
room, this algorithm can capture an estimate of each source in a ﬁrst
step and propagate it over the microphone array in order to increase
the separation performance in a second step. We show that this ap-
proach performs even better when the number of sources and nodes
increases. We also study the inﬂuence of a mismatch in the number
of sources between the training and testing conditions.
Index Terms— Speech separation, microphone arrays, dis-
tributed processing.



hal_id    :    hal-03265871



Dans cet article nous reproduisons un scénario d’apprentissage selon lequel les données cibles
ne sont pas accessibles et seules des données connexes le sont. Nous utilisons une approche par
méta-apprentissage aﬁn de déterminer si les méta-informations apprises à partir de messages issus
de médias sociaux, ﬁnement annotés en émotions, peuvent produire de bonnes performances une
fois utilisées sur des messages issus de conversations, étiquetés en émotions avec une granularité
différente. Nous mettons à proﬁt l’apprentissage sur quelques exemples (few-shot learning) pour la
mise en place de ce scénario. Cette approche se montre efﬁcace pour capturer les méta-informations
d’un jeu d’étiquettes émotionnelles pour prédire des étiquettes jusqu’alors inconnues au modèle. Bien
que le fait de varier le type de données engendre une baisse de performance, notre approche par
méta-apprentissage atteint des résultats décents comparés au référentiel d’apprentissage supervisé.
ABSTRACT
Meta-learning : Classifying Messages into Unseen Emotional Categories
In this paper, we place ourselves in a classiﬁcation scenario in which the target data set classes and
data type are not accessible during training. We use a meta-learning approach to determine whether
or not meta-trained information from common social network data with ﬁne-grained emotion labels
can achieve competitive performance on conversation utterances labeled with different, higher level,
emotions. We leverage few-shot learning to concur with the classiﬁcation scenario. This



hal_id    :    hal-02429681



Discrete time trawl processes constitute a large class of time series parameterized by a
trawl sequence (aj)j∈N and deﬁned though a sequence of independent and identically
distributed (i.i.d.) copies of a continuous time process (γ(t))t∈R called the seed process.
They provide a general framework for modeling linear or non-linear long range dependent
time series. We investigate the spectral estimation, either pointwise or broadband, of long
range dependent discrete-time trawl processes. The diﬃculty arising from the variety of
seed processes and of trawl sequences is twofold. First, the spectral density may take
diﬀerent forms, often including smooth additive correction terms. Second, trawl processes
with similar spectral densities may exhibit very diﬀerent statistical behaviors. We prove
the consistency of our estimators under very general conditions and we show that a wide
class of trawl processes satisfy them. This is done in particular by introducing a weighted
weak dependence index that can be of independent interest.
The broadband spectral
estimator includes an estimator of the long memory parameter. We complete this work
with numerical experiments to evaluate the ﬁnite sample size performance of this estimator
for various integer valued discrete time trawl processes.
Keywords: trawl processes; integer-valued time series; long memory parameter estimation
MSC: 62M10; 62F12; 60G51;
1



hal_id    :    hal-03189235



Data depth is a concept in multivariate statistics that measures the centrality
of a point in a given data cloud in Rd. If the depth of a point can be represented
as the minimum of the depths with respect to all one-dimensional projections
of the data, then the depth satisﬁes the so-called projection property. Such
depths form an important class that includes many of the depths that have
been proposed in literature. For depths that satisfy the projection property an
approximate algorithm can easily be constructed since taking the minimum of
the depths with respect to only a ﬁnite number of one-dimensional projections
yields an upper bound for the depth with respect to the multivariate data. Such
an algorithm is particularly useful if no exact algorithm exists or if the exact
algorithm has a high computational complexity, as is the case with the halfspace
depth or the projection depth. To compute these depths in high dimensions,
the use of an approximate algorithm with better complexity is surely preferable.
Instead of focusing on a single method we provide a comprehensive and fair
comparison of several methods, both already described in the literature and
original.
Keywords:
data depth, projection property, approximate computation,
∗Corresponding author
Email addresses: rainer.dyckerhoff@statistik.uni-koeln.de (Rainer Dyckerhoﬀ),
pavlo.mozharovskyi@telecom-paris.fr (Pavlo Mozharovskyi), nagy@karlin.mff.cuni.cz
(Stanislav Nagy)
Preprint submitted to Computational Statistics and Data Analysis
November 20,



hal_id    :    hal-02088860



. In this contribution we are interested in proving that a given
observation-driven model is identiﬁable. In the case of a GARCH(p, q) model,
a simple suﬃcient condition has been established in [2] for showing the consis-
tency of the quasi-maximum likelihood estimator. It turns out that this condi-
tion applies for a much larger class of observation-driven models, that we call
the class of linearly observation-driven models. This class includes standard in-
teger valued observation-driven time series such as the Poisson autoregression
model and its numerous extensions. Our results also apply to vector-valued
time series such as the bivariate integer valued GARCH model, to non-linear
models such as the threshold Poisson autoregression or to observation-driven
models with exogenous covariates such as the PARX model.



hal_id    :    hal-03188029



John W. Tukey (1975) deﬁned statistical data depth as a function that determines centrality of
an arbitrary point with respect to a data cloud or to a probability measure. During the last decades,
this seminal idea of data depth evolved into a powerful tool proving to be useful in various ﬁelds
of science. Recently, extending the notion of data depth to the functional setting attracted a lot
of attention among theoretical and applied statisticians. We go further and suggest a notion of
data depth suitable for data represented as curves, or trajectories, which is independent of the
parametrization. We show that our curve depth satisﬁes theoretical requirements of general depth
functions that are meaningful for trajectories. We apply our methodology to diffusion tensor
brain images and also to pattern recognition of hand written digits and letters. Supplementary
Materials are available online.
Keywords: data depth, space of curves, unparametrized curves, nonparametric statistics,
curve registration, DT-MRI ﬁbers, classiﬁcation, DD-plot.
1



hal_id    :    hal-02933051



Screening rules were recently introduced as a technique for explicitly
identifying active structures such as sparsity, in optimization problem
arising in machine learning. This has led to new methods of acceleration
based on a substantial dimension reduction.
We show that screening
rules stem from a combination of natural properties of subdiﬀerential sets
and optimality conditions, and can hence be understood in a uniﬁed way.
Under mild assumptions, we analyze the number of iterations needed to
identify the optimal active set for any converging algorithm. We show that
it only depends on its convergence rate.
1



hal_id    :    hal-03134854



While being an essential component
of spoken language, ﬁllers (e.g. “um”
or “uh”) often remain overlooked in
Spoken Language Understanding (SLU)
tasks.
We explore the possibility of
representing them with deep contex-
tualised embeddings, showing improve-
ments on modelling spoken language
and two downstream tasks — predict-
ing a speaker’s stance and expressed
conﬁdence.
1



hal_id    :    hal-02934433



Music tags are commonly used to describe and catego-
rize music. Various auto-tagging models and datasets have
been proposed for the automatic music annotation with
tags. However, the past approaches often neglect the fact
that many of these tags largely depend on the user, espe-
cially the tags related to the context of music listening. In
this paper, we address this problem by proposing a user-
aware music auto-tagging system and evaluation protocol.
Speciﬁcally, we use both the audio content and user infor-
mation extracted from the user listening history to predict
contextual tags for a given user/track pair. We propose a
new dataset of music tracks annotated with contextual tags
per user. We compare our model to the traditional audio-
based model and study the inﬂuence of user embeddings
on the classiﬁcation quality. Our work shows that explic-
itly modeling the user listening history into the automatic
tagging process could lead to more accurate estimation of
contextual tags.



hal_id    :    hal-02507316



.
We present a framework for deﬁning the “right” level of
explainability based on technical, legal and economic considerations.
Our approach involves three logical steps: First, deﬁne the main con-
textual factors, such as who is the audience of the explanation, the
operational context, the level of harm that the system could cause,
and the legal/regulatory framework. This step will help characterize
the operational and legal needs for explanation, and the correspond-
ing social beneﬁts. Second, examine the technical tools available,
including post-hoc approaches (input perturbation, saliency maps...)
and hybrid AI approaches. Third, as function of the ﬁrst two steps,
choose the right levels of global and local explanation outputs, taking
into the account the costs involved. We identify seven kinds of costs
and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1



hal_id    :    hal-03132996



With the ubiquity of sensors in the IoT era,
statistical observations are becoming increas-
ingly available in the form of massive (multi-
variate) time-series. Formulated as unsuper-
vised anomaly detection tasks, an abundance
of applications like aviation safety manage-
ment, the health monitoring of complex in-
frastructures or fraud detection can now rely
on such functional data, acquired and stored
with an ever ﬁner granularity. The concept
of statistical depth, which reﬂects centrality
of an arbitrary observation w.r.t. a statisti-
cal population may play a crucial role in this
regard, anomalies corresponding to observa-
tions with ’small’ depth. Supported by sound
theoretical and computational developments
in the recent decades, it has proven to be
extremely useful, in particular in functional
spaces.
However, most approaches docu-
mented in the literature consist in evaluat-
ing independently the centrality of each point
forming the time series and consequently ex-
hibit a certain insensitivity to possible shape
changes. In this paper, we propose a novel
notion of functional depth based on the area
of the convex hull of sampled curves, captur-
ing gradual departures from centrality, even
beyond the envelope of the data, in a nat-
ural fashion. We discuss practical relevance
of commonly imposed axioms on functional
depths and investigate which of them are sat-
isﬁed by the notion of depth we promote here.
Estimation and computational issues are also
addressed and various numerical experiments
provide empirical evidence



hal_id    :    hal-02547012



The problem of multi-label classification with missing labels (MLML)
is a common challenge that is prevalent in several domains, e.g.
image annotation and auto-tagging. In multi-label classification,
each instance may belong to multiple class labels simultaneously.
Due to the nature of the dataset collection and labelling proce-
dure, it is common to have incomplete annotations in the dataset,
i.e. not all samples are labelled with all the corresponding labels.
However, the incomplete data labelling hinders the training of clas-
sification models. MLML has received much attention from the
research community. However, in cases where a pre-trained model
is fine-tuned on an MLML dataset, there has been no straightfor-
ward approach to tackle the missing labels, specifically when there
is no information about which are the missing ones. In this paper,
we propose a weighted loss function to account for the confidence
in each label/sample pair that can easily be incorporated to fine-
tune a pre-trained model on an incomplete dataset. Our experiment
results show that using the proposed loss function improves the
performance of the model as the ratio of missing labels increases.
CCS CONCEPTS
• Computing methodologies →Neural networks.
KEYWORDS
Multi-label classification; missing labels; neural networks
ACM Reference Format:
Karim M. Ibrahim, Elena V. Epure, Geoffroy Peeters, and Gaël Richard. 2020.
Confidence-based Weighted Loss for Multi-label Classification with Missing
Labels. In Proceedings of the



hal_id    :    hal-02481374



Music listening context such as location or activity has been shown
to greatly inﬂuence the users’ musical tastes. In this work, we study
the relationship between user context and audio content in order to
enable context-aware music recommendation agnostic to user data.
For that, we propose a semi-automatic procedure to collect track sets
which leverages playlist titles as a proxy for context labelling. Using
this, we create and release a dataset of ∼50k tracks labelled with
15 different contexts. Then, we present benchmark classiﬁcation
results on the created dataset using an audio auto-tagging model. As
the training and evaluation of these models are impacted by missing
negative labels due to incomplete annotations, we propose a sample-
level weighted cross entropy loss to account for the conﬁdence in
missing labels and show improved context prediction results.
Index Terms— music auto-tagging, user context, dataset col-
lection, multi-label classiﬁcation, missing labels.



hal_id    :    hal-02389159



Multichannel processing is widely used for speech enhancement but
several limitations appear when trying to deploy these solutions in
the real world. Distributed sensor arrays that consider several de-
vices with a few microphones is a viable solution which allows for
exploiting the multiple devices equipped with microphones that we
are using in our everyday life. In this context, we propose to extend
the distributed adaptive node-speciﬁc signal estimation approach to
a neural network framework. At each node, a local ﬁltering is per-
formed to send one signal to the other nodes where a mask is esti-
mated by a neural network in order to compute a global multichan-
nel Wiener ﬁlter. In an array of two nodes, we show that this addi-
tional signal can be leveraged to predict the masks and leads to better
speech enhancement performance than when the mask estimation re-
lies only on the local signals.
Index Terms— Speech enhancement, microphone arrays, dis-
tributed processing.



hal_id    :    hal-02914840



The principle of compositionality, which enables natural language to represent
complex concepts via a structured combination of simpler ones, allows us to con-
vey an open-ended set of messages using a limited vocabulary. If compositionality
is indeed a natural property of language, we may expect it to appear in commu-
nication protocols that are created by neural agents in language games. In this
paper, we propose an effective neural iterated learning (NIL) algorithm that, when
applied to interacting neural agents, facilitates the emergence of a more structured
type of language. Indeed, these languages provide learning speed advantages to
neural agents during training, which can be incrementally ampliﬁed via NIL. We
provide a probabilistic model of NIL and an explanation of why the advantage
of compositional language exist. Our experiments conﬁrm our analysis, and also
demonstrate that the emerged languages largely improve the generalizing power
of the neural agent communication.
1



hal_id    :    hal-02506409



The recent enthusiasm for artiﬁcial intelligence (AI) is due principally to
advances in deep learning. Deep learning methods are remarkably accurate,
but also opaque, which limits their potential use in safety-critical applications.
To achieve trust and accountability, designers and operators of machine learn-
ing algorithms must be able to explain the inner workings, the results and the
causes of failures of algorithms to users, regulators, and citizens. The orig-
inality of this paper is to combine technical, legal and economic aspects of
explainability to develop a framework for deﬁning the ”right” level of explain-
ability in a given context. We propose three logical steps: First, deﬁne the
main contextual factors, such as who the audience of the explanation is, the
operational context, the level of harm that the system could cause, and the
legal/regulatory framework. This step will help characterize the operational
and legal needs for explanation, and the corresponding social beneﬁts. Second,
examine the technical tools available, including post hoc approaches (input
perturbation, saliency maps...) and hybrid AI approaches. Third, as function
of the ﬁrst two steps, choose the right levels of global and local explanation
outputs, taking into the account the costs involved. We identify seven kinds
of costs and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1We would like to



hal_id    :    hal-01440269



We present single imputation method for missing values which borrows the idea of data  
depth—a measure of centrality defined for an arbitrary point of a space with respect to a prob- 
ability distribution or data cloud. This consists in iterative maximization of the depth of each 
observation with missing values, and can be employed with any properly defined statistical depth 
function. For each single iteration, imputation reverts to optimization of quadratic, linear, or 
quasiconcave functions that are solved analytically by linear programming or the Nelder-Mead 
method. As it accounts for the underlying data topology, the procedure is distribution free, allows 
imputation close to the data geometry, can make prediction in situations where local imputation 
(k-nearest neighbors, random forest) cannot, and has attractive robustness and asymptotic prop- 
erties under elliptical symmetry. It is shown that a special case—when using the Mahalanobis 
depth—has direct connection to well-known methods for the multivariate normal model, such as 
iterated regression and regularized PCA. The methodology is extended to multiple imputation for 
data stemming from an elliptically symmetric distribution. Simulation and real data studies show 
good results compared with existing popular alternatives. The method has been implemented as 
an R-package. Supplementary materials for the article



hal_id    :    hal-02433213



Source separation aims at decomposing a vector into additive components. This
is often done by ﬁrst estimating source parameters before feeding them into a
ﬁltering method, often based on ratios of covariances. The whole pipeline is
traditionally rooted in some probabilistic framework providing both the likeli-
hood for parameter estimation and the separation method. While Gaussians
are ubiquitous for this purpose, many studies showed the beneﬁt of heavy-tailed
models for estimation. However, there is no counterpart ﬁltering method to date
exploiting such formalism, so that related studies revert to covariance-based ﬁl-
tering after estimation is ﬁnished.
Here, we introduce a new multivariate separation technique, that fully ex-
ploits the ﬂexibility of α-stable heavy-tailed distributions. We show how a spa-
tial representation can be exploited, which decomposes the observation as an
inﬁnite sum of contributions originating from all directions. Two methods for
separation are derived. The ﬁrst one is non-linear and similar to a beamforming
technique, while the second one is linear, but minimizes a covariation criterion,
which is the counterpart of the covariance for α-stable vectors. We evaluate the
proposed techniques in a large number of challenging and adverse situations on
synthetic experiments, demonstrating their performance for the extraction of
signals from strong interferences.
Keywords:
alpha-stable distribution, separation theory, additive models,
measure theory, optimization
$This work was partly supported by the research



hal_id    :    hal-01502252



Locally stationary Hawkes processes have been introduced in order to generalise clas-
sical Hawkes processes away from stationarity by allowing for a time-varying second-order
structure. This class of self-exciting point processes has recently attracted a lot of inter-
est in applications in the life sciences (seismology, genomics, neuro-science,...), but also
in the modeling of high-frequency ﬁnancial data. In this contribution we provide a fully
developed nonparametric estimation theory of both local mean density and local Bartlett
spectra of a locally stationary Hawkes process. In particular we apply our kernel estima-
tion of the spectrum localised both in time and frequency to two data sets of transaction
times revealing pertinent features in the data that had not been made visible by classical
non-localised approaches based on models with constant fertility functions over time.
Keywords: Time frequency analysis; Locally stationary time series; high frequency ﬁ-
nancial data; Non-parametric kernel estimation; Self-exciting point processes.
1



hal_id    :    hal-01497104



This paper introduces a randomized coordinate descent version of the V˜u-Condat algorithm.
By
coordinate descent, we mean that only a subset of the coordinates of the primal and dual iterates is
updated at each iteration, the other coordinates being maintained to their past value.
Our method
allows us to solve optimization problems with a combination of diﬀerentiable functions, constraints as
well as non-separable and non-diﬀerentiable regularizers.
We show that the sequences generated by our algorithm almost surely converge to a saddle point
of the problem at stake, for a wider range of parameter values than previous methods. In particular,
the condition on the step-sizes depends on the coordinate-wise Lipschitz constant of the diﬀerentiable
function’s gradient, which is a major feature allowing classical coordinate descent to perform so well when
it is applicable. We then prove a sublinear rate of convergence in general and a linear rate of convergence
if the objective enjoys strong convexity properties.
We illustrate the performances of the algorithm on a total-variation regularized least squares regression
problem and on large scale support vector machine problems.
1



hal_id    :    hal-02369435



For the purpose of monitoring the behavior of complex infrastructures (e.g.
aircrafts,
transport or energy networks), high-rate sensors are deployed to capture multivariate data,
generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anoma-
lies that may jeopardize the smooth operation of the system of interest. The statistical
analysis of such massive data of functional nature raises many challenging methodological
questions. The primary goal of this paper is to extend the popular Isolation Forest (IF)
approach to Anomaly Detection, originally dedicated to ﬁnite dimensional observations, to
functional data. The major diﬃculty lies in the wide variety of topological structures that
may equip a space of functions and the great variety of patterns that may characterize
abnormal curves.
We address the issue of (randomly) splitting the functional space in
a ﬂexible manner in order to isolate progressively any trajectory from the others, a key
ingredient to the eﬃciency of the algorithm. Beyond a detailed description of the algo-
rithm, computational complexity and stability issues are investigated at length. From the
scoring function measuring the degree of abnormality of an observation provided by the
proposed variant of the IF algorithm, a Functional Statistical Depth function is deﬁned and
discussed, as well as a multivariate functional extension. Numerical experiments provide
strong empirical evidence of the accuracy of the extension



hal_id    :    hal-02420416



In this paper, we address how to evaluate and improve the perfor-
mance of automatic dominant melody extraction systems from a
pattern mining perspective with a focus on jazz improvisations.
Traditionally, dominant melody extraction systems estimate the
melody on the frame-level, but for real-world musicological appli-
cations note-level representations are needed. For the evaluation of
estimated note tracks, the current frame-wise metrics are not fully
suitable and provide at most a first approximation. Furthermore,
mining melodic patterns (n-grams) poses another challenge because
note-wise errors propagate geometrically with increasing length of
the pattern. On the other hand, for certain derived metrics such as
pattern commonalities between performers, extraction errors might
be less critical if at least qualitative rankings can be reproduced.
Finally, while searching for similar patterns in a melody database
the number of irrelevant patterns in the result set increases with
lower similarity thresholds. For reasons of usability, it would be in-
teresting to know the behavior using imperfect automated melody
extractions. We propose three novel evaluation strategies for es-
timated note-tracks based on three application scenarios: Pattern
mining, pattern commonalities, and fuzzy pattern search. We apply
the proposed metrics to one general state-of-the-art melody esti-
mation method (Melodia) and to two variants of an algorithm that
was optimized for the extraction of jazz solos melodies. A subset of
the Weimar Jazz Database



hal_id    :    hal-02943462



In the last few years, several datasets have been released
to meet the requirements of “hungry” yet promising data-
driven approaches in music technology research. Since,
for historical reasons, most investigations conducted in the
ﬁeld still revolve around music of the so-called “West-
ern” tradition, the corresponding data, methodology and
conclusions carry a strong cultural bias. Music of non-
“Western” background, whenever present, is usually un-
derrepresented, poorly labeled, or even mislabeled, the
exception being projects that aim at speciﬁcally describ-
ing such music. In this paper we present SAMBASET,
a dataset of Brazilian samba music that contains over
40 hours of historical and modern samba de enredo com-
mercial recordings. To the best of our knowledge, this is
the ﬁrst dataset of this genre. We describe the collection of
metadata (e.g. artist, composer, release date) and outline
our semiautomatic approach to the challenging task of an-
notating beats in this large dataset, which includes the as-
sessment of the performance of state-of-the-art beat track-
ing algorithms for this speciﬁc case. Finally, we present
a study on tempo and beat tracking that illustrates SAM-
BASET’s value, and we comment on other tasks for which
it could be used.



hal_id    :    hal-02166428



. The development of cluster computing frameworks has al-
lowed practitioners to scale out various statistical estimation and ma-
chine learning algorithms with minimal programming eﬀort. This is es-
pecially true for machine learning problems whose objective function
is nicely separable across individual data points, such as classiﬁcation
and regression. In contrast, statistical learning tasks involving pairs (or
more generally tuples) of data points — such as metric learning, clus-
tering or ranking — do not lend themselves as easily to data-parallelism
and in-memory computing. In this paper, we investigate how to bal-
ance between statistical performance and computational eﬃciency in
such distributed tuplewise statistical problems. We ﬁrst propose a sim-
ple strategy based on occasionally repartitioning data across workers
between parallel computation stages, where the number of repartition-
ing steps rules the trade-oﬀbetween accuracy and runtime. We then
present some theoretical results highlighting the beneﬁts brought by the
proposed method in terms of variance reduction, and extend our results
to design distributed stochastic gradient descent algorithms for tuplewise
empirical risk minimization. Our results are supported by numerical ex-
periments in pairwise statistical estimation and learning on synthetic and
real-world datasets.
Keywords: Distributed Machine Learning · Distributed Data Process-
ing · U-Statistics · Stochastic Gradient Descent · AUC Optimization
1



hal_id    :    hal-02288063



—We propose a semi-supervised multichannel speech
enhancement system based on a probabilistic model which as-
sumes that both speech and noise follow the heavy-tailed multi-
variate complex Cauchy distribution. As we advocate, this allows
handling strong and adverse noisy conditions. Consequently, the
model is parameterized by the source magnitude spectrograms
and the source spatial scatter matrices. To deal with the non-
additivity of scatter matrices, our ﬁrst contribution is to perform
the enhancement on a projected space. Then, our second contri-
bution is to combine a latent variable model for speech, which
is trained by following the variational autoencoder framework,
with a low-rank model for the noise source. At test time, an it-
erative inference algorithm is applied, which produces estimated
parameters to use for separation. The speech latent variables are
estimated ﬁrst from the noisy speech and then updated by a gra-
dient descent method, while a majorization-equalization strategy
is used to update both the noise and the spatial parameters of
both sources. Our experimental results show that the Cauchy
model outperforms the state-of-art methods. The standard devi-
ation scores also reveal that the proposed method is more robust
against non-stationary noise.
Index Terms—Multichannel speech enhancement, multivariate
complex Cauchy distribution, variational autoencoder, nonnega-
tive matrix factorization



hal_id    :    hal-01900037



Popular machine learning estimators involve
regularization parameters that can be chal-
lenging to tune, and standard strategies rely
on grid search for this task. In this paper,
we revisit the techniques of approximating
the regularization path up to predeﬁned tol-
erance ϵ in a uniﬁed framework and show
that its complexity is O(1/ d√ϵ) for uniformly
convex loss of order d > 0 and O(1/√ϵ)
for Generalized Self-Concordant functions.
This framework encompasses least-squares
but also logistic regression (a case that as far
as we know was not handled as precisely by
previous works). We leverage our technique
to provide reﬁned bounds on the validation
error as well as a practical algorithm for hy-
perparameter tuning.
The later has global
convergence guarantee when targeting a pre-
scribed accuracy on the validation set. Last
but not least, our approach helps relieving
the practitioner from the (often neglected)
task of selecting a stopping criterion when
optimizing over the training set: our method
automatically calibrates it based on the tar-
geted accuracy on the validation set.
1



hal_id    :    hal-02303823



No abstract found in the PDF.



hal_id    :    hal-02912385



Noise-Contrastive Estimation (NCE) is a learning criterion that is regularly used to train neural
language models in place of Maximum Likelihood Estimation, since it avoids the computational
bottleneck caused by the output softmax. In this paper, we analyse and explain some of the
weaknesses of this objective function, linked to the mechanism of self-normalization, by closely
monitoring comparative experiments. We then explore several remedies and modiﬁcations to
propose tractable and efﬁcient NCE training strategies. In particular, we propose to make the
scaling factor a trainable parameter of the model, and to use the noise distribution to initialize the
output bias. These solutions, yet simple, yield stable and competitive performances in either small
and large scale language modelling tasks.
1



hal_id    :    lirmm-01766795



. This paper introduces a new method for multichannel speech
enhancement based on a versatile modeling of the residual noise spec-
trogram. Such a model has already been presented before in the single
channel case where the noise component is assumed to follow an alpha-
stable distribution for each time-frequency bin, whereas the speech spec-
trogram, supposed to be more regular, is modeled as Gaussian. In this
paper, we describe a multichannel extension of this model, as well as
a Monte Carlo Expectation - Maximisation algorithm for parameter es-
timation. In particular, a multichannel extension of the Itakura-Saito
nonnegative matrix factorization is exploited to estimate the spectral
parameters for speech, and a Metropolis-Hastings algorithm is proposed
to estimate the noise contribution. We evaluate the proposed method in
a challenging multichannel denoising application and compare it to other
state-of-the-art algorithms.
1



hal_id    :    hal-02912471



L’estimation contrastive bruitée (NCE) et l’échantillonage par importance (IS) sont des procédures
d’entraînement basées sur l’échantillonage, que l’on utilise habituellement à la place de l’estimation
du maximum de vraisemblance (MLE) pour éviter le calcul du softmax lorsque l’on entraîne des
modèles de langue neuronaux. Dans cet article, nous cherchons à résumer le fonctionnement de ces
algorithmes, et leur utilisation dans la littérature du TAL. Nous les comparons expérimentalement, et
présentons des manières de faciliter l’entraînement du NCE.
ABSTRACT
Here the title in English.
Noise Contrastive Estimation (NCE) and Importance Sampling (IS) are sampling based algorithms
traditionally used to avoid computing the costly output softmax when training neural language models
with Maximum Likelihood Estimation (MLE). In this work, we attempt to summarize how these
procedures work, and how they have been used in the computational linguistics literature. We then
compare them, and experiment with tricks that ease NCE training.
MOTS-CLÉS : Modèle de langue, Estimation contrastive bruitée, Negative Sampling.
KEYWORDS: Neural Language Model, Noise Contrastive Estimation, Negative Sampling.



hal_id    :    hal-01812011



In high dimension, it is customary to consider
Lasso-type estimators to enforce sparsity. For
standard Lasso theory to hold, the regulariza-
tion parameter should be proportional to the
noise level, which is often unknown in prac-
tice. A remedy is to consider estimators such
as the Concomitant Lasso, which jointly opti-
mize over the regression coeﬃcients and the
noise level. However, when data from diﬀer-
ent sources are pooled to increase sample size,
noise levels diﬀer and new dedicated estima-
tors are needed. We provide new statistical
and computational solutions to perform het-
eroscedastic regression, with an emphasis on
brain imaging with magneto- and electroen-
cephalography (M/EEG). When instantiated
to de-correlated noise, our framework leads to
an eﬃcient algorithm whose computational
cost is not higher than for the Lasso, but ad-
dresses more complex noise structures. Ex-
periments demonstrate improved prediction
and support identiﬁcation with correct esti-
mation of noise levels.
1



hal_id    :    hal-01269137



. In this contribution we introduce weakly locally stationary time series through
the local approximation of the non-stationary covariance structure by a stationary one.
This allows us to deﬁne autoregression coeﬃcients in a non-stationary context, which, in
the particular case of a locally stationary Time Varying Autoregressive (TVAR) process,
coincide with the generating coeﬃcients. We provide and study an estimator of the time
varying autoregression coeﬃcients in a general setting. The proposed estimator of these
coeﬃcients enjoys an optimal minimax convergence rate under limited smoothness condi-
tions. In a second step, using a bias reduction technique, we derive a minimax-rate estima-
tor for arbitrarily smooth time-evolving coeﬃcients, which outperforms the previous one
for large data sets. In turn, for TVAR processes, the predictor derived from the estimator
exhibits an optimal minimax prediction rate.



hal_id    :    hal-01679078



We address the issue of reliably detecting and quantifying cross-frequency coupling (CFC)
in neural time series. Based on non-linear auto-regressive models, the proposed method
provides a generative and parametric model of the time-varying spectral content of the
signals. As this method models the entire spectrum simultaneously, it avoids the pitfalls
related to incorrect filtering or the use of the Hilbert transform on wide-band signals. As the
model is probabilistic, it also provides a score of the model “goodness of fit” via the likeli-
hood, enabling easy and legitimate model selection and parameter comparison; this data-
driven feature is unique to our model-based approach. Using three datasets obtained with
invasive neurophysiological recordings in humans and rodents, we demonstrate that these
models are able to replicate previous results obtained with other metrics, but also reveal
new insights such as the influence of the amplitude of the slow oscillation. Using simulations,
we demonstrate that our parametric method can reveal neural couplings with shorter signals
than non-parametric methods. We also show how the likelihood can be used to find optimal
filtering parameters, suggesting new properties on the spectrum of the driving signal, but
also to estimate the optimal delay between the coupled signals, enabling a directionality esti-
mation in the coupling.
Author summary
Neural oscillations synchronize information across brain areas at



hal_id    :    hal-01404966



No abstract found in the PDF.



hal_id    :    hal-01593459



Leveraging the celebrated support vector regression (SVR) method, we propose a unifying
framework in order to deliver regression machines in reproducing kernel Hilbert spaces
(RKHSs) with data sparsity. The central point is a new deﬁnition of ϵ-insensitivity, valid for
many regression losses (including quantile and expectile regression) and their multivariate
extensions. We show that the dual optimization problem to empirical risk minimization
with ϵ-insensitivity involves a data sparse regularization. We also provide an analysis of
the excess of risk as well as a randomized coordinate descent algorithm for solving the dual.
Numerical experiments validate our approach.
Keywords: Quantile regression, Expectile regression, Operator-valued kernel.



hal_id    :    hal-01548475



While most dereverberation methods focus on how to estimate the
magnitude of an anechoic signal in the time-frequency domain, we
propose a method which also takes the phase into account. By ap-
plying a harmonic model to the anechoic signal, we derive a formu-
lation to compute the amplitude and phase of each harmonic. These
parameters are then estimated by our method in presence of rever-
beration. As we jointly estimate the amplitude and phase of the
clean signal, we achieve a very strong dereverberation on synthetic
harmonic signals, resulting in a signiﬁcant improvement of standard
dereverberation objective measures over the state-of-the-art.
Index Terms— dereverberation, phase, sinusoidal modeling,



hal_id    :    hal-01548508



This paper introduces a new method for single-channel denoising
that sheds new light on classical early developments on this topic
that occurred in the 70’s and 80’s with Wiener ﬁltering and spectral
subtraction. Operating both in the short-time Fourier transform
domain, these methods consist in estimating the power spectral
density (PSD) of the noise without speech. Then, the clean speech
signal is obtained by manipulating the corrupted time-frequency
bins thanks to these noise PSD estimates. Theoretically grounded
when using power spectra, these methods were subsequently gener-
alized to magnitude spectra, or shown to yield better performance
by weighting the PSDs in the so-called parameterized Wiener ﬁlter.
Both these strategies were long considered ad-hoc. To the best
of our knowledge, while we recently proposed an interpretation
of magnitude processing, there is still no theoretical result that
would justify the better performance of parameterized Wiener
ﬁlters. Here, we show how the α-stable probabilistic model for
waveforms naturally leads to these weighted ﬁlters and we provide
a grounded and fast algorithm to enhance corrupted audio that
compares favorably with classical denoising methods.
Index Terms—denoising, Wiener ﬁltering, α-stable processes, prob-
ability theory



hal_id    :    hal-01531259



—While most dereverberation methods focus on how
to estimate the amplitude of an anechoic signal, we propose a
method which also takes the phase into account. By applying a
sinusoidal model to the anechoic signal, we derive a formulation
to compute the amplitude and phase of each sinusoid. These
parameters are then estimated by our method in the reverberant
case. As we jointly estimate the amplitude and phase of the clean
signal, we achieve a very strong dereverberation, resulting in a
signiﬁcant improvement of objective dereverberation measures
over the state-of-the-art.



hal_id    :    hal-01531252



In this paper, we focus on the problem of sound source localization
and we propose a technique that exploits the known and arbitrary
geometry of the microphone array. While most probabilistic tech-
niques presented in the past rely on Gaussian models, we go further
in this direction and detail a method for source localization that is
based on the recently proposed α-stable harmonizable processes.
They include Cauchy and Gaussian as special cases and their
remarkable feature is to allow a simple modeling of impulsive
and real world sounds with few parameters. The approach we
present builds on the classical convolutive mixing model and has
the particularities of requiring going through the data only once,
to also work in the underdetermined case of more sources than
microphones and to allow massively parallelizable implementations
operating in the time-frequency domain. We show that the method
yields interesting performance for acoustic imaging in realistic
simulations.
Index Terms—source localization, acoustic modeling, α-
stable random variables, spectral measure, sketching



hal_id    :    hal-02912472



Cet article propose une architecture neuronale pour un modèle de langue à vocabulaire ouvert. Les
représentations continues des mots sont calculées à la volée à partir des caractères les composant,
gràce à une couche convolutionnelle suivie d’une couche de regroupement (pooling). Cela permet
au modèle de représenter n’importe quel mot, qu’il fasse partie du contexte ou soit évalué pour la
prédiction. La fonction objectif est dérivée de l’estimation contrastive bruitée (Noise Contrastive
Estimation, ou NCE), calculable dans notre cas sans vocabulaire. Nous évaluons la capacité de
notre modèle à construire des représentations continues de mots inconnus sur la tâche de traduction
automatique IWSLT-2016, de l’Anglais vers le Tchèque, en ré-évaluant les N meilleures hypothèses
(N-best reranking). Les résultats expérimentaux permettent des gains jusqu’à 0,7 point BLEU. Ils
montrent aussi la difﬁculté d’utiliser des représentations dérivées des caractères pour la prédiction.
ABSTRACT
Opening the vocabulary of neural language models with character-level word representations
This paper introduces an architecture for an open-vocabulary neural language model. Word represen-
tations are computed on-the-ﬂy by a convolution network followed by pooling layer. This allows the
model to consider any word, in the context or for the prediction. The training objective is derived from
the Noise-Contrastive Estimation to adapt it the open vocabulary case. We test the ability of our model
to



hal_id    :    hal-02395677



- Parkinson’s disease (PD) is a neurological disorder associated 
with a progressive decline in motor skills, speech, and cognitive processes. 
Since the diagnosis of Parkinson’s disease is difficult, researchers have 
worked to develop a support tool based on algorithms to differentiate 
healthy controls from PD patients. Online handwriting analysis is one of 
the methods that can be used to diagnose PD. The aim of this study is to 
find a subset of handwriting features suitable for efficiently identifying 
subjects with PD. Data was taken from PDMultiMC database collected in 
Lebanon, and consisting of 16 medicated PD patients and 16 age matched 
controls. Seven handwriting tasks were collected such as copying patterns, 
copying words in Arabic, and writing full names. For each task kinematic 
and spatio-temporal, pressure, energy, entropy, and intrinsic features were 
extracted. Feature selection was done in two stages, the first stage selected 
a subset using statistical analysis, and the second step select the most 
relevant features of this subset, by a suboptimal approach. The selected 
features were fed to a support vector machine classifier with RBF kernel, 
whose aim is to identify the subjects suffering from PD. The accuracy of 
the classification of PD was as high as



hal_id    :    hal-02912384



Noise Contrastive Estimation (NCE) is a
learning procedure that is regularly used
to train neural language models, since
it avoids the computational bottleneck
caused by the output softmax. In this pa-
per, we attempt to explain some of the
weaknesses of this objective function, and
to draw directions for further develop-
ments. Experiments on a small task show
the issues raised by the unigram noise
distribution, and that a context dependent
noise distribution, such as the bigram dis-
tribution, can solve these issues and pro-
vide stable and data-efﬁcient learning.
1



hal_id    :    hal-01401988



. We propose a probabilistic model for acoustic source local-
ization with known but arbitrary geometry of the microphone array. The
approach has several features. First, it relies on a simple nearﬁeld acous-
tic model for wave propagation. Second, it does not require the number
of active sources. On the contrary, it produces a heat map representing
the energy of a large set of candidate locations, thus imaging the acous-
tic ﬁeld. Second, it relies on a heavy-tail α-stable probabilistic model,
whose most important feature is to yield an estimation strategy where
the multichannel signals need to be processed only once in a simple on-
line procedure, called sketching. This sketching produces a ﬁxed-sized
representation of the data that is then analyzed for localization. The
resulting algorithm has a small computational complexity and in this
paper, we demonstrate that it compares favorably with state of the art
for localization in realistic simulations of reverberant environments.
1



hal_id    :    hal-01272327



Addressing the will to give a more complete picture than an average relationship provided
by standard regression, a novel framework for estimating and predicting simultaneously several
conditional quantiles is introduced. The proposed methodology leverages kernel-based multi-task
learning to curb the embarrassing phenomenon of quantile crossing, with a one-step estimation
procedure and no post-processing. Moreover, this framework comes along with theoretical guaran-
tees and an eﬃcient coordinate descent learning algorithm. Numerical experiments on benchmark
and real datasets highlight the enhancements of our approach regarding the prediction error, the
crossing occurrences and the training time.
1



hal_id    :    hal-01337860



Most dereverberation methods aim to reconstruct the ane-
choic magnitude spectrogram, given a reverberant signal.
Regardless of the method, the dereverberated signal is sys-
tematically synthesized with the reverberant phase.
This
corrupted phase reintroduces reverberation and distortion in
the signal. This is why we intend to also reconstruct the ane-
choic phase, given a reverberant signal. Before processing
speech signals, we propose in this paper a method for esti-
mating the anechoic phase of reverberant chirp signals. Our
method presents an accurate estimation of the instantaneous
phase and improves objective measures of dereverberation.
Index Terms— Dereverberation, phase, reassignment, si-
nusoidal modeling.



hal_id    :    hal-01418963



We propose an efﬁcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in
presence of pileup from a sample of low-frequency observa-
tions. Based on a functional equation linking the marks’ den-
sity to the characteristic function of the observations and its
derivative, we propose a new time-efﬁcient method using B-
splines to estimate the density of the underlying γ-ray spec-
trum which is able to handle large datasets used in nuclear
physics. A discussion on the numerical computation of the al-
gorithm and its performances on simulated data are provided
to support our ﬁndings.
Index Terms— Shot-noise, nonparametric estimation, B-
splines, γ-spectroscopy, pile-up correction



hal_id    :    hal-01347167



We propose a method that performs anomaly
detection and localisation within heterogeneous
data using a pairwise undirected mixed graphical
model. The data are a mixture of categorical and
quantitative variables, and the model is learned
over a dataset that is supposed not to contain any
anomaly. We then use the model over temporal
data, potentially a data stream, using a version of
the two-sided CUSUM algorithm. The proposed
decision statistic is based on a conditional likeli-
hood ratio computed for each variable given the
others. Our results show that this function allows
to detect anomalies variable by variable, and thus
to localise the variables involved in the anomalies
more precisely than univariate methods based on
simple marginals.



hal_id    :    hal-02287434



. In this paper, we propose an eﬃcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in presence of pileup from a
sample of low-frequency observations. Based on a functional equation linking the marks’
density to the characteristic function of the observations and its derivative, we propose a
new time-eﬃcient method using B-splines to estimate the density of the underlying γ-ray
spectrum, which is able to handle large datasets used in nuclear physics. A discussion on
the numerical computation of the algorithm and its performances on simulated data are
provided to support our ﬁndings.
Keywords. Shot-noise, B-splines, inverse problem, γ spectrometry



hal_id    :    hal-01248010



Room acoustic parameters are key information for dereverberation or speech recognition. Usually, when
one needs to assess the level of reverberation, only the reverberation time RT60 or a direct to reverberant
sounds index Dτ is estimated. Yet, methods which blindly estimate the reverberation time from reverberant
recorded speech do not always diﬀerentiate the RT60 from the Dτ to evaluate the level of reverberation. That
is why we propose a method to jointly blindly estimate these parameters, from the signal energy decay rate
distribution, by means of kernel regression. Evaluation is carried out with real and simulated room impulse
responses to generate noise-free reverberant speech signals. The results show this new method outperforms
baseline approaches in our evaluation.
1.



hal_id    :    hal-01153882



This paper addresses the generalisation of stationary Hawkes processes in order to allow
for a time-evolving second-order analysis.
Motivated by the concept of locally stationary
autoregressive processes, we apply however inherently diﬀerent techniques to describe the
time-varying dynamics of self-exciting point processes. In particular we derive a stationary
approximation of the Laplace transform of a locally stationary Hawkes process. This allows
us to deﬁne a local intensity function and a local Bartlett spectrum which can be used to
compute approximations of ﬁrst and second order moments of the process. We complete the
paper by some insightful simulation studies.
Keywords:
Locally stationary processes, Hawkes processes, Bartlett spectrum, time
frequency analysis, point processes
2000 MSC: 60G55, 62M15, 46N30



hal_id    :    hal-01080955



. This paper deals with a parametrized family of partially
observed bivariate Markov chains. We establish that, under very mild
assumptions, the limit of the normalized log-likelihood function is max-
imized when the parameters belong to the equivalence class of the true
parameter, which is a key feature for obtaining the consistency of the
maximum likelihood estimators (MLEs) in well-speciﬁed models. This
result is obtained in the general framework of partially dominated mod-
els. We examine two speciﬁc cases of interest, namely, hidden Markov
models (HMMs) and observation-driven time series models. In contrast
with previous approaches, the identiﬁability is addressed by relying on
the uniqueness of the invariant distribution of the Markov chain asso-
ciated to the complete data, regardless its rate of convergence to the
equilibrium.



hal_id    :    hal-01078073



This paper generalizes asymptotic properties obtained in the
observation-driven times series models considered by [7] in the sense
that the conditional law of each observation is also permitted to depend
on the parameter. The existence of ergodic solutions and the consis-
tency of the Maximum Likelihood Estimator (MLE) are derived under
easy-to-check conditions. The obtained conditions appear to apply for a
wide class of models. We illustrate our results with speciﬁc observation-
driven times series, including the recently introduced NBIN-GARCH
and NM-GARCH models, demonstrating the consistency of the MLE
for these two models.
MSC: Primary: 62F12; Secondary: 60J05.
Keywords: consistency, ergodicity, maximum likelihood, observation-driven
models, time series of counts.
1



hal_id    :    hal-01030799



. Consider a non–linear function G(Xt) where Xt is a stationary Gaussian se-
quence with long–range dependence. The usual reduction principle states that the partial
sums of G(Xt) behave asymptotically like the partial sums of the ﬁrst term in the expansion
of G in Hermite polynomials. In the context of the wavelet estimation of the long–range
dependence parameter, one replaces the partial sums of G(Xt) by the wavelet scalogram,
namely the partial sum of squares of the wavelet coeﬃcients. Is there a reduction principle
in the wavelet setting, namely is the asymptotic behavior of the scalogram for G(Xt) the
same as that for the ﬁrst term in the expansion of G in Hermite polynomial? The answer
is negative in general. This paper provides a minimal growth condition on the scales of the
wavelet coeﬃcients which ensures that the reduction principle also holds for the scalogram.
The results are applied to testing the hypothesis that the long-range dependence parameter
takes a speciﬁc value.
Contents
1.



hal_id    :    hal-01164121



In this paper, we consider a nonlinear inverse problem occuring in nu-
clear science. Gamma rays randomly hit a semiconductor detector which
produces an impulse response of electric current. Because the sampling
period of the measured current is larger than the mean interarrival time
of photons, the impulse responses associated to diﬀerent gamma rays can
overlap: this phenomenon is known as pileup.
In this work, it is as-
sumed that the impulse response is an exponentially decaying function.
We propose a novel method to infer the distribution of gamma photon en-
ergies from the indirect measurements obtained from the detector. This
technique is based on a formula linking the characteristic function of the
photon density to a function involving the characteristic function and its
derivative of the observations. We establish that our estimator converges
to the mark density in uniform norm at a polynomial rate.
A limited
Monte-Carlo experiment is provided to support our ﬁndings.
1



hal_id    :    hal-00984064



In this work, we study the problem of aggregating a ﬁnite number of predic-
tors for non stationary sub-linear processes. We provide oracle inequalities relying
essentially on three ingredients: 1) a uniform bound of the ℓ1 norm of the time-
varying sub-linear coeﬃcients, 2) a Lipschitz assumption on the predictors and
3) moment conditions on the noise appearing in the linear representation. Two
kinds of aggregations are considered giving rise to diﬀerent moment conditions
on the noise and more or less sharp oracle inequalities. We apply this approach
for deriving an adaptive predictor for locally stationary time varying autoregres-
sive (TVAR) processes.
It is obtained by aggregating a ﬁnite number of well
chosen predictors, each of them enjoying an optimal minimax convergence rate
under speciﬁc smoothness conditions on the TVAR coeﬃcients. We show that
the obtained aggregated predictor achieves a minimax rate while adapting to the
unknown smoothness. To prove this result, a lower bound is established for the
minimax rate of the prediction risk for the TVAR process. Numerical experiments
complete this study. An important feature of this approach is that the aggregated
predictor can be computed recursively and is thus applicable in an online predic-
tion context.
1



hal_id    :    hal-00755255



We study the convergence of centered and normalized sums of i.i.d. random elements
of the space D of c`adl`ag functions endowed with Skorohod’s J1 topology, to stable distri-
butions in D. Our results are based on the concept of regular variation on metric spaces
and on point process convergence. We provide some applications, in particular to the
empirical process of the renewal-reward process.
1



hal_id    :    hal-02437193



– We propose an eﬃcient method to estimate in a nonparametric fashion the marks’ density of a shot-noise process
subject to a high pile-up eﬀect. Based on a formula linking the characteristic function of the mark density to a function involving
the shot-noise characteristic function and its derivative, we construct a “plug-in” estimator which converges to the mark density
in uniform norm at a logarithmic speed. Two limited Monte-Carlo experiments are provided to support our ﬁndings.
1



hal_id    :    hal-01167391



An important challenge in the aeronautic industry is to cope with maintenance issues of the prod-
ucts, notably detection and localization of components breakdowns. Modern equipments enjoy better
recording and processing capacities, allowing the storage of a large amount of data, on which better
maintenance systems are expected to be built. Eﬃcient probabilistic models able to represent the
statistic distribution of the collected variables in the “normal state” of the system are needed in order
to derive anomaly detection algorithms. Graphical models constitute a rich class of models and are
natural candidates to address this task. This article proposes a method for learning undirected hy-
brid graphical models from heterogeneous data. The data are heterogeneous as they include physical
(quantitative) measures as well as a collection of inherently discrete variables for instance describing
the state of electronic devices. The model we propose is adapted from the Ising and Gaussian models
so that the data don’t require to be translated from their original space, allowing the user to easily
interpret the dependency graph learned from data. The learning step is carried out by minimizing
the negative pseudo-log-likelihood using a proximal gradient algorithm with Lasso and group Lasso
penalization for addressing the high dimension of variables. Once the model is learned, we use the
penalized negative



hal_id    :    hal-04762097



We introduce Annealed Multiple Choice Learning (aMCL) which combines simu-
lated annealing with MCL. MCL is a learning framework handling ambiguous tasks
by predicting a small set of plausible hypotheses. These hypotheses are trained
using the Winner-takes-all (WTA) scheme, which promotes the diversity of the
predictions. However, this scheme may converge toward an arbitrarily suboptimal
local minimum, due to the greedy nature of WTA. We overcome this limitation
using annealing, which enhances the exploration of the hypothesis space during
training. We leverage insights from statistical physics and information theory
to provide a detailed description of the model training trajectory. Additionally,
we validate our algorithm by extensive experiments on synthetic datasets, on the
standard UCI benchmark, and on speech separation.
1



hal_id    :    hal-04736454



—This paper describes speech enhancement for real-
time automatic speech recognition (ASR) in real environments.
A standard approach to this task is to use neural beamforming
that can work efficiently in an online manner. It estimates the
masks of clean dry speech from a noisy echoic mixture spectro-
gram with a deep neural network (DNN) and then computes a
enhancement filter used for beamforming. The performance of
such a supervised approach, however, is drastically degraded un-
der mismatched conditions. This calls for run-time adaptation
of the DNN. Although the ground-truth speech spectrogram re-
quired for adaptation is not available at run time, blind dere-
verberation and separation methods such as weighted prediction
error (WPE) and fast multichannel nonnegative matrix factor-
ization (FastMNMF) can be used for generating pseudo ground-
truth data from a mixture. Based on this idea, a prior work pro-
posed a dual-process system based on a cascade of WPE and
minimum variance distortionless response (MVDR) beamform-
ing asynchronously fine-tuned by block-online FastMNMF. To in-
tegrate the dereverberation capability into neural beamforming
and make it fine-tunable at run time, we propose to use weighted
power minimization distortionless response (WPD) beamforming,
a unified version of WPE and minimum power distortionless re-
sponse (MPDR), whose joint dereverberation and denoising filter
is estimated using a DNN. We evaluated the impact of run-time
adaptation under various



hal_id    :    hal-04768296



In this paper, we propose a novel Self-Supervised-
Learning scheme to train rhythm analysis systems and
instantiate it for few-shot beat tracking.
Taking inspi-
ration from the Contrastive Predictive Coding paradigm,
we propose to train a Log-Mel-Spectrogram-Transformer-
encoder to contrast observations at times separated by hy-
pothesized beat intervals from those that are not. We do
this without the knowledge of ground-truth tempo or beat
positions, as we rely on the local maxima of a Predomi-
nant Local Pulse function, considered as a proxy for Tatum
positions, to define candidate anchors, candidate positives
(located at a distance of a power of two from the anchor)
and negatives (remaining time positions). We show that
a model pre-trained using this approach on the unlabeled
FMA, MTT and MTG-Jamendo datasets can successfully
be fine-tuned in the few-shot regime, i.e. with just a few
annotated examples to get a competitive beat-tracking per-
formance.
1



hal_id    :    hal-04665063



The task of music structure analysis has been mostly
addressed as a sequential problem, by relying on the inter-
nal homogeneity of musical sections or their repetitions.
In this work, we instead regard it as a pairwise link pre-
diction task. If for any pair of time instants in a track, one
can successfully predict whether they belong to the same
structural entity or not, then the underlying structure can
be easily recovered. Building upon this assumption, we
propose a method that first learns to classify pairwise links
between time frames as belonging to the same section (or
segment) or not. The resulting link features, along with
node-specific information, are combined through a graph
attention network. The latter is regularized with a graph
partitioning training objective and outputs boundary loca-
tions between musical segments and section labels. The
overall system is lightweight and performs competitively
with previous methods.
The evaluation is done on two
standard datasets for music structure analysis and an ab-
lation study is conducted in order to gain insight on the
role played by its different components.



hal_id    :    hal-04695595



Machine listening systems often rely on fixed taxonomies to or-
ganize and label audio data, key for training and evaluating deep
neural networks (DNNs) and other supervised algorithms. How-
ever, such taxonomies face significant constraints: they are com-
posed of application-dependent predefined categories, which hin-
ders the integration of new or varied sounds, and exhibits limited
cross-dataset compatibility due to inconsistent labeling standards.
To overcome these limitations, we introduce SALT: Standardized
Audio event Label Taxonomy. Building upon the hierarchical struc-
ture of AudioSet’s ontology, our taxonomy extends and standardizes
labels across 24 publicly available environmental sound datasets, al-
lowing the mapping of class labels from diverse datasets to a unified
system. Our proposal comes with a new Python package designed
for navigating and utilizing this taxonomy, easing cross-dataset la-
bel searching and hierarchical exploration. Notably, our package
allows effortless data aggregation from diverse sources, hence easy
experimentation with combined datasets.
Index Terms— Machine listening, DCASE, sound taxonomy,
sound categorization, data aggregation



hal_id    :    hal-04701759



Audio-text models trained via contrastive learning offer a practical
approach to perform audio classiﬁcation through natural language
prompts, such as “this is a sound of” followed by category names. In
this work, we explore alternative prompt templates for zero-shot au-
dio classiﬁcation, demonstrating the existence of higher-performing
options. First, we ﬁnd that the formatting of the prompts signif-
icantly affects performance so that simply prompting the models
with properly formatted class labels performs competitively with
optimized prompt templates and even prompt ensembling. More-
over, we look into complementing class labels by audio-centric de-
scriptions. By leveraging large language models, we generate tex-
tual descriptions that prioritize acoustic features of sound events
to disambiguate between classes, without extensive prompt engi-
neering. We show that prompting with class descriptions leads to
state-of-the-art results in zero-shot audio classiﬁcation across ma-
jor ambient sound datasets. Remarkably, this method requires no
additional training and remains fully zero-shot.
Index Terms— Zero-shot audio classiﬁcation, audio-text mod-
els, contrastive language-audio pretraining, in-context learning



hal_id    :    hal-04720291



The Prototypical Network (ProtoNet) has emerged as a popular
choice in Few-shot Learning (FSL) scenarios due to its remark-
able performance and straightforward implementation.
Building
upon such success, we first propose a simple (yet novel) method
to fine-tune a ProtoNet on the (labeled) support set of the test
episode of a C-way-K-shot test episode (without using the query
set which is only used for evaluation). We then propose an algo-
rithmic framework that combines ProtoNet with optimization-based
FSL algorithms (MAML and Meta-Curvature) to work with such
a fine-tuning method. Since optimization-based algorithms endow
the target learner model with the ability to fast adaption to only a
few samples, we utilize ProtoNet as the target model to enhance
its fine-tuning performance with the help of a specifically designed
episodic fine-tuning strategy. The experimental results confirm that
our proposed models, MAML-Proto and MC-Proto, combined with
our unique fine-tuning method, outperform regular ProtoNet by a
large margin in few-shot audio classification tasks on the ESC-50
and Speech Commands v2 datasets. We note that although we have
only applied our model to the audio domain, it is a general method
and can be easily extended to other domains.
Index Terms— Few-shot learning, Audio classification, Proto-
typical Network, Model-Agnostic Meta-Learning, Meta-Curvature



hal_id    :    hal-04685184



As diffusion-based deep generative models gain prevalence, re-
searchers are actively investigating their potential applications
across various domains, including music synthesis and style al-
teration. Within this work, we are interested in timbre transfer, a
process that involves seamlessly altering the instrumental character-
istics of musical pieces while preserving essential musical elements.
This paper introduces WaveTransfer, an end-to-end diffusion model
designed for timbre transfer. We specifically employ the bilateral
denoising diffusion model (BDDM) for noise scheduling search.
Our model is capable of conducting timbre transfer between audio
mixtures as well as individual instruments. Notably, it exhibits ver-
satility in that it accommodates multiple types of timbre transfer
between unique instrument pairs in a single model, eliminating the
need for separate model training for each pairing.
Furthermore,
unlike recent works limited to 16 kHz, WaveTransfer can be trained
at various sampling rates, including the industry-standard 44.1 kHz,
a feature of particular interest to the music community.
Index Terms— Multi-instrumental timbre transfer, diffusion
models, music transformation, generative AI



hal_id    :    hal-04632526



This paper describes a method for estimating the room impulse
response (RIR) for a microphone and a sound source located at
arbitrary positions from the 3D mesh data of the room. Simulat-
ing realistic RIRs with pure physics-driven methods often fails
the balance between physical consistency and computational ef-
ficiency, hindering application to real-time speech processing.
Alternatively, one can use MESH2IR, a fast black-box estima-
tor that consists of an encoder extracting latent code from mesh
data with a graph convolutional network (GCN) and a decoder
generating the RIR from the latent code. Combining these two
approaches, we propose a fast yet physically coherent estimator
with interpretable latent code based on differentiable digital sig-
nal processing (DDSP). Specifically, the encoder estimates a vir-
tual shoebox room scene that acoustically approximates the real
scene, accelerating physical simulation with the differentiable
image-source model in the decoder. Our experiments showed
that our method outperformed MESH2IR for real mesh data ob-
tained with the depth scanner of Microsoft HoloLens 2, and can
provide correct spatial consistency for binaural RIRs.
Index Terms: Spatial audio, room acoustics, 3D mesh data,
physical models, DDSP



hal_id    :    hal-04640068



Single-channel speech dereverberation aims at extracting a
dry speech signal from a recording affected by the acoustic re-
flections in a room. However, most current deep learning-based
approaches for speech dereverberation are not interpretable for
room acoustics, and can be considered as black-box systems
in that regard. In this work, we address this problem by regu-
larizing the training loss using a novel physical coherence loss
which encourages the room impulse response (RIR) induced by
the dereverberated output of the model to match the acoustic
properties of the room in which the signal was recorded. Our
investigation demonstrates the preservation of the original dere-
verberated signal alongside the provision of a more physically
coherent RIR.
Index Terms: Speech dereverberation, hybrid deep learning,
room acoustics, acoustic matching, speech processing



hal_id    :    hal-04705811



—Latent representation learning has been an active
field of study for decades in numerous applications. Inspired
among others by the tokenization from Natural Language
Processing and motivated by the research of a simple data
representation, recent works have introduced a quantization step
into the feature extraction. In this work, we propose a novel
strategy to build the neural discrete representation by means of
random codebooks. These codebooks are obtained by randomly
sampling a large, predefined fixed codebook. We experimentally
show the merits and potential of our approach in a task of audio
compression and reconstruction.
Index Terms—feature extraction, quantization, random code-
books, audio reconstruction



hal_id    :    hal-04614241



—This paper addresses the challenge of estimating
multiple highly oscillating amplitudes within the nonlinear chirp
signal model. The problem is analogous to the mode detection
task with fixed instantaneous frequencies, where the oscillating
amplitudes signify mechanical vibrations concealing crucial infor-
mation for predictive maintenance. Existing methods often focus
on single-frequency estimation, employ simple amplitude func-
tions, or impose strong noise assumptions. Furthermore, these
methods frequently rely on arbitrarily chosen hyperparameters,
leading to sub-optimal generalization for a diverse range of am-
plitudes. To address these limitations, our approach introduces
two estimators, based on Capon filters and negative log-likelihood
approaches respectively, that leverage locally stationary assump-
tions and incorporate hyperparameters estimation. The results
demonstrate that, even under challenging conditions, these esti-
mators yield competitive outcomes across various noisy scenarios,
mitigating the drawbacks associated with existing methods.
Index Terms—chirp signal, amplitude estimation, locally sta-
tionary process, filtering, hyperparameters estimation



hal_id    :    hal-04574640



Winner-takes-all training is a simple learning
paradigm, which handles ambiguous tasks by pre-
dicting a set of plausible hypotheses. Recently,
a connection was established between Winner-
takes-all training and centroidal Voronoi tessel-
lations, showing that, once trained, hypotheses
should quantize optimally the shape of the condi-
tional distribution to predict. However, the best
use of these hypotheses for uncertainty quantifi-
cation is still an open question. In this work, we
show how to leverage the appealing geometric
properties of the Winner-takes-all learners for con-
ditional density estimation, without modifying its
original training scheme. We theoretically estab-
lish the advantages of our novel estimator both in
terms of quantization and density estimation, and
we demonstrate its competitiveness on synthetic
and real-world datasets, including audio data.



hal_id    :    halshs-04654217



No abstract found in the PDF.



hal_id    :    hal-04602229



In recent years, significant advances have been made in deep learn-
ing models for audio generation, offering promising tools for mu-
sical creation. In this work, we investigate the use of deep audio
generative models in interactive dance/music performance. We
adopted a performance-led research design approach, establish-
ing an art-research collaboration between a researcher/musician
and a dancer. First, we describe our motion-sound interactive sys-
tem integrating deep audio generative model and propose three
methods for embodied exploration of deep latent spaces. Then, we
detail the creative process for building the performance centered
on the co-design of the system. Finally, we report feedback from
the dancer’s interviews and discuss the results and perspectives.
The code implementation is publicly available on our github1.
CCS CONCEPTS
• Human-centered computing →Sound-based input / output;
Gestural input; Auditory feedback; Collaborative interaction;
• Applied computing →Sound and music computing; • Com-
puting methodologies →Machine learning.
KEYWORDS
dance-music-AI performance, HCI, motion-sound interaction, deep
learning, generative models, embodied exploration, latent space
ACM Reference Format:
Sarah Nabi, Philippe Esling, Geoffroy Peeters, and Frédéric Bevilacqua. 2024.
Embodied exploration of deep latent spaces in interactive dance-music
performance. In 9th International Conference on Movement and Computing
(MOCO ’24), May 30-June 2, 2024, Utrecht, Netherlands. ACM, New York, NY,
USA, 9 pages. https://doi.org/10.1145/3658852.3659072
1https://github.com/ircam-ismm/embodied-latent-exploration
Permission to make digital or hard copies of all or part of this work for personal or
classroom



hal_id    :    hal-04541350



Isolating the desired speaker’s voice amidst multiple
speakers in a noisy acoustic context is a challenging task. Per-
sonalized speech enhancement (PSE) endeavours to achieve
this by leveraging prior knowledge of the speaker’s voice.
Recent research efforts have yielded promising PSE mod-
els, albeit often accompanied by computationally intensive
architectures, unsuitable for resource-constrained embedded
devices. In this paper, we introduce a novel method to per-
sonalize a lightweight dual-stage Speech Enhancement (SE)
model and implement it within DeepFilterNet2, a SE model
renowned for its state-of-the-art performance. We seek an
optimal integration of speaker information within the model,
exploring different positions for the integration of the speaker
embeddings within the dual-stage enhancement architec-
ture. We also investigate a tailored training strategy when
adapting DeepFilterNet2 to a PSE task. We show that our
personalization method greatly improves the performances
of DeepFilterNet2 while preserving minimal computational
overhead.
Index Terms— Target speech extraction, speech en-
hancement, real-time.



hal_id    :    hal-04358467



In neural audio signal processing, pitch conditioning has been
used to enhance the performance of synthesizers. However, jointly
training pitch estimators and synthesizers is a challenge when us-
ing standard audio-to-audio reconstruction loss, leading to reliance
on external pitch trackers. To address this issue, we propose us-
ing a spectral loss function inspired by optimal transportation theory
that minimizes the displacement of spectral energy. We validate this
approach through an unsupervised autoencoding task that fits a har-
monic template to harmonic signals. We jointly estimate the funda-
mental frequency and amplitudes of harmonics using a lightweight
encoder and reconstruct the signals using a differentiable harmonic
synthesizer. The proposed approach offers a promising direction for
improving unsupervised parameter estimation in neural audio appli-
cations.
Index Terms— differentiable signal processing, machine learn-
ing, optimal transport, frequency estimation



hal_id    :    hal-04424100



Diffusion models are receiving a growing interest for a variety of
signal generation tasks such as speech or music synthesis. WaveG-
rad, for example, is a successful diffusion model that conditionally
uses the mel spectrogram to guide a diffusion process for the gen-
eration of high-fidelity audio. However, such models face important
challenges concerning the noise diffusion process for training and
inference, and they have difficulty generating high-quality speech
for speakers that were not seen during training. With the aim of
minimizing the conditioning error and increasing the efficiency of
the noise diffusion process, we propose in this paper a new scheme
called GLA-Grad, which consists in introducing a phase recovery al-
gorithm such as the Griffin-Lim algorithm (GLA) at each step of the
regular diffusion process. Furthermore, it can be directly applied to
an already-trained waveform generation model, without additional
training or fine-tuning. We show that our algorithm outperforms
state-of-the-art diffusion models for speech generation, especially
when generating speech for a previously unseen target speaker.
Index Terms— Diffusion models, speech generation, Griffin-
Lim algorithm, domain adaptation



hal_id    :    hal-04360221



Current state-of-the-art audio analysis systems rely on pre-
trained embedding models, often used off-the-shelf as (frozen)
feature extractors. Choosing the best one for a set of tasks is the
subject of many recent publications.
However, one aspect often
overlooked in these works is the influence of the duration of audio
input considered to extract an embedding, which we refer to as Tem-
poral Support (TS). In this work, we study the influence of the TS
for well-established or emerging pre-trained embeddings, chosen to
represent different types of architectures and learning paradigms.
We conduct this evaluation using both musical instrument and envi-
ronmental sound datasets, namely OpenMIC, TAU Urban Acoustic
Scenes 2020 Mobile, and ESC-50. We especially highlight that Au-
dio Spectrogram Transformer-based systems (PaSST and BEATs)
remain effective with smaller TS, which therefore allows for a dras-
tic reduction in memory and computational cost.
Moreover, we
show that by choosing the optimal TS we reach competitive results
across all tasks. In particular, we improve the state-of-the-art results
on OpenMIC, using BEATs and PaSST without any fine-tuning.
Index Terms— audio embeddings, acoustic scene classification,
instrument recognition, temporal support, transformers



hal_id    :    hal-04479188



We address the problem of accurately interpolating measured ane-
choic steering vectors with a deep learning framework called the
neural field. This task plays a pivotal role in reducing the resource-
intensive measurements required for precise sound source separa-
tion and localization, essential as the front-end of speech recogni-
tion. Classical approaches to interpolation rely on linear weighting of
nearby measurements in space on a fixed, discrete set of frequencies.
Drawing inspiration from the success of neural fields for novel view
synthesis in computer vision, we introduce the neural steerer, a con-
tinuous complex-valued function that takes both frequency and direc-
tion as input and produces the corresponding steering vector. Impor-
tantly, it incorporates inter-channel phase difference information and
a regularization term enforcing filter causality, essential for accurate
steering vector modeling. Our experiments, conducted using a dataset
of real measured steering vectors, demonstrate the effectiveness of
our resolution-free model in interpolating such measurements.
Index Terms— Steering vector, neural field, spatial audio, inter-
polation, representation learning



hal_id    :    hal-04423979



Generative adversarial network (GAN) models can synthesize high-
quality audio signals while ensuring fast sample generation. How-
ever, they are difficult to train and are prone to several issues in-
cluding mode collapse and divergence. In this paper, we introduce
SpecDiff-GAN, a neural vocoder based on HiFi-GAN, which was
initially devised for speech synthesis from mel spectrogram. In our
model, the training stability is enhanced by means of a forward dif-
fusion process which consists in injecting noise from a Gaussian
distribution to both real and fake samples before inputting them to
the discriminator. We further improve the model by exploiting a
spectrally-shaped noise distribution with the aim to make the dis-
criminator’s task more challenging. We then show the merits of our
proposed model for speech and music synthesis on several datasets.
Our experiments confirm that our model compares favorably in au-
dio quality and efficiency compared to several baselines.
Index Terms— Generative adversarial network (GAN), diffu-
sion process, deep audio synthesis, spectral envelope



hal_id    :    hal-04419041



Overlapped speech is notoriously problematic for speaker diarization
systems. Consequently, the use of speech separation has recently
been proposed to improve their performance. Although promising,
speech separation models struggle with realistic data because they
are trained on simulated mixtures with a fixed number of speakers. In
this work, we introduce a new speech separation-guided diarization
scheme suitable for the online speaker diarization of long meeting
recordings with a variable number of speakers, as present in the AMI
corpus. We envisage ConvTasNet and DPRNN as alternatives for the
separation networks, with two or three output sources. To obtain the
speaker diarization result, voice activity detection is applied on each
estimated source. The final model is fine-tuned end-to-end, after first
adapting the separation to real data using AMI. The system operates
on short segments, and inference is performed by stitching the local
predictions using speaker embeddings and incremental clustering.
The results show that our system improves the state-of-the-art on
the AMI headset mix, using no oracle information and under full
evaluation (no collar and including overlapped speech). Finally, we
show the strength of our system particularly on overlapped speech
sections.
Index Terms— online speaker diarization, source separation,
overlapped speech, AMI, speaker embedding



hal_id    :    hal-04432659



Music generated by deep learning methods often suffers
from a lack of coherence and long-term organization. Yet,
multi-scale hierarchical structure is a distinctive feature of
music signals. To leverage this information, we propose a
structure-informed positional encoding framework for music
generation with Transformers. We design three variants in
terms of absolute, relative and non-stationary positional in-
formation. We comprehensively test them on two symbolic
music generation tasks: next-timestep prediction and accom-
paniment generation.
As a comparison, we choose multi-
ple baselines from the literature and demonstrate the merits
of our methods using several musically-motivated evaluation
metrics. In particular, our methods improve the melodic and
structural consistency of the generated pieces.
Index Terms— symbolic music generation, Transform-
ers, music structure, positional encoding



hal_id    :    hal-04423348



. With the progress of generative neural models, Hierarchical Text Classification
(HTC) can be cast as a generative task. In this case, given an input text, the model generates
the sequence of predicted class labels taken from a label tree of arbitrary width and depth.
Treating HTC as a generative task introduces multiple modeling choices. These choices vary
from choosing the order for visiting the class tree and therefore defining the order of generat-
ing tokens, choosing either to constrain the decoding to labels that respect the previous level
predictions, up to choosing the pre-trained Language Model itself. Each HTC model therefore
differs from the others from an architectural standpoint, but also from the modeling choices
that were made. Prior contributions lack transparent modeling choices and open implemen-
tations, hindering the assessment of whether model performance stems from architectural or
modeling decisions. For these reasons, we propose with this paper an analysis of the impact
of different modeling choices along with common model errors and successes for this task.
This analysis is based on an open framework coming along this paper that can facilitate the
development of future contributions in the field by providing datasets, metrics, error analysis
toolkit and the capability to readily test various modeling choices for one given model.
Keywords: Hierarchical text



hal_id    :    hal-04604650



. In recent years, there has been a signicant surge in machine
learning techniques, particularly in the domain of deep learning, tailored
for handling attributed graphs. Nevertheless, to work, these methods as-
sume that the attributes values are fully known, which is not realistic
in numerous real-world applications. This paper explores the potential
of Optimal Transport (OT) to impute missing attributes on graphs. To
proceed, we design a novel multi-view OT loss function that can encom-
pass both node feature data and the underlying topological structure of
the graph by utilizing multiple graph representations. We then utilize
this novel loss to train eciently a Graph Convolutional Neural Net-
work (GCN) architecture capable of imputing all missing values over the
graph at once. We evaluate the interest of our approach with experiments
both on synthetic data and real-world graphs, including dierent miss-
ingness mechanisms and a wide range of missing data. These experiments
demonstrate that our method is competitive with the state-of-the-art in
all cases and of particular interest on weakly homophilic graphs.
Keywords: Attributed Graph · Missing Data Imputation · Optimal
Transport
1



hal_id    :    hal-04575332



We consider the statistical seriation problem, where the statistician seeks to recover a
hidden ordering from a noisy observation of a permuted Robinson matrix. In this paper,
we tightly characterize the minimax rate for this problem of matrix reordering when
the Robinson matrix is bi-Lipschitz, and we also provide a polynomial time algorithm
achieving this rate; thereby answering two open questions of [Giraud et al., 2021]. Our
analysis further extends to broader classes of similarity matrices.
1



hal_id    :    hal-04729913



Multimodal large language models have fueled progress in image captioning.
These models, fine-tuned on vast image datasets, exhibit a deep understanding
of semantic concepts. In this work, we show that this ability can be re-purposed
for audio captioning, where the joint image-language decoder can be leveraged to
describe auditory content associated with image sequences within videos featuring
audiovisual content. This can be achieved via multimodal alignment. Yet, this
multimodal alignment task is non-trivial due to the inherent disparity between
audible and visible elements in real-world videos. Moreover, multimodal repre-
sentation learning often relies on contrastive learning, facing the challenge of the
so-called modality gap which hinders smooth integration between modalities. In
this work, we introduce a novel methodology for bridging the audiovisual modality
gap by matching the distributions of tokens produced by an audio backbone and
those of an image captioner. Our approach aligns the audio token distribution
with that of the image tokens, enabling the model to perform zero-shot audio
captioning in an unsupervised fashion while keeping the initial image captioning
component unaltered. This alignment allows for the use of either audio or audiovi-
sual input by combining or substituting the image encoder with the aligned audio
encoder. Our method achieves significantly improved performances in zero-shot
audio captioning, compared to existing approaches.1
1



hal_id    :    hal-04593480



When deriving contextualized word repre-
sentations from language models, a decision
needs to be made on how to obtain one for
out-of-vocabulary (OOV) words that are seg-
mented into subwords. What is the best way
to represent these words with a single vector,
and are these representations of worse quality
than those of in-vocabulary words? We carry
out an intrinsic evaluation of embeddings from
different models on semantic similarity tasks
involving OOV words. Our analysis reveals,
among other interesting findings, that the qual-
ity of representations of words that are split is
often, but not always, worse than that of the
embeddings of known words. Their similar-
ity values, however, must be interpreted with
caution.
1



hal_id    :    hal-04578273



. The pair-matching problem appears in many applications where one wants to discover
matches between pairs of entities or individuals. Formally, the set of individuals is represented by
the nodes of a graph where the edges, unobserved at first, represent the matches. The algorithm
queries pairs of nodes and observes the presence/absence of edges. Its goal is to discover as
many edges as possible with a fixed budget of queries. Pair-matching is a particular instance of
multi-armed bandit problem in which the arms are pairs of individuals and the rewards are edges
linking these pairs. This bandit problem is non-standard though, as each arm can only be played
once.
Given this last constraint, sublinear regret can be expected only if the graph presents some
underlying structure. This paper shows that sublinear regret is achievable in the case where
the graph is generated according to a Stochastic Block Model (SBM) with two communities.
Optimal regret bounds are computed for this pair-matching problem. They exhibit a phase trans-
ition related to the Kesten-Stigum threshold for community detection in SBM. The pair-matching
problem is considered in the case where each node is constrained to be sampled less than a given
amount of times, for example for ensuring individual fairness. We show how optimal regret rates
depend on this



hal_id    :    hal-04539879



—This paper tackles two major problem settings for
interpretability of audio processing networks, post-hoc and by-
design interpretation. For post-hoc interpretation, we aim to in-
terpret decisions of a network in terms of high-level audio objects
that are also listenable for the end-user. This is extended to
present an inherently interpretable model with high performance.
To this end, we propose a novel interpreter design that incor-
porates non-negative matrix factorization (NMF). In particular,
an interpreter is trained to generate a regularized intermediate
embedding from hidden layers of a target network, learnt as time-
activations of a pre-learnt NMF dictionary. Our methodology
allows us to generate intuitive audio-based interpretations that
explicitly enhance parts of the input signal most relevant for a
network’s decision. We demonstrate our method’s applicability
on a variety of classification tasks, including multi-label data for
real-world audio and music.
Index Terms—Audio interpretability, explainability, by-design
interpretable models, audio convolutional networks, non-negative
matrix factorization



hal_id    :    hal-03615137



—Tensor factorization models are widely used in many
applied ﬁelds such as chemometrics, psychometrics, computer
vision or communication networks. Real life data collection is
often subject to errors, resulting in missing data. Here we focus
in understanding how this issue should be dealt with for non-
negative tensor factorization. We investigate several criteria used
for non-negative tensor factorization in the case where some
entries are missing. In particular we show how smoothness
penalties can compensate the presence of missing values in order
to ensure the existence of an optimum. This lead us to propose
new criteria with efﬁcient numerical optimization algorithms.
Numerical experiments are conducted to support our claims.
Index Terms—Non-negative tensor decomposition, missing val-
ues, Tensor completion, smoothness, PARAFAC, CP decomposi-
tion.



hal_id    :    hal-04410338



Seals are small coin-shaped artifacts, mostly made of lead, held with strings to seal letters.
This work presents the first attempt towards automatic reading of text on Byzantine seal
images. Byzantine seals are generally decorated with iconography on the obverse side and
Greek text on the reverse side. Text may include the sender’s name, position in the Byzantine
aristocracy, and elements of prayers. Both text and iconography are precious literary sources
that wait to be exploited electronically, so the development of computerized systems for
interpreting seals images is of paramount importance. This work’s contribution is hence a
deep, two-stages, character reading pipeline for transcribing Byzantine seal images. A first deep
convolutional neural network (CNN) detects characters in the seal (character localization). A
second convolutional network reads the localized characters (character classification). Finally, a
diplomatic transcription of the seal is provided by post-processing the two network outputs. We
provide an experimental evaluation of each CNN in isolation and both CNNs in combination. All
performances are evaluated by cross-validation. Character localization achieves a mean average
precision (mAP@0.5) greater than 0.9. Classification of characters cropped from ground truth
bounding boxes achieves Top-1 accuracy greater than 0.92. End-to-end evaluation shows the
efficiency of the proposed approach when compared to the SoTA for similar tasks.



hal_id    :    hal-04552478



Data augmentation is an essential building block for learning efﬁcient deep learning
models. Among all augmentation techniques proposed so far, linear interpolation
of training data points, also called mixup, has found to be effective for a large
panel of applications. While the majority of works have focused on selecting
the right points to mix, or applying complex non-linear interpolation, we are
interested in mixing similar points more frequently and strongly than less similar
ones. To this end, we propose to dynamically change the underlying distribution of
interpolation coefﬁcients through warping functions, depending on the similarity
between data points to combine. We deﬁne an efﬁcient and ﬂexible framework to do
so without losing in diversity. We provide extensive experiments for classiﬁcation
and regression tasks, showing that our proposed method improves both performance
and calibration of models. Code available in torch-uncertainty.
1



hal_id    :    hal-04390768



Group fairness is a central research topic in
text classification, where reaching fair treat-
ment between sensitive groups (e.g. women
vs. men) remains an open challenge. This
paper presents a novel method for mitigating
biases in neural text classification, agnostic to
the model architecture. Considering the diffi-
culty to distinguish fair from unfair informa-
tion in a text encoder, we take inspiration from
adversarial training to induce Wasserstein in-
dependence between representations learned to
predict our target label and the ones learned to
predict some sensitive attribute. Our approach
provides two significant advantages. Firstly,
it does not require annotations of sensitive at-
tributes in both testing and training data. This is
more suitable for real-life scenarios compared
to existing methods that require annotations
of sensitive attributes at train time. Secondly,
our approach exhibits a comparable or better
fairness-accuracy trade-off compared to exist-
ing methods. Our implementation is available
on Github1.
1



hal_id    :    hal-04216055



We introduce Resilient Multiple Choice Learning (rMCL), an extension of the
MCL approach for conditional distribution estimation in regression settings where
multiple targets may be sampled for each training input. Multiple Choice Learning
is a simple framework to tackle multimodal density estimation, using the Winner-
Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing
MCL variants focus on merging the hypotheses, thereby eventually sacriﬁcing
the diversity of the predictions. In contrast, our method relies on a novel learned
scoring scheme underpinned by a mathematical framework based on Voronoi tessel-
lations of the output space, from which we can derive a probabilistic interpretation.
After empirically validating rMCL with experiments on synthetic data, we further
assess its merits on the sound source localization task, demonstrating its practical
usefulness and the relevance of its interpretation.
1



hal_id    :    hal-04172863



This paper revisits single-channel audio source separation based on
a probabilistic generative model of a mixture signal defined in the
continuous time domain. We assume that each source signal fol-
lows a non-stationary Gaussian process (GP), i.e., any finite set of
sampled points follows a zero-mean multivariate Gaussian distribu-
tion whose covariance matrix is governed by a kernel function over
time-varying latent variables. The mixture signal composed of such
source signals thus follows a GP whose covariance matrix is given
by the sum of the source covariance matrices. To estimate the latent
variables from the mixture signal, we use a deep neural network with
an encoder-separator-decoder architecture (e.g., Conv-TasNet) that
separates the latent variables in a pseudo-time-frequency space. The
key feature of our method is to feed the latent variables into the ker-
nel function for estimating the source covariance matrices, instead
of using the decoder for directly estimating the time-domain source
signals. This enables the decomposition of a mixture signal into the
source signals with a classical yet powerful Wiener filter that consid-
ers the full covariance structure over all samples. The kernel func-
tion and the network are trained jointly in the maximum likelihood
framework. Comparative experiments using two-speech mixtures
under clean, noisy, and noisy-reverberant conditions from the WSJ0-
2mix, WHAM!, and WHAMR! benchmark datasets demonstrated
that the proposed method



hal_id    :    hal-04135264



BHAI 1 (Byzantine Hybrid Artificial Intelligence) is the first project
based on artificial intelligence dedicated to Byzantine seals. The
scientific consortium comprises a multidisciplinary team involving
historians specialized in the Byzantine period, specialists in sig-
illography, and computer science experts. This article describes the
main objectives of this project: data acquisition of seal images, text
and iconography recognition, seal dating, as well as our current
achievements and first results on character recognition and spatial
analysis of personages.
CCS CONCEPTS
• Applied computing →Arts and humanities; • Computing
methodologies →Spatial and physical reasoning; Semantic
networks; Natural language processing.
KEYWORDS
Byzantine Greek, Byzantine history, seal images, deep neural net-
works, character recognition, iconography recognition
ACM Reference Format:
Victoria EYHARABIDE, Laurence LIKFORMAN-SULEM, Lucia ORLANDI,
Alexandre BINOUX, Théophile RAGEAU, Qijia HUANG, Attilio FIAN-
DROTTI, Beatrice CASEAU, and Isabelle BLOCH. 2023. Study of historical
Byzantine seal images: the BHAI project for computer-based sigillography.
In 7th International Workshop on Historical Document Imaging and Processing
(HIP ’23), August 25–26, 2023, San Jose, CA, USA. ACM, New York, NY, USA,
6 pages. https://doi.org/10.1145/3604951.3605523
1



hal_id    :    hal-04216177



Self-Supervised Learning (SSL) has allowed leveraging large
amounts of unlabeled speech data to improve the perfor-
mance of speech recognition models even with small annotated
datasets.
Despite this, speech SSL representations may fail
while facing an acoustic mismatch between the pretraining and
target datasets. To address this issue, we propose a novel super-
vised domain adaptation method, designed for cases exhibiting
such a mismatch in acoustic domains. It consists in applying
properly calibrated data augmentations on a large clean dataset,
bringing it closer to the target domain, and using it as part of
an initial fine-tuning stage. Augmentations are automatically
selected through the minimization of a conditional-dependence
estimator, based on the target dataset. The approach is vali-
dated during an oracle experiment with controlled distortions
and on two amateur-collected low-resource domains, reaching
better performances compared to the baselines in both cases.
Index Terms: self-supervised learning, domain adaptation.



hal_id    :    hal-04593478



Dialog participants sometimes align their lin-
guistic styles, e.g., they use the same words
and syntactic constructions as their interlocu-
tors. We propose to investigate the notion of
lexico-semantic alignment: to what extent do
speakers convey the same meaning when they
use the same words? We design measures of
lexico-semantic alignment relying on contextu-
alized word representations. We show that they
reflect interesting semantic differences between
the two sides of a debate and that they can assist
in the task of debate’s winner prediction.
1



hal_id    :    hal-04131585



No abstract found in the PDF.



hal_id    :    hal-04130213



La façon dont nous utilisons les mots est influencée par notre opinion. Nous cherchons à savoir si cela
se reflète dans les plongements de mots contextualisés. Par exemple, la représentation d’ « animal »
est-elle différente pour les gens qui voudraient abolir les zoos et ceux qui ne le voudraient pas? Nous
explorons cette question du point de vue du changement sémantique des mots. Nos expériences avec
des représentations dérivées d’ensembles de données annotés avec les points de vue révèlent des
différences minimes, mais significatives, entre postures opposées 1.
ABSTRACT
One Word, Two Sides : Traces of Stance in Contextualized Word Representations
The way we use words is influenced by our opinion. We investigate whether this is reflected in
contextualized word embeddings. For example, is the representation of “animal” different between
people who would abolish zoos and those who would not? We explore this question from a Lexical
Semantic Change standpoint. Our experiments with BERT embeddings derived from datasets with
stance annotations reveal small but significant differences in word representations between opposing
stances.
MOTS-CLÉS : Représentations contextualisées, changement sémantique, détection de point de vue.
KEYWORDS: Contextualized representations, semantic change, stance detection.
1



hal_id    :    hal-04093374



Measuring noise in cities and automatically identifying the cor-
responding sound sources are a crucial challenge for policymak-
ers. Indeed, such information helps addressing noise pollution and
improving the well-being of urban dwellers. In recent years, re-
searchers have provided annotated datasets recorded in two ma-
jor cities to foster the development of urban sound event detection
(SED) systems. This paper presents an in-depth study of the be-
haviour of state-of-the-art SED systems well suited to our problem,
combining three far-field real recordings datasets which can be used
jointly during training. In our evaluation, we highlight the perfor-
mance gaps existing between simple and hard recording examples
based on the salience of sound events and the polyphony of the
recordings. We provide new proximity annotations for this anal-
ysis. We evaluate the ability of urban SED systems to generalize
across cities with varying degrees of training supervision. We show
that such generalization is hindered mostly by the difficulties current
urban SED systems have to detect sound events with low salience
along with sound events in highly polyphonic soundscapes.
Index Terms— Sound Event Detection (SED), Far-field urban
audio recordings, urban sound monitoring,



hal_id    :    ujm-04165556



. In contrast to classic autoregressive generation, insertion-
based models can predict in a order-free way multiple tokens at a time,
which make their generation uniquely controllable: it can be constrained
to strictly include an ordered list of tokens. We propose to exploit this
feature in a new diverse paraphrasing framework: ﬁrst, we extract im-
portant tokens or keywords in the source sentence; second, we augment
them; third, we generate new samples around them by using insertion
models. We show that the generated paraphrases are competitive with
state of the art autoregressive paraphrasers, not only in diversity but also
in quality. We further investigate their potential to create new pseudo-
labelled samples for data augmentation, using a meta-learning classiﬁca-
tion framework, and ﬁnd equally competitive result. In addition to prov-
ing non-autoregressive (NAR) viability for paraphrasing, we contribute
our open-source framework as a starting point for further research into
controllable NAR generation.
Keywords: Deep Learning · Natural language processing · Controllable
text generation · Transformers · Non-autoregressive · Insertion models.
1



hal_id    :    hal-04213215



. In recent years, large Transformer-based Pre-trained Lan-
guage Models (PLM) have changed the Natural Language Processing
(NLP) landscape, by pushing the performance boundaries of the state-
of-the-art on a wide variety of tasks. However, this performance gain goes
along with an increase in complexity, and as a result, the size of such
models (up to billions of parameters) represents a constraint for their
deployment on embedded devices or short-inference time tasks. To cope
with this situation, compressed models emerged (e.g. DistilBERT), de-
mocratizing their usage in a growing number of applications that impact
our daily lives. A crucial issue is the fairness of the predictions made by
both PLMs and their distilled counterparts. In this paper, we propose
an empirical exploration of this problem by formalizing two questions:
(1) Can we identify the neural mechanism(s) responsible for gender bias
in BERT (and by extension DistilBERT)? (2) Does distillation tend to
accentuate or mitigate gender bias (e.g. is DistilBERT more prone to
gender bias than its uncompressed version, BERT)? Our findings are the
following: (I) one cannot identify a specific layer that produces bias; (II)
every attention head uniformly encodes bias; except in the context of un-
derrepresented classes with a high imbalance of the sensitive attribute;
(III) this subset of heads is different as we re-fine tune the



hal_id    :    hal-04253752



Non-deterministic measurements are common in real-world scenarios: the performance
of a stochastic optimization algorithm or the total reward of a reinforcement learning agent
in a chaotic environment are just two examples in which unpredictable outcomes are com-
mon. These measures can be modeled as random variables and compared among each other
via their expected values or more sophisticated tools such as null hypothesis statistical
tests. In this paper, we propose an alternative framework to visually compare two sam-
ples according to their estimated cumulative distribution functions. First, we introduce a
dominance measure for two random variables that quantiﬁes the proportion in which the
cumulative distribution function of one of the random variables stochastically dominates
the other one. Then, we present a graphical method that decomposes in quantiles i) the
proposed dominance measure and ii) the probability that one of the random variables takes
lower values than the other. With illustrative purposes, we re-evaluate the experimentation
of an already published work with the proposed methodology and we show that additional
conclusions—missed by the rest of the methods—can be inferred. Additionally, the software
package RVCompare was created as a convenient way of applying and experimenting with
the proposed framework.
Keywords:
Data visualization, Random variables, Cumulative distribution function, First-order
stochastic dominance
1
arXiv:2203.07889v4  [stat.ML]  30 Aug 2022
0.0225 0.0250 0.0275 0.0300 0.0325



hal_id    :    hal-04244852



Handling large datasets and calculating complex statistics on huge datasets require
important computing resources. Using subsampling methods to calculate statistics
of interest on small samples is often used in practice to reduce computational com-
plexity, for instance using the divide and conquer strategy. In this article, we recall
some results on subsampling distributions and derive a precise rate of convergence
for these quantities and the corresponding quantiles. We also develop some standard-
ization techniques based on subsampling unstandardized statistics in the framework
of large datasets. It is argued that using several subsampling distributions with dif-
ferent subsampling sizes brings a lot of information on the behavior of statistical
learning procedures: subsampling allows to estimate the rate of convergence of dif-
ferent algorithms, to estimate the variability of complex statistics, to estimate conﬁ-
dence intervals for out-of-sample errors and interpolate their values at larger scales.
These results are illustrated on simulations, but also on two important datasets,
frequently analyzed in the statistical learning community, EMNIST (recognition of
digits) and VeReMi (analysis of Network Vehicular Reference Misbehavior).
KEYWORDS
Scaling, big data, Subsampling, Convergence rate estimation, Conﬁdence intervals
in statistical learning, Out-of sample error, EMNIST digits VeReMi



hal_id    :    hal-04310171



Argumentation
. . . . .
51
G. Dubuisson Duplessis, M. Richard, A.-L. Guénet (APIA)
Segmentation de phases de dialogue dans des retranscriptions de conversations de centres
d’appels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
A. Ferdjaoui, S. Affeldt, M. Nadif (SFC)
Modèles graphiques causaux interactifs pour les données textuelles . . . . . . . . . . . . .
65
C. Fèvre, H. Zgaya-Biau, P. Mathieu, S. Hammadi (JFSMA)
L’optimisation du covoiturage dynamique multi-saut . . . . . . . . . . . . . . . . . . . . .
71
S. Forest, J.-C. Quinton, M. Lefort (CNIA)
Champ neuronal et apprentissage profond de topologies pour la fusion multimodale . . . .
81
A. Godinot, E. Le Merrer, C. Penzo, F. Taïani, G. Tredan (RJCIA)
Change-Relaxed Active Fairness Auditing . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
K. Le Gall, L. Bellanger, A. Stamm, D.A. Laplaud (SFC)
Génération de données



hal_id    :    hal-04258177



No abstract found in the PDF.



hal_id    :    hal-04390005



Optimal transport (OT) compares probability distributions by
computing a meaningful alignment between their samples. CO-
optimal transport (COOT) takes this comparison further by
inferring an alignment between features as well. While this ap-
proach leads to better alignments and generalizes both OT and
Gromov-Wasserstein distances, we provide a theoretical result
showing that it is sensitive to outliers that are omnipresent
in real-world data. This prompts us to propose unbalanced
COOT for which we provably show its robustness to noise in
the compared datasets. To the best of our knowledge, this is
the ﬁrst such result for OT methods in incomparable spaces.
With this result in hand, we provide empirical evidence of this
robustness for the challenging tasks of heterogeneous domain
adaptation with and without varying proportions of classes
and simultaneous alignment of samples and features across
single-cell measurements.



hal_id    :    hal-03608767



—This paper introduces a theoretically-rigorous sound
source localization (SSL) method based on a robust extension
of the classical multiple signal classification (MUSIC) algorithm.
The original SSL method estimates the noise eigenvectors and the
MUSIC spectrum by computing the spatial covariance matrix of
the observed multichannel signal and then detects the peaks from
the spectrum. In this work, the covariance matrix is replaced with
the positive definite shape matrix originating from the elliptically
contoured α-stable model, which is more suitable under real
noisy high-reverberant conditions. Evaluation on synthetic data
shows that the proposed method outperforms baseline methods
under such adverse conditions, while it is comparable on real
data recorded in a mild acoustic condition.
Index Terms— sound source localization, MUSIC, α-stable
theory, covariation



hal_id    :    hal-03990543



No abstract found in the PDF.



hal_id    :    hal-03821125



—This article describes a computationally-efﬁcient sta-
tistical approach to joint (semi-)blind source separation and dere-
verberation for multichannel noisy reverberant mixture signals. A
standard approach to source separation is to formulate a generative
model of a multichannel mixture spectrogram that consists of
source and spatial models representing the time-frequency power
spectral densities (PSDs) and spatial covariance matrices (SCMs)
of source images, respectively, and ﬁnd the maximum-likelihood
estimates of these parameters. A state-of-the-art blind source sep-
aration method in this thread of research is fast multichannel
nonnegative matrix factorization (FastMNMF) based on the low-
rank PSDs and jointly-diagonalizable full-rank SCMs. To perform
mutually-dependent separation and dereverberation jointly, in this
paper we integrate both moving average (MA) and autoregressive
(AR) models that represent the early reﬂections and late rever-
berations of sources, respectively, into the FastMNMF formalism.
Using a pretrained deep generative model of speech PSDs as a
source model, we realize semi-blind joint speech separation and
dereverberation. We derive an iterative optimization algorithm
based on iterative projection or iterative source steering for jointly
and efﬁciently updating the AR parameters and the SCMs. Our
experimentalresultsshowedthesuperiorityoftheproposedARMA
extensionoveritsAR-orMA-ablatedversioninaspeechseparation
and/or dereverberation task.
Index Terms—Multichannel audio signal processing, source
separation, dereverberation, joint diagonalization.
Manuscript received 4 October 2021; revised 31 March 2022; accepted 18
June2022.Dateofpublication13July2022;dateofcurrentversion28July2022.
This work was supported in part by JSPS KAKENHI under Grants 19H04137,
20K19833, and 20H01159, and in part by NII



hal_id    :    hal-03657196



—This paper describes heavy-tailed extensions of a
state-of-the-art versatile blind source separation method called
fast multichannel nonnegative matrix factorization (FastMNMF)
from a uniﬁed point of view. The common way of deriving such an
extension is to replace the multivariate complex Gaussian distribu-
tion in the likelihood function with its heavy-tailed generalization,
e.g., the multivariate complex Student’s t and leptokurtic gener-
alized Gaussian distributions, and tailor-make the corresponding
parameter optimization algorithm. Using a wider class of heavy-
tailed distributions called a Gaussian scale mixture (GSM), i.e., a
mixture of Gaussian distributions whose variances are perturbed
by positive random scalars called impulse variables, we propose
GSM-FastMNMF and develop an expectation-maximization algo-
rithm that works even when the probability density function of
the impulse variables have no analytical expressions. We show
that existing heavy-tailed FastMNMF extensions are instances of
GSM-FastMNMF and derive a new instance based on the gen-
eralized hyperbolic distribution that include the normal-inverse
Gaussian, Student’s t, and Gaussian distributions as the special
cases. Our experiments show that the normal-inverse Gaussian
FastMNMF outperforms the state-of-the-art FastMNMF exten-
sions and ILRMA model in speech enhancement and separation
in terms of the signal-to-distortion ratio.
Index Terms—Nonnegative matrix factorization, blind source
separation, probabilistic framework, expectation-maximization



hal_id    :    hal-03860497



, ISMIR 2022 Conference
SSM-NET: FEATURE LEARNING FOR MUSIC STRUCTURE ANALYSIS
USING A SELF-SIMILARITY-MATRIX BASED LOSS
Geoffroy Peeters
LTCI, Télécom-Paris, IP-Paris
geoffroy.peeters@telecom-paris.fr
Florian Angulo
LTCI, Télécom-Paris, IP-Paris
florian.angulo@telecom-paris.fr
ABSTRACT
In this paper, we propose a new paradigm to learn au-
dio features for Music Structure Analysis (MSA).
We
train a deep encoder to learn features such that the Self-
Similarity-Matrix (SSM) resulting from those approxi-
mates a ground-truth SSM. This is done by minimizing
a loss between both SSMs.
Since this loss is differen-
tiable w.r.t. its input features we can train the encoder in a
straightforward way. We successfully demonstrate the use
of this training paradigm using the Area Under the Curve
ROC (AUC) on the RWC-Pop dataset.



hal_id    :    hal-03903647



As music has become more available especially on music
streaming platforms, people have started to have distinct
preferences to fit to their varying listening situations, also
known as context. Hence, there has been a growing inter-
est in considering the user’s situation when recommending
music to users. Previous works have proposed user-aware
autotaggers to infer situation-related tags from music con-
tent and user’s global listening preferences. However, in
a practical music retrieval system, the autotagger could be
only used by assuming that the context class is explicitly
provided by the user. In this work, for designing a fully
automatised music retrieval system, we propose to disam-
biguate the user’s listening information from their stream
data. Namely, we propose a system which can generate a
situational playlist for a user at a certain time 1) by leverag-
ing user-aware music autotaggers, and 2) by automatically
inferring the user’s situation from stream data (e.g. device,
network) and user’s general profile information (e.g. age).
Experiments show that such a context-aware personalized
music retrieval system is feasible, but the performance de-
creases in the case of new users, new tracks or when the
number of context classes increases.



hal_id    :    hal-03782827



Invariance-based learning is a promising approach in deep learning.
Among other benefits, it can mitigate the lack of diversity of avail-
able datasets and increase the interpretability of trained models. To
this end, practitioners often use a consistency cost penalizing the
sensitivity of a model to a set of carefully selected data augmen-
tations. However, there is no consensus about how these augmen-
tations should be selected. In this paper, we study the behavior
of several augmentation strategies. We consider the task of sound
event detection and classification for our experiments. In particular,
we show that transformations operating on the internal layers of a
deep neural network are beneficial for this task.
Index Terms— sound event detection, data augmentation, ad-
versarial learning



hal_id    :    hal-03860830



The way we use words is influenced by our
opinion.
We investigate whether this is re-
flected in contextualized word embeddings.
For example, is the representation of “animal”
different between people who would abolish
zoos and those who would not? We explore
this question from a Lexical Semantic Change
standpoint. Our experiments with BERT em-
beddings derived from datasets with stance
annotations reveal small but significant differ-
ences in word representations between oppos-
ing stances.
1



hal_id    :    hal-03817736



Contrastive learning enables learning useful audio and speech
representations without ground-truth labels by maximizing the
similarity between latent representations of similar signal seg-
ments. In this framework various data augmentation techniques
are usually exploited to help enforce desired invariances within
the learned representations, improving performance on various
audio tasks thanks to more robust embeddings. Now, selecting
the most relevant augmentations has proven crucial for better
downstream performances. Thus, this work introduces a condi-
tional independance-based method which allows for automati-
cally selecting a suitable distribution on the choice of augmenta-
tions and their parametrization from a set of predefined ones, for
contrastive self-supervised pre-training. This is performed with
respect to a downstream task of interest, hence saving a costly
hyper-parameter search. Experiments performed on two differ-
ent downstream tasks validate the proposed approach showing
better results than experimenting without augmentation or with
baseline augmentations. We furthermore conduct a qualitative
analysis of the automatically selected augmentations and their
variation according to the considered final downstream dataset.
Index Terms: self-supervised learning, data augmentation.



hal_id    :    hal-03860827



Our discourses are full of potential lexical ambiguities, due in part to the pervasive use of words having multiple senses.
Sometimes, one word may even be used in more than one sense throughout a text. But, to what extent is this true for different
kinds of texts? Does the use of polysemous words change when a discourse involves two people, or when speakers have time
to plan what to say? We investigate these questions by comparing the polysemy level of texts of different nature, with a focus
on spontaneous spoken dialogs; unlike previous work which examines solely scripted, written, monolog-like data. We compare
multiple metrics that presuppose different conceptualizations of text polysemy, i.e., they consider the observed or the potential
number of senses of words, or their sense distribution in a discourse. We show that the polysemy level of texts varies greatly
depending on the kind of text considered, with dialog and spoken discourses having generally a higher polysemy level than
written monologs. Additionally, our results emphasize the need for relaxing the popular “one sense per discourse” hypothesis.
Keywords: Semantics, Word Sense Disambiguation, Document classification / Text categorisation
1.



hal_id    :    hal-04273536



Users generate content constantly, leading to new data requiring annotation.
Among this data, textual conversations are
created every day and come with some specificities: they are mostly private through instant messaging applications, requiring
the conversational context to be labeled. These specificities led to several annotation tools dedicated to conversation, and
mostly dedicated to dialogue tasks, requiring complex annotation schemata, not always customizable and not taking into
account conversation-level labels.
In this paper, we present EZCAT, an easy-to-use interface to annotate conversations
in a two-level configurable schema, leveraging message-level labels and conversation-level labels at once.
Our interface
is characterized by the voluntary absence of a server and accounts management, enhancing its availability to anyone, and
the control over data, which is crucial to confidential conversations. We also present our first usage of EZCAT along with
our annotation schema we used to annotate confidential customer service conversations.
EZCAT is freely available at
https://gguibon.github.io/ezcat.
Keywords: conversations, annotation tool, text messages
1.



hal_id    :    hal-04276012



In this paper, we present the process we used in order to collect new annotations of opinions over the multimodal corpus
SEMAINE composed of dyadic interactions. The dataset had already been annotated continuously in two affective dimensions
related to the emotions: Valence and Arousal.
We annotated the part of SEMAINE called Solid SAL composed of 79
interactions between a user and an operator playing the role of a virtual agent designed to engage a person in a sustained,
emotionally colored conversation. We aligned the audio at the word level using the available high-quality manual transcriptions.
The annotated dataset contains 5627 speech turns for a total of 73,944 words, corresponding to 6 hours 20 minutes of dyadic
interactions. Each interaction has been labeled by three annotators at the speech turn level following a three-step process. This
method allows us to obtain a precise annotation regarding the opinion of a speaker. We obtain thus a dataset dense in opinions,
with more than 48% of the annotated speech turns containing at least one opinion. We then propose a new baseline for the
detection of opinions in interactions improving slightly a state of the art model with RoBERTa embeddings. The obtained
results on the database are promising with a F1-score at 0.72.
Keywords: Opinion, Multimodal Machine



hal_id    :    hal-04166172



. Handwriting is an everyday life human activity. It can be
collected oﬀ-line by scanning sheets of paper. The resulting images can
then be processed by a computer-based system. Thanks to digitizing
tablets, handwriting can also be collected on-line. From the collected raw
signals (pen position, pressure over time), the dynamics of the writing
can be recovered. Since handwriting is unique for each individual, it can
be considered as a biometric modality.
Biometric systems predicting gender from oﬀ-line handwriting, have been
recently proposed. However we observe that, in contrast to other modal-
ities such as speech, it is not straightforward for a human being (even
expert) to predict gender. In this study we explore the limits of auto-
matic gender prediction from on-line handwriting collected from a young
adults population, homogeneous in terms of age and education. In our
previous work [1], a statistical analysis of on-line dynamic features has
shown diﬀerences between male and female groups. In the present study,
we provide these features to a classiﬁer, based on a machine learning ap-
proach (SVMs). Since datasets are relatively small (240 subjects), several
evaluation frameworks are explored: cross validation (CV), bootstrap,
and ﬁxed train/test partitions. Accuracies obtained from ﬁxed partitions
range from 37% to 79%, while those estimated by CV and bootstrap
are around 60%.
This shows to our opinion



hal_id    :    hal-03637425



This paper describes a blind source separation method for multichan-
nel audio signals, called NF-FastMNMF, based on the integration of
the normalizing ﬂow (NF) into the multichannel nonnegative matrix
factorization with jointly-diagonalizable spatial covariance matrices,
a.k.a. FastMNMF. Whereas the NF of ﬂow-based independent vector
analysis, called NF-IVA, acts as the demixing matrices to transform
an M-channel mixture into M independent sources, the NF of NF-
FastMNMF acts as the diagonalization matrices to transform an M-
channel mixture into a spatially-independent M-channel mixture rep-
resented as a weighted sum of N source images. This diagonalization
enables the NF, which has been used only for determined separation
because of its bijective nature, to be applicable to non-determined
separation. NF-FastMNMF has time-varying diagonalization matri-
ces that are potentially better at handling dynamical data variation
than the time-invariant ones in FastMNMF. To have an NF with richer
expression capability, the dimension-wise scalings using diagonal ma-
trices originally used in NF-IVA are replaced with linear transforma-
tions using upper triangular matrices; in both cases, the diagonal and
upper triangular matrices are estimated by neural networks. The eval-
uation shows that NF-FastMNMF performs well for both determined
and non-determined separations of multiple speech utterances by sta-
tionary or non-stationary speakers from a noisy reverberant mixture.
Index Terms— Blind source separation, normalizing ﬂow, joint
diagonalization, multichannel nonnegative matrix factorization



hal_id    :    hal-03602455



This paper introduces a new extragradient-type algorithm for a class of
nonconvex-nonconcave minimax problems. It is well-known that ﬁnding a local
solution for general minimax problems is computationally intractable. This ob-
servation has recently motivated the study of structures suﬃcient for convergence
of ﬁrst order methods in the more general setting of variational inequalities when
the so-called weak Minty variational inequality (MVI) holds. This problem class
captures non-trivial structures as we demonstrate with examples, for which a large
family of existing algorithms provably converge to limit cycles. Our results require
a less restrictive parameter range in the weak MVI compared to what is previously
known, thus extending the applicability of our scheme. The proposed algorithm is
applicable to constrained and regularized problems, and involves an adaptive step-
size allowing for potentially larger stepsizes. Our scheme also converges globally
even in settings where the underlying operator exhibits limit cycles.
1



hal_id    :    hal-03727169



— This paper describes the practical response- and
performance-aware development of online speech enhancement
for an augmented reality (AR) headset that helps a user under-
stand conversations made in real noisy echoic environments (e.g.,
cocktail party). One may use a state-of-the-art blind source sep-
aration method called fast multichannel nonnegative matrix fac-
torization (FastMNMF) that works well in various environments
thanks to its unsupervised nature. Its heavy computational cost,
however, prevents its application to real-time processing. In con-
trast, a supervised beamforming method that uses a deep neural
network (DNN) for estimating spatial information of speech and
noise readily fits real-time processing, but suffers from drastic
performance degradation in mismatched conditions. Given such
complementary characteristics, we propose a dual-process ro-
bust online speech enhancement method based on DNN-based
beamforming with FastMNMF-guided adaptation. FastMNMF
(back end) is performed in a mini-batch style and the noisy and
enhanced speech pairs are used together with the original par-
allel training data for updating the direction-aware DNN (front
end) with backpropagation at a computationally-allowable inter-
val. This method is used with a blind dereverberation method
called weighted prediction error (WPE) for transcribing the
noisy reverberant speech of a speaker, which can be detected
from video or selected by a user’s hand gesture or eye gaze, in
a streaming manner and spatially showing the transcriptions
with an AR technique. Our



hal_id    :    hal-03701451



Cet article présente l’approche de l’équipe TGV lors de sa participation à la tâche de base de DEFT
2022, dont l’objectif était de prédire automatiquement les notes obtenues par des étudiants sur la
base de leurs réponses à des questionnaires. Notre stratégie s’est focalisée sur la mise au point d’une
méthode de classification des questions en fonction du type de réponse qu’elles attendent, de manière
à pouvoir mener une approche différenciée pour chaque type. Nos trois runs ont consisté en une
approche non différenciée, servant de référence, et deux approches différenciées, la première se basant
sur la constitution d’un jeu de caractéristiques et la seconde sur le calcul de TF-IDF et de la fonction
de hashage. Notre objectif premier était ainsi de vérifier si des approches dédiées à chaque type de
questions sont préférables à une approche globale.
ABSTRACT
Team TGV at DEFT 2022 : automatic prediction of students’ grades according to the different
question types.
In this paper we present the work of the TGV team for the DEFT 2022 challenge. We tackled the
base task only, which consists of automatically grading students based on their answers to several
questions. Our strategy consider this task as a classification task with multiple approaches, each being
specific to a question type leading to different types of



hal_id    :    hal-03821095



This paper describes a practical dual-process speech enhance-
ment system that adapts environment-sensitive frame-online
beamforming (front-end) with help from environment-free
block-online source separation (back-end). To use minimum
variance distortionless response (MVDR) beamforming, one
may train a deep neural network (DNN) that estimates time-
frequency masks used for computing the covariance matrices
of sources (speech and noise). Backpropagation-based run-
time adaptation of the DNN was proposed for dealing with the
mismatched training-test conditions. Instead, one may try to
directly estimate the source covariance matrices with a state-of-
the-art blind source separation method called fast multichannel
non-negative matrix factorization (FastMNMF). In practice,
however, neither the DNN nor the FastMNMF can be updated
in a frame-online manner due to its computationally-expensive
iterative nature. Our DNN-free system leverages the posteri-
ors of the latest source spectrograms given by block-online
FastMNMF to derive the current source covariance matrices
for frame-online beamforming. The evaluation shows that our
frame-online system can quickly respond to scene changes
caused by interfering speaker movements and outperformed
an existing block-online system with DNN-based beamform-
ing by 5.0 points in terms of the word error rate.
Index Terms— speech enhancement, beamforming, blind
source separation, automatic speech recognition



hal_id    :    hal-03727181



This paper describes noisy speech recognition for an augmented
reality headset that helps verbal communication with in real mul-
tiparty conversational environments. A major approach that has
actively been studied in simulated environments is to sequentially
perform speech enhancement and automatic speech recognition
(ASR) based on deep neural networks (DNNs) trained in a su-
pervised manner. In our task, however, such a pretrained system
fails to work due to the mismatch between the training and test
conditions and the head movements of the user. To enhance only
the utterances of a target speaker, we use beamforming based on
a DNN-based speech mask estimator that can adaptively extract
the speech components corresponding to a head-relative particu-
lar direction. We propose a semi-supervised adaptation method
that jointly updates the mask estimator and the ASR model at
run-time using clean speech signals with ground-truth transcrip-
tions and noisy speech signals with highly-confident estimated
transcriptions. Comparative experiments using the state-of-the-
art distant speech recognition system show that the proposed
method significantly improves the ASR performance.
Index Terms: speech enhancement, speech recognition, human-
computer interaction, run-time adaptation.



hal_id    :    hal-03574595



Spoken dialog systems need to be able to han-
dle both multiple languages and multilingual-
ity inside a conversation (e.g in case of code-
switching). In this work, we introduce new
pretraining losses tailored to learn multilingual
spoken dialog representations.
The goal of
these losses is to expose the model to code-
switched language. To scale up training, we
automatically build a pretraining corpus com-
posed of multilingual conversations in ﬁve dif-
ferent languages (French, Italian, English, Ger-
man and Spanish) from OpenSubtitles, a
huge multilingual corpus composed of 24.3G
tokens. We test the generic representations on
MIAM, a new benchmark composed of ﬁve di-
alog act corpora on the same aforementioned
languages as well as on two novel multilingual
downstream tasks (i.e multilingual mask utter-
ance retrieval and multilingual inconsistency
identiﬁcation). Our experiments show that our
new code switched-inspired losses achieve a
better performance in both monolingual and
multilingual settings.
1



hal_id    :    hal-03344680



Several recent studies on dyadic human-
human interactions have been done on con-
versations without speciﬁc business objectives.
However, many companies might beneﬁt from
studies dedicated to more precise environ-
ments such as after sales services or customer
satisfaction surveys. In this work, we place
ourselves in the scope of a live chat customer
service in which we want to detect emotions
and their evolution in the conversation ﬂow.
This context leads to multiple challenges that
range from exploiting restricted, small and
mostly unlabeled datasets to ﬁnding and adapt-
ing methods for such context.
We tackle
these challenges by using Few-Shot Learning
while making the hypothesis it can serve con-
versational emotion classiﬁcation for different
languages and sparse labels.
We contribute
by proposing a variation of Prototypical Net-
works for sequence labeling in conversation
that we name ProtoSeq. We test this method
on two datasets with different languages: daily
conversations in English and customer service
chat conversations in French. When applied
to emotion classiﬁcation in conversations, our
method proved to be competitive even when
compared to other ones. The code for Proto-
Seq is available at https://github.com/
gguibon/ProtoSeq.
1



hal_id    :    hal-03574609



Multimodal sentiment analysis is a trending
area of research, and the multimodal fusion
is one of its most active topic. Acknowledg-
ing humans communicate through a variety of
channels (i.e visual, acoustic, linguistic), mul-
timodal systems aim at integrating different
unimodal representations into a synthetic one.
So far, a consequent effort has been made on
developing complex architectures allowing the
fusion of these modalities. However, such sys-
tems are mainly trained by minimising sim-
ple losses such as L1 or cross-entropy.
In
this work, we investigate unexplored penalties
and propose a set of new objectives that mea-
sure the dependency between modalities. We
demonstrate that our new penalties lead to a
consistent improvement (up to 4.3 on accu-
racy) across a large variety of state-of-the-art
models on two well-known sentiment analysis
datasets: CMU-MOSI and CMU-MOSEI. Our
method not only achieves a new SOTA on both
datasets but also produces representations that
are more robust to modality drops. Finally, a
by-product of our methods includes a statisti-
cal network which can be used to interpret the
high dimensional representations learnt by the
model.
1



hal_id    :    hal-03329932



—Analog-to-feature (A2F) conversion is an acquisition
method thought for IoT devices in order to increase wireless
sensor’s battery life. The operating principle of A2F is to
perform classification tasks at sub-Nyquist rate, by extracting
relevant features in the analog domain and then performing
the classification step in the digital domain. We propose to use
non-uniform wavelet sampling (NUWS) combined with feature
selection to find and extract from the signal, a small set of relevant
features for electrocardiogram (ECG) anomalies detection. A
CMOS 0.18 µm mixed architecture for NUWS feature extraction
is proposed, to obtain a power consumption model for A2F.
This model can be taken into account in the feature selection
step by evaluating the energy cost of each wavelet and then
try to maximize classification accuracy while minimizing the
energy needed for extraction. We demonstrate the benefits of A2F
showing that the energy needed can be divided by 15 compared
to classical approach.
Index Terms—Analog-to-Feature converter, Bio-sensing ac-
quisition, Feature selection, Low power, Non-Uniform Wavelet
Sampling.



hal_id    :    hal-03409892



Emergent states are behavioral, cognitive and affective processes ap-
pearing among the members of a group when they interact together.
In the last decade, the development of computational approaches
received a growing interest in building Human-Centered systems.
Such a development is particularly difficult because some of these
states have several dimensions interplaying somehow and some-
where over time. In this paper, we focus on cohesion, its dimensions
and their interplay. Several definitions of cohesion exist, it can be
simply defined as the tendency of a group to stick together to pursue
goals and/or affective needs. This plethora of definitions resulted in
many different cohesion dimensions. Social and Task dimensions
are the most investigated both in Social Sciences and Computer
Science since they both play an important role in a wide range of
contexts and groups. To the best of our knowledge, however, no pre-
vious work on the prediction of cohesion dynamics focused on how
these 2 dimensions interplay. We leverage Social Sciences to address
this issue. In particular, we take advantage of the importance of
Social cohesion for creating flexible and constructive relationships
to reinforce Task cohesion. We describe a Deep Neural Network
architecture (DNN) for predicting the dynamics of Task cohesion
by applying transfer learning from a pre-trained model dedicated
to the prediction of Social cohesion dynamics. Our architecture
is



hal_id    :    hal-03167498



—The analysis of load curves collected
from smart meters is a key step for many energy man-
agement tasks ranging from consumption forecasting
to customers characterization and load monitoring.
In this contribution, we propose a model based on a
functional formulation of nonnegative tensor factor-
ization and derive updates for the corresponding opti-
mization problem. We show on the concrete example
of multi-sites load curves disaggregation how this
formulation is helpful for 1) exhibiting smooth intra-
day consumption patterns and 2) taking into account
external variables such as the outside temperature.
The beneﬁts are demonstrated on simulated and real
data by exhibiting a meaningful clustering of the
observed sites based on the obtained decomposition.



hal_id    :    hal-03563675



In this paper, we place ourselves in a classi-
ﬁcation scenario in which the target classes
and data type are not accessible during train-
ing. We use a meta-learning approach to de-
termine whether or not meta-trained informa-
tion from common social network data with
ﬁne-grained emotion labels can achieve com-
petitive performance on messages labeled with
different emotion categories. We leverage few-
shot learning to match with the classiﬁcation
scenario and consider metric learning based
meta-learning by setting up Prototypical Net-
works with a Transformer encoder, trained in
an episodic fashion.
This approach proves
to be effective for capturing meta-information
from a source emotional tag set to predict pre-
viously unseen emotional tags. Even though
shifting the data type triggers an expected per-
formance drop, our meta-learning approach
achieves decent results when compared to the
fully supervised one.
1



hal_id    :    hal-02985794



Speech separation with several speakers is a challenging task be-
cause of the non-stationarity of the speech and the strong signal
similarity between interferent sources. Current state-of-the-art so-
lutions can separate well the different sources using sophisticated
deep neural networks which are very tedious to train. When several
microphones are available, spatial information can be exploited to
design much simpler algorithms to discriminate speakers. We pro-
pose a distributed algorithm that can process spatial information in
a spatially unconstrained microphone array. The algorithm relies on
a convolutional recurrent neural network that can exploit the signal
diversity from the distributed nodes. In a typical case of a meeting
room, this algorithm can capture an estimate of each source in a ﬁrst
step and propagate it over the microphone array in order to increase
the separation performance in a second step. We show that this ap-
proach performs even better when the number of sources and nodes
increases. We also study the inﬂuence of a mismatch in the number
of sources between the training and testing conditions.
Index Terms— Speech separation, microphone arrays, dis-
tributed processing.



hal_id    :    hal-03265871



Dans cet article nous reproduisons un scénario d’apprentissage selon lequel les données cibles
ne sont pas accessibles et seules des données connexes le sont. Nous utilisons une approche par
méta-apprentissage aﬁn de déterminer si les méta-informations apprises à partir de messages issus
de médias sociaux, ﬁnement annotés en émotions, peuvent produire de bonnes performances une
fois utilisées sur des messages issus de conversations, étiquetés en émotions avec une granularité
différente. Nous mettons à proﬁt l’apprentissage sur quelques exemples (few-shot learning) pour la
mise en place de ce scénario. Cette approche se montre efﬁcace pour capturer les méta-informations
d’un jeu d’étiquettes émotionnelles pour prédire des étiquettes jusqu’alors inconnues au modèle. Bien
que le fait de varier le type de données engendre une baisse de performance, notre approche par
méta-apprentissage atteint des résultats décents comparés au référentiel d’apprentissage supervisé.
ABSTRACT
Meta-learning : Classifying Messages into Unseen Emotional Categories
In this paper, we place ourselves in a classiﬁcation scenario in which the target data set classes and
data type are not accessible during training. We use a meta-learning approach to determine whether
or not meta-trained information from common social network data with ﬁne-grained emotion labels
can achieve competitive performance on conversation utterances labeled with different, higher level,
emotions. We leverage few-shot learning to concur with the classiﬁcation scenario. This



hal_id    :    hal-02429681



Discrete time trawl processes constitute a large class of time series parameterized by a
trawl sequence (aj)j∈N and deﬁned though a sequence of independent and identically
distributed (i.i.d.) copies of a continuous time process (γ(t))t∈R called the seed process.
They provide a general framework for modeling linear or non-linear long range dependent
time series. We investigate the spectral estimation, either pointwise or broadband, of long
range dependent discrete-time trawl processes. The diﬃculty arising from the variety of
seed processes and of trawl sequences is twofold. First, the spectral density may take
diﬀerent forms, often including smooth additive correction terms. Second, trawl processes
with similar spectral densities may exhibit very diﬀerent statistical behaviors. We prove
the consistency of our estimators under very general conditions and we show that a wide
class of trawl processes satisfy them. This is done in particular by introducing a weighted
weak dependence index that can be of independent interest.
The broadband spectral
estimator includes an estimator of the long memory parameter. We complete this work
with numerical experiments to evaluate the ﬁnite sample size performance of this estimator
for various integer valued discrete time trawl processes.
Keywords: trawl processes; integer-valued time series; long memory parameter estimation
MSC: 62M10; 62F12; 60G51;
1



hal_id    :    hal-03189235



Data depth is a concept in multivariate statistics that measures the centrality
of a point in a given data cloud in Rd. If the depth of a point can be represented
as the minimum of the depths with respect to all one-dimensional projections
of the data, then the depth satisﬁes the so-called projection property. Such
depths form an important class that includes many of the depths that have
been proposed in literature. For depths that satisfy the projection property an
approximate algorithm can easily be constructed since taking the minimum of
the depths with respect to only a ﬁnite number of one-dimensional projections
yields an upper bound for the depth with respect to the multivariate data. Such
an algorithm is particularly useful if no exact algorithm exists or if the exact
algorithm has a high computational complexity, as is the case with the halfspace
depth or the projection depth. To compute these depths in high dimensions,
the use of an approximate algorithm with better complexity is surely preferable.
Instead of focusing on a single method we provide a comprehensive and fair
comparison of several methods, both already described in the literature and
original.
Keywords:
data depth, projection property, approximate computation,
∗Corresponding author
Email addresses: rainer.dyckerhoff@statistik.uni-koeln.de (Rainer Dyckerhoﬀ),
pavlo.mozharovskyi@telecom-paris.fr (Pavlo Mozharovskyi), nagy@karlin.mff.cuni.cz
(Stanislav Nagy)
Preprint submitted to Computational Statistics and Data Analysis
November 20,



hal_id    :    hal-02088860



. In this contribution we are interested in proving that a given
observation-driven model is identiﬁable. In the case of a GARCH(p, q) model,
a simple suﬃcient condition has been established in [2] for showing the consis-
tency of the quasi-maximum likelihood estimator. It turns out that this condi-
tion applies for a much larger class of observation-driven models, that we call
the class of linearly observation-driven models. This class includes standard in-
teger valued observation-driven time series such as the Poisson autoregression
model and its numerous extensions. Our results also apply to vector-valued
time series such as the bivariate integer valued GARCH model, to non-linear
models such as the threshold Poisson autoregression or to observation-driven
models with exogenous covariates such as the PARX model.



hal_id    :    hal-03188029



John W. Tukey (1975) deﬁned statistical data depth as a function that determines centrality of
an arbitrary point with respect to a data cloud or to a probability measure. During the last decades,
this seminal idea of data depth evolved into a powerful tool proving to be useful in various ﬁelds
of science. Recently, extending the notion of data depth to the functional setting attracted a lot
of attention among theoretical and applied statisticians. We go further and suggest a notion of
data depth suitable for data represented as curves, or trajectories, which is independent of the
parametrization. We show that our curve depth satisﬁes theoretical requirements of general depth
functions that are meaningful for trajectories. We apply our methodology to diffusion tensor
brain images and also to pattern recognition of hand written digits and letters. Supplementary
Materials are available online.
Keywords: data depth, space of curves, unparametrized curves, nonparametric statistics,
curve registration, DT-MRI ﬁbers, classiﬁcation, DD-plot.
1



hal_id    :    hal-02933051



Screening rules were recently introduced as a technique for explicitly
identifying active structures such as sparsity, in optimization problem
arising in machine learning. This has led to new methods of acceleration
based on a substantial dimension reduction.
We show that screening
rules stem from a combination of natural properties of subdiﬀerential sets
and optimality conditions, and can hence be understood in a uniﬁed way.
Under mild assumptions, we analyze the number of iterations needed to
identify the optimal active set for any converging algorithm. We show that
it only depends on its convergence rate.
1



hal_id    :    hal-03134854



While being an essential component
of spoken language, ﬁllers (e.g. “um”
or “uh”) often remain overlooked in
Spoken Language Understanding (SLU)
tasks.
We explore the possibility of
representing them with deep contex-
tualised embeddings, showing improve-
ments on modelling spoken language
and two downstream tasks — predict-
ing a speaker’s stance and expressed
conﬁdence.
1



hal_id    :    hal-02934433



Music tags are commonly used to describe and catego-
rize music. Various auto-tagging models and datasets have
been proposed for the automatic music annotation with
tags. However, the past approaches often neglect the fact
that many of these tags largely depend on the user, espe-
cially the tags related to the context of music listening. In
this paper, we address this problem by proposing a user-
aware music auto-tagging system and evaluation protocol.
Speciﬁcally, we use both the audio content and user infor-
mation extracted from the user listening history to predict
contextual tags for a given user/track pair. We propose a
new dataset of music tracks annotated with contextual tags
per user. We compare our model to the traditional audio-
based model and study the inﬂuence of user embeddings
on the classiﬁcation quality. Our work shows that explic-
itly modeling the user listening history into the automatic
tagging process could lead to more accurate estimation of
contextual tags.



hal_id    :    hal-02507316



.
We present a framework for deﬁning the “right” level of
explainability based on technical, legal and economic considerations.
Our approach involves three logical steps: First, deﬁne the main con-
textual factors, such as who is the audience of the explanation, the
operational context, the level of harm that the system could cause,
and the legal/regulatory framework. This step will help characterize
the operational and legal needs for explanation, and the correspond-
ing social beneﬁts. Second, examine the technical tools available,
including post-hoc approaches (input perturbation, saliency maps...)
and hybrid AI approaches. Third, as function of the ﬁrst two steps,
choose the right levels of global and local explanation outputs, taking
into the account the costs involved. We identify seven kinds of costs
and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1



hal_id    :    hal-03132996



With the ubiquity of sensors in the IoT era,
statistical observations are becoming increas-
ingly available in the form of massive (multi-
variate) time-series. Formulated as unsuper-
vised anomaly detection tasks, an abundance
of applications like aviation safety manage-
ment, the health monitoring of complex in-
frastructures or fraud detection can now rely
on such functional data, acquired and stored
with an ever ﬁner granularity. The concept
of statistical depth, which reﬂects centrality
of an arbitrary observation w.r.t. a statisti-
cal population may play a crucial role in this
regard, anomalies corresponding to observa-
tions with ’small’ depth. Supported by sound
theoretical and computational developments
in the recent decades, it has proven to be
extremely useful, in particular in functional
spaces.
However, most approaches docu-
mented in the literature consist in evaluat-
ing independently the centrality of each point
forming the time series and consequently ex-
hibit a certain insensitivity to possible shape
changes. In this paper, we propose a novel
notion of functional depth based on the area
of the convex hull of sampled curves, captur-
ing gradual departures from centrality, even
beyond the envelope of the data, in a nat-
ural fashion. We discuss practical relevance
of commonly imposed axioms on functional
depths and investigate which of them are sat-
isﬁed by the notion of depth we promote here.
Estimation and computational issues are also
addressed and various numerical experiments
provide empirical evidence



hal_id    :    hal-02547012



The problem of multi-label classification with missing labels (MLML)
is a common challenge that is prevalent in several domains, e.g.
image annotation and auto-tagging. In multi-label classification,
each instance may belong to multiple class labels simultaneously.
Due to the nature of the dataset collection and labelling proce-
dure, it is common to have incomplete annotations in the dataset,
i.e. not all samples are labelled with all the corresponding labels.
However, the incomplete data labelling hinders the training of clas-
sification models. MLML has received much attention from the
research community. However, in cases where a pre-trained model
is fine-tuned on an MLML dataset, there has been no straightfor-
ward approach to tackle the missing labels, specifically when there
is no information about which are the missing ones. In this paper,
we propose a weighted loss function to account for the confidence
in each label/sample pair that can easily be incorporated to fine-
tune a pre-trained model on an incomplete dataset. Our experiment
results show that using the proposed loss function improves the
performance of the model as the ratio of missing labels increases.
CCS CONCEPTS
• Computing methodologies →Neural networks.
KEYWORDS
Multi-label classification; missing labels; neural networks
ACM Reference Format:
Karim M. Ibrahim, Elena V. Epure, Geoffroy Peeters, and Gaël Richard. 2020.
Confidence-based Weighted Loss for Multi-label Classification with Missing
Labels. In Proceedings of the



hal_id    :    hal-02481374



Music listening context such as location or activity has been shown
to greatly inﬂuence the users’ musical tastes. In this work, we study
the relationship between user context and audio content in order to
enable context-aware music recommendation agnostic to user data.
For that, we propose a semi-automatic procedure to collect track sets
which leverages playlist titles as a proxy for context labelling. Using
this, we create and release a dataset of ∼50k tracks labelled with
15 different contexts. Then, we present benchmark classiﬁcation
results on the created dataset using an audio auto-tagging model. As
the training and evaluation of these models are impacted by missing
negative labels due to incomplete annotations, we propose a sample-
level weighted cross entropy loss to account for the conﬁdence in
missing labels and show improved context prediction results.
Index Terms— music auto-tagging, user context, dataset col-
lection, multi-label classiﬁcation, missing labels.



hal_id    :    hal-02389159



Multichannel processing is widely used for speech enhancement but
several limitations appear when trying to deploy these solutions in
the real world. Distributed sensor arrays that consider several de-
vices with a few microphones is a viable solution which allows for
exploiting the multiple devices equipped with microphones that we
are using in our everyday life. In this context, we propose to extend
the distributed adaptive node-speciﬁc signal estimation approach to
a neural network framework. At each node, a local ﬁltering is per-
formed to send one signal to the other nodes where a mask is esti-
mated by a neural network in order to compute a global multichan-
nel Wiener ﬁlter. In an array of two nodes, we show that this addi-
tional signal can be leveraged to predict the masks and leads to better
speech enhancement performance than when the mask estimation re-
lies only on the local signals.
Index Terms— Speech enhancement, microphone arrays, dis-
tributed processing.



hal_id    :    hal-02914840



The principle of compositionality, which enables natural language to represent
complex concepts via a structured combination of simpler ones, allows us to con-
vey an open-ended set of messages using a limited vocabulary. If compositionality
is indeed a natural property of language, we may expect it to appear in commu-
nication protocols that are created by neural agents in language games. In this
paper, we propose an effective neural iterated learning (NIL) algorithm that, when
applied to interacting neural agents, facilitates the emergence of a more structured
type of language. Indeed, these languages provide learning speed advantages to
neural agents during training, which can be incrementally ampliﬁed via NIL. We
provide a probabilistic model of NIL and an explanation of why the advantage
of compositional language exist. Our experiments conﬁrm our analysis, and also
demonstrate that the emerged languages largely improve the generalizing power
of the neural agent communication.
1



hal_id    :    hal-02506409



The recent enthusiasm for artiﬁcial intelligence (AI) is due principally to
advances in deep learning. Deep learning methods are remarkably accurate,
but also opaque, which limits their potential use in safety-critical applications.
To achieve trust and accountability, designers and operators of machine learn-
ing algorithms must be able to explain the inner workings, the results and the
causes of failures of algorithms to users, regulators, and citizens. The orig-
inality of this paper is to combine technical, legal and economic aspects of
explainability to develop a framework for deﬁning the ”right” level of explain-
ability in a given context. We propose three logical steps: First, deﬁne the
main contextual factors, such as who the audience of the explanation is, the
operational context, the level of harm that the system could cause, and the
legal/regulatory framework. This step will help characterize the operational
and legal needs for explanation, and the corresponding social beneﬁts. Second,
examine the technical tools available, including post hoc approaches (input
perturbation, saliency maps...) and hybrid AI approaches. Third, as function
of the ﬁrst two steps, choose the right levels of global and local explanation
outputs, taking into the account the costs involved. We identify seven kinds
of costs and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1We would like to



hal_id    :    hal-01440269



We present single imputation method for missing values which borrows the idea of data  
depth—a measure of centrality defined for an arbitrary point of a space with respect to a prob- 
ability distribution or data cloud. This consists in iterative maximization of the depth of each 
observation with missing values, and can be employed with any properly defined statistical depth 
function. For each single iteration, imputation reverts to optimization of quadratic, linear, or 
quasiconcave functions that are solved analytically by linear programming or the Nelder-Mead 
method. As it accounts for the underlying data topology, the procedure is distribution free, allows 
imputation close to the data geometry, can make prediction in situations where local imputation 
(k-nearest neighbors, random forest) cannot, and has attractive robustness and asymptotic prop- 
erties under elliptical symmetry. It is shown that a special case—when using the Mahalanobis 
depth—has direct connection to well-known methods for the multivariate normal model, such as 
iterated regression and regularized PCA. The methodology is extended to multiple imputation for 
data stemming from an elliptically symmetric distribution. Simulation and real data studies show 
good results compared with existing popular alternatives. The method has been implemented as 
an R-package. Supplementary materials for the article



hal_id    :    hal-02433213



Source separation aims at decomposing a vector into additive components. This
is often done by ﬁrst estimating source parameters before feeding them into a
ﬁltering method, often based on ratios of covariances. The whole pipeline is
traditionally rooted in some probabilistic framework providing both the likeli-
hood for parameter estimation and the separation method. While Gaussians
are ubiquitous for this purpose, many studies showed the beneﬁt of heavy-tailed
models for estimation. However, there is no counterpart ﬁltering method to date
exploiting such formalism, so that related studies revert to covariance-based ﬁl-
tering after estimation is ﬁnished.
Here, we introduce a new multivariate separation technique, that fully ex-
ploits the ﬂexibility of α-stable heavy-tailed distributions. We show how a spa-
tial representation can be exploited, which decomposes the observation as an
inﬁnite sum of contributions originating from all directions. Two methods for
separation are derived. The ﬁrst one is non-linear and similar to a beamforming
technique, while the second one is linear, but minimizes a covariation criterion,
which is the counterpart of the covariance for α-stable vectors. We evaluate the
proposed techniques in a large number of challenging and adverse situations on
synthetic experiments, demonstrating their performance for the extraction of
signals from strong interferences.
Keywords:
alpha-stable distribution, separation theory, additive models,
measure theory, optimization
$This work was partly supported by the research



hal_id    :    hal-01502252



Locally stationary Hawkes processes have been introduced in order to generalise clas-
sical Hawkes processes away from stationarity by allowing for a time-varying second-order
structure. This class of self-exciting point processes has recently attracted a lot of inter-
est in applications in the life sciences (seismology, genomics, neuro-science,...), but also
in the modeling of high-frequency ﬁnancial data. In this contribution we provide a fully
developed nonparametric estimation theory of both local mean density and local Bartlett
spectra of a locally stationary Hawkes process. In particular we apply our kernel estima-
tion of the spectrum localised both in time and frequency to two data sets of transaction
times revealing pertinent features in the data that had not been made visible by classical
non-localised approaches based on models with constant fertility functions over time.
Keywords: Time frequency analysis; Locally stationary time series; high frequency ﬁ-
nancial data; Non-parametric kernel estimation; Self-exciting point processes.
1



hal_id    :    hal-01497104



This paper introduces a randomized coordinate descent version of the V˜u-Condat algorithm.
By
coordinate descent, we mean that only a subset of the coordinates of the primal and dual iterates is
updated at each iteration, the other coordinates being maintained to their past value.
Our method
allows us to solve optimization problems with a combination of diﬀerentiable functions, constraints as
well as non-separable and non-diﬀerentiable regularizers.
We show that the sequences generated by our algorithm almost surely converge to a saddle point
of the problem at stake, for a wider range of parameter values than previous methods. In particular,
the condition on the step-sizes depends on the coordinate-wise Lipschitz constant of the diﬀerentiable
function’s gradient, which is a major feature allowing classical coordinate descent to perform so well when
it is applicable. We then prove a sublinear rate of convergence in general and a linear rate of convergence
if the objective enjoys strong convexity properties.
We illustrate the performances of the algorithm on a total-variation regularized least squares regression
problem and on large scale support vector machine problems.
1



hal_id    :    hal-02369435



For the purpose of monitoring the behavior of complex infrastructures (e.g.
aircrafts,
transport or energy networks), high-rate sensors are deployed to capture multivariate data,
generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anoma-
lies that may jeopardize the smooth operation of the system of interest. The statistical
analysis of such massive data of functional nature raises many challenging methodological
questions. The primary goal of this paper is to extend the popular Isolation Forest (IF)
approach to Anomaly Detection, originally dedicated to ﬁnite dimensional observations, to
functional data. The major diﬃculty lies in the wide variety of topological structures that
may equip a space of functions and the great variety of patterns that may characterize
abnormal curves.
We address the issue of (randomly) splitting the functional space in
a ﬂexible manner in order to isolate progressively any trajectory from the others, a key
ingredient to the eﬃciency of the algorithm. Beyond a detailed description of the algo-
rithm, computational complexity and stability issues are investigated at length. From the
scoring function measuring the degree of abnormality of an observation provided by the
proposed variant of the IF algorithm, a Functional Statistical Depth function is deﬁned and
discussed, as well as a multivariate functional extension. Numerical experiments provide
strong empirical evidence of the accuracy of the extension



hal_id    :    hal-02420416



In this paper, we address how to evaluate and improve the perfor-
mance of automatic dominant melody extraction systems from a
pattern mining perspective with a focus on jazz improvisations.
Traditionally, dominant melody extraction systems estimate the
melody on the frame-level, but for real-world musicological appli-
cations note-level representations are needed. For the evaluation of
estimated note tracks, the current frame-wise metrics are not fully
suitable and provide at most a first approximation. Furthermore,
mining melodic patterns (n-grams) poses another challenge because
note-wise errors propagate geometrically with increasing length of
the pattern. On the other hand, for certain derived metrics such as
pattern commonalities between performers, extraction errors might
be less critical if at least qualitative rankings can be reproduced.
Finally, while searching for similar patterns in a melody database
the number of irrelevant patterns in the result set increases with
lower similarity thresholds. For reasons of usability, it would be in-
teresting to know the behavior using imperfect automated melody
extractions. We propose three novel evaluation strategies for es-
timated note-tracks based on three application scenarios: Pattern
mining, pattern commonalities, and fuzzy pattern search. We apply
the proposed metrics to one general state-of-the-art melody esti-
mation method (Melodia) and to two variants of an algorithm that
was optimized for the extraction of jazz solos melodies. A subset of
the Weimar Jazz Database



hal_id    :    hal-02943462



In the last few years, several datasets have been released
to meet the requirements of “hungry” yet promising data-
driven approaches in music technology research. Since,
for historical reasons, most investigations conducted in the
ﬁeld still revolve around music of the so-called “West-
ern” tradition, the corresponding data, methodology and
conclusions carry a strong cultural bias. Music of non-
“Western” background, whenever present, is usually un-
derrepresented, poorly labeled, or even mislabeled, the
exception being projects that aim at speciﬁcally describ-
ing such music. In this paper we present SAMBASET,
a dataset of Brazilian samba music that contains over
40 hours of historical and modern samba de enredo com-
mercial recordings. To the best of our knowledge, this is
the ﬁrst dataset of this genre. We describe the collection of
metadata (e.g. artist, composer, release date) and outline
our semiautomatic approach to the challenging task of an-
notating beats in this large dataset, which includes the as-
sessment of the performance of state-of-the-art beat track-
ing algorithms for this speciﬁc case. Finally, we present
a study on tempo and beat tracking that illustrates SAM-
BASET’s value, and we comment on other tasks for which
it could be used.



hal_id    :    hal-02166428



. The development of cluster computing frameworks has al-
lowed practitioners to scale out various statistical estimation and ma-
chine learning algorithms with minimal programming eﬀort. This is es-
pecially true for machine learning problems whose objective function
is nicely separable across individual data points, such as classiﬁcation
and regression. In contrast, statistical learning tasks involving pairs (or
more generally tuples) of data points — such as metric learning, clus-
tering or ranking — do not lend themselves as easily to data-parallelism
and in-memory computing. In this paper, we investigate how to bal-
ance between statistical performance and computational eﬃciency in
such distributed tuplewise statistical problems. We ﬁrst propose a sim-
ple strategy based on occasionally repartitioning data across workers
between parallel computation stages, where the number of repartition-
ing steps rules the trade-oﬀbetween accuracy and runtime. We then
present some theoretical results highlighting the beneﬁts brought by the
proposed method in terms of variance reduction, and extend our results
to design distributed stochastic gradient descent algorithms for tuplewise
empirical risk minimization. Our results are supported by numerical ex-
periments in pairwise statistical estimation and learning on synthetic and
real-world datasets.
Keywords: Distributed Machine Learning · Distributed Data Process-
ing · U-Statistics · Stochastic Gradient Descent · AUC Optimization
1



hal_id    :    hal-02288063



—We propose a semi-supervised multichannel speech
enhancement system based on a probabilistic model which as-
sumes that both speech and noise follow the heavy-tailed multi-
variate complex Cauchy distribution. As we advocate, this allows
handling strong and adverse noisy conditions. Consequently, the
model is parameterized by the source magnitude spectrograms
and the source spatial scatter matrices. To deal with the non-
additivity of scatter matrices, our ﬁrst contribution is to perform
the enhancement on a projected space. Then, our second contri-
bution is to combine a latent variable model for speech, which
is trained by following the variational autoencoder framework,
with a low-rank model for the noise source. At test time, an it-
erative inference algorithm is applied, which produces estimated
parameters to use for separation. The speech latent variables are
estimated ﬁrst from the noisy speech and then updated by a gra-
dient descent method, while a majorization-equalization strategy
is used to update both the noise and the spatial parameters of
both sources. Our experimental results show that the Cauchy
model outperforms the state-of-art methods. The standard devi-
ation scores also reveal that the proposed method is more robust
against non-stationary noise.
Index Terms—Multichannel speech enhancement, multivariate
complex Cauchy distribution, variational autoencoder, nonnega-
tive matrix factorization



hal_id    :    hal-01900037



Popular machine learning estimators involve
regularization parameters that can be chal-
lenging to tune, and standard strategies rely
on grid search for this task. In this paper,
we revisit the techniques of approximating
the regularization path up to predeﬁned tol-
erance ϵ in a uniﬁed framework and show
that its complexity is O(1/ d√ϵ) for uniformly
convex loss of order d > 0 and O(1/√ϵ)
for Generalized Self-Concordant functions.
This framework encompasses least-squares
but also logistic regression (a case that as far
as we know was not handled as precisely by
previous works). We leverage our technique
to provide reﬁned bounds on the validation
error as well as a practical algorithm for hy-
perparameter tuning.
The later has global
convergence guarantee when targeting a pre-
scribed accuracy on the validation set. Last
but not least, our approach helps relieving
the practitioner from the (often neglected)
task of selecting a stopping criterion when
optimizing over the training set: our method
automatically calibrates it based on the tar-
geted accuracy on the validation set.
1



hal_id    :    hal-02303823



No abstract found in the PDF.



hal_id    :    hal-02912385



Noise-Contrastive Estimation (NCE) is a learning criterion that is regularly used to train neural
language models in place of Maximum Likelihood Estimation, since it avoids the computational
bottleneck caused by the output softmax. In this paper, we analyse and explain some of the
weaknesses of this objective function, linked to the mechanism of self-normalization, by closely
monitoring comparative experiments. We then explore several remedies and modiﬁcations to
propose tractable and efﬁcient NCE training strategies. In particular, we propose to make the
scaling factor a trainable parameter of the model, and to use the noise distribution to initialize the
output bias. These solutions, yet simple, yield stable and competitive performances in either small
and large scale language modelling tasks.
1



hal_id    :    lirmm-01766795



. This paper introduces a new method for multichannel speech
enhancement based on a versatile modeling of the residual noise spec-
trogram. Such a model has already been presented before in the single
channel case where the noise component is assumed to follow an alpha-
stable distribution for each time-frequency bin, whereas the speech spec-
trogram, supposed to be more regular, is modeled as Gaussian. In this
paper, we describe a multichannel extension of this model, as well as
a Monte Carlo Expectation - Maximisation algorithm for parameter es-
timation. In particular, a multichannel extension of the Itakura-Saito
nonnegative matrix factorization is exploited to estimate the spectral
parameters for speech, and a Metropolis-Hastings algorithm is proposed
to estimate the noise contribution. We evaluate the proposed method in
a challenging multichannel denoising application and compare it to other
state-of-the-art algorithms.
1



hal_id    :    hal-02912471



L’estimation contrastive bruitée (NCE) et l’échantillonage par importance (IS) sont des procédures
d’entraînement basées sur l’échantillonage, que l’on utilise habituellement à la place de l’estimation
du maximum de vraisemblance (MLE) pour éviter le calcul du softmax lorsque l’on entraîne des
modèles de langue neuronaux. Dans cet article, nous cherchons à résumer le fonctionnement de ces
algorithmes, et leur utilisation dans la littérature du TAL. Nous les comparons expérimentalement, et
présentons des manières de faciliter l’entraînement du NCE.
ABSTRACT
Here the title in English.
Noise Contrastive Estimation (NCE) and Importance Sampling (IS) are sampling based algorithms
traditionally used to avoid computing the costly output softmax when training neural language models
with Maximum Likelihood Estimation (MLE). In this work, we attempt to summarize how these
procedures work, and how they have been used in the computational linguistics literature. We then
compare them, and experiment with tricks that ease NCE training.
MOTS-CLÉS : Modèle de langue, Estimation contrastive bruitée, Negative Sampling.
KEYWORDS: Neural Language Model, Noise Contrastive Estimation, Negative Sampling.



hal_id    :    hal-01812011



In high dimension, it is customary to consider
Lasso-type estimators to enforce sparsity. For
standard Lasso theory to hold, the regulariza-
tion parameter should be proportional to the
noise level, which is often unknown in prac-
tice. A remedy is to consider estimators such
as the Concomitant Lasso, which jointly opti-
mize over the regression coeﬃcients and the
noise level. However, when data from diﬀer-
ent sources are pooled to increase sample size,
noise levels diﬀer and new dedicated estima-
tors are needed. We provide new statistical
and computational solutions to perform het-
eroscedastic regression, with an emphasis on
brain imaging with magneto- and electroen-
cephalography (M/EEG). When instantiated
to de-correlated noise, our framework leads to
an eﬃcient algorithm whose computational
cost is not higher than for the Lasso, but ad-
dresses more complex noise structures. Ex-
periments demonstrate improved prediction
and support identiﬁcation with correct esti-
mation of noise levels.
1



hal_id    :    hal-01269137



. In this contribution we introduce weakly locally stationary time series through
the local approximation of the non-stationary covariance structure by a stationary one.
This allows us to deﬁne autoregression coeﬃcients in a non-stationary context, which, in
the particular case of a locally stationary Time Varying Autoregressive (TVAR) process,
coincide with the generating coeﬃcients. We provide and study an estimator of the time
varying autoregression coeﬃcients in a general setting. The proposed estimator of these
coeﬃcients enjoys an optimal minimax convergence rate under limited smoothness condi-
tions. In a second step, using a bias reduction technique, we derive a minimax-rate estima-
tor for arbitrarily smooth time-evolving coeﬃcients, which outperforms the previous one
for large data sets. In turn, for TVAR processes, the predictor derived from the estimator
exhibits an optimal minimax prediction rate.



hal_id    :    hal-01679078



We address the issue of reliably detecting and quantifying cross-frequency coupling (CFC)
in neural time series. Based on non-linear auto-regressive models, the proposed method
provides a generative and parametric model of the time-varying spectral content of the
signals. As this method models the entire spectrum simultaneously, it avoids the pitfalls
related to incorrect filtering or the use of the Hilbert transform on wide-band signals. As the
model is probabilistic, it also provides a score of the model “goodness of fit” via the likeli-
hood, enabling easy and legitimate model selection and parameter comparison; this data-
driven feature is unique to our model-based approach. Using three datasets obtained with
invasive neurophysiological recordings in humans and rodents, we demonstrate that these
models are able to replicate previous results obtained with other metrics, but also reveal
new insights such as the influence of the amplitude of the slow oscillation. Using simulations,
we demonstrate that our parametric method can reveal neural couplings with shorter signals
than non-parametric methods. We also show how the likelihood can be used to find optimal
filtering parameters, suggesting new properties on the spectrum of the driving signal, but
also to estimate the optimal delay between the coupled signals, enabling a directionality esti-
mation in the coupling.
Author summary
Neural oscillations synchronize information across brain areas at



hal_id    :    hal-01404966



No abstract found in the PDF.



hal_id    :    hal-01593459



Leveraging the celebrated support vector regression (SVR) method, we propose a unifying
framework in order to deliver regression machines in reproducing kernel Hilbert spaces
(RKHSs) with data sparsity. The central point is a new deﬁnition of ϵ-insensitivity, valid for
many regression losses (including quantile and expectile regression) and their multivariate
extensions. We show that the dual optimization problem to empirical risk minimization
with ϵ-insensitivity involves a data sparse regularization. We also provide an analysis of
the excess of risk as well as a randomized coordinate descent algorithm for solving the dual.
Numerical experiments validate our approach.
Keywords: Quantile regression, Expectile regression, Operator-valued kernel.



hal_id    :    hal-01548475



While most dereverberation methods focus on how to estimate the
magnitude of an anechoic signal in the time-frequency domain, we
propose a method which also takes the phase into account. By ap-
plying a harmonic model to the anechoic signal, we derive a formu-
lation to compute the amplitude and phase of each harmonic. These
parameters are then estimated by our method in presence of rever-
beration. As we jointly estimate the amplitude and phase of the
clean signal, we achieve a very strong dereverberation on synthetic
harmonic signals, resulting in a signiﬁcant improvement of standard
dereverberation objective measures over the state-of-the-art.
Index Terms— dereverberation, phase, sinusoidal modeling,



hal_id    :    hal-01548508



This paper introduces a new method for single-channel denoising
that sheds new light on classical early developments on this topic
that occurred in the 70’s and 80’s with Wiener ﬁltering and spectral
subtraction. Operating both in the short-time Fourier transform
domain, these methods consist in estimating the power spectral
density (PSD) of the noise without speech. Then, the clean speech
signal is obtained by manipulating the corrupted time-frequency
bins thanks to these noise PSD estimates. Theoretically grounded
when using power spectra, these methods were subsequently gener-
alized to magnitude spectra, or shown to yield better performance
by weighting the PSDs in the so-called parameterized Wiener ﬁlter.
Both these strategies were long considered ad-hoc. To the best
of our knowledge, while we recently proposed an interpretation
of magnitude processing, there is still no theoretical result that
would justify the better performance of parameterized Wiener
ﬁlters. Here, we show how the α-stable probabilistic model for
waveforms naturally leads to these weighted ﬁlters and we provide
a grounded and fast algorithm to enhance corrupted audio that
compares favorably with classical denoising methods.
Index Terms—denoising, Wiener ﬁltering, α-stable processes, prob-
ability theory



hal_id    :    hal-01531259



—While most dereverberation methods focus on how
to estimate the amplitude of an anechoic signal, we propose a
method which also takes the phase into account. By applying a
sinusoidal model to the anechoic signal, we derive a formulation
to compute the amplitude and phase of each sinusoid. These
parameters are then estimated by our method in the reverberant
case. As we jointly estimate the amplitude and phase of the clean
signal, we achieve a very strong dereverberation, resulting in a
signiﬁcant improvement of objective dereverberation measures
over the state-of-the-art.



hal_id    :    hal-01531252



In this paper, we focus on the problem of sound source localization
and we propose a technique that exploits the known and arbitrary
geometry of the microphone array. While most probabilistic tech-
niques presented in the past rely on Gaussian models, we go further
in this direction and detail a method for source localization that is
based on the recently proposed α-stable harmonizable processes.
They include Cauchy and Gaussian as special cases and their
remarkable feature is to allow a simple modeling of impulsive
and real world sounds with few parameters. The approach we
present builds on the classical convolutive mixing model and has
the particularities of requiring going through the data only once,
to also work in the underdetermined case of more sources than
microphones and to allow massively parallelizable implementations
operating in the time-frequency domain. We show that the method
yields interesting performance for acoustic imaging in realistic
simulations.
Index Terms—source localization, acoustic modeling, α-
stable random variables, spectral measure, sketching



hal_id    :    hal-02912472



Cet article propose une architecture neuronale pour un modèle de langue à vocabulaire ouvert. Les
représentations continues des mots sont calculées à la volée à partir des caractères les composant,
gràce à une couche convolutionnelle suivie d’une couche de regroupement (pooling). Cela permet
au modèle de représenter n’importe quel mot, qu’il fasse partie du contexte ou soit évalué pour la
prédiction. La fonction objectif est dérivée de l’estimation contrastive bruitée (Noise Contrastive
Estimation, ou NCE), calculable dans notre cas sans vocabulaire. Nous évaluons la capacité de
notre modèle à construire des représentations continues de mots inconnus sur la tâche de traduction
automatique IWSLT-2016, de l’Anglais vers le Tchèque, en ré-évaluant les N meilleures hypothèses
(N-best reranking). Les résultats expérimentaux permettent des gains jusqu’à 0,7 point BLEU. Ils
montrent aussi la difﬁculté d’utiliser des représentations dérivées des caractères pour la prédiction.
ABSTRACT
Opening the vocabulary of neural language models with character-level word representations
This paper introduces an architecture for an open-vocabulary neural language model. Word represen-
tations are computed on-the-ﬂy by a convolution network followed by pooling layer. This allows the
model to consider any word, in the context or for the prediction. The training objective is derived from
the Noise-Contrastive Estimation to adapt it the open vocabulary case. We test the ability of our model
to



hal_id    :    hal-02395677



- Parkinson’s disease (PD) is a neurological disorder associated 
with a progressive decline in motor skills, speech, and cognitive processes. 
Since the diagnosis of Parkinson’s disease is difficult, researchers have 
worked to develop a support tool based on algorithms to differentiate 
healthy controls from PD patients. Online handwriting analysis is one of 
the methods that can be used to diagnose PD. The aim of this study is to 
find a subset of handwriting features suitable for efficiently identifying 
subjects with PD. Data was taken from PDMultiMC database collected in 
Lebanon, and consisting of 16 medicated PD patients and 16 age matched 
controls. Seven handwriting tasks were collected such as copying patterns, 
copying words in Arabic, and writing full names. For each task kinematic 
and spatio-temporal, pressure, energy, entropy, and intrinsic features were 
extracted. Feature selection was done in two stages, the first stage selected 
a subset using statistical analysis, and the second step select the most 
relevant features of this subset, by a suboptimal approach. The selected 
features were fed to a support vector machine classifier with RBF kernel, 
whose aim is to identify the subjects suffering from PD. The accuracy of 
the classification of PD was as high as



hal_id    :    hal-02912384



Noise Contrastive Estimation (NCE) is a
learning procedure that is regularly used
to train neural language models, since
it avoids the computational bottleneck
caused by the output softmax. In this pa-
per, we attempt to explain some of the
weaknesses of this objective function, and
to draw directions for further develop-
ments. Experiments on a small task show
the issues raised by the unigram noise
distribution, and that a context dependent
noise distribution, such as the bigram dis-
tribution, can solve these issues and pro-
vide stable and data-efﬁcient learning.
1



hal_id    :    hal-01401988



. We propose a probabilistic model for acoustic source local-
ization with known but arbitrary geometry of the microphone array. The
approach has several features. First, it relies on a simple nearﬁeld acous-
tic model for wave propagation. Second, it does not require the number
of active sources. On the contrary, it produces a heat map representing
the energy of a large set of candidate locations, thus imaging the acous-
tic ﬁeld. Second, it relies on a heavy-tail α-stable probabilistic model,
whose most important feature is to yield an estimation strategy where
the multichannel signals need to be processed only once in a simple on-
line procedure, called sketching. This sketching produces a ﬁxed-sized
representation of the data that is then analyzed for localization. The
resulting algorithm has a small computational complexity and in this
paper, we demonstrate that it compares favorably with state of the art
for localization in realistic simulations of reverberant environments.
1



hal_id    :    hal-01272327



Addressing the will to give a more complete picture than an average relationship provided
by standard regression, a novel framework for estimating and predicting simultaneously several
conditional quantiles is introduced. The proposed methodology leverages kernel-based multi-task
learning to curb the embarrassing phenomenon of quantile crossing, with a one-step estimation
procedure and no post-processing. Moreover, this framework comes along with theoretical guaran-
tees and an eﬃcient coordinate descent learning algorithm. Numerical experiments on benchmark
and real datasets highlight the enhancements of our approach regarding the prediction error, the
crossing occurrences and the training time.
1



hal_id    :    hal-01337860



Most dereverberation methods aim to reconstruct the ane-
choic magnitude spectrogram, given a reverberant signal.
Regardless of the method, the dereverberated signal is sys-
tematically synthesized with the reverberant phase.
This
corrupted phase reintroduces reverberation and distortion in
the signal. This is why we intend to also reconstruct the ane-
choic phase, given a reverberant signal. Before processing
speech signals, we propose in this paper a method for esti-
mating the anechoic phase of reverberant chirp signals. Our
method presents an accurate estimation of the instantaneous
phase and improves objective measures of dereverberation.
Index Terms— Dereverberation, phase, reassignment, si-
nusoidal modeling.



hal_id    :    hal-01418963



We propose an efﬁcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in
presence of pileup from a sample of low-frequency observa-
tions. Based on a functional equation linking the marks’ den-
sity to the characteristic function of the observations and its
derivative, we propose a new time-efﬁcient method using B-
splines to estimate the density of the underlying γ-ray spec-
trum which is able to handle large datasets used in nuclear
physics. A discussion on the numerical computation of the al-
gorithm and its performances on simulated data are provided
to support our ﬁndings.
Index Terms— Shot-noise, nonparametric estimation, B-
splines, γ-spectroscopy, pile-up correction



hal_id    :    hal-01347167



We propose a method that performs anomaly
detection and localisation within heterogeneous
data using a pairwise undirected mixed graphical
model. The data are a mixture of categorical and
quantitative variables, and the model is learned
over a dataset that is supposed not to contain any
anomaly. We then use the model over temporal
data, potentially a data stream, using a version of
the two-sided CUSUM algorithm. The proposed
decision statistic is based on a conditional likeli-
hood ratio computed for each variable given the
others. Our results show that this function allows
to detect anomalies variable by variable, and thus
to localise the variables involved in the anomalies
more precisely than univariate methods based on
simple marginals.



hal_id    :    hal-02287434



. In this paper, we propose an eﬃcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in presence of pileup from a
sample of low-frequency observations. Based on a functional equation linking the marks’
density to the characteristic function of the observations and its derivative, we propose a
new time-eﬃcient method using B-splines to estimate the density of the underlying γ-ray
spectrum, which is able to handle large datasets used in nuclear physics. A discussion on
the numerical computation of the algorithm and its performances on simulated data are
provided to support our ﬁndings.
Keywords. Shot-noise, B-splines, inverse problem, γ spectrometry



hal_id    :    hal-01248010



Room acoustic parameters are key information for dereverberation or speech recognition. Usually, when
one needs to assess the level of reverberation, only the reverberation time RT60 or a direct to reverberant
sounds index Dτ is estimated. Yet, methods which blindly estimate the reverberation time from reverberant
recorded speech do not always diﬀerentiate the RT60 from the Dτ to evaluate the level of reverberation. That
is why we propose a method to jointly blindly estimate these parameters, from the signal energy decay rate
distribution, by means of kernel regression. Evaluation is carried out with real and simulated room impulse
responses to generate noise-free reverberant speech signals. The results show this new method outperforms
baseline approaches in our evaluation.
1.



hal_id    :    hal-01153882



This paper addresses the generalisation of stationary Hawkes processes in order to allow
for a time-evolving second-order analysis.
Motivated by the concept of locally stationary
autoregressive processes, we apply however inherently diﬀerent techniques to describe the
time-varying dynamics of self-exciting point processes. In particular we derive a stationary
approximation of the Laplace transform of a locally stationary Hawkes process. This allows
us to deﬁne a local intensity function and a local Bartlett spectrum which can be used to
compute approximations of ﬁrst and second order moments of the process. We complete the
paper by some insightful simulation studies.
Keywords:
Locally stationary processes, Hawkes processes, Bartlett spectrum, time
frequency analysis, point processes
2000 MSC: 60G55, 62M15, 46N30



hal_id    :    hal-01080955



. This paper deals with a parametrized family of partially
observed bivariate Markov chains. We establish that, under very mild
assumptions, the limit of the normalized log-likelihood function is max-
imized when the parameters belong to the equivalence class of the true
parameter, which is a key feature for obtaining the consistency of the
maximum likelihood estimators (MLEs) in well-speciﬁed models. This
result is obtained in the general framework of partially dominated mod-
els. We examine two speciﬁc cases of interest, namely, hidden Markov
models (HMMs) and observation-driven time series models. In contrast
with previous approaches, the identiﬁability is addressed by relying on
the uniqueness of the invariant distribution of the Markov chain asso-
ciated to the complete data, regardless its rate of convergence to the
equilibrium.



hal_id    :    hal-01078073



This paper generalizes asymptotic properties obtained in the
observation-driven times series models considered by [7] in the sense
that the conditional law of each observation is also permitted to depend
on the parameter. The existence of ergodic solutions and the consis-
tency of the Maximum Likelihood Estimator (MLE) are derived under
easy-to-check conditions. The obtained conditions appear to apply for a
wide class of models. We illustrate our results with speciﬁc observation-
driven times series, including the recently introduced NBIN-GARCH
and NM-GARCH models, demonstrating the consistency of the MLE
for these two models.
MSC: Primary: 62F12; Secondary: 60J05.
Keywords: consistency, ergodicity, maximum likelihood, observation-driven
models, time series of counts.
1



hal_id    :    hal-01030799



. Consider a non–linear function G(Xt) where Xt is a stationary Gaussian se-
quence with long–range dependence. The usual reduction principle states that the partial
sums of G(Xt) behave asymptotically like the partial sums of the ﬁrst term in the expansion
of G in Hermite polynomials. In the context of the wavelet estimation of the long–range
dependence parameter, one replaces the partial sums of G(Xt) by the wavelet scalogram,
namely the partial sum of squares of the wavelet coeﬃcients. Is there a reduction principle
in the wavelet setting, namely is the asymptotic behavior of the scalogram for G(Xt) the
same as that for the ﬁrst term in the expansion of G in Hermite polynomial? The answer
is negative in general. This paper provides a minimal growth condition on the scales of the
wavelet coeﬃcients which ensures that the reduction principle also holds for the scalogram.
The results are applied to testing the hypothesis that the long-range dependence parameter
takes a speciﬁc value.
Contents
1.



hal_id    :    hal-01164121



In this paper, we consider a nonlinear inverse problem occuring in nu-
clear science. Gamma rays randomly hit a semiconductor detector which
produces an impulse response of electric current. Because the sampling
period of the measured current is larger than the mean interarrival time
of photons, the impulse responses associated to diﬀerent gamma rays can
overlap: this phenomenon is known as pileup.
In this work, it is as-
sumed that the impulse response is an exponentially decaying function.
We propose a novel method to infer the distribution of gamma photon en-
ergies from the indirect measurements obtained from the detector. This
technique is based on a formula linking the characteristic function of the
photon density to a function involving the characteristic function and its
derivative of the observations. We establish that our estimator converges
to the mark density in uniform norm at a polynomial rate.
A limited
Monte-Carlo experiment is provided to support our ﬁndings.
1



hal_id    :    hal-00984064



In this work, we study the problem of aggregating a ﬁnite number of predic-
tors for non stationary sub-linear processes. We provide oracle inequalities relying
essentially on three ingredients: 1) a uniform bound of the ℓ1 norm of the time-
varying sub-linear coeﬃcients, 2) a Lipschitz assumption on the predictors and
3) moment conditions on the noise appearing in the linear representation. Two
kinds of aggregations are considered giving rise to diﬀerent moment conditions
on the noise and more or less sharp oracle inequalities. We apply this approach
for deriving an adaptive predictor for locally stationary time varying autoregres-
sive (TVAR) processes.
It is obtained by aggregating a ﬁnite number of well
chosen predictors, each of them enjoying an optimal minimax convergence rate
under speciﬁc smoothness conditions on the TVAR coeﬃcients. We show that
the obtained aggregated predictor achieves a minimax rate while adapting to the
unknown smoothness. To prove this result, a lower bound is established for the
minimax rate of the prediction risk for the TVAR process. Numerical experiments
complete this study. An important feature of this approach is that the aggregated
predictor can be computed recursively and is thus applicable in an online predic-
tion context.
1



hal_id    :    hal-00755255



We study the convergence of centered and normalized sums of i.i.d. random elements
of the space D of c`adl`ag functions endowed with Skorohod’s J1 topology, to stable distri-
butions in D. Our results are based on the concept of regular variation on metric spaces
and on point process convergence. We provide some applications, in particular to the
empirical process of the renewal-reward process.
1



hal_id    :    hal-02437193



– We propose an eﬃcient method to estimate in a nonparametric fashion the marks’ density of a shot-noise process
subject to a high pile-up eﬀect. Based on a formula linking the characteristic function of the mark density to a function involving
the shot-noise characteristic function and its derivative, we construct a “plug-in” estimator which converges to the mark density
in uniform norm at a logarithmic speed. Two limited Monte-Carlo experiments are provided to support our ﬁndings.
1



hal_id    :    hal-01167391



An important challenge in the aeronautic industry is to cope with maintenance issues of the prod-
ucts, notably detection and localization of components breakdowns. Modern equipments enjoy better
recording and processing capacities, allowing the storage of a large amount of data, on which better
maintenance systems are expected to be built. Eﬃcient probabilistic models able to represent the
statistic distribution of the collected variables in the “normal state” of the system are needed in order
to derive anomaly detection algorithms. Graphical models constitute a rich class of models and are
natural candidates to address this task. This article proposes a method for learning undirected hy-
brid graphical models from heterogeneous data. The data are heterogeneous as they include physical
(quantitative) measures as well as a collection of inherently discrete variables for instance describing
the state of electronic devices. The model we propose is adapted from the Ising and Gaussian models
so that the data don’t require to be translated from their original space, allowing the user to easily
interpret the dependency graph learned from data. The learning step is carried out by minimizing
the negative pseudo-log-likelihood using a proximal gradient algorithm with Lasso and group Lasso
penalization for addressing the high dimension of variables. Once the model is learned, we use the
penalized negative