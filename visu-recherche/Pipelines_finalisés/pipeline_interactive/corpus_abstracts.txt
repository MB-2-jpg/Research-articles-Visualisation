



hal_id    :    hal-04762097



We introduce Annealed Multiple Choice Learning (aMCL) which combines simu-
lated annealing with MCL. MCL is a learning framework handling ambiguous tasks
by predicting a small set of plausible hypotheses. These hypotheses are trained
using the Winner-takes-all (WTA) scheme, which promotes the diversity of the
predictions. However, this scheme may converge toward an arbitrarily suboptimal
local minimum, due to the greedy nature of WTA. We overcome this limitation
using annealing, which enhances the exploration of the hypothesis space during
training. We leverage insights from statistical physics and information theory
to provide a detailed description of the model training trajectory. Additionally,
we validate our algorithm by extensive experiments on synthetic datasets, on the
standard UCI benchmark, and on speech separation.
1



hal_id    :    hal-04736454



—This paper describes speech enhancement for real-
time automatic speech recognition (ASR) in real environments.
A standard approach to this task is to use neural beamforming
that can work efficiently in an online manner. It estimates the
masks of clean dry speech from a noisy echoic mixture spectro-
gram with a deep neural network (DNN) and then computes a
enhancement filter used for beamforming. The performance of
such a supervised approach, however, is drastically degraded un-
der mismatched conditions. This calls for run-time adaptation
of the DNN. Although the ground-truth speech spectrogram re-
quired for adaptation is not available at run time, blind dere-
verberation and separation methods such as weighted prediction
error (WPE) and fast multichannel nonnegative matrix factor-
ization (FastMNMF) can be used for generating pseudo ground-
truth data from a mixture. Based on this idea, a prior work pro-
posed a dual-process system based on a cascade of WPE and
minimum variance distortionless response (MVDR) beamform-
ing asynchronously fine-tuned by block-online FastMNMF. To in-
tegrate the dereverberation capability into neural beamforming
and make it fine-tunable at run time, we propose to use weighted
power minimization distortionless response (WPD) beamforming,
a unified version of WPE and minimum power distortionless re-
sponse (MPDR), whose joint dereverberation and denoising filter
is estimated using a DNN. We evaluated the impact of run-time
adaptation under various



hal_id    :    hal-04768296



In this paper, we propose a novel Self-Supervised-
Learning scheme to train rhythm analysis systems and
instantiate it for few-shot beat tracking.
Taking inspi-
ration from the Contrastive Predictive Coding paradigm,
we propose to train a Log-Mel-Spectrogram-Transformer-
encoder to contrast observations at times separated by hy-
pothesized beat intervals from those that are not. We do
this without the knowledge of ground-truth tempo or beat
positions, as we rely on the local maxima of a Predomi-
nant Local Pulse function, considered as a proxy for Tatum
positions, to define candidate anchors, candidate positives
(located at a distance of a power of two from the anchor)
and negatives (remaining time positions). We show that
a model pre-trained using this approach on the unlabeled
FMA, MTT and MTG-Jamendo datasets can successfully
be fine-tuned in the few-shot regime, i.e. with just a few
annotated examples to get a competitive beat-tracking per-
formance.
1



hal_id    :    hal-04665063



The task of music structure analysis has been mostly
addressed as a sequential problem, by relying on the inter-
nal homogeneity of musical sections or their repetitions.
In this work, we instead regard it as a pairwise link pre-
diction task. If for any pair of time instants in a track, one
can successfully predict whether they belong to the same
structural entity or not, then the underlying structure can
be easily recovered. Building upon this assumption, we
propose a method that first learns to classify pairwise links
between time frames as belonging to the same section (or
segment) or not. The resulting link features, along with
node-specific information, are combined through a graph
attention network. The latter is regularized with a graph
partitioning training objective and outputs boundary loca-
tions between musical segments and section labels. The
overall system is lightweight and performs competitively
with previous methods.
The evaluation is done on two
standard datasets for music structure analysis and an ab-
lation study is conducted in order to gain insight on the
role played by its different components.



hal_id    :    hal-04695595



Machine listening systems often rely on fixed taxonomies to or-
ganize and label audio data, key for training and evaluating deep
neural networks (DNNs) and other supervised algorithms. How-
ever, such taxonomies face significant constraints: they are com-
posed of application-dependent predefined categories, which hin-
ders the integration of new or varied sounds, and exhibits limited
cross-dataset compatibility due to inconsistent labeling standards.
To overcome these limitations, we introduce SALT: Standardized
Audio event Label Taxonomy. Building upon the hierarchical struc-
ture of AudioSet’s ontology, our taxonomy extends and standardizes
labels across 24 publicly available environmental sound datasets, al-
lowing the mapping of class labels from diverse datasets to a unified
system. Our proposal comes with a new Python package designed
for navigating and utilizing this taxonomy, easing cross-dataset la-
bel searching and hierarchical exploration. Notably, our package
allows effortless data aggregation from diverse sources, hence easy
experimentation with combined datasets.
Index Terms— Machine listening, DCASE, sound taxonomy,
sound categorization, data aggregation



hal_id    :    hal-04701759



Audio-text models trained via contrastive learning offer a practical
approach to perform audio classiﬁcation through natural language
prompts, such as “this is a sound of” followed by category names. In
this work, we explore alternative prompt templates for zero-shot au-
dio classiﬁcation, demonstrating the existence of higher-performing
options. First, we ﬁnd that the formatting of the prompts signif-
icantly affects performance so that simply prompting the models
with properly formatted class labels performs competitively with
optimized prompt templates and even prompt ensembling. More-
over, we look into complementing class labels by audio-centric de-
scriptions. By leveraging large language models, we generate tex-
tual descriptions that prioritize acoustic features of sound events
to disambiguate between classes, without extensive prompt engi-
neering. We show that prompting with class descriptions leads to
state-of-the-art results in zero-shot audio classiﬁcation across ma-
jor ambient sound datasets. Remarkably, this method requires no
additional training and remains fully zero-shot.
Index Terms— Zero-shot audio classiﬁcation, audio-text mod-
els, contrastive language-audio pretraining, in-context learning



hal_id    :    hal-04720291



The Prototypical Network (ProtoNet) has emerged as a popular
choice in Few-shot Learning (FSL) scenarios due to its remark-
able performance and straightforward implementation.
Building
upon such success, we first propose a simple (yet novel) method
to fine-tune a ProtoNet on the (labeled) support set of the test
episode of a C-way-K-shot test episode (without using the query
set which is only used for evaluation). We then propose an algo-
rithmic framework that combines ProtoNet with optimization-based
FSL algorithms (MAML and Meta-Curvature) to work with such
a fine-tuning method. Since optimization-based algorithms endow
the target learner model with the ability to fast adaption to only a
few samples, we utilize ProtoNet as the target model to enhance
its fine-tuning performance with the help of a specifically designed
episodic fine-tuning strategy. The experimental results confirm that
our proposed models, MAML-Proto and MC-Proto, combined with
our unique fine-tuning method, outperform regular ProtoNet by a
large margin in few-shot audio classification tasks on the ESC-50
and Speech Commands v2 datasets. We note that although we have
only applied our model to the audio domain, it is a general method
and can be easily extended to other domains.
Index Terms— Few-shot learning, Audio classification, Proto-
typical Network, Model-Agnostic Meta-Learning, Meta-Curvature



hal_id    :    hal-04685184



As diffusion-based deep generative models gain prevalence, re-
searchers are actively investigating their potential applications
across various domains, including music synthesis and style al-
teration. Within this work, we are interested in timbre transfer, a
process that involves seamlessly altering the instrumental character-
istics of musical pieces while preserving essential musical elements.
This paper introduces WaveTransfer, an end-to-end diffusion model
designed for timbre transfer. We specifically employ the bilateral
denoising diffusion model (BDDM) for noise scheduling search.
Our model is capable of conducting timbre transfer between audio
mixtures as well as individual instruments. Notably, it exhibits ver-
satility in that it accommodates multiple types of timbre transfer
between unique instrument pairs in a single model, eliminating the
need for separate model training for each pairing.
Furthermore,
unlike recent works limited to 16 kHz, WaveTransfer can be trained
at various sampling rates, including the industry-standard 44.1 kHz,
a feature of particular interest to the music community.
Index Terms— Multi-instrumental timbre transfer, diffusion
models, music transformation, generative AI



hal_id    :    hal-04632526



This paper describes a method for estimating the room impulse
response (RIR) for a microphone and a sound source located at
arbitrary positions from the 3D mesh data of the room. Simulat-
ing realistic RIRs with pure physics-driven methods often fails
the balance between physical consistency and computational ef-
ficiency, hindering application to real-time speech processing.
Alternatively, one can use MESH2IR, a fast black-box estima-
tor that consists of an encoder extracting latent code from mesh
data with a graph convolutional network (GCN) and a decoder
generating the RIR from the latent code. Combining these two
approaches, we propose a fast yet physically coherent estimator
with interpretable latent code based on differentiable digital sig-
nal processing (DDSP). Specifically, the encoder estimates a vir-
tual shoebox room scene that acoustically approximates the real
scene, accelerating physical simulation with the differentiable
image-source model in the decoder. Our experiments showed
that our method outperformed MESH2IR for real mesh data ob-
tained with the depth scanner of Microsoft HoloLens 2, and can
provide correct spatial consistency for binaural RIRs.
Index Terms: Spatial audio, room acoustics, 3D mesh data,
physical models, DDSP



hal_id    :    hal-04640068



Single-channel speech dereverberation aims at extracting a
dry speech signal from a recording affected by the acoustic re-
flections in a room. However, most current deep learning-based
approaches for speech dereverberation are not interpretable for
room acoustics, and can be considered as black-box systems
in that regard. In this work, we address this problem by regu-
larizing the training loss using a novel physical coherence loss
which encourages the room impulse response (RIR) induced by
the dereverberated output of the model to match the acoustic
properties of the room in which the signal was recorded. Our
investigation demonstrates the preservation of the original dere-
verberated signal alongside the provision of a more physically
coherent RIR.
Index Terms: Speech dereverberation, hybrid deep learning,
room acoustics, acoustic matching, speech processing



hal_id    :    hal-04705811



—Latent representation learning has been an active
field of study for decades in numerous applications. Inspired
among others by the tokenization from Natural Language
Processing and motivated by the research of a simple data
representation, recent works have introduced a quantization step
into the feature extraction. In this work, we propose a novel
strategy to build the neural discrete representation by means of
random codebooks. These codebooks are obtained by randomly
sampling a large, predefined fixed codebook. We experimentally
show the merits and potential of our approach in a task of audio
compression and reconstruction.
Index Terms—feature extraction, quantization, random code-
books, audio reconstruction



hal_id    :    hal-04645968



—Experimental and theoretical evidences suggest that
invariance constraints can improve the performance and gener-
alization capabilities of a classification model. While invariance-
based regularization has become part of the standard tool-belt
of machine learning practitioners, this regularization is usually
applied near the decision layers or at the end of the feature
extracting layers of a deep classification network. However,
the optimal placement of invariance constraints inside a deep
classifier is yet an open question. In particular, it would be
beneficial to link it to the structural properties of the network (e.g.
its architecture), or its dynamical properties (e.g. the effectively
used volume of its latent spaces). The purpose of this article
is to initiate an investigation on these aspects. We use the
experimental framework of the DCASE 2023 Task 4A challenge,
which considers the training of a sound event classifier in a
semi-supervised manner. We show that the optimal placement of
invariance constraints improves the performance of the standard
baseline for this task.
Index Terms—DCASE task 4, invariance-based learning, semi-
supervised learning.



hal_id    :    hal-04614241



—This paper addresses the challenge of estimating
multiple highly oscillating amplitudes within the nonlinear chirp
signal model. The problem is analogous to the mode detection
task with fixed instantaneous frequencies, where the oscillating
amplitudes signify mechanical vibrations concealing crucial infor-
mation for predictive maintenance. Existing methods often focus
on single-frequency estimation, employ simple amplitude func-
tions, or impose strong noise assumptions. Furthermore, these
methods frequently rely on arbitrarily chosen hyperparameters,
leading to sub-optimal generalization for a diverse range of am-
plitudes. To address these limitations, our approach introduces
two estimators, based on Capon filters and negative log-likelihood
approaches respectively, that leverage locally stationary assump-
tions and incorporate hyperparameters estimation. The results
demonstrate that, even under challenging conditions, these esti-
mators yield competitive outcomes across various noisy scenarios,
mitigating the drawbacks associated with existing methods.
Index Terms—chirp signal, amplitude estimation, locally sta-
tionary process, filtering, hyperparameters estimation



hal_id    :    hal-04574640



Winner-takes-all training is a simple learning
paradigm, which handles ambiguous tasks by pre-
dicting a set of plausible hypotheses. Recently,
a connection was established between Winner-
takes-all training and centroidal Voronoi tessel-
lations, showing that, once trained, hypotheses
should quantize optimally the shape of the condi-
tional distribution to predict. However, the best
use of these hypotheses for uncertainty quantifi-
cation is still an open question. In this work, we
show how to leverage the appealing geometric
properties of the Winner-takes-all learners for con-
ditional density estimation, without modifying its
original training scheme. We theoretically estab-
lish the advantages of our novel estimator both in
terms of quantization and density estimation, and
we demonstrate its competitiveness on synthetic
and real-world datasets, including audio data.



hal_id    :    halshs-04654217



No abstract found in the PDF.



hal_id    :    hal-04602229



In recent years, significant advances have been made in deep learn-
ing models for audio generation, offering promising tools for mu-
sical creation. In this work, we investigate the use of deep audio
generative models in interactive dance/music performance. We
adopted a performance-led research design approach, establish-
ing an art-research collaboration between a researcher/musician
and a dancer. First, we describe our motion-sound interactive sys-
tem integrating deep audio generative model and propose three
methods for embodied exploration of deep latent spaces. Then, we
detail the creative process for building the performance centered
on the co-design of the system. Finally, we report feedback from
the dancer’s interviews and discuss the results and perspectives.
The code implementation is publicly available on our github1.
CCS CONCEPTS
• Human-centered computing →Sound-based input / output;
Gestural input; Auditory feedback; Collaborative interaction;
• Applied computing →Sound and music computing; • Com-
puting methodologies →Machine learning.
KEYWORDS
dance-music-AI performance, HCI, motion-sound interaction, deep
learning, generative models, embodied exploration, latent space
ACM Reference Format:
Sarah Nabi, Philippe Esling, Geoffroy Peeters, and Frédéric Bevilacqua. 2024.
Embodied exploration of deep latent spaces in interactive dance-music
performance. In 9th International Conference on Movement and Computing
(MOCO ’24), May 30-June 2, 2024, Utrecht, Netherlands. ACM, New York, NY,
USA, 9 pages. https://doi.org/10.1145/3658852.3659072
1https://github.com/ircam-ismm/embodied-latent-exploration
Permission to make digital or hard copies of all or part of this work for personal or
classroom



hal_id    :    hal-04541350



Isolating the desired speaker’s voice amidst multiple
speakers in a noisy acoustic context is a challenging task. Per-
sonalized speech enhancement (PSE) endeavours to achieve
this by leveraging prior knowledge of the speaker’s voice.
Recent research efforts have yielded promising PSE mod-
els, albeit often accompanied by computationally intensive
architectures, unsuitable for resource-constrained embedded
devices. In this paper, we introduce a novel method to per-
sonalize a lightweight dual-stage Speech Enhancement (SE)
model and implement it within DeepFilterNet2, a SE model
renowned for its state-of-the-art performance. We seek an
optimal integration of speaker information within the model,
exploring different positions for the integration of the speaker
embeddings within the dual-stage enhancement architec-
ture. We also investigate a tailored training strategy when
adapting DeepFilterNet2 to a PSE task. We show that our
personalization method greatly improves the performances
of DeepFilterNet2 while preserving minimal computational
overhead.
Index Terms— Target speech extraction, speech en-
hancement, real-time.



hal_id    :    hal-04544157



Tempo estimation is the task of estimating the periodicity of the
dominant rhythm pulse of a music audio signal. It has therefore
a close relationship with dominant pitch estimation. Recently, both
tasks have been addressed in a Self-Supervised Learning (SSL) fash-
ion so as to leverage unlabelled data for training. In this work, we
study the applicability of two successful pitch-based SSL models,
SPICE and PESTO, for the purpose of tempo estimation. Both suc-
cessfully exploit Siamese networks with a pitch-shifting view gen-
eration between the two branches. To apply these models for tempo
estimation, we represent the audio signal by the Constant-Q trans-
form (CQT) of its onset-strength-function and adapt their view gen-
eration using time-stretching (instead of pitch shifting), which is ef-
ficiently implemented by shifting the CQT. In a large experiment,
we show that simply adapting PESTO in this way yields superior re-
sults than the previous SSL approach to tempo estimation for most
datasets used in the reference benchmark. Further, since PESTO
is light-weight, requiring only a few training data, we study a new
learning scheme where the downstream datasets are processed di-
rectly in a SSL fashion (without access to labels) showing that this
is an interesting alternative further improving the performance for
some datasets.
Index Terms— tempo estimation, self-supervised-learning



hal_id    :    hal-04358467



In neural audio signal processing, pitch conditioning has been
used to enhance the performance of synthesizers. However, jointly
training pitch estimators and synthesizers is a challenge when us-
ing standard audio-to-audio reconstruction loss, leading to reliance
on external pitch trackers. To address this issue, we propose us-
ing a spectral loss function inspired by optimal transportation theory
that minimizes the displacement of spectral energy. We validate this
approach through an unsupervised autoencoding task that fits a har-
monic template to harmonic signals. We jointly estimate the funda-
mental frequency and amplitudes of harmonics using a lightweight
encoder and reconstruct the signals using a differentiable harmonic
synthesizer. The proposed approach offers a promising direction for
improving unsupervised parameter estimation in neural audio appli-
cations.
Index Terms— differentiable signal processing, machine learn-
ing, optimal transport, frequency estimation



hal_id    :    hal-04424100



Diffusion models are receiving a growing interest for a variety of
signal generation tasks such as speech or music synthesis. WaveG-
rad, for example, is a successful diffusion model that conditionally
uses the mel spectrogram to guide a diffusion process for the gen-
eration of high-fidelity audio. However, such models face important
challenges concerning the noise diffusion process for training and
inference, and they have difficulty generating high-quality speech
for speakers that were not seen during training. With the aim of
minimizing the conditioning error and increasing the efficiency of
the noise diffusion process, we propose in this paper a new scheme
called GLA-Grad, which consists in introducing a phase recovery al-
gorithm such as the Griffin-Lim algorithm (GLA) at each step of the
regular diffusion process. Furthermore, it can be directly applied to
an already-trained waveform generation model, without additional
training or fine-tuning. We show that our algorithm outperforms
state-of-the-art diffusion models for speech generation, especially
when generating speech for a previously unseen target speaker.
Index Terms— Diffusion models, speech generation, Griffin-
Lim algorithm, domain adaptation



hal_id    :    hal-04360221



Current state-of-the-art audio analysis systems rely on pre-
trained embedding models, often used off-the-shelf as (frozen)
feature extractors. Choosing the best one for a set of tasks is the
subject of many recent publications.
However, one aspect often
overlooked in these works is the influence of the duration of audio
input considered to extract an embedding, which we refer to as Tem-
poral Support (TS). In this work, we study the influence of the TS
for well-established or emerging pre-trained embeddings, chosen to
represent different types of architectures and learning paradigms.
We conduct this evaluation using both musical instrument and envi-
ronmental sound datasets, namely OpenMIC, TAU Urban Acoustic
Scenes 2020 Mobile, and ESC-50. We especially highlight that Au-
dio Spectrogram Transformer-based systems (PaSST and BEATs)
remain effective with smaller TS, which therefore allows for a dras-
tic reduction in memory and computational cost.
Moreover, we
show that by choosing the optimal TS we reach competitive results
across all tasks. In particular, we improve the state-of-the-art results
on OpenMIC, using BEATs and PaSST without any fine-tuning.
Index Terms— audio embeddings, acoustic scene classification,
instrument recognition, temporal support, transformers



hal_id    :    hal-04539329



Blind Estimation of Audio Effects (BE-AFX) aims at estimating the
audio effects (AFXs) applied to an original, unprocessed audio sam-
ple solely based on the processed audio sample. To train such a
system traditional approaches optimize a loss between ground truth
and estimated AFX parameters. This involves knowing the exact
implementation of the AFXs used for the process. In this work, we
propose an alternative solution that eliminates the requirement for
knowing this implementation. Instead, we introduce an auto-encoder
approach, which optimizes an audio quality metric. We explore, sug-
gest, and compare various implementations of commonly used mas-
tering AFXs, using differential signal processing or neural approx-
imations. Our findings demonstrate that our auto-encoder approach
yields superior estimates of the audio quality produced by a chain of
AFXs, compared to the traditional parameter-based approach, even
if the latter provides a more accurate parameter estimation.
Index Terms— audio effects, differentiable digital signal pro-
cessing, neural proxy, deep learning



hal_id    :    hal-04479188



We address the problem of accurately interpolating measured ane-
choic steering vectors with a deep learning framework called the
neural field. This task plays a pivotal role in reducing the resource-
intensive measurements required for precise sound source separa-
tion and localization, essential as the front-end of speech recogni-
tion. Classical approaches to interpolation rely on linear weighting of
nearby measurements in space on a fixed, discrete set of frequencies.
Drawing inspiration from the success of neural fields for novel view
synthesis in computer vision, we introduce the neural steerer, a con-
tinuous complex-valued function that takes both frequency and direc-
tion as input and produces the corresponding steering vector. Impor-
tantly, it incorporates inter-channel phase difference information and
a regularization term enforcing filter causality, essential for accurate
steering vector modeling. Our experiments, conducted using a dataset
of real measured steering vectors, demonstrate the effectiveness of
our resolution-free model in interpolating such measurements.
Index Terms— Steering vector, neural field, spatial audio, inter-
polation, representation learning



hal_id    :    hal-04423979



Generative adversarial network (GAN) models can synthesize high-
quality audio signals while ensuring fast sample generation. How-
ever, they are difficult to train and are prone to several issues in-
cluding mode collapse and divergence. In this paper, we introduce
SpecDiff-GAN, a neural vocoder based on HiFi-GAN, which was
initially devised for speech synthesis from mel spectrogram. In our
model, the training stability is enhanced by means of a forward dif-
fusion process which consists in injecting noise from a Gaussian
distribution to both real and fake samples before inputting them to
the discriminator. We further improve the model by exploiting a
spectrally-shaped noise distribution with the aim to make the dis-
criminator’s task more challenging. We then show the merits of our
proposed model for speech and music synthesis on several datasets.
Our experiments confirm that our model compares favorably in au-
dio quality and efficiency compared to several baselines.
Index Terms— Generative adversarial network (GAN), diffu-
sion process, deep audio synthesis, spectral envelope



hal_id    :    hal-04419041



Overlapped speech is notoriously problematic for speaker diarization
systems. Consequently, the use of speech separation has recently
been proposed to improve their performance. Although promising,
speech separation models struggle with realistic data because they
are trained on simulated mixtures with a fixed number of speakers. In
this work, we introduce a new speech separation-guided diarization
scheme suitable for the online speaker diarization of long meeting
recordings with a variable number of speakers, as present in the AMI
corpus. We envisage ConvTasNet and DPRNN as alternatives for the
separation networks, with two or three output sources. To obtain the
speaker diarization result, voice activity detection is applied on each
estimated source. The final model is fine-tuned end-to-end, after first
adapting the separation to real data using AMI. The system operates
on short segments, and inference is performed by stitching the local
predictions using speaker embeddings and incremental clustering.
The results show that our system improves the state-of-the-art on
the AMI headset mix, using no oracle information and under full
evaluation (no collar and including overlapped speech). Finally, we
show the strength of our system particularly on overlapped speech
sections.
Index Terms— online speaker diarization, source separation,
overlapped speech, AMI, speaker embedding



hal_id    :    hal-04432659



Music generated by deep learning methods often suffers
from a lack of coherence and long-term organization. Yet,
multi-scale hierarchical structure is a distinctive feature of
music signals. To leverage this information, we propose a
structure-informed positional encoding framework for music
generation with Transformers. We design three variants in
terms of absolute, relative and non-stationary positional in-
formation. We comprehensively test them on two symbolic
music generation tasks: next-timestep prediction and accom-
paniment generation.
As a comparison, we choose multi-
ple baselines from the literature and demonstrate the merits
of our methods using several musically-motivated evaluation
metrics. In particular, our methods improve the melodic and
structural consistency of the generated pieces.
Index Terms— symbolic music generation, Transform-
ers, music structure, positional encoding



hal_id    :    hal-04423348



. With the progress of generative neural models, Hierarchical Text Classification
(HTC) can be cast as a generative task. In this case, given an input text, the model generates
the sequence of predicted class labels taken from a label tree of arbitrary width and depth.
Treating HTC as a generative task introduces multiple modeling choices. These choices vary
from choosing the order for visiting the class tree and therefore defining the order of generat-
ing tokens, choosing either to constrain the decoding to labels that respect the previous level
predictions, up to choosing the pre-trained Language Model itself. Each HTC model therefore
differs from the others from an architectural standpoint, but also from the modeling choices
that were made. Prior contributions lack transparent modeling choices and open implemen-
tations, hindering the assessment of whether model performance stems from architectural or
modeling decisions. For these reasons, we propose with this paper an analysis of the impact
of different modeling choices along with common model errors and successes for this task.
This analysis is based on an open framework coming along this paper that can facilitate the
development of future contributions in the field by providing datasets, metrics, error analysis
toolkit and the capability to readily test various modeling choices for one given model.
Keywords: Hierarchical text



hal_id    :    hal-04729913



Multimodal large language models have fueled progress in image captioning.
These models, fine-tuned on vast image datasets, exhibit a deep understanding
of semantic concepts. In this work, we show that this ability can be re-purposed
for audio captioning, where the joint image-language decoder can be leveraged to
describe auditory content associated with image sequences within videos featuring
audiovisual content. This can be achieved via multimodal alignment. Yet, this
multimodal alignment task is non-trivial due to the inherent disparity between
audible and visible elements in real-world videos. Moreover, multimodal repre-
sentation learning often relies on contrastive learning, facing the challenge of the
so-called modality gap which hinders smooth integration between modalities. In
this work, we introduce a novel methodology for bridging the audiovisual modality
gap by matching the distributions of tokens produced by an audio backbone and
those of an image captioner. Our approach aligns the audio token distribution
with that of the image tokens, enabling the model to perform zero-shot audio
captioning in an unsupervised fashion while keeping the initial image captioning
component unaltered. This alignment allows for the use of either audio or audiovi-
sual input by combining or substituting the image encoder with the aligned audio
encoder. Our method achieves significantly improved performances in zero-shot
audio captioning, compared to existing approaches.1
1



hal_id    :    hal-04036482



: In this paper, we consider functional data with heterogeneity
in time and population. We propose a mixture model with segmentation
of time to represent this heterogeneity while keeping the functional struc-
ture. The maximum likelihood estimator is considered and proved to be
identiﬁable and consistent. In practice, an EM algorithm is used, combined
with dynamic programming for the maximization step, to approximate the
maximum likelihood estimator. The method is illustrated on a simulated
dataset and used on a real dataset of electricity consumption.
MSC2020 subject classiﬁcations: Primary 62M10, 62F12; secondary
62-08.
Keywords and phrases: Mixture model, segmentation, functional data,
consistency.
Received February 2024.



hal_id    :    hal-04688068



: ˙VO2max is recognized as a key measure in exercise physiology and sports medicine.
However, only 20–50% of maximal incremental exercise tests (IET) result in a plateau of ˙VO2 ( ˙VO2pl).
To our knowledge, no study has yet examined the possible difference in brain activity during an
IET, in ˙VO2pl and non-plateau athletes with the same ˙VO2max and age. This study aimed to shed
light on the central governor hypothesis, namely that the inability to reach a ˙VO2pl may be dictated
by the brain rather than by a peripheral physical limit. This hypothesis can now be explored using
electroencephalography (EEG) during IET, measuring concomitant power in specific frequency bands.
Forty-two athletes were divided into two groups: those who practiced endurance sports and those
who did not, and were asked to perform an IET. EEG signals and gas exchange were recorded. A
˙VO2pl was observed in twenty-two subjects (52%). EEG power increased in all subjects during IET,
except in the alpha band, which showed variability, but not significantly (64% increase, 34% decrease,
p = 0.07). No differences were found between endurance athletes and non-endurance athletes, except
for ˙VO2max (60.10 ± 6.16 vs. 51.77 ± 6.41, p < 0.001). However, the baseline-corrected ratio of EEG
power to ˙VO2 was found to decrease in all subjects



hal_id    :    hal-04593480



When deriving contextualized word repre-
sentations from language models, a decision
needs to be made on how to obtain one for
out-of-vocabulary (OOV) words that are seg-
mented into subwords. What is the best way
to represent these words with a single vector,
and are these representations of worse quality
than those of in-vocabulary words? We carry
out an intrinsic evaluation of embeddings from
different models on semantic similarity tasks
involving OOV words. Our analysis reveals,
among other interesting findings, that the qual-
ity of representations of words that are split is
often, but not always, worse than that of the
embeddings of known words. Their similar-
ity values, however, must be interpreted with
caution.
1



hal_id    :    hal-04548715



No abstract found in the PDF.



hal_id    :    hal-04578273



. The pair-matching problem appears in many applications where one wants to discover
matches between pairs of entities or individuals. Formally, the set of individuals is represented by
the nodes of a graph where the edges, unobserved at first, represent the matches. The algorithm
queries pairs of nodes and observes the presence/absence of edges. Its goal is to discover as
many edges as possible with a fixed budget of queries. Pair-matching is a particular instance of
multi-armed bandit problem in which the arms are pairs of individuals and the rewards are edges
linking these pairs. This bandit problem is non-standard though, as each arm can only be played
once.
Given this last constraint, sublinear regret can be expected only if the graph presents some
underlying structure. This paper shows that sublinear regret is achievable in the case where
the graph is generated according to a Stochastic Block Model (SBM) with two communities.
Optimal regret bounds are computed for this pair-matching problem. They exhibit a phase trans-
ition related to the Kesten-Stigum threshold for community detection in SBM. The pair-matching
problem is considered in the case where each node is constrained to be sampled less than a given
amount of times, for example for ensuring individual fairness. We show how optimal regret rates
depend on this



hal_id    :    hal-04539879



—This paper tackles two major problem settings for
interpretability of audio processing networks, post-hoc and by-
design interpretation. For post-hoc interpretation, we aim to in-
terpret decisions of a network in terms of high-level audio objects
that are also listenable for the end-user. This is extended to
present an inherently interpretable model with high performance.
To this end, we propose a novel interpreter design that incor-
porates non-negative matrix factorization (NMF). In particular,
an interpreter is trained to generate a regularized intermediate
embedding from hidden layers of a target network, learnt as time-
activations of a pre-learnt NMF dictionary. Our methodology
allows us to generate intuitive audio-based interpretations that
explicitly enhance parts of the input signal most relevant for a
network’s decision. We demonstrate our method’s applicability
on a variety of classification tasks, including multi-label data for
real-world audio and music.
Index Terms—Audio interpretability, explainability, by-design
interpretable models, audio convolutional networks, non-negative
matrix factorization



hal_id    :    hal-03442137



In non-smooth stochastic optimization, we establish the non-convergence of the stochas-
tic subgradient descent (SGD) to the critical points recently called active strict saddles
by Davis and Drusvyatskiy. Such points lie on a manifold M where the function f has a
direction of second-order negative curvature. Off this manifold, the norm of the Clarke
subdifferential of f is lower-bounded. We require two conditions on f. The first assump-
tion is a Verdier stratification condition, which is a refinement of the popular Whitney
stratification. It allows us to establish a strengthened version of the projection formula
of Bolte et al. for Whitney stratifiable functions, and which is of independent interest.
The second assumption, termed the angle condition, allows to control the distance of the
iterates to M. When f is weakly convex, our assumptions are generic. Consequently,
generically in the class of definable weakly convex functions, SGD converges to a local
minimizer.
Keywords.
Non-smooth optimization, stochastic gradient descent, avoidance of traps,
Clarke subdifferential, stratification, weak convexity
1



hal_id    :    hal-03615137



—Tensor factorization models are widely used in many
applied ﬁelds such as chemometrics, psychometrics, computer
vision or communication networks. Real life data collection is
often subject to errors, resulting in missing data. Here we focus
in understanding how this issue should be dealt with for non-
negative tensor factorization. We investigate several criteria used
for non-negative tensor factorization in the case where some
entries are missing. In particular we show how smoothness
penalties can compensate the presence of missing values in order
to ensure the existence of an optimum. This lead us to propose
new criteria with efﬁcient numerical optimization algorithms.
Numerical experiments are conducted to support our claims.
Index Terms—Non-negative tensor decomposition, missing val-
ues, Tensor completion, smoothness, PARAFAC, CP decomposi-
tion.



hal_id    :    hal-04485065



—The task of music structure analysis refers to au-
tomatically identifying the location and the nature of musical
sections within a song. In the supervised scenario, structural
annotations generally result from exhaustive data collection
processes, which represents one of the main challenges of this
task. Moreover, both the subjectivity of music structure and
the hierarchical characteristics it exhibits make the obtained
structural annotations not fully reliable, in the sense that they
do not convey a “universal ground-truth” unlike other tasks
in music information retrieval. On the other hand, the quickly
growing quantity of available music data has enabled weakly
supervised and self-supervised approaches to achieve impressive
results on a wide range of music-related problems. In this work,
a self-supervised learning method is proposed to learn robust
multi-level music representations prior to structural segmentation
using contrastive learning. To this end, sets of frames sampled at
different levels of detail are used to train a deep neural network
in a disentangled manner. The proposed method is evaluated on
both flat and multi-level segmentation. We show that each distinct
sub-region of the output embeddings can efficiently account
for structural similarity at their own targeted level of detail,
which ultimately improves performance of downstream flat and
multi-level segmentation. Finally, complementary experiments
are carried out to study how the obtained representations can be
further adapted to specific datasets using



hal_id    :    hal-04390768



Group fairness is a central research topic in
text classification, where reaching fair treat-
ment between sensitive groups (e.g. women
vs. men) remains an open challenge. This
paper presents a novel method for mitigating
biases in neural text classification, agnostic to
the model architecture. Considering the diffi-
culty to distinguish fair from unfair informa-
tion in a text encoder, we take inspiration from
adversarial training to induce Wasserstein in-
dependence between representations learned to
predict our target label and the ones learned to
predict some sensitive attribute. Our approach
provides two significant advantages. Firstly,
it does not require annotations of sensitive at-
tributes in both testing and training data. This is
more suitable for real-life scenarios compared
to existing methods that require annotations
of sensitive attributes at train time. Secondly,
our approach exhibits a comparable or better
fairness-accuracy trade-off compared to exist-
ing methods. Our implementation is available
on Github1.
1



hal_id    :    hal-04216055



We introduce Resilient Multiple Choice Learning (rMCL), an extension of the
MCL approach for conditional distribution estimation in regression settings where
multiple targets may be sampled for each training input. Multiple Choice Learning
is a simple framework to tackle multimodal density estimation, using the Winner-
Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing
MCL variants focus on merging the hypotheses, thereby eventually sacriﬁcing
the diversity of the predictions. In contrast, our method relies on a novel learned
scoring scheme underpinned by a mathematical framework based on Voronoi tessel-
lations of the output space, from which we can derive a probabilistic interpretation.
After empirically validating rMCL with experiments on synthetic data, we further
assess its merits on the sound source localization task, demonstrating its practical
usefulness and the relevance of its interpretation.
1



hal_id    :    hal-04202766



Contrastive learning has recently appeared as a well-suited
method to find representations of music audio signals that
are suitable for structural segmentation. However, most
existing unsupervised training strategies omit the notion of
repetition and therefore fail at encompassing this essential
aspect of music structure. This work introduces a triplet
mining method which explicitly considers repeating se-
quences occurring inside a music track by leveraging com-
mon audio descriptors. We study its impact on the learned
representations through downstream music segmentation.
Because musical repetitions can be of different natures, we
give further insight on the role of the audio descriptors em-
ployed at the triplet mining stage as well as the trade-off
existing between the quality of the triplets mined and the
quantity of unlabelled data used for training. We observe
that our method requires less non-annotated data while re-
maining competitive against other unsupervised methods
trained on a larger corpus.



hal_id    :    hal-04260042



In this paper, we address the problem of pitch estimation
using Self Supervised Learning (SSL). The SSL paradigm
we use is equivariance to pitch transposition, which en-
ables our model to accurately perform pitch estimation on
monophonic audio after being trained only on a small un-
labeled dataset. We use a lightweight (< 30k parameters)
Siamese neural network that takes as inputs two differ-
ent pitch-shifted versions of the same audio represented
by its Constant-Q Transform. To prevent the model from
collapsing in an encoder-only setting, we propose a novel
class-based transposition-equivariant objective which cap-
tures pitch information. Furthermore, we design the archi-
tecture of our network to be transposition-preserving by
introducing learnable Toeplitz matrices.
We evaluate our model for the two tasks of singing voice
and musical instrument pitch estimation and show that our
model is able to generalize across tasks and datasets while
being lightweight, hence remaining compatible with low-
resource devices and suitable for real-time applications. In
particular, our results surpass self-supervised baselines and
narrow the performance gap between self-supervised and
supervised methods for pitch estimation.



hal_id    :    hal-04160013



Deep neural network models have become the dominant
approach to a large variety of tasks within music informa-
tion retrieval (MIR). These models generally require large
amounts of (annotated) training data to achieve high ac-
curacy. Because not all applications in MIR have suffi-
cient quantities of training data, it is becoming increasingly
common to transfer models across domains. This approach
allows representations derived for one task to be applied to
another, and can result in high accuracy with less strin-
gent training data requirements for the downstream task.
However, the properties of pre-trained audio embeddings
are not fully understood. Specifically, and unlike tradi-
tionally engineered features, the representations extracted
from pre-trained deep networks may embed and propagate
biases from the model’s training regime.
This work investigates the phenomenon of bias prop-
agation in the context of pre-trained audio representations
for the task of instrument recognition. We first demonstrate
that three different pre-trained representations (VGGish,
OpenL3, and YAMNet) exhibit comparable performance
when constrained to a single dataset, but differ in their abil-
ity to generalize across datasets (OpenMIC and IRMAS).
We then investigate dataset identity and genre distribution
as potential sources of bias. Finally, we propose and evalu-
ate post-processing countermeasures to mitigate the effects
of bias, and improve generalization across datasets.



hal_id    :    hal-04172863



This paper revisits single-channel audio source separation based on
a probabilistic generative model of a mixture signal defined in the
continuous time domain. We assume that each source signal fol-
lows a non-stationary Gaussian process (GP), i.e., any finite set of
sampled points follows a zero-mean multivariate Gaussian distribu-
tion whose covariance matrix is governed by a kernel function over
time-varying latent variables. The mixture signal composed of such
source signals thus follows a GP whose covariance matrix is given
by the sum of the source covariance matrices. To estimate the latent
variables from the mixture signal, we use a deep neural network with
an encoder-separator-decoder architecture (e.g., Conv-TasNet) that
separates the latent variables in a pseudo-time-frequency space. The
key feature of our method is to feed the latent variables into the ker-
nel function for estimating the source covariance matrices, instead
of using the decoder for directly estimating the time-domain source
signals. This enables the decomposition of a mixture signal into the
source signals with a classical yet powerful Wiener filter that consid-
ers the full covariance structure over all samples. The kernel func-
tion and the network are trained jointly in the maximum likelihood
framework. Comparative experiments using two-speech mixtures
under clean, noisy, and noisy-reverberant conditions from the WSJ0-
2mix, WHAM!, and WHAMR! benchmark datasets demonstrated
that the proposed method



hal_id    :    hal-04135264



BHAI 1 (Byzantine Hybrid Artificial Intelligence) is the first project
based on artificial intelligence dedicated to Byzantine seals. The
scientific consortium comprises a multidisciplinary team involving
historians specialized in the Byzantine period, specialists in sig-
illography, and computer science experts. This article describes the
main objectives of this project: data acquisition of seal images, text
and iconography recognition, seal dating, as well as our current
achievements and first results on character recognition and spatial
analysis of personages.
CCS CONCEPTS
• Applied computing →Arts and humanities; • Computing
methodologies →Spatial and physical reasoning; Semantic
networks; Natural language processing.
KEYWORDS
Byzantine Greek, Byzantine history, seal images, deep neural net-
works, character recognition, iconography recognition
ACM Reference Format:
Victoria EYHARABIDE, Laurence LIKFORMAN-SULEM, Lucia ORLANDI,
Alexandre BINOUX, Théophile RAGEAU, Qijia HUANG, Attilio FIAN-
DROTTI, Beatrice CASEAU, and Isabelle BLOCH. 2023. Study of historical
Byzantine seal images: the BHAI project for computer-based sigillography.
In 7th International Workshop on Historical Document Imaging and Processing
(HIP ’23), August 25–26, 2023, San Jose, CA, USA. ACM, New York, NY, USA,
6 pages. https://doi.org/10.1145/3604951.3605523
1



hal_id    :    hal-04216175



Self-supervised learning (SSL) has recently allowed leveraging
large datasets of unlabeled speech signals to reach impressive
performance on speech tasks using only small amounts of an-
notated data. The high number of proposed approaches fostered
the need and rise of extended benchmarks that evaluate their
performance on a set of downstream tasks exploring various as-
pects of the speech signal. However, and while the number of
considered tasks has been growing, most rely upon a single de-
coding architecture that maps the frozen SSL representations to
the downstream labels. This work investigates the robustness
of such benchmarking results to changes in the decoder archi-
tecture. Interestingly, it appears that varying the architecture
of the downstream decoder leads to significant variations in the
leaderboards of most tasks. Concerningly, our study reveals that
benchmarking using limited decoders may cause a counterpro-
ductive increase in the sizes of the developed SSL models.
Index Terms: self-supervised learning, representation learning



hal_id    :    hal-04216177



Self-Supervised Learning (SSL) has allowed leveraging large
amounts of unlabeled speech data to improve the perfor-
mance of speech recognition models even with small annotated
datasets.
Despite this, speech SSL representations may fail
while facing an acoustic mismatch between the pretraining and
target datasets. To address this issue, we propose a novel super-
vised domain adaptation method, designed for cases exhibiting
such a mismatch in acoustic domains. It consists in applying
properly calibrated data augmentations on a large clean dataset,
bringing it closer to the target domain, and using it as part of
an initial fine-tuning stage. Augmentations are automatically
selected through the minimization of a conditional-dependence
estimator, based on the target dataset. The approach is vali-
dated during an oracle experiment with controlled distortions
and on two amateur-collected low-resource domains, reaching
better performances compared to the baselines in both cases.
Index Terms: self-supervised learning, domain adaptation.



hal_id    :    hal-04593478



Dialog participants sometimes align their lin-
guistic styles, e.g., they use the same words
and syntactic constructions as their interlocu-
tors. We propose to investigate the notion of
lexico-semantic alignment: to what extent do
speakers convey the same meaning when they
use the same words? We design measures of
lexico-semantic alignment relying on contextu-
alized word representations. We show that they
reflect interesting semantic differences between
the two sides of a debate and that they can assist
in the task of debate’s winner prediction.
1



hal_id    :    hal-04131585



No abstract found in the PDF.



hal_id    :    hal-04130213



La façon dont nous utilisons les mots est influencée par notre opinion. Nous cherchons à savoir si cela
se reflète dans les plongements de mots contextualisés. Par exemple, la représentation d’ « animal »
est-elle différente pour les gens qui voudraient abolir les zoos et ceux qui ne le voudraient pas? Nous
explorons cette question du point de vue du changement sémantique des mots. Nos expériences avec
des représentations dérivées d’ensembles de données annotés avec les points de vue révèlent des
différences minimes, mais significatives, entre postures opposées 1.
ABSTRACT
One Word, Two Sides : Traces of Stance in Contextualized Word Representations
The way we use words is influenced by our opinion. We investigate whether this is reflected in
contextualized word embeddings. For example, is the representation of “animal” different between
people who would abolish zoos and those who would not? We explore this question from a Lexical
Semantic Change standpoint. Our experiments with BERT embeddings derived from datasets with
stance annotations reveal small but significant differences in word representations between opposing
stances.
MOTS-CLÉS : Représentations contextualisées, changement sémantique, détection de point de vue.
KEYWORDS: Contextualized representations, semantic change, stance detection.
1



hal_id    :    hal-04093374



Measuring noise in cities and automatically identifying the cor-
responding sound sources are a crucial challenge for policymak-
ers. Indeed, such information helps addressing noise pollution and
improving the well-being of urban dwellers. In recent years, re-
searchers have provided annotated datasets recorded in two ma-
jor cities to foster the development of urban sound event detection
(SED) systems. This paper presents an in-depth study of the be-
haviour of state-of-the-art SED systems well suited to our problem,
combining three far-field real recordings datasets which can be used
jointly during training. In our evaluation, we highlight the perfor-
mance gaps existing between simple and hard recording examples
based on the salience of sound events and the polyphony of the
recordings. We provide new proximity annotations for this anal-
ysis. We evaluate the ability of urban SED systems to generalize
across cities with varying degrees of training supervision. We show
that such generalization is hindered mostly by the difficulties current
urban SED systems have to detect sound events with low salience
along with sound events in highly polyphonic soundscapes.
Index Terms— Sound Event Detection (SED), Far-field urban
audio recordings, urban sound monitoring,



hal_id    :    hal-04048829



Due to their performances, deep neural networks have emerged as
a major method in nearly all modern audio processing applications.
Deep neural networks can be used to estimate some parameters or
hyperparameters of a model, or in some cases the entire model in
an end-to-end fashion. Although deep learning can lead to state of
the art performances, they also suffer from inherent weaknesses as
they usually remain complex and non interpretable to a large extent.
For instance, the internal filters used in each layers are chosen in
an adhoc manner with only a loose relation with the nature of the
processed signal. We propose in this paper an approach to learn in-
terpretable filters within a specific neural architecture which allow
to better understand the behaviour of the neural network and to re-
duce its complexity. We validate the approach on a task of speech
enhancement and show that the gain in interpretability does not de-
grade the performance of the model.
Index Terms— Representation learning, interpretability, speech
enhancement



hal_id    :    hal-04076307



Self-supervised learning (SSL) has allowed substantial progress in
Automatic Speech Recognition (ASR) performance in low-resource
settings. In this context, it has been demonstrated that larger self-
supervised feature extractors are crucial for achieving lower down-
stream ASR error rates. Thus, better performance might be sanc-
tioned with longer inferences. This article explores different ap-
proaches that may be deployed during the ﬁne-tuning to reduce the
computations needed in the SSL encoder, leading to faster infer-
ences. We adapt a number of existing techniques to common ASR
settings and benchmark them, displaying performance drops and
gains in inference times. Interestingly, we found that given enough
downstream data, a simple downsampling of the input sequences
outperforms the other methods with both low performance drops and
high computational savings, reducing computations by 61.3% with
an WER increase of only 0.81. Finally, we analyze the robustness of
the comparison to changes in dataset conditions, revealing sensitiv-
ity to dataset size.
Index Terms— Speech recognition, self-supervised learning.



hal_id    :    ujm-04165556



. In contrast to classic autoregressive generation, insertion-
based models can predict in a order-free way multiple tokens at a time,
which make their generation uniquely controllable: it can be constrained
to strictly include an ordered list of tokens. We propose to exploit this
feature in a new diverse paraphrasing framework: ﬁrst, we extract im-
portant tokens or keywords in the source sentence; second, we augment
them; third, we generate new samples around them by using insertion
models. We show that the generated paraphrases are competitive with
state of the art autoregressive paraphrasers, not only in diversity but also
in quality. We further investigate their potential to create new pseudo-
labelled samples for data augmentation, using a meta-learning classiﬁca-
tion framework, and ﬁnd equally competitive result. In addition to prov-
ing non-autoregressive (NAR) viability for paraphrasing, we contribute
our open-source framework as a starting point for further research into
controllable NAR generation.
Keywords: Deep Learning · Natural language processing · Controllable
text generation · Transformers · Non-autoregressive · Insertion models.
1



hal_id    :    hal-04213215



. In recent years, large Transformer-based Pre-trained Lan-
guage Models (PLM) have changed the Natural Language Processing
(NLP) landscape, by pushing the performance boundaries of the state-
of-the-art on a wide variety of tasks. However, this performance gain goes
along with an increase in complexity, and as a result, the size of such
models (up to billions of parameters) represents a constraint for their
deployment on embedded devices or short-inference time tasks. To cope
with this situation, compressed models emerged (e.g. DistilBERT), de-
mocratizing their usage in a growing number of applications that impact
our daily lives. A crucial issue is the fairness of the predictions made by
both PLMs and their distilled counterparts. In this paper, we propose
an empirical exploration of this problem by formalizing two questions:
(1) Can we identify the neural mechanism(s) responsible for gender bias
in BERT (and by extension DistilBERT)? (2) Does distillation tend to
accentuate or mitigate gender bias (e.g. is DistilBERT more prone to
gender bias than its uncompressed version, BERT)? Our findings are the
following: (I) one cannot identify a specific layer that produces bias; (II)
every attention head uniformly encodes bias; except in the context of un-
derrepresented classes with a high imbalance of the sensitive attribute;
(III) this subset of heads is different as we re-fine tune the



hal_id    :    hal-04126067



Athlete’s pose acquisition and analysis is promising to provide coaches with details of athletes
performance and thus help to improve athletes’ performances with more detailed supervision from
coaches. Compared with traditional ways of acquiring an athlete's gesture, such as using wearable
sensors, computer vision technology has advantages of low-cost, high-efficient and non-intrusive.
This paper aims to bridge these two fields, by reconstructing athletes’ trajectory using monocular
(i.e. single-camera-shot) videos. Under a few assumptions that are applicable to most of the sports
of athletics, we proposed a method combining computer vision techniques and physics laws to
reconstruct athletes’ trajectories from monocular videos. The method first estimates 3D pose of
athletes from video inputs, then performs kinematic analysis on estimated poses to reconstruct the
trajectories of athletes. We tested this algorithm on videos from the triple jump finals of the 2016
Olympics in Rio de Janeiro. We achieved a best performance with 9.1% mean average error when
using ground-truth foot-ground contact signal and 21.4% mean average error when using predicted
foot-ground contact signal.



hal_id    :    hal-04319492



This paper introduces a new method to tackle the issue of the almost sure conver-
gence of stochastic approximation algorithms deﬁned from a diﬀerential inclusion.
Under the assumption of slowly decaying step-sizes, we establish that the set of es-
sential accumulation points of the iterates belongs to the Birkhoﬀcenter associated
with the diﬀerential inclusion. Unlike previous works, our results do not rely on
the notion of asymptotic pseudotrajectories introduced by Bena¨ım–Hofbauer–Sorin,
which is the predominant technique to address the convergence problem. They fol-
low as a consequence of Young’s superposition principle for closed measures. This
perspective bridges the gap between Young’s principle and the notion of invariant
measure of set-valued dynamical systems introduced by Faure and Roth. Also, the
proposed method allows to obtain suﬃcient conditions under which the velocities
locally compensate around any essential accumulation point.
KEYWORDS
Stochastic approximation: Closed measures; Weak convergence; Diﬀerential
inclusions



hal_id    :    hal-02318267



. The spectral theory for weakly stationary processes valued in a separable Hilbert space has
known renewed interest in the past decade. Here we follow earlier approaches which fully exploit the
normal Hilbert module property of the time domain. The key point is to build the Gramian-Cram´er rep-
resentation as an isomorphic mapping from the modular spectral domain to the modular time domain.
We also discuss the general Bochner theorem and provide useful results on the composition and inver-
sion of lag-invariant linear ﬁlters. Finally, we derive the Cram´er-Karhunen-Lo`eve decomposition and
harmonic functional principal component analysis, which are established without relying on additional
assumptions.
Mathematics Subject Classiﬁcation. 60G12, 47A56, 46G10.
Received may 19, 2021. Accepted July 12, 2023.



hal_id    :    hal-04112575



No abstract found in the PDF.



hal_id    :    hal-04253752



Non-deterministic measurements are common in real-world scenarios: the performance
of a stochastic optimization algorithm or the total reward of a reinforcement learning agent
in a chaotic environment are just two examples in which unpredictable outcomes are com-
mon. These measures can be modeled as random variables and compared among each other
via their expected values or more sophisticated tools such as null hypothesis statistical
tests. In this paper, we propose an alternative framework to visually compare two sam-
ples according to their estimated cumulative distribution functions. First, we introduce a
dominance measure for two random variables that quantiﬁes the proportion in which the
cumulative distribution function of one of the random variables stochastically dominates
the other one. Then, we present a graphical method that decomposes in quantiles i) the
proposed dominance measure and ii) the probability that one of the random variables takes
lower values than the other. With illustrative purposes, we re-evaluate the experimentation
of an already published work with the proposed methodology and we show that additional
conclusions—missed by the rest of the methods—can be inferred. Additionally, the software
package RVCompare was created as a convenient way of applying and experimenting with
the proposed framework.
Keywords:
Data visualization, Random variables, Cumulative distribution function, First-order
stochastic dominance
1
arXiv:2203.07889v4  [stat.ML]  30 Aug 2022
0.0225 0.0250 0.0275 0.0300 0.0325



hal_id    :    hal-04038023



—Supervised deep learning approaches to underdeter-
mined audio source separation achieve state-of-the-art perfor-
mance but require a dataset of mixtures along with their corre-
sponding isolated source signals. Such datasets can be extremely
costly to obtain for musical mixtures. This raises a need for unsu-
pervised methods. We propose a novel unsupervised model-based
deep learning approach to musical source separation. Each source
is modelled with a differentiable parametric source-ﬁlter model. A
neural network is trained to reconstruct the observed mixture as
a sum of the sources by estimating the source models’ parameters
given their fundamental frequencies. At test time, soft masks are
obtained from the synthesized source signals. The experimental
evaluation on a vocal ensemble separation task shows that the
proposed method outperforms learning-free methods based on
nonnegative matrix factorization and a supervised deep learning
baseline. Integrating domain knowledge in the form of source
models into a data-driven method leads to high data efﬁciency: the
proposed approach achieves good separation quality even when
trained on less than three minutes of audio. This work makes
powerful deep learning based separation usable in scenarios where
training data with ground truth is expensive or nonexistent.
Index Terms—Unsupervised learning, audio source separation,
signal processing, model-based, deep learning.



hal_id    :    hal-04244852



Handling large datasets and calculating complex statistics on huge datasets require
important computing resources. Using subsampling methods to calculate statistics
of interest on small samples is often used in practice to reduce computational com-
plexity, for instance using the divide and conquer strategy. In this article, we recall
some results on subsampling distributions and derive a precise rate of convergence
for these quantities and the corresponding quantiles. We also develop some standard-
ization techniques based on subsampling unstandardized statistics in the framework
of large datasets. It is argued that using several subsampling distributions with dif-
ferent subsampling sizes brings a lot of information on the behavior of statistical
learning procedures: subsampling allows to estimate the rate of convergence of dif-
ferent algorithms, to estimate the variability of complex statistics, to estimate conﬁ-
dence intervals for out-of-sample errors and interpolate their values at larger scales.
These results are illustrated on simulations, but also on two important datasets,
frequently analyzed in the statistical learning community, EMNIST (recognition of
digits) and VeReMi (analysis of Network Vehicular Reference Misbehavior).
KEYWORDS
Scaling, big data, Subsampling, Convergence rate estimation, Conﬁdence intervals
in statistical learning, Out-of sample error, EMNIST digits VeReMi



hal_id    :    hal-03228252



We study the linear convergence of the primal-dual hybrid gradient method. After a review of current
analyses, we show that they do not explain properly the behavior of the algorithm, even on the most
simple problems. We thus introduce the quadratic error bound of the smoothed gap, a new regularity
assumption that holds for a wide class of optimization problems. Equipped with this tool, we manage
to prove tighter convergence rates. Then, we show that averaging and restarting the primal-dual hybrid
gradient allows us to leverage better the regularity constant.
Numerical experiments on linear and
quadratic programs, ridge regression and image denoising illustrate the ﬁndings of the paper.
1



hal_id    :    hal-03164338



In this paper, we introduce a novel family of iterative algorithms which carry out α-
divergence minimisation in a Variational Inference context. They do so by ensuring a
systematic decrease at each step in the α-divergence between the variational and the
posterior distributions. In its most general form, the variational distribution is a mixture
model and our framework allows us to simultaneously optimise the weights and components
parameters of this mixture model. Our approach permits us to build on various methods
previously proposed for α-divergence minimisation such as Gradient or Power Descent
schemes and we also shed a new light on an integrated Expectation Maximization algorithm.
Lastly, we provide empirical evidence that our methodology yields improved results on
several multimodal target distributions and on a real data example.
Keywords:
Variational Inference, Kullback-Leibler, Alpha-Divergence, Mixture Models,
Bayesian Inference



hal_id    :    hal-03990543



No abstract found in the PDF.



hal_id    :    hal-03601330



Through solving pretext tasks, self-supervised learning leverages unlabeled data
to extract useful latent representations replacing traditional input features in the
downstream task. In audio/speech signal processing, a wide range of features
where engineered through decades of research efforts. As it turns out, learning
to predict such features (a.k.a pseudo-labels) has proven to be a particularly rel-
evant pretext task, leading to useful self-supervised representations which prove
to be effective for downstream tasks. However, methods and common practices
for combining such pretext tasks for better performance on the downstream task
have not been explored and understood properly. In fact, the process relies almost
exclusively on a computationally heavy experimental procedure, which becomes
intractable with the increase of the number of pretext tasks. This paper introduces
a method to select a group of pretext tasks among a set of candidates. The method
we propose estimates calibrated weights for the partial losses corresponding to the
considered pretext tasks during the self-supervised training process. The experi-
ments conducted on automatic speech recognition, speaker and emotion recogni-
tion validate our approach, as the groups selected and weighted with our method
perform better than classic baselines, thus facilitating the selection and combina-
tion of relevant pseudo-labels for self-supervised representation learning.
1



hal_id    :    hal-02564349



This paper studies the asymptotic behavior of the constant step Stochastic Gradient
Descent for the minimization of an unknown function, deﬁned as the expectation of a
non convex, non smooth, locally Lipschitz random function. As the gradient may not
exist, it is replaced by a certain operator: a reasonable choice is to use an element of
the Clarke subdiﬀerential of the random function; another choice is the output of the
celebrated backpropagation algorithm, which is popular amongst practioners, and whose
properties have recently been studied by Bolte and Pauwels. Since the expectation of the
chosen operator is not in general an element of the Clarke subdiﬀerential of the mean
function, it has been assumed in the literature that an oracle of the Clarke subdiﬀerential
of the mean function is available. As a ﬁrst result, it is shown in this paper that such
an oracle is not needed for almost all initialization points of the algorithm.
Next, in
the small step size regime, it is shown that the interpolated trajectory of the algorithm
converges in probability (in the compact convergence sense) towards the set of solutions
of a particular diﬀerential inclusion: the subgradient ﬂow. Finally, viewing the iterates as
a Markov chain whose transition kernel is indexed by the step size, it is shown that the
invariant



hal_id    :    hal-03821125



—This article describes a computationally-efﬁcient sta-
tistical approach to joint (semi-)blind source separation and dere-
verberation for multichannel noisy reverberant mixture signals. A
standard approach to source separation is to formulate a generative
model of a multichannel mixture spectrogram that consists of
source and spatial models representing the time-frequency power
spectral densities (PSDs) and spatial covariance matrices (SCMs)
of source images, respectively, and ﬁnd the maximum-likelihood
estimates of these parameters. A state-of-the-art blind source sep-
aration method in this thread of research is fast multichannel
nonnegative matrix factorization (FastMNMF) based on the low-
rank PSDs and jointly-diagonalizable full-rank SCMs. To perform
mutually-dependent separation and dereverberation jointly, in this
paper we integrate both moving average (MA) and autoregressive
(AR) models that represent the early reﬂections and late rever-
berations of sources, respectively, into the FastMNMF formalism.
Using a pretrained deep generative model of speech PSDs as a
source model, we realize semi-blind joint speech separation and
dereverberation. We derive an iterative optimization algorithm
based on iterative projection or iterative source steering for jointly
and efﬁciently updating the AR parameters and the SCMs. Our
experimentalresultsshowedthesuperiorityoftheproposedARMA
extensionoveritsAR-orMA-ablatedversioninaspeechseparation
and/or dereverberation task.
Index Terms—Multichannel audio signal processing, source
separation, dereverberation, joint diagonalization.
Manuscript received 4 October 2021; revised 31 March 2022; accepted 18
June2022.Dateofpublication13July2022;dateofcurrentversion28July2022.
This work was supported in part by JSPS KAKENHI under Grants 19H04137,
20K19833, and 20H01159, and in part by NII



hal_id    :    hal-03657196



—This paper describes heavy-tailed extensions of a
state-of-the-art versatile blind source separation method called
fast multichannel nonnegative matrix factorization (FastMNMF)
from a uniﬁed point of view. The common way of deriving such an
extension is to replace the multivariate complex Gaussian distribu-
tion in the likelihood function with its heavy-tailed generalization,
e.g., the multivariate complex Student’s t and leptokurtic gener-
alized Gaussian distributions, and tailor-make the corresponding
parameter optimization algorithm. Using a wider class of heavy-
tailed distributions called a Gaussian scale mixture (GSM), i.e., a
mixture of Gaussian distributions whose variances are perturbed
by positive random scalars called impulse variables, we propose
GSM-FastMNMF and develop an expectation-maximization algo-
rithm that works even when the probability density function of
the impulse variables have no analytical expressions. We show
that existing heavy-tailed FastMNMF extensions are instances of
GSM-FastMNMF and derive a new instance based on the gen-
eralized hyperbolic distribution that include the normal-inverse
Gaussian, Student’s t, and Gaussian distributions as the special
cases. Our experiments show that the normal-inverse Gaussian
FastMNMF outperforms the state-of-the-art FastMNMF exten-
sions and ILRMA model in speech enhancement and separation
in terms of the signal-to-distortion ratio.
Index Terms—Nonnegative matrix factorization, blind source
separation, probabilistic framework, expectation-maximization



hal_id    :    hal-03295581



Song lyrics contain repeated patterns that have been proven to facilitate automated lyrics
segmentation, with the ﬁnal goal of detecting the building blocks (e.g. chorus, verse) of a
song text. Our contribution in this article is two-fold. First, we introduce a convolutional
neural network-based model that learns to segment the lyrics based on their repetitive text
structure. We experiment with novel features to reveal diﬀerent kinds of repetitions in the
lyrics, for instance based on phonetical and syntactical properties. Second, using a novel
corpus where the song text is synchronized to the audio of the song, we show that the text
and audio modalities capture complementary structure of the lyrics and that combining
both is beneﬁcial for lyrics segmentation performance. For the purely text-based lyrics
segmentation on a dataset of 103k lyrics, we achieve an f-score of 67.4%, improving on
the state of the art (59.2% f-score). On the synchronized text-audio dataset of 4.8k songs,
we show that the additional audio features improve segmentation performance to 75.3%
f-score, signiﬁcantly outperforming the purely text-based approaches.
1



hal_id    :    hal-03780032



Recent work in music structure analysis has shown the
potential of deep features to highlight the underlying struc-
ture of music audio signals.
Despite promising results
achieved by such representations, dealing with the inher-
ent hierarchical aspect of music structure remains a chal-
lenging problem. Because different levels of segmentation
can be considered as equally valid, specifically designed
representations should be optimized to improve hierarchi-
cal structure analysis. In this work, unsupervised learning
of such representations using a contrastive approach op-
erating at different time-scales is explored. The proposed
system is evaluated on flat and multi-level music segmen-
tation. By leveraging both time and the hierarchical orga-
nization of music structure, we show that the obtained deep
embeddings can encode meaningful patterns and improve
segmentation at various levels of granularity.



hal_id    :    hal-03860497



, ISMIR 2022 Conference
SSM-NET: FEATURE LEARNING FOR MUSIC STRUCTURE ANALYSIS
USING A SELF-SIMILARITY-MATRIX BASED LOSS
Geoffroy Peeters
LTCI, Télécom-Paris, IP-Paris
geoffroy.peeters@telecom-paris.fr
Florian Angulo
LTCI, Télécom-Paris, IP-Paris
florian.angulo@telecom-paris.fr
ABSTRACT
In this paper, we propose a new paradigm to learn au-
dio features for Music Structure Analysis (MSA).
We
train a deep encoder to learn features such that the Self-
Similarity-Matrix (SSM) resulting from those approxi-
mates a ground-truth SSM. This is done by minimizing
a loss between both SSMs.
Since this loss is differen-
tiable w.r.t. its input features we can train the encoder in a
straightforward way. We successfully demonstrate the use
of this training paradigm using the Area Under the Curve
ROC (AUC) on the RWC-Pop dataset.



hal_id    :    hal-03903647



As music has become more available especially on music
streaming platforms, people have started to have distinct
preferences to fit to their varying listening situations, also
known as context. Hence, there has been a growing inter-
est in considering the user’s situation when recommending
music to users. Previous works have proposed user-aware
autotaggers to infer situation-related tags from music con-
tent and user’s global listening preferences. However, in
a practical music retrieval system, the autotagger could be
only used by assuming that the context class is explicitly
provided by the user. In this work, for designing a fully
automatised music retrieval system, we propose to disam-
biguate the user’s listening information from their stream
data. Namely, we propose a system which can generate a
situational playlist for a user at a certain time 1) by leverag-
ing user-aware music autotaggers, and 2) by automatically
inferring the user’s situation from stream data (e.g. device,
network) and user’s general profile information (e.g. age).
Experiments show that such a context-aware personalized
music retrieval system is feasible, but the performance de-
creases in the case of new users, new tracks or when the
number of context classes increases.



hal_id    :    hal-03782827



Invariance-based learning is a promising approach in deep learning.
Among other benefits, it can mitigate the lack of diversity of avail-
able datasets and increase the interpretability of trained models. To
this end, practitioners often use a consistency cost penalizing the
sensitivity of a model to a set of carefully selected data augmen-
tations. However, there is no consensus about how these augmen-
tations should be selected. In this paper, we study the behavior
of several augmentation strategies. We consider the task of sound
event detection and classification for our experiments. In particular,
we show that transformations operating on the internal layers of a
deep neural network are beneficial for this task.
Index Terms— sound event detection, data augmentation, ad-
versarial learning



hal_id    :    hal-03671852



Riemannian spaces with negative curvature constitute the proper setting for the distribution of images created
by irregular polyhedral rooms with obtuse angles. The crucial parameter is the excess angle that arises around
speciﬁc edges, called hinges, when ﬁrst and second order images are considered, as it pilots the metric tensor of
the space and all its geometrical properties. With the use of these geometrical properties, and complementing
it with the uncertainty principle, we describe the scattering of wave packets around dihedral angles: it is pro-
portional to the excess angle, and is best described in terms of the conservation of the stress-energy tensor. The
basic elements for computing the scattering are given.
Keywords: Riemannian geometry, Polyhedral rooms, Scattering, Stress-energy tensor
1



hal_id    :    hal-03671851



In the stress-energy tensor formalism, the symmetry between absorption and scattering coefﬁcients, as proven
by measurements combined with simulations, is counter-intuitive. By introducing the wall admittance, we
show that the scattering coefﬁcient is partly created by the real part of the wall admittance combined with the
active intensity, that is, is partly due to absorption. However, it also depends on the imaginary part of the wall
admittance in combination with the reactive intensity, which confers it genuine scattering properties. In the case
of plane waves impinging on planar boundary, the admittance formalism shows that reactive intensity vanishes
in directions parallel to the wall; when the source is at ﬁnite distance from the wall, a residual reactive intensity
subsists. However, for curved boundaries, the velocity in directions parallel to the wall is no longer proportional
to the pressure, and scattering occurs.
Keywords: Energy density, Sound intensity, Absorption coefﬁcient, Scattering coefﬁcient, Wall admittance
1



hal_id    :    hal-03860830



The way we use words is influenced by our
opinion.
We investigate whether this is re-
flected in contextualized word embeddings.
For example, is the representation of “animal”
different between people who would abolish
zoos and those who would not? We explore
this question from a Lexical Semantic Change
standpoint. Our experiments with BERT em-
beddings derived from datasets with stance
annotations reveal small but significant differ-
ences in word representations between oppos-
ing stances.
1



hal_id    :    hal-03817736



Contrastive learning enables learning useful audio and speech
representations without ground-truth labels by maximizing the
similarity between latent representations of similar signal seg-
ments. In this framework various data augmentation techniques
are usually exploited to help enforce desired invariances within
the learned representations, improving performance on various
audio tasks thanks to more robust embeddings. Now, selecting
the most relevant augmentations has proven crucial for better
downstream performances. Thus, this work introduces a condi-
tional independance-based method which allows for automati-
cally selecting a suitable distribution on the choice of augmenta-
tions and their parametrization from a set of predefined ones, for
contrastive self-supervised pre-training. This is performed with
respect to a downstream task of interest, hence saving a costly
hyper-parameter search. Experiments performed on two differ-
ent downstream tasks validate the proposed approach showing
better results than experimenting without augmentation or with
baseline augmentations. We furthermore conduct a qualitative
analysis of the automatically selected augmentations and their
variation according to the considered final downstream dataset.
Index Terms: self-supervised learning, data augmentation.



hal_id    :    hal-03759651



– L’apprentissage d’invariants est une méthode d’entraînement prometteuse pour les réseaux de neurones profonds, puisqu’elle permet
à la fois de pallier le manque de diversité des bases de données disponibles, et de rendre les modèles entraînés plus interprétables. En pratique,
l’apprentissage d’invariants passe souvent par l’utilisation d’augmentations de données et de coûts de consistance pénalisant la sensibilité d’un
modèle à ces augmentations. Il n’existe cependant pas de consensus concernant la sélection de ces augmentations pour une tâche cible. Cet
article étudie l’impact de plusieurs types d’augmentations sur l’entraînement d’un modèle de l’état de l’art, dans le cadre de la détection et de
la classification d’évènements sonores. Nous montrons en particulier que la perturbation des représentations internes d’un réseau de neurones
profond est bénéfique pour cette tâche.
Abstract – Invariance-based learning is a promising approach in deep learning. Among other benefits, it can mitigate the lack of diversity
of available datasets and increase the interpretability of trained models. Practitioners often use a consistency cost penalizing the sensitivity of
a model to a set of carefully selected data augmentations. However, there is no consensus about how these augmentations should be selected.
This article studies the impact of several types of augmentations on the training of a model. We consider the task of



hal_id    :    hal-03759647



– The use of parameterized audio encoders has proven to be an encouraging avenue for improving the interpretability and performance
of end-to-end source separation models. We present properties of interest needed to learn the filters of these encoders ; and propose a param-
eterization to constrain these filters. Based on the Hilbert transform and the Bedrosian theorem, we propose to construct a set of phase-shifted
filters by modulating sinusoids through freely learned low-pass filters. These filters allow to obtain invariances for time shifts, phase shifts while
avoiding the use of complex neural networks thanks to a trick of over-parameterization of the phase for a given waveform.
1



hal_id    :    hal-03670586



Starting from new measurements of the acoustical pots and room geometry in the phonocamptic cave at the Cathedral
of Noyon, a numerical study was undertaken to understand the acoustical effects at the boundaries, and to provide an
auralization of the space. An implementation of the finite volume time domain (FVTD) method was used to model
the cave, including fitting the impedance presented by the acoustical pots on certain boundaries. The individual
impedances of the pots were estimated from impulse responses collected pot-by-pot and parameterized in terms of a
Helmholtz resonator model. Then, using the electroacoustic analogy, the sum effect of the pots was modeled as an
equivalent spatial distribution in the FVTD boundary conditions. Additionally, the space was discretized with an
unstructured mesh in order to capture the complex geometry, minimize dispersion error, and to check the accuracy of
the FVTD implementation.
1.



hal_id    :    hal-03670577



The paper investigates under which assumptions the EST method, initially developed for modelling the propagation
of acoustical energy in ﬂat spaces such as hallways and open space oﬃces, can be adapted to unbounded spaces such
as ancient theatres. It turns out that it mainly requires that the air column above any position in the open theatre
contains ﬁnite acoustical energy, whatever its height. This is indeed the case since at high altitudes above the theatre,
energy decreases with the square of the height due to the increasingly accurate assimilation of the theatre to a point
source. In other words, one must use high enough elements, so that the intensity on the top of the elements can be
considered as negligible, leading to negligible absorption and scattering on the top boundary. Therefore, one only needs
considering absorption and scattering at the bottom boundary of the elements; and the integration on the elements
must be revisited to account for the decrease of intensity with altitude. The corresponding bi-dimensional equations
will be presented and solved for a variety of absorption and scattering coeﬃcients on the surface of the theatre, and
compared to measurements in an actual theatre.
1.



hal_id    :    hal-03860827



Our discourses are full of potential lexical ambiguities, due in part to the pervasive use of words having multiple senses.
Sometimes, one word may even be used in more than one sense throughout a text. But, to what extent is this true for different
kinds of texts? Does the use of polysemous words change when a discourse involves two people, or when speakers have time
to plan what to say? We investigate these questions by comparing the polysemy level of texts of different nature, with a focus
on spontaneous spoken dialogs; unlike previous work which examines solely scripted, written, monolog-like data. We compare
multiple metrics that presuppose different conceptualizations of text polysemy, i.e., they consider the observed or the potential
number of senses of words, or their sense distribution in a discourse. We show that the polysemy level of texts varies greatly
depending on the kind of text considered, with dialog and spoken discourses having generally a higher polysemy level than
written monologs. Additionally, our results emphasize the need for relaxing the popular “one sense per discourse” hypothesis.
Keywords: Semantics, Word Sense Disambiguation, Document classification / Text categorisation
1.



hal_id    :    hal-04273536



Users generate content constantly, leading to new data requiring annotation.
Among this data, textual conversations are
created every day and come with some specificities: they are mostly private through instant messaging applications, requiring
the conversational context to be labeled. These specificities led to several annotation tools dedicated to conversation, and
mostly dedicated to dialogue tasks, requiring complex annotation schemata, not always customizable and not taking into
account conversation-level labels.
In this paper, we present EZCAT, an easy-to-use interface to annotate conversations
in a two-level configurable schema, leveraging message-level labels and conversation-level labels at once.
Our interface
is characterized by the voluntary absence of a server and accounts management, enhancing its availability to anyone, and
the control over data, which is crucial to confidential conversations. We also present our first usage of EZCAT along with
our annotation schema we used to annotate confidential customer service conversations.
EZCAT is freely available at
https://gguibon.github.io/ezcat.
Keywords: conversations, annotation tool, text messages
1.



hal_id    :    hal-04276012



In this paper, we present the process we used in order to collect new annotations of opinions over the multimodal corpus
SEMAINE composed of dyadic interactions. The dataset had already been annotated continuously in two affective dimensions
related to the emotions: Valence and Arousal.
We annotated the part of SEMAINE called Solid SAL composed of 79
interactions between a user and an operator playing the role of a virtual agent designed to engage a person in a sustained,
emotionally colored conversation. We aligned the audio at the word level using the available high-quality manual transcriptions.
The annotated dataset contains 5627 speech turns for a total of 73,944 words, corresponding to 6 hours 20 minutes of dyadic
interactions. Each interaction has been labeled by three annotators at the speech turn level following a three-step process. This
method allows us to obtain a precise annotation regarding the opinion of a speaker. We obtain thus a dataset dense in opinions,
with more than 48% of the annotated speech turns containing at least one opinion. We then propose a new baseline for the
detection of opinions in interactions improving slightly a state of the art model with RoBERTa embeddings. The obtained
results on the database are promising with a F1-score at 0.72.
Keywords: Opinion, Multimodal Machine



hal_id    :    hal-04166172



. Handwriting is an everyday life human activity. It can be
collected oﬀ-line by scanning sheets of paper. The resulting images can
then be processed by a computer-based system. Thanks to digitizing
tablets, handwriting can also be collected on-line. From the collected raw
signals (pen position, pressure over time), the dynamics of the writing
can be recovered. Since handwriting is unique for each individual, it can
be considered as a biometric modality.
Biometric systems predicting gender from oﬀ-line handwriting, have been
recently proposed. However we observe that, in contrast to other modal-
ities such as speech, it is not straightforward for a human being (even
expert) to predict gender. In this study we explore the limits of auto-
matic gender prediction from on-line handwriting collected from a young
adults population, homogeneous in terms of age and education. In our
previous work [1], a statistical analysis of on-line dynamic features has
shown diﬀerences between male and female groups. In the present study,
we provide these features to a classiﬁer, based on a machine learning ap-
proach (SVMs). Since datasets are relatively small (240 subjects), several
evaluation frameworks are explored: cross validation (CV), bootstrap,
and ﬁxed train/test partitions. Accuracies obtained from ﬁxed partitions
range from 37% to 79%, while those estimated by CV and bootstrap
are around 60%.
This shows to our opinion



hal_id    :    hal-03637425



This paper describes a blind source separation method for multichan-
nel audio signals, called NF-FastMNMF, based on the integration of
the normalizing ﬂow (NF) into the multichannel nonnegative matrix
factorization with jointly-diagonalizable spatial covariance matrices,
a.k.a. FastMNMF. Whereas the NF of ﬂow-based independent vector
analysis, called NF-IVA, acts as the demixing matrices to transform
an M-channel mixture into M independent sources, the NF of NF-
FastMNMF acts as the diagonalization matrices to transform an M-
channel mixture into a spatially-independent M-channel mixture rep-
resented as a weighted sum of N source images. This diagonalization
enables the NF, which has been used only for determined separation
because of its bijective nature, to be applicable to non-determined
separation. NF-FastMNMF has time-varying diagonalization matri-
ces that are potentially better at handling dynamical data variation
than the time-invariant ones in FastMNMF. To have an NF with richer
expression capability, the dimension-wise scalings using diagonal ma-
trices originally used in NF-IVA are replaced with linear transforma-
tions using upper triangular matrices; in both cases, the diagonal and
upper triangular matrices are estimated by neural networks. The eval-
uation shows that NF-FastMNMF performs well for both determined
and non-determined separations of multiple speech utterances by sta-
tionary or non-stationary speakers from a noisy reverberant mixture.
Index Terms— Blind source separation, normalizing ﬂow, joint
diagonalization, multichannel nonnegative matrix factorization



hal_id    :    hal-03708610



The use of a parameterized encoders or audio front-ends has
shown promises in improving the interpretability of time do-
main single-channel source separation models such as Conv-
TasNet. This type of ﬁlters also allows a potential reduction
of the computational cost since larger encoder ﬁlters can be
used. In this work, we propose to build a new parameteri-
zation of such encoder ﬁlter-bank which allows gaining in-
terpretability while keeping ﬂexibility. Based on the Hilbert
transform and the Bedrosian theorem, we propose to build
phase-shifted set of ﬁlters by modulating sinusoids through
freely learned low pass ﬁlters. We show that the use of these
ﬁlters allows to keep the same performances when using small
ﬁlters and even improve them when using large ﬁlters.
Index Terms— Audio source separation, audio ﬁlterbank



hal_id    :    hal-03848222



No abstract found in the PDF.



hal_id    :    hal-03848224



No abstract found in the PDF.



hal_id    :    hal-03559398



No abstract found in the PDF.



hal_id    :    hal-03537148



The concept of median/consensus has been
widely investigated in order to provide a sta-
tistical summary of ranking data, i.e.
re-
alizations of a random permutation Σ of a
ﬁnite set, {1, . . . , n} with n ≥1 say. As it
sheds light onto only one aspect of Σ’s dis-
tribution P, it may neglect other informative
features. It is the purpose of this paper to
deﬁne analogues of quantiles, ranks and sta-
tistical procedures based on such quantities
for the analysis of ranking data by means of a
metric-based notion of depth function on the
symmetric group. Overcoming the absence
of vector space structure on Sn, the latter
deﬁnes a center-outward ordering of the per-
mutations in the support of P and extends
the classic metric-based formulation of con-
sensus ranking (medians corresponding then
to the deepest permutations). The axiomatic
properties that ranking depths should ideally
possess are listed, while computational and
generalization issues are studied at length.
Beyond the theoretical analysis carried out,
the relevance of the novel concepts and meth-
ods introduced for a wide variety of statistical
tasks are also supported by numerous numer-
ical experiments.
1



hal_id    :    hal-03860881



Actor-critic methods integrating target net-
works have exhibited a stupendous empirical
success in deep reinforcement learning. How-
ever, a theoretical understanding of the use
of target networks in actor-critic methods is
largely missing in the literature. In this pa-
per, we reduce this gap between theory and
practice by proposing the ﬁrst theoretical anal-
ysis of an online target-based actor-critic al-
gorithm with linear function approximation
in the discounted reward setting. Our algo-
rithm uses three diﬀerent timescales: one for
the actor and two for the critic. Instead of
using the standard single timescale temporal
diﬀerence (TD) learning algorithm as a critic,
we use a two timescales target-based version
of TD learning closely inspired from practical
actor-critic algorithms implementing target
networks. First, we establish asymptotic con-
vergence results for both the critic and the
actor under Markovian sampling. Then, we
provide a ﬁnite-time analysis showing the im-
pact of incorporating a target network into
actor-critic methods.
1



hal_id    :    hal-03602455



This paper introduces a new extragradient-type algorithm for a class of
nonconvex-nonconcave minimax problems. It is well-known that ﬁnding a local
solution for general minimax problems is computationally intractable. This ob-
servation has recently motivated the study of structures suﬃcient for convergence
of ﬁrst order methods in the more general setting of variational inequalities when
the so-called weak Minty variational inequality (MVI) holds. This problem class
captures non-trivial structures as we demonstrate with examples, for which a large
family of existing algorithms provably converge to limit cycles. Our results require
a less restrictive parameter range in the weak MVI compared to what is previously
known, thus extending the applicability of our scheme. The proposed algorithm is
applicable to constrained and regularized problems, and involves an adaptive step-
size allowing for potentially larger stepsizes. Our scheme also converges globally
even in settings where the underlying operator exhibits limit cycles.
1



hal_id    :    hal-03727169



— This paper describes the practical response- and
performance-aware development of online speech enhancement
for an augmented reality (AR) headset that helps a user under-
stand conversations made in real noisy echoic environments (e.g.,
cocktail party). One may use a state-of-the-art blind source sep-
aration method called fast multichannel nonnegative matrix fac-
torization (FastMNMF) that works well in various environments
thanks to its unsupervised nature. Its heavy computational cost,
however, prevents its application to real-time processing. In con-
trast, a supervised beamforming method that uses a deep neural
network (DNN) for estimating spatial information of speech and
noise readily fits real-time processing, but suffers from drastic
performance degradation in mismatched conditions. Given such
complementary characteristics, we propose a dual-process ro-
bust online speech enhancement method based on DNN-based
beamforming with FastMNMF-guided adaptation. FastMNMF
(back end) is performed in a mini-batch style and the noisy and
enhanced speech pairs are used together with the original par-
allel training data for updating the direction-aware DNN (front
end) with backpropagation at a computationally-allowable inter-
val. This method is used with a blind dereverberation method
called weighted prediction error (WPE) for transcribing the
noisy reverberant speech of a speaker, which can be detected
from video or selected by a user’s hand gesture or eye gaze, in
a streaming manner and spatially showing the transcriptions
with an AR technique. Our



hal_id    :    hal-03701451



Cet article présente l’approche de l’équipe TGV lors de sa participation à la tâche de base de DEFT
2022, dont l’objectif était de prédire automatiquement les notes obtenues par des étudiants sur la
base de leurs réponses à des questionnaires. Notre stratégie s’est focalisée sur la mise au point d’une
méthode de classification des questions en fonction du type de réponse qu’elles attendent, de manière
à pouvoir mener une approche différenciée pour chaque type. Nos trois runs ont consisté en une
approche non différenciée, servant de référence, et deux approches différenciées, la première se basant
sur la constitution d’un jeu de caractéristiques et la seconde sur le calcul de TF-IDF et de la fonction
de hashage. Notre objectif premier était ainsi de vérifier si des approches dédiées à chaque type de
questions sont préférables à une approche globale.
ABSTRACT
Team TGV at DEFT 2022 : automatic prediction of students’ grades according to the different
question types.
In this paper we present the work of the TGV team for the DEFT 2022 challenge. We tackled the
base task only, which consists of automatically grading students based on their answers to several
questions. Our strategy consider this task as a classification task with multiple approaches, each being
specific to a question type leading to different types of



hal_id    :    hal-03821095



This paper describes a practical dual-process speech enhance-
ment system that adapts environment-sensitive frame-online
beamforming (front-end) with help from environment-free
block-online source separation (back-end). To use minimum
variance distortionless response (MVDR) beamforming, one
may train a deep neural network (DNN) that estimates time-
frequency masks used for computing the covariance matrices
of sources (speech and noise). Backpropagation-based run-
time adaptation of the DNN was proposed for dealing with the
mismatched training-test conditions. Instead, one may try to
directly estimate the source covariance matrices with a state-of-
the-art blind source separation method called fast multichannel
non-negative matrix factorization (FastMNMF). In practice,
however, neither the DNN nor the FastMNMF can be updated
in a frame-online manner due to its computationally-expensive
iterative nature. Our DNN-free system leverages the posteri-
ors of the latest source spectrograms given by block-online
FastMNMF to derive the current source covariance matrices
for frame-online beamforming. The evaluation shows that our
frame-online system can quickly respond to scene changes
caused by interfering speaker movements and outperformed
an existing block-online system with DNN-based beamform-
ing by 5.0 points in terms of the word error rate.
Index Terms— speech enhancement, beamforming, blind
source separation, automatic speech recognition



hal_id    :    hal-03727181



This paper describes noisy speech recognition for an augmented
reality headset that helps verbal communication with in real mul-
tiparty conversational environments. A major approach that has
actively been studied in simulated environments is to sequentially
perform speech enhancement and automatic speech recognition
(ASR) based on deep neural networks (DNNs) trained in a su-
pervised manner. In our task, however, such a pretrained system
fails to work due to the mismatch between the training and test
conditions and the head movements of the user. To enhance only
the utterances of a target speaker, we use beamforming based on
a DNN-based speech mask estimator that can adaptively extract
the speech components corresponding to a head-relative particu-
lar direction. We propose a semi-supervised adaptation method
that jointly updates the mask estimator and the ASR model at
run-time using clean speech signals with ground-truth transcrip-
tions and noisy speech signals with highly-confident estimated
transcriptions. Comparative experiments using the state-of-the-
art distant speech recognition system show that the proposed
method significantly improves the ASR performance.
Index Terms: speech enhancement, speech recognition, human-
computer interaction, run-time adaptation.



hal_id    :    hal-03494781



The Sliced-Wasserstein distance (SW) is being increasingly used in machine learn-
ing applications as an alternative to the Wasserstein distance and offers signiﬁcant
computational and statistical beneﬁts. Since it is deﬁned as an expectation over
random projections, SW is commonly approximated by Monte Carlo. We adopt a
new perspective to approximate SW by making use of the concentration of measure
phenomenon: under mild assumptions, one-dimensional projections of a high-
dimensional random vector are approximately Gaussian. Based on this observation,
we develop a simple deterministic approximation for SW. Our method does not
require sampling a number of random projections, and is therefore both accurate
and easy to use compared to the usual Monte Carlo approximation. We derive
nonasymptotical guarantees for our approach, and show that the approximation
error goes to zero as the dimension increases, under a weak dependence condition
on the data distribution. We validate our theoretical ﬁndings on synthetic datasets,
and illustrate the proposed approximation on a generative modeling problem.
1



hal_id    :    hal-03330800



Recommending automatically a video given a music or a
music given a video has become an important asset for the
audiovisual industry - with user-generated or professional
content. While both music and video have speciﬁc tempo-
ral organizations, most current works do not consider those
and only focus on globally recommending a media. As a
ﬁrst step toward the improvement of these recommenda-
tion systems, we study in this paper the relationship be-
tween music and video temporal organization. We do this
for the case of ofﬁcial music videos, with a quantitative and
a qualitative approach. Our assumption is that the move-
ment in the music are correlated to the ones in the video.
To validate this, we ﬁrst interview a set of internationally
recognized music video experts. We then perform a large-
scale analysis of ofﬁcial music-video clips (which we man-
ually annotated into video genres) using MIR description
tools (downbeats and functional segments estimation) and
Computer Vision tools (shot detection). Our study con-
ﬁrms that a "language of music-video clips" exists; i.e. ed-
itors favor the co-occurrence of music and video events us-
ing strategies such as anticipation. It also highlights that
the amount of co-occurrence depends on the music and
video genres.



hal_id    :    hal-03349734



Despite the success of end-to-end approaches, chroma (or
pitch-class) features remain a useful mid-level represen-
tation of music audio recordings due to their direct in-
terpretability. Since traditional chroma variants obtained
with signal processing suffer from timbral artifacts such
as overtones or vibrato, they do not directly reflect the
pitch classes notated in the score. For this reason, train-
ing a chroma representation using deep learning (“deep
chroma”) has become an interesting strategy.
Existing
approaches involve the use of supervised learning with
strongly aligned labels for which, however, only few
datasets are available. Recently, the Connectionist Tempo-
ral Classification (CTC) loss, initially proposed for speech,
has been adopted to learn monophonic (single-label) pitch-
class features using weakly aligned labels based on corre-
sponding score–audio segment pairs. To exploit this strat-
egy for the polyphonic case, we propose the use of a multi-
label variant of this CTC loss, the MCTC, and formal-
ize this loss for the pitch-class scenario. Our experiments
demonstrate that the weakly aligned approach achieves al-
most equivalent pitch-class estimates than training with
strongly aligned annotations. We then study the sensitivity
of our approach to segment duration and mismatch. Fi-
nally, we compare the learned features with other pitch-
class representations and demonstrate their use for chord
and local key recognition on classical music datasets.



hal_id    :    hal-03574595



Spoken dialog systems need to be able to han-
dle both multiple languages and multilingual-
ity inside a conversation (e.g in case of code-
switching). In this work, we introduce new
pretraining losses tailored to learn multilingual
spoken dialog representations.
The goal of
these losses is to expose the model to code-
switched language. To scale up training, we
automatically build a pretraining corpus com-
posed of multilingual conversations in ﬁve dif-
ferent languages (French, Italian, English, Ger-
man and Spanish) from OpenSubtitles, a
huge multilingual corpus composed of 24.3G
tokens. We test the generic representations on
MIAM, a new benchmark composed of ﬁve di-
alog act corpora on the same aforementioned
languages as well as on two novel multilingual
downstream tasks (i.e multilingual mask utter-
ance retrieval and multilingual inconsistency
identiﬁcation). Our experiments show that our
new code switched-inspired losses achieve a
better performance in both monolingual and
multilingual settings.
1



hal_id    :    hal-03344680



Several recent studies on dyadic human-
human interactions have been done on con-
versations without speciﬁc business objectives.
However, many companies might beneﬁt from
studies dedicated to more precise environ-
ments such as after sales services or customer
satisfaction surveys. In this work, we place
ourselves in the scope of a live chat customer
service in which we want to detect emotions
and their evolution in the conversation ﬂow.
This context leads to multiple challenges that
range from exploiting restricted, small and
mostly unlabeled datasets to ﬁnding and adapt-
ing methods for such context.
We tackle
these challenges by using Few-Shot Learning
while making the hypothesis it can serve con-
versational emotion classiﬁcation for different
languages and sparse labels.
We contribute
by proposing a variation of Prototypical Net-
works for sequence labeling in conversation
that we name ProtoSeq. We test this method
on two datasets with different languages: daily
conversations in English and customer service
chat conversations in French. When applied
to emotion classiﬁcation in conversations, our
method proved to be competitive even when
compared to other ones. The code for Proto-
Seq is available at https://github.com/
gguibon/ProtoSeq.
1



hal_id    :    hal-03574609



Multimodal sentiment analysis is a trending
area of research, and the multimodal fusion
is one of its most active topic. Acknowledg-
ing humans communicate through a variety of
channels (i.e visual, acoustic, linguistic), mul-
timodal systems aim at integrating different
unimodal representations into a synthetic one.
So far, a consequent effort has been made on
developing complex architectures allowing the
fusion of these modalities. However, such sys-
tems are mainly trained by minimising sim-
ple losses such as L1 or cross-entropy.
In
this work, we investigate unexplored penalties
and propose a set of new objectives that mea-
sure the dependency between modalities. We
demonstrate that our new penalties lead to a
consistent improvement (up to 4.3 on accu-
racy) across a large variety of state-of-the-art
models on two well-known sentiment analysis
datasets: CMU-MOSI and CMU-MOSEI. Our
method not only achieves a new SOTA on both
datasets but also produces representations that
are more robust to modality drops. Finally, a
by-product of our methods includes a statisti-
cal network which can be used to interpret the
high dimensional representations learnt by the
model.
1



hal_id    :    hal-03329932



—Analog-to-feature (A2F) conversion is an acquisition
method thought for IoT devices in order to increase wireless
sensor’s battery life. The operating principle of A2F is to
perform classification tasks at sub-Nyquist rate, by extracting
relevant features in the analog domain and then performing
the classification step in the digital domain. We propose to use
non-uniform wavelet sampling (NUWS) combined with feature
selection to find and extract from the signal, a small set of relevant
features for electrocardiogram (ECG) anomalies detection. A
CMOS 0.18 µm mixed architecture for NUWS feature extraction
is proposed, to obtain a power consumption model for A2F.
This model can be taken into account in the feature selection
step by evaluating the energy cost of each wavelet and then
try to maximize classification accuracy while minimizing the
energy needed for extraction. We demonstrate the benefits of A2F
showing that the energy needed can be divided by 15 compared
to classical approach.
Index Terms—Analog-to-Feature converter, Bio-sensing ac-
quisition, Feature selection, Low power, Non-Uniform Wavelet
Sampling.



hal_id    :    hal-03409892



Emergent states are behavioral, cognitive and affective processes ap-
pearing among the members of a group when they interact together.
In the last decade, the development of computational approaches
received a growing interest in building Human-Centered systems.
Such a development is particularly difficult because some of these
states have several dimensions interplaying somehow and some-
where over time. In this paper, we focus on cohesion, its dimensions
and their interplay. Several definitions of cohesion exist, it can be
simply defined as the tendency of a group to stick together to pursue
goals and/or affective needs. This plethora of definitions resulted in
many different cohesion dimensions. Social and Task dimensions
are the most investigated both in Social Sciences and Computer
Science since they both play an important role in a wide range of
contexts and groups. To the best of our knowledge, however, no pre-
vious work on the prediction of cohesion dynamics focused on how
these 2 dimensions interplay. We leverage Social Sciences to address
this issue. In particular, we take advantage of the importance of
Social cohesion for creating flexible and constructive relationships
to reinforce Task cohesion. We describe a Deep Neural Network
architecture (DNN) for predicting the dynamics of Task cohesion
by applying transfer learning from a pre-trained model dedicated
to the prediction of Social cohesion dynamics. Our architecture
is



hal_id    :    hal-03219350



Music source separation is the task of isolating individual instru-
ments which are mixed in a musical piece. This task is particularly
challenging, and even state-of-the-art models can hardly general-
ize to unseen test data. Nevertheless, prior knowledge about indi-
vidual sources can be used to better adapt a generic source sepa-
ration model to the observed signal. In this work, we propose to
exploit a temporal segmentation provided by the user, that indicates
when each instrument is active, in order to ﬁne-tune a pre-trained
deep model for source separation and adapt it to one speciﬁc mix-
ture. This paradigm can be referred to as user-guided one-shot deep
model adaptation for music source separation, as the adaptation
acts on the target song instance only. Our results are promising
and show that state-of-the-art source separation models have large
margins of improvement especially for those instruments which are
underrepresented in the training data.
Index Terms— Music Source Separation, One-shot Domain
Adaptation, User-guided Source Separation



hal_id    :    hal-03298695



In various audio signal processing applications, such as source sepa-
ration and dereverberation, accurate mathematical modeling of both
source signals and room reverberation is needed to properly describe
the audio data. In a previous paper, we introduced a stochastic room
impulse response model based on the image source principle, and
we proposed an expectation-maximization algorithm that was able
to eﬃciently estimate the model parameters in various experimental
settings. This paper aims to extend the model in order to account for
the dependency of the exponential decay over frequency, due to the
walls usually absorbing less energy at low frequencies than at high
frequencies. Our experimental results show that this reﬁnement of
the model is able to generate realistic room impulse responses, that
are perceptively very close to the original ones.
Index Terms— Reverberation, room impulse response, prob-
abilistic modeling, expectation-maximization algorithm, artiﬁcial
reverberation.



hal_id    :    hal-03255349



Estimating mixtures of damped chirp sinusoids in noise is a
problem that affects audio analysis, coding, and synthesis appli-
cations. Phase-based non-stationary parameter estimators assume
that sinusoids can be resolved in the Fourier transform domain,
whereas high-resolution methods estimate superimposed compo-
nents with accuracy close to the theoretical limits, but only for
sinusoids with constant frequencies. We present a new method
for estimating the parameters of superimposed damped chirps that
has an accuracy competitive with existing non-stationary estima-
tors but also has a high-resolution like subspace techniques. Af-
ter providing the analytical expression for a Gaussian-windowed
damped chirp signal’s Fourier transform, we propose an efficient
variational EM algorithm for nonlinear Bayesian regression that
jointly estimates the amplitudes, phases, frequencies, chirp rates,
and decay rates of multiple non-stationary components that may be
obfuscated under the same local maximum in the frequency spec-
trum. Quantitative results show that the new method not only has
an estimation accuracy that is close to the Cramér-Rao bound, but
also a high resolution that outperforms the state-of-the-art.



hal_id    :    hal-03255341



—Supervised source separation requires expensive
synthetic datasets containing clean, ground truth-source signals,
while unsupervised separation requires only data mixtures.
Existing unsupervised methods still use supervision to avoid
over-separation and compete with fully supervised methods. We
present a new method of completely unsupervised single-channel
blind source separation, based on variational auto-encoding,
that automatically learns the correct number of sources in data
mixtures and quantitatively outperforms the existing methods.
A deep inference network disentangles (separates) data mixtures
into low-dimensional latent source variables. A deep generative
network individually decodes each latent source into its source
signal, such that their sum represents the given mixture. Qualita-
tive and quantitative results from separation experiments on pairs
of randomly mixed MNIST handwritten digits and mixed audio
spectrograms demonstrate that our method outperforms state-
of-the-art unsupervised and semi-supervised methods, showing
promise as a solution to this long-standing problem in computer
vision and audition.
Index Terms—blind source separation, Bayesian inference,
unmixing, latent variable model, universal sound separation



hal_id    :    hal-03259801



—Speech enhancement promises higher efﬁciency in
ad-hoc microphone arrays than in constrained microphone
arrays thanks to the wide spatial coverage of the devices in
the acoustic scene. However, speech enhancement in ad-hoc
microphone arrays still raises many challenges. In particular,
the algorithms should be able to handle a variable number of
microphones, as some devices in the array might appear or
disappear. In this paper, we propose a solution that can efﬁciently
process the spatial information captured by the different devices
of the microphone array, while being robust to a link failure. To
do this, we use an attention mechanism in order to put more
weight on the relevant signals sent throughout the array and to
neglect the redundant or empty channels.
Index Terms—Speech enhancement, distributed processing,
attention mechanisms, ad-hoc microphone arrays



hal_id    :    hal-03167498



—The analysis of load curves collected
from smart meters is a key step for many energy man-
agement tasks ranging from consumption forecasting
to customers characterization and load monitoring.
In this contribution, we propose a model based on a
functional formulation of nonnegative tensor factor-
ization and derive updates for the corresponding opti-
mization problem. We show on the concrete example
of multi-sites load curves disaggregation how this
formulation is helpful for 1) exhibiting smooth intra-
day consumption patterns and 2) taking into account
external variables such as the outside temperature.
The beneﬁts are demonstrated on simulated and real
data by exhibiting a meaningful clustering of the
observed sites based on the obtained decomposition.



hal_id    :    hal-03563675



In this paper, we place ourselves in a classi-
ﬁcation scenario in which the target classes
and data type are not accessible during train-
ing. We use a meta-learning approach to de-
termine whether or not meta-trained informa-
tion from common social network data with
ﬁne-grained emotion labels can achieve com-
petitive performance on messages labeled with
different emotion categories. We leverage few-
shot learning to match with the classiﬁcation
scenario and consider metric learning based
meta-learning by setting up Prototypical Net-
works with a Transformer encoder, trained in
an episodic fashion.
This approach proves
to be effective for capturing meta-information
from a source emotional tag set to predict pre-
viously unseen emotional tags. Even though
shifting the data type triggers an expected per-
formance drop, our meta-learning approach
achieves decent results when compared to the
fully supervised one.
1



hal_id    :    hal-03208323



—In this work, we study music/video cross-
modal recommendation, i.e. recommending a music track
for a video or vice versa. We rely on a self-supervised
learning paradigm to learn from a large amount of
unlabelled data. We rely on a self-supervised learning
paradigm to learn from a large amount of unlabelled
data. More precisely, we jointly learn audio and video
embeddings by using their co-occurrence in music-video
clips. In this work, we build upon a recent video-music
retrieval system (the VM-NET), which originally relies on
an audio representation obtained by a set of statistics
computed over handcrafted features. We demonstrate
here that using audio representation learning such as the
audio embeddings provided by the pre-trained MuSimNet,
OpenL3, MusicCNN or by AudioSet, largely improves rec-
ommendations. We also validate the use of the cross-modal
triplet loss originally proposed in the VM-NET compared
to the binary cross-entropy loss commonly used in self-
supervised learning. We perform all our experiments using
the Music Video Dataset (MVD).



hal_id    :    hal-02978978



We propose a novel informed music source separation paradigm,
which can be referred to as neuro-steered music source separation.
More precisely, the source separation process is guided by the user’s
selective auditory attention decoded from his/her EEG response to
the stimulus. This high-level prior information is used to select the
desired instrument to isolate and to adapt the generic source sepa-
ration model to the observed signal. To this aim, we leverage the
fact that the attended instrument’s neural encoding is substantially
stronger than the one of the unattended sources left in the mixture.
This “contrast” is extracted using an attention decoder and used to
inform a source separation model based on non-negative matrix fac-
torization named Contrastive-NMF. The results are promising and
show that the EEG information can automatically select the desired
source to enhance and improve the separation quality.
Index Terms— Audio source separation, Auditory attention de-
coding, Polyphonic music, EEG



hal_id    :    hal-02985794



Speech separation with several speakers is a challenging task be-
cause of the non-stationarity of the speech and the strong signal
similarity between interferent sources. Current state-of-the-art so-
lutions can separate well the different sources using sophisticated
deep neural networks which are very tedious to train. When several
microphones are available, spatial information can be exploited to
design much simpler algorithms to discriminate speakers. We pro-
pose a distributed algorithm that can process spatial information in
a spatially unconstrained microphone array. The algorithm relies on
a convolutional recurrent neural network that can exploit the signal
diversity from the distributed nodes. In a typical case of a meeting
room, this algorithm can capture an estimate of each source in a ﬁrst
step and propagate it over the microphone array in order to increase
the separation performance in a second step. We show that this ap-
proach performs even better when the number of sources and nodes
increases. We also study the inﬂuence of a mismatch in the number
of sources between the training and testing conditions.
Index Terms— Speech separation, microphone arrays, dis-
tributed processing.



hal_id    :    hal-03073936



—In this paper, we compare different audio signal
representations, including the raw audio waveform and a variety
of time-frequency representations, for the task of audio synthesis
with Generative Adversarial Networks (GANs). We conduct the
experiments on a subset of the NSynth dataset. The architecture
follows the benchmark Progressive Growing Wasserstein GAN.
We perform experiments both in a fully non-conditional manner
as well as conditioning the network on the pitch information. We
quantitatively evaluate the generated material utilizing standard
metrics for assessing generative models, and compare training
and sampling times. We show that complex-valued as well
as the magnitude and Instantaneous Frequency of the Short-
Time Fourier Transform achieve the best results, and yield fast
generation and inversion times. The code for feature extraction,
training and evaluating the model is available online.1
Index Terms—audio, representations, synthesis, generative,
adversarial



hal_id    :    hal-03265871



Dans cet article nous reproduisons un scénario d’apprentissage selon lequel les données cibles
ne sont pas accessibles et seules des données connexes le sont. Nous utilisons une approche par
méta-apprentissage aﬁn de déterminer si les méta-informations apprises à partir de messages issus
de médias sociaux, ﬁnement annotés en émotions, peuvent produire de bonnes performances une
fois utilisées sur des messages issus de conversations, étiquetés en émotions avec une granularité
différente. Nous mettons à proﬁt l’apprentissage sur quelques exemples (few-shot learning) pour la
mise en place de ce scénario. Cette approche se montre efﬁcace pour capturer les méta-informations
d’un jeu d’étiquettes émotionnelles pour prédire des étiquettes jusqu’alors inconnues au modèle. Bien
que le fait de varier le type de données engendre une baisse de performance, notre approche par
méta-apprentissage atteint des résultats décents comparés au référentiel d’apprentissage supervisé.
ABSTRACT
Meta-learning : Classifying Messages into Unseen Emotional Categories
In this paper, we place ourselves in a classiﬁcation scenario in which the target data set classes and
data type are not accessible during training. We use a meta-learning approach to determine whether
or not meta-trained information from common social network data with ﬁne-grained emotion labels
can achieve competitive performance on conversation utterances labeled with different, higher level,
emotions. We leverage few-shot learning to concur with the classiﬁcation scenario. This



hal_id    :    hal-02429681



Discrete time trawl processes constitute a large class of time series parameterized by a
trawl sequence (aj)j∈N and deﬁned though a sequence of independent and identically
distributed (i.i.d.) copies of a continuous time process (γ(t))t∈R called the seed process.
They provide a general framework for modeling linear or non-linear long range dependent
time series. We investigate the spectral estimation, either pointwise or broadband, of long
range dependent discrete-time trawl processes. The diﬃculty arising from the variety of
seed processes and of trawl sequences is twofold. First, the spectral density may take
diﬀerent forms, often including smooth additive correction terms. Second, trawl processes
with similar spectral densities may exhibit very diﬀerent statistical behaviors. We prove
the consistency of our estimators under very general conditions and we show that a wide
class of trawl processes satisfy them. This is done in particular by introducing a weighted
weak dependence index that can be of independent interest.
The broadband spectral
estimator includes an estimator of the long memory parameter. We complete this work
with numerical experiments to evaluate the ﬁnite sample size performance of this estimator
for various integer valued discrete time trawl processes.
Keywords: trawl processes; integer-valued time series; long memory parameter estimation
MSC: 62M10; 62F12; 60G51;
1



hal_id    :    hal-03310455



: In this paper, a general stochastic optimization procedure is
studied, unifying several variants of the stochastic gradient descent such
as, among others, the stochastic heavy ball method, the Stochastic Nes-
terov Accelerated Gradient algorithm (S-NAG), and the widely used Adam
algorithm. The algorithm is seen as a noisy Euler discretization of a non-
autonomous ordinary diﬀerential equation, recently introduced by Belotto
da Silva and Gazeau, which is analyzed in depth. Assuming that the objec-
tive function is non-convex and diﬀerentiable, the stability and the almost
sure convergence of the iterates to the set of critical points are established.
A noteworthy special case is the convergence proof of S-NAG in a non-
convex setting. Under some assumptions, the convergence rate is provided
under the form of a Central Limit Theorem. Finally, the non-convergence
of the algorithm to undesired critical points, such as local maxima or saddle
points, is established. Here, the main ingredient is a new avoidance of traps
result for non-autonomous settings, which is of independent interest.
MSC2020 subject classiﬁcations: Primary 62L20; secondary 34A12,
68T99, 60F99.
Keywords and phrases: stochastic approximation, dynamical systems,
adaptive gradient methods with momentum, Nesterov accelerated gradient,
ADAM, avoidance of traps.
Contents
1



hal_id    :    hal-01383554



. The class of observation-driven models (ODMs) includes many
models of non-linear time series which, in a fashion similar to, yet diﬀerent
from, hidden Markov models (HMMs), involve hidden variables. Interestingly,
in contrast to most HMMs, ODMs enjoy likelihoods that can be computed
exactly with computational complexity of the same order as the number of
observations, making maximum likelihood estimation the privileged approach
for statistical inference for these models. A celebrated example of general or-
der ODMs is the GARCH(p, q) model, for which ergodicity and inference has
been studied extensively. However little is known on more general models, in
particular integer-valued ones, such as the log-linear Poisson GARCH or the
NBIN-GARCH of order (p, q) about which most of the existing results seem
restricted to the case p = q = 1. Here we ﬁll this gap and derive ergodicity
conditions for general ODMs. The consistency and the asymptotic normality
of the maximum likelihood estimator (MLE) can then be derived using the
method already developed for ﬁrst order ODMs.



hal_id    :    hal-03189235



Data depth is a concept in multivariate statistics that measures the centrality
of a point in a given data cloud in Rd. If the depth of a point can be represented
as the minimum of the depths with respect to all one-dimensional projections
of the data, then the depth satisﬁes the so-called projection property. Such
depths form an important class that includes many of the depths that have
been proposed in literature. For depths that satisfy the projection property an
approximate algorithm can easily be constructed since taking the minimum of
the depths with respect to only a ﬁnite number of one-dimensional projections
yields an upper bound for the depth with respect to the multivariate data. Such
an algorithm is particularly useful if no exact algorithm exists or if the exact
algorithm has a high computational complexity, as is the case with the halfspace
depth or the projection depth. To compute these depths in high dimensions,
the use of an approximate algorithm with better complexity is surely preferable.
Instead of focusing on a single method we provide a comprehensive and fair
comparison of several methods, both already described in the literature and
original.
Keywords:
data depth, projection property, approximate computation,
∗Corresponding author
Email addresses: rainer.dyckerhoff@statistik.uni-koeln.de (Rainer Dyckerhoﬀ),
pavlo.mozharovskyi@telecom-paris.fr (Pavlo Mozharovskyi), nagy@karlin.mff.cuni.cz
(Stanislav Nagy)
Preprint submitted to Computational Statistics and Data Analysis
November 20,



hal_id    :    hal-02088860



. In this contribution we are interested in proving that a given
observation-driven model is identiﬁable. In the case of a GARCH(p, q) model,
a simple suﬃcient condition has been established in [2] for showing the consis-
tency of the quasi-maximum likelihood estimator. It turns out that this condi-
tion applies for a much larger class of observation-driven models, that we call
the class of linearly observation-driven models. This class includes standard in-
teger valued observation-driven time series such as the Poisson autoregression
model and its numerous extensions. Our results also apply to vector-valued
time series such as the bivariate integer valued GARCH model, to non-linear
models such as the threshold Poisson autoregression or to observation-driven
models with exogenous covariates such as the PARX model.



hal_id    :    hal-03188029



John W. Tukey (1975) deﬁned statistical data depth as a function that determines centrality of
an arbitrary point with respect to a data cloud or to a probability measure. During the last decades,
this seminal idea of data depth evolved into a powerful tool proving to be useful in various ﬁelds
of science. Recently, extending the notion of data depth to the functional setting attracted a lot
of attention among theoretical and applied statisticians. We go further and suggest a notion of
data depth suitable for data represented as curves, or trajectories, which is independent of the
parametrization. We show that our curve depth satisﬁes theoretical requirements of general depth
functions that are meaningful for trajectories. We apply our methodology to diffusion tensor
brain images and also to pattern recognition of hand written digits and letters. Supplementary
Materials are available online.
Keywords: data depth, space of curves, unparametrized curves, nonparametric statistics,
curve registration, DT-MRI ﬁbers, classiﬁcation, DD-plot.
1



hal_id    :    hal-02933051



Screening rules were recently introduced as a technique for explicitly
identifying active structures such as sparsity, in optimization problem
arising in machine learning. This has led to new methods of acceleration
based on a substantial dimension reduction.
We show that screening
rules stem from a combination of natural properties of subdiﬀerential sets
and optimality conditions, and can hence be understood in a uniﬁed way.
Under mild assumptions, we analyze the number of iterations needed to
identify the optimal active set for any converging algorithm. We show that
it only depends on its convergence rate.
1



hal_id    :    hal-03255319



—State space models have been extensively applied
to model and control dynamical systems in disciplines including
neuroscience, target tracking, and audio processing. A common
modeling assumption is that both the state and data noise are
Gaussian because it simpliﬁes the estimation of the system’s state
and model parameters. However, in many real-world scenarios
where the noise is heavy-tailed or includes outliers, this assump-
tion does not hold, and the performance of the model degrades.
In this paper, we present a new approximate inference algorithm
for state space models with Laplace-distributed multivariate data
that is robust to a wide range of non-Gaussian noise. Locally
exact inference is combined with an expectation propagation
algorithm, leading to ﬁltering and smoothing that outperforms
existing approximate inference methods for Laplace-distributed
data, while retaining a fast speed similar to the Kalman ﬁlter.
Further, we present a maximum posterior expectation maximiza-
tion (EM) algorithm that learns the parameters of the model in
an unsupervised way, automatically avoids over-ﬁtting the data,
and provides better model estimation than existing methods for
the Gaussian model. The quality of the inference and learning
algorithms are exempliﬁed through a diverse set of experiments
and an application to non-linear tracking of audio frequency.
Index Terms—Bayesian inference, time series, heavy-tailed
noise, EM algorithm, machine learning, expectation propagation



hal_id    :    hal-02985867



—Deep neural network (DNN)-based speech enhance-
ment algorithms in microphone arrays have now proven to be
efﬁcient solutions to speech understanding and speech recog-
nition in noisy environments. However, in the context of ad-
hoc microphone arrays, many challenges remain and raise the
need for distributed processing. In this paper, we propose to
extend a previously introduced distributed DNN-based time-
frequency mask estimation scheme that can efﬁciently use spatial
information in form of so-called compressed signals which are
pre-ﬁltered target estimations. We study the performance of this
algorithm named Tango under realistic acoustic conditions and
investigate practical aspects of its optimal application. We show
that the nodes in the microphone array cooperate by taking proﬁt
of their spatial coverage in the room. We also propose to use the
compressed signals not only to convey the target estimation but
also the noise estimation in order to exploit the acoustic diversity
recorded throughout the microphone array.



hal_id    :    hal-03255334



—The goal of singing voice separation is to recover the
vocals signal from music mixtures. State-of-the-art performance
is achieved by deep neural networks trained in a supervised
fashion. Since training data are scarce and music signals are ex-
tremely diverse, it remains challenging to achieve high separation
quality across various recording and mixing conditions as well
as music styles. In this paper, we investigate to which extent the
separation can be improved when lyrics transcripts are used as
additional information. To this end, we propose a joint approach
to phoneme level lyrics alignment and text-informed singing voice
separation. It is based on DTW-attention, a new monotonic
attention mechanism including a differentiable approximation
of dynamic time warping. Experimental results show that the
method can align phonemes with mixed singing voice with high
precision given accurate transcripts. It also achieves competitive
results on challenging word level alignment test sets using less
training data than state-of-the-art methods. Sequential alignment
and informed separation lead to improved separation quality ac-
cording to objective measures. Text information helps preserving
spectral phoneme properties in the separated voice signals.
Index Terms—Singing voice separation, lyrics alignment,
monotonic attention mechanism



hal_id    :    hal-02366280



. Adam is a popular variant of stochastic gradient descent for ﬁnding a local minimizer
of a function. In the constant stepsize regime, assuming that the objective function is diﬀerentiable
and non-convex, we establish the convergence in the long run of the iterates to a stationary point
under a stability condition. The key ingredient is the



hal_id    :    hal-03235295



A hybrid approach to room impulse response synthesis
and auralization is developed in the context of an energy-
stress tensor based model of stochastic reverberation. This
method for efﬁciently computing spatially varying en-
ergy envelopes has been demonstrated to represent the
sound ﬁeld in a sufﬁciently-diffusing 1-dimensional hall-
way above 250 Hz. To synthesize a realistic impulse re-
sponse from the computed decay curves, the direct path,
early reﬂections, and low frequency portion of the sound
ﬁeld must be calculated separately and then combined with
the stochastic ﬁeld to form a hybrid scheme. In this work,
we propose one strategy for generating the stochastic ﬁeld
from the aforementioned energy envelopes and suggest
the use of a typical pressure-velocity wave-based scheme
and the image source method to generate the other nec-
essary sound ﬁeld components. Because of the efﬁciency
of the energy-stress tensor based method and the reduced
demands on the secondary simulation technique, such a
hybridization presents a promising architecture for future
real-time auralization in large spaces that may be difﬁcult
to model using only a single method.



hal_id    :    hal-02366337



Although Adam is a very popular algorithm for optimizing the weights of neural networks,
it has been recently shown that it can diverge even in simple convex optimization examples.
Several variants of Adam have been proposed to circumvent this convergence issue. In
this work, we study the Adam algorithm for smooth nonconvex optimization under a
boundedness assumption on the adaptive learning rate. The bound on the adaptive step size
depends on the Lipschitz constant of the gradient of the objective function and provides safe
theoretical adaptive step sizes. Under this boundedness assumption, we show a novel ﬁrst
order convergence rate result in both deterministic and stochastic contexts. Furthermore,
we establish convergence rates of the function value sequence using the Kurdyka- Lojasiewicz
property.
Keywords: Nonconvex optimization, Adaptive gradient methods, Kurdyka- Lojasiewicz
inequality.



hal_id    :    hal-03134854



While being an essential component
of spoken language, ﬁllers (e.g. “um”
or “uh”) often remain overlooked in
Spoken Language Understanding (SLU)
tasks.
We explore the possibility of
representing them with deep contex-
tualised embeddings, showing improve-
ments on modelling spoken language
and two downstream tasks — predict-
ing a speaker’s stance and expressed
conﬁdence.
1



hal_id    :    hal-03127155



. Tempo and genre are two inter-leaved aspects of music, gen-
res are often associated to rhythm patterns which are played in speciﬁc
tempo ranges. In this paper, we focus on the recent Deep Rhythm sys-
tem based on a harmonic representation of rhythm used as an input to
a convolutional neural network. To consider the relationships between
frequency bands, we process complex-valued inputs through complex-
convolutions. We also study the joint estimation of tempo/genre using a
multitask learning approach. Finally, we study the addition of a second
input branch to the system based on a VGG-like architecture applied to
a mel-spectrogram input. This multi-input approach allows to improve
the performances for tempo and genre estimation.
Keywords: Tempo estimation, genre classiﬁcation, deep-learning, com-
plex network, multitask, multi-input.
1



hal_id    :    hal-03200161



Informed source separation has recently gained re-
newed interest with the



hal_id    :    hal-02934433



Music tags are commonly used to describe and catego-
rize music. Various auto-tagging models and datasets have
been proposed for the automatic music annotation with
tags. However, the past approaches often neglect the fact
that many of these tags largely depend on the user, espe-
cially the tags related to the context of music listening. In
this paper, we address this problem by proposing a user-
aware music auto-tagging system and evaluation protocol.
Speciﬁcally, we use both the audio content and user infor-
mation extracted from the user listening history to predict
contextual tags for a given user/track pair. We propose a
new dataset of music tracks annotated with contextual tags
per user. We compare our model to the traditional audio-
based model and study the inﬂuence of user embeddings
on the classiﬁcation quality. Our work shows that explic-
itly modeling the user listening history into the automatic
tagging process could lead to more accurate estimation of
contextual tags.



hal_id    :    hal-02932485



Various audio signal processing applications, such as source
separation and dereverberation, require an accurate mathematical
modeling of the input audio data. In the literature, many works
have focused on source signal modeling, while the reverberation
model is often kept very simplistic.
This paper aims to investigate a stochastic room impulse re-
sponse model presented in a previous article: this model is first
adapted to discrete time, then we propose a parametric estimation
algorithm, that we evaluate experimentally. Our results show that
this algorithm is able to efficiently estimate the model parameters,
in various experimental settings (various signal-to-noise ratios and
absorption coefficients of the room walls).



hal_id    :    hal-02507316



.
We present a framework for deﬁning the “right” level of
explainability based on technical, legal and economic considerations.
Our approach involves three logical steps: First, deﬁne the main con-
textual factors, such as who is the audience of the explanation, the
operational context, the level of harm that the system could cause,
and the legal/regulatory framework. This step will help characterize
the operational and legal needs for explanation, and the correspond-
ing social beneﬁts. Second, examine the technical tools available,
including post-hoc approaches (input perturbation, saliency maps...)
and hybrid AI approaches. Third, as function of the ﬁrst two steps,
choose the right levels of global and local explanation outputs, taking
into the account the costs involved. We identify seven kinds of costs
and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1



hal_id    :    hal-03132996



With the ubiquity of sensors in the IoT era,
statistical observations are becoming increas-
ingly available in the form of massive (multi-
variate) time-series. Formulated as unsuper-
vised anomaly detection tasks, an abundance
of applications like aviation safety manage-
ment, the health monitoring of complex in-
frastructures or fraud detection can now rely
on such functional data, acquired and stored
with an ever ﬁner granularity. The concept
of statistical depth, which reﬂects centrality
of an arbitrary observation w.r.t. a statisti-
cal population may play a crucial role in this
regard, anomalies corresponding to observa-
tions with ’small’ depth. Supported by sound
theoretical and computational developments
in the recent decades, it has proven to be
extremely useful, in particular in functional
spaces.
However, most approaches docu-
mented in the literature consist in evaluat-
ing independently the centrality of each point
forming the time series and consequently ex-
hibit a certain insensitivity to possible shape
changes. In this paper, we propose a novel
notion of functional depth based on the area
of the convex hull of sampled curves, captur-
ing gradual departures from centrality, even
beyond the envelope of the data, in a nat-
ural fashion. We discuss practical relevance
of commonly imposed axioms on functional
depths and investigate which of them are sat-
isﬁed by the notion of depth we promote here.
Estimation and computational issues are also
addressed and various numerical experiments
provide empirical evidence



hal_id    :    hal-02932836



The generalized linear bandit framework has at-
tracted a lot of attention in recent years by ex-
tending the well-understood linear setting and
allowing to model richer reward structures.
It
notably covers the logistic model, widely used
when rewards are binary. For logistic bandits,
the frequentist regret guarantees of existing al-
gorithms are ˜O(κ
√
T), where κ is a problem-
dependent constant. Unfortunately, κ can be ar-
bitrarily large as it scales exponentially with the
size of the decision set. This may lead to sig-
niﬁcantly loose regret bounds and poor empirical
performance. In this work, we study the logis-
tic bandit with a focus on the prohibitive depen-
dencies introduced by κ. We propose a new op-
timistic algorithm based on a ﬁner examination
of the non-linearities of the reward function. We
show that it enjoys a ˜O(
√
T) regret with no de-
pendency in κ, but for a second order term. Our
analysis is based on a new tail-inequality for self-
normalized martingales, of independent interest.



hal_id    :    hal-02547012



The problem of multi-label classification with missing labels (MLML)
is a common challenge that is prevalent in several domains, e.g.
image annotation and auto-tagging. In multi-label classification,
each instance may belong to multiple class labels simultaneously.
Due to the nature of the dataset collection and labelling proce-
dure, it is common to have incomplete annotations in the dataset,
i.e. not all samples are labelled with all the corresponding labels.
However, the incomplete data labelling hinders the training of clas-
sification models. MLML has received much attention from the
research community. However, in cases where a pre-trained model
is fine-tuned on an MLML dataset, there has been no straightfor-
ward approach to tackle the missing labels, specifically when there
is no information about which are the missing ones. In this paper,
we propose a weighted loss function to account for the confidence
in each label/sample pair that can easily be incorporated to fine-
tune a pre-trained model on an incomplete dataset. Our experiment
results show that using the proposed loss function improves the
performance of the model as the ratio of missing labels increases.
CCS CONCEPTS
• Computing methodologies →Neural networks.
KEYWORDS
Multi-label classification; missing labels; neural networks
ACM Reference Format:
Karim M. Ibrahim, Elena V. Epure, Geoffroy Peeters, and Gaël Richard. 2020.
Confidence-based Weighted Loss for Multi-label Classification with Missing
Labels. In Proceedings of the



hal_id    :    hal-02481374



Music listening context such as location or activity has been shown
to greatly inﬂuence the users’ musical tastes. In this work, we study
the relationship between user context and audio content in order to
enable context-aware music recommendation agnostic to user data.
For that, we propose a semi-automatic procedure to collect track sets
which leverages playlist titles as a proxy for context labelling. Using
this, we create and release a dataset of ∼50k tracks labelled with
15 different contexts. Then, we present benchmark classiﬁcation
results on the created dataset using an audio auto-tagging model. As
the training and evaluation of these models are impacted by missing
negative labels due to incomplete annotations, we propose a sample-
level weighted cross entropy loss to account for the conﬁdence in
missing labels and show improved context prediction results.
Index Terms— music auto-tagging, user context, dataset col-
lection, multi-label classiﬁcation, missing labels.



hal_id    :    hal-02477242



Most music streaming services rely on automatic recommendation
algorithms to exploit their large music catalogs. These algorithms
aim at retrieving a ranked list of music tracks based on their similar-
ity with a target music track. In this work, we propose a method for
direct recommendation based on the audio content without explicitly
tagging the music tracks. To that aim, we propose several strategies
to perform triplet mining from ranked lists. We train a Convolutional
Neural Network to learn the similarity via triplet loss. These differ-
ent strategies are compared and validated on a large-scale experiment
against an auto-tagging based approach. The results obtained high-
light the efﬁciency of our system, especially when associated with
an Auto-pooling layer.
Index Terms— audio music similarity, deep learning, triplet
loss, triplet mining.



hal_id    :    hal-02389159



Multichannel processing is widely used for speech enhancement but
several limitations appear when trying to deploy these solutions in
the real world. Distributed sensor arrays that consider several de-
vices with a few microphones is a viable solution which allows for
exploiting the multiple devices equipped with microphones that we
are using in our everyday life. In this context, we propose to extend
the distributed adaptive node-speciﬁc signal estimation approach to
a neural network framework. At each node, a local ﬁltering is per-
formed to send one signal to the other nodes where a mask is esti-
mated by a neural network in order to compute a global multichan-
nel Wiener ﬁlter. In an array of two nodes, we show that this addi-
tional signal can be leveraged to predict the masks and leads to better
speech enhancement performance than when the mask estimation re-
lies only on the local signals.
Index Terms— Speech enhancement, microphone arrays, dis-
tributed processing.



hal_id    :    hal-02457075



Speech separation quality can be improved by exploiting textual
information. However, this usually requires text-to-speech align-
ment at phoneme level. Classical alignment methods are made for
rather clean speech and do not work as well on corrupted speech.
We propose to perform text-informed speech-music separation and
phoneme alignment jointly using recurrent neural networks and the
attention mechanism.
We show that it leads to beneﬁts for both
tasks. In experiments, phoneme transcripts are used to improve the
perceived quality of separated speech over a non-informed baseline.
Moreover, our novel phoneme alignment method based on the at-
tention mechanism achieves state-of-the-art alignment accuracy on
clean and on heavily corrupted speech.
Index Terms— Speech separation, phoneme alignment, atten-
tion, informed source separation



hal_id    :    hal-02456651



Variational inference of the Bayesian linear dynamical system
is a powerful method for estimating latent variable sequences and
learning sparse dynamic models in domains ranging from neuro-
science to audio processing. The hardest part of the method is in-
ferring the model’s latent variable sequence. Here, we propose a so-
lution using matrix inversion lemmas to derive what may be consid-
ered as the Bayesian counterparts to the Kalman ﬁlter and smoother,
which are particular forms of the forward-backward algorithm that
have known properties of numerical stability and efﬁciency. Op-
posed to existing methods, we do not augment the model dimension-
ality, use Cholesky decompositions or inaccurate numerical matrix
inversions. We provide mathematical proof and empirical evidence
that the new algorithm respects parameter expected values to more
accurately infer hidden state statistics. An application to Bayesian
frequency estimation of a stochastic sum of sinusoids model is pre-
sented and compared with state-of-the-art estimators.
Index Terms— Time-series, Kalman ﬁlter, Variational infer-
ence



hal_id    :    hal-02456643



We present a Bayesian ﬁlter for state space models with Laplace-
distributed observation noise that is robust to heavy-tailed and
outlier-ridden univariate time-series data. We analytically derive a
closed-form expression of the exact posterior for a Laplace likeli-
hood conditioned on a Gaussian prior. Posterior statistics are prop-
agated forward in time by a proxy Gaussian density. The forward
Kullback-Leibler divergence from the posterior to the Gaussian
is minimized by matching their moments. The proposed method
supports both linear and non-linear systems, and has a fast recur-
sive structure analogous to the Kalman ﬁlter that enables online
inference. Results show that the new method outperforms existing
approximate inference methods, especially in challenging scenarios
where the system’s parameters are uncertain.
Index Terms— heavy-tailed noise, Kalman ﬁlter, state estima-
tion, Laplace distribution, Bayesian inference



hal_id    :    hal-02914840



The principle of compositionality, which enables natural language to represent
complex concepts via a structured combination of simpler ones, allows us to con-
vey an open-ended set of messages using a limited vocabulary. If compositionality
is indeed a natural property of language, we may expect it to appear in commu-
nication protocols that are created by neural agents in language games. In this
paper, we propose an effective neural iterated learning (NIL) algorithm that, when
applied to interacting neural agents, facilitates the emergence of a more structured
type of language. Indeed, these languages provide learning speed advantages to
neural agents during training, which can be incrementally ampliﬁed via NIL. We
provide a probabilistic model of NIL and an explanation of why the advantage
of compositional language exist. Our experiments conﬁrm our analysis, and also
demonstrate that the emerged languages largely improve the generalizing power
of the neural agent communication.
1



hal_id    :    hal-01613583



In this paper, we consider the design of wavelet ﬁlters based on the Thiran common-
factor approach proposed in Selesnick [2001]. This approach aims at building ﬁnite impulse
response ﬁlters of a Hilbert-pair of wavelets serving as real and imaginary part of a complex
wavelet.
Unfortunately it is not possible to construct wavelets which are both ﬁnitely
supported and analytic. The wavelet ﬁlters constructed using the common-factor approach
are then approximately analytic. Thus, it is of interest to control their analyticity. The
purpose of this paper is to ﬁrst provide precise and explicit expressions as well as easily
exploitable bounds for quantifying the analytic approximation of this complex wavelet.
Then, we prove the existence of such ﬁlters enjoying the classical perfect reconstruction
conditions, with arbitrarily many vanishing moments.
Keywords. Complex wavelet, Hilbert-pair, orthonormal ﬁlter banks, common-factor wavelets
1



hal_id    :    hal-02369882



A new stochastic primal-dual algorithm for solving a composite
optimization problem is proposed. It is assumed that all the functions
/ operators that enter the optimization problem are given as statistical
expectations. These expectations are unknown but revealed across
time through i.i.d realizations. The proposed algorithm is proven to
converge to a saddle point of the Lagrangian function. In the frame-
work of the monotone operator theory, the convergence proof relies on
recent results on the stochastic Forward Backward algorithm involving
random monotone operators. An example of convex optimization under
stochastic linear constraints is considered.
1



hal_id    :    hal-02506409



The recent enthusiasm for artiﬁcial intelligence (AI) is due principally to
advances in deep learning. Deep learning methods are remarkably accurate,
but also opaque, which limits their potential use in safety-critical applications.
To achieve trust and accountability, designers and operators of machine learn-
ing algorithms must be able to explain the inner workings, the results and the
causes of failures of algorithms to users, regulators, and citizens. The orig-
inality of this paper is to combine technical, legal and economic aspects of
explainability to develop a framework for deﬁning the ”right” level of explain-
ability in a given context. We propose three logical steps: First, deﬁne the
main contextual factors, such as who the audience of the explanation is, the
operational context, the level of harm that the system could cause, and the
legal/regulatory framework. This step will help characterize the operational
and legal needs for explanation, and the corresponding social beneﬁts. Second,
examine the technical tools available, including post hoc approaches (input
perturbation, saliency maps...) and hybrid AI approaches. Third, as function
of the ﬁrst two steps, choose the right levels of global and local explanation
outputs, taking into the account the costs involved. We identify seven kinds
of costs and emphasize that explanations are socially useful only when total
social beneﬁts exceed costs.
1We would like to



hal_id    :    hal-04081621



: In this work we establish the posterior consistency for a para-
metrized family of partially observed, fully dominated Markov models. As
a main assumption, we suppose that the prior distribution assigns posi-
tive probability to all neighborhoods of the true parameter, for a distance
induced by the expected Kullback-Leibler divergence between the family
members’ Markov transition densities. This assumption is easily checked
in general. In addition, under some additional, mild assumptions we show
that the posterior consistency is implied by the consistency of the maximum
likelihood estimator. The latter has recently been established also for mod-
els with non-compact state space. The result is then extended to possibly
non-compact parameter spaces and non-stationary observations. Finally,
we check our assumptions on examples including the partially observed
Gaussian linear model with correlated noise and a widely used stochastic
volatility model.



hal_id    :    hal-01440269



We present single imputation method for missing values which borrows the idea of data  
depth—a measure of centrality defined for an arbitrary point of a space with respect to a prob- 
ability distribution or data cloud. This consists in iterative maximization of the depth of each 
observation with missing values, and can be employed with any properly defined statistical depth 
function. For each single iteration, imputation reverts to optimization of quadratic, linear, or 
quasiconcave functions that are solved analytically by linear programming or the Nelder-Mead 
method. As it accounts for the underlying data topology, the procedure is distribution free, allows 
imputation close to the data geometry, can make prediction in situations where local imputation 
(k-nearest neighbors, random forest) cannot, and has attractive robustness and asymptotic prop- 
erties under elliptical symmetry. It is shown that a special case—when using the Mahalanobis 
depth—has direct connection to well-known methods for the multivariate normal model, such as 
iterated regression and regularized PCA. The methodology is extended to multiple imputation for 
data stemming from an elliptically symmetric distribution. Simulation and real data studies show 
good results compared with existing popular alternatives. The method has been implemented as 
an R-package. Supplementary materials for the article



hal_id    :    hal-02433213



Source separation aims at decomposing a vector into additive components. This
is often done by ﬁrst estimating source parameters before feeding them into a
ﬁltering method, often based on ratios of covariances. The whole pipeline is
traditionally rooted in some probabilistic framework providing both the likeli-
hood for parameter estimation and the separation method. While Gaussians
are ubiquitous for this purpose, many studies showed the beneﬁt of heavy-tailed
models for estimation. However, there is no counterpart ﬁltering method to date
exploiting such formalism, so that related studies revert to covariance-based ﬁl-
tering after estimation is ﬁnished.
Here, we introduce a new multivariate separation technique, that fully ex-
ploits the ﬂexibility of α-stable heavy-tailed distributions. We show how a spa-
tial representation can be exploited, which decomposes the observation as an
inﬁnite sum of contributions originating from all directions. Two methods for
separation are derived. The ﬁrst one is non-linear and similar to a beamforming
technique, while the second one is linear, but minimizes a covariation criterion,
which is the counterpart of the covariance for α-stable vectors. We evaluate the
proposed techniques in a large number of challenging and adverse situations on
synthetic experiments, demonstrating their performance for the extraction of
signals from strong interferences.
Keywords:
alpha-stable distribution, separation theory, additive models,
measure theory, optimization
$This work was partly supported by the research



hal_id    :    hal-02399993



—Audio-visual (AV) representation learning is an im-
portant task from the perspective of designing machines with the
ability to understand complex events. To this end, we propose a
novel multimodal framework that instantiates multiple instance
learning. Speciﬁcally, we develop methods that identify events
and localize corresponding AV cues in unconstrained videos.
Importantly, this is done using weak labels where only video-
level event labels are known without any information about their
location in time.
We show that the learnt representations are useful for perform-
ing several tasks such as event/object classiﬁcation, audio event
detection, audio source separation and visual object localization.
An important feature of our method is its capacity to learn
from unsynchronized audio-visual events. We also demonstrate
our framework’s ability to separate out the audio source of
interest through a novel use of nonnegative matrix factorization.
State-of-the-art classiﬁcation results, with a F1-score of 65.0,
are achieved on DCASE 2017 smart cars challenge data with
promising generalization to diverse object types such as musical
instruments. Visualizations of localized visual regions and audio
segments substantiate our system’s efﬁcacy, especially when
dealing with noisy situations where modality-speciﬁc cues appear
asynchronously.
Index Terms—Multimodal classiﬁcation, sound event detection,
object localization, multiple instance learning, deep learning,
audio-visual fusion



hal_id    :    hal-01941152



We present a generic coordinate descent solver for the minimization of a nonsmooth convex ob-
jective with structure. The method can deal in particular with problems with linear constraints.
The implementation makes use of eﬃcient residual updates and automatically determines which
dual variables should be duplicated. A list of basic functional atoms is pre-compiled for eﬃ-
ciency and a modelling language in Python allows the user to combine them at run time. So, the
algorithm can be used to solve a large variety of problems including Lasso, sparse multinomial
logistic regression, linear and quadratic programs.
KEYWORDS
Coordinate descent; convex optimization; generic solver; eﬃcient implementation



hal_id    :    hal-01958485



No abstract found in the PDF.



hal_id    :    hal-01502252



Locally stationary Hawkes processes have been introduced in order to generalise clas-
sical Hawkes processes away from stationarity by allowing for a time-varying second-order
structure. This class of self-exciting point processes has recently attracted a lot of inter-
est in applications in the life sciences (seismology, genomics, neuro-science,...), but also
in the modeling of high-frequency ﬁnancial data. In this contribution we provide a fully
developed nonparametric estimation theory of both local mean density and local Bartlett
spectra of a locally stationary Hawkes process. In particular we apply our kernel estima-
tion of the spectrum localised both in time and frequency to two data sets of transaction
times revealing pertinent features in the data that had not been made visible by classical
non-localised approaches based on models with constant fertility functions over time.
Keywords: Time frequency analysis; Locally stationary time series; high frequency ﬁ-
nancial data; Non-parametric kernel estimation; Self-exciting point processes.
1



hal_id    :    hal-02369439



No abstract found in the PDF.



hal_id    :    hal-01497104



This paper introduces a randomized coordinate descent version of the V˜u-Condat algorithm.
By
coordinate descent, we mean that only a subset of the coordinates of the primal and dual iterates is
updated at each iteration, the other coordinates being maintained to their past value.
Our method
allows us to solve optimization problems with a combination of diﬀerentiable functions, constraints as
well as non-separable and non-diﬀerentiable regularizers.
We show that the sequences generated by our algorithm almost surely converge to a saddle point
of the problem at stake, for a wider range of parameter values than previous methods. In particular,
the condition on the step-sizes depends on the coordinate-wise Lipschitz constant of the diﬀerentiable
function’s gradient, which is a major feature allowing classical coordinate descent to perform so well when
it is applicable. We then prove a sublinear rate of convergence in general and a linear rate of convergence
if the objective enjoys strong convexity properties.
We illustrate the performances of the algorithm on a total-variation regularized least squares regression
problem and on large scale support vector machine problems.
1



hal_id    :    hal-01725134



A stochastic Forward-Backward algorithm with a constant step is studied. At each time
step, this algorithm involves an independent copy of a couple of random maximal monotone
operators. Deﬁning a mean operator as a selection integral, the diﬀerential inclusion built
from the sum of the two mean operators is considered. As a ﬁrst result, it is shown that the
interpolated process obtained from the iterates converges narrowly in the small step regime
to the solution of this diﬀerential inclusion. In order to control the long term behavior of the
iterates, a stability result is needed in addition. To this end, the sequence of the iterates is
seen as a homogeneous Feller Markov chain whose transition kernel is parameterized by the
algorithm step size. The cluster points of the Markov chains invariant measures in the small
step regime are invariant for the semiﬂow induced by the diﬀerential inclusion. Conclusions
regarding the long run behavior of the iterates for small steps are drawn. It is shown that
when the sum of the mean operators is demipositive, the probabilities that the iterates are
away from the set of zeros of this sum are small in Ces`aro mean. The ergodic behavior of
these iterates is studied as well. Applications of the proposed algorithm are considered. In
particular, a



hal_id    :    hal-02280948



The Wasserstein distance and its variations, e.g.,
the sliced-Wasserstein (SW) distance, have re-
cently drawn tremendous amount of attention
from the machine learning community. The SW
distance, speciﬁcally, was shown to have similar
ﬂavor to that of the Wasserstein distance, while
being much simpler to compute, and is used in
various applications including generative mod-
eling and supervised learning. In this paper, we
ﬁrst clarify the mathematical connections between
the SW distance and the Radon transform. We
then utilize the generalized Radon transform to
deﬁne a new family of distances for probabil-
ity measures, which we call generalized sliced-
Wasserstein (GSW) distances. We provide the
conditions under which a GSW is a distance. We
then show that, similarly to the SW distance, the
GSW distance can be extended to a max-GSW
distance.
Finally, we compare the numerical
performance of the proposed distances between
probability measures on several generative model-
ing tasks, including sliced-Wasserstein ﬂows and
sliced-Wasserstein auto-encoders.



hal_id    :    hal-02369435



For the purpose of monitoring the behavior of complex infrastructures (e.g.
aircrafts,
transport or energy networks), high-rate sensors are deployed to capture multivariate data,
generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anoma-
lies that may jeopardize the smooth operation of the system of interest. The statistical
analysis of such massive data of functional nature raises many challenging methodological
questions. The primary goal of this paper is to extend the popular Isolation Forest (IF)
approach to Anomaly Detection, originally dedicated to ﬁnite dimensional observations, to
functional data. The major diﬃculty lies in the wide variety of topological structures that
may equip a space of functions and the great variety of patterns that may characterize
abnormal curves.
We address the issue of (randomly) splitting the functional space in
a ﬂexible manner in order to isolate progressively any trajectory from the others, a key
ingredient to the eﬃciency of the algorithm. Beyond a detailed description of the algo-
rithm, computational complexity and stability issues are investigated at length. From the
scoring function measuring the degree of abnormality of an observation provided by the
proposed variant of the IF algorithm, a Functional Statistical Depth function is deﬁned and
discussed, as well as a multivariate functional extension. Numerical experiments provide
strong empirical evidence of the accuracy of the extension



hal_id    :    hal-02420416



In this paper, we address how to evaluate and improve the perfor-
mance of automatic dominant melody extraction systems from a
pattern mining perspective with a focus on jazz improvisations.
Traditionally, dominant melody extraction systems estimate the
melody on the frame-level, but for real-world musicological appli-
cations note-level representations are needed. For the evaluation of
estimated note tracks, the current frame-wise metrics are not fully
suitable and provide at most a first approximation. Furthermore,
mining melodic patterns (n-grams) poses another challenge because
note-wise errors propagate geometrically with increasing length of
the pattern. On the other hand, for certain derived metrics such as
pattern commonalities between performers, extraction errors might
be less critical if at least qualitative rankings can be reproduced.
Finally, while searching for similar patterns in a melody database
the number of irrelevant patterns in the result set increases with
lower similarity thresholds. For reasons of usability, it would be in-
teresting to know the behavior using imperfect automated melody
extractions. We propose three novel evaluation strategies for es-
timated note-tracks based on three application scenarios: Pattern
mining, pattern commonalities, and fuzzy pattern search. We apply
the proposed metrics to one general state-of-the-art melody esti-
mation method (Melodia) and to two variants of an algorithm that
was optimized for the extraction of jazz solos melodies. A subset of
the Weimar Jazz Database



hal_id    :    hal-02448917



Data-driven models for audio source separation such
as U-Net or Wave-U-Net are usually models dedicated to
and speciﬁcally trained for a single task, e.g. a particu-
lar instrument isolation. Training them for various tasks at
once commonly results in worse performances than train-
ing them for a single specialized task. In this work, we
introduce the Conditioned-U-Net (C-U-Net) which adds
a control mechanism to the standard U-Net. The control
mechanism allows us to train a unique and generic U-Net
to perform the separation of various instruments. The C-
U-Net decides the instrument to isolate according to a one-
hot-encoding input vector. The input vector is embedded
to obtain the parameters that control Feature-wise Linear
Modulation (FiLM) layers. FiLM layers modify the U-Net
feature maps in order to separate the desired instrument via
afﬁne transformations. The C-U-Net performs different in-
strument separations, all with a single model achieving the
same performances as the dedicated ones at a lower cost.



hal_id    :    hal-02457735



Automatic cover detection – the task of ﬁnding in an au-
dio database all the covers of one or several query tracks
– has long been seen as a challenging theoretical problem
in the MIR community and as an acute practical problem
for authors and composers societies. Original algorithms
proposed for this task have proven their accuracy on small
datasets, but are unable to scale up to modern real-life au-
dio corpora. On the other hand, faster approaches designed
to process thousands of pairwise comparisons resulted in
lower accuracy, making them unsuitable for practical use.
In this work, we propose a neural network architecture
that is trained to represent each track as a single embed-
ding vector. The computation burden is therefore left to
the embedding extraction – that can be conducted ofﬂine
and stored, while the pairwise comparison task reduces to
a simple Euclidean distance computation. We further pro-
pose to extract each track’s embedding out of its dominant
melody representation, obtained by another neural network
trained for this task. We then show that this architecture
improves state-of-the-art accuracy both on small and large
datasets, and is able to scale to query databases of thou-
sands of tracks in a few seconds.



hal_id    :    hal-02419361



Events in music frequently exhibit small-scale temporal
deviations (microtiming), with respect to the underlying
regular metrical grid. In some cases, as in music from the
Afro-Latin American tradition, such deviations appear sys-
tematically, disclosing their structural importance in rhyth-
mic and stylistic conﬁguration. In this work we explore the
idea of automatically and jointly tracking beats and micro-
timing in timekeeper instruments of Afro-Latin American
music, in particular Brazilian samba and Uruguayan can-
dombe. To that end, we propose a language model based
on conditional random ﬁelds that integrates beat and onset
likelihoods as observations. We derive those activations
using deep neural networks and evaluate its performance
on manually annotated data using a scheme adapted to this
task. We assess our approach in controlled conditions suit-
able for these timekeeper instruments, and study the micro-
timing proﬁles’ dependency on genre and performer, illus-
trating promising aspects of this technique towards a more
comprehensive understanding of these music traditions.



hal_id    :    hal-02457638



It has been shown that the harmonic series at the tempo
frequency of the onset-strength-function of an audio sig-
nal accurately describes its rhythm pattern and can be used
to perform tempo or rhythm pattern estimation. Recently,
in the case of multi-pitch estimation, the depth of the input
layer of a convolutional network has been used to represent
the harmonic series of pitch candidates. We use a similar
idea here to represent the harmonic series of tempo candi-
dates. We propose the Harmonic-Constant-Q-Modulation
which represents, using a 4D-tensors, the harmonic se-
ries of modulation frequencies (considered as tempo fre-
quencies) in several acoustic frequency bands over time.
This representation is used as input to a convolutional net-
work which is trained to estimate tempo or rhythm pattern
classes. Using a large number of datasets, we evaluate the
performance of our approach and compare it with previous
approaches. We show that it slightly increases Accuracy-1
for tempo estimation but not the average-mean-Recall for
rhythm pattern recognition.



hal_id    :    hal-02371140



The task of predicting ﬁne grained user opin-
ion based on spontaneous spoken language is
a key problem arising in the development of
Computational Agents as well as in the devel-
opment of social network based opinion min-
ers. Unfortunately, gathering reliable data on
which a model can be trained is notoriously dif-
ﬁcult and existing works rely only on coarsely
labeled opinions. In this work we aim at bridg-
ing the gap separating ﬁne grained opinion
models already developed for written language
and coarse grained models developed for spon-
taneous multimodal opinion mining. We take
advantage of the implicit hierarchical structure
of opinions to build a joint ﬁne and coarse
grained opinion model that exploits different
views of the opinion expression. The resulting
model shares some properties with attention-
based models and is shown to provide compet-
itive results on a recently released multimodal
ﬁne grained annotated corpus.
1



hal_id    :    hal-02943462



In the last few years, several datasets have been released
to meet the requirements of “hungry” yet promising data-
driven approaches in music technology research. Since,
for historical reasons, most investigations conducted in the
ﬁeld still revolve around music of the so-called “West-
ern” tradition, the corresponding data, methodology and
conclusions carry a strong cultural bias. Music of non-
“Western” background, whenever present, is usually un-
derrepresented, poorly labeled, or even mislabeled, the
exception being projects that aim at speciﬁcally describ-
ing such music. In this paper we present SAMBASET,
a dataset of Brazilian samba music that contains over
40 hours of historical and modern samba de enredo com-
mercial recordings. To the best of our knowledge, this is
the ﬁrst dataset of this genre. We describe the collection of
metadata (e.g. artist, composer, release date) and outline
our semiautomatic approach to the challenging task of an-
notating beats in this large dataset, which includes the as-
sessment of the performance of state-of-the-art beat track-
ing algorithms for this speciﬁc case. Finally, we present
a study on tempo and beat tracking that illustrates SAM-
BASET’s value, and we comment on other tasks for which
it could be used.



hal_id    :    hal-02280472



Prior information about the target source can improve audio
source separation quality but is usually not available with the nec-
essary level of audio alignment. This has limited its usability in
the past. We propose a separation model that can nevertheless ex-
ploit such weak information for the separation task while aligning
it on the mixture as a byproduct using an attention mechanism. We
demonstrate the capabilities of the model on a singing voice separa-
tion task exploiting artiﬁcial side information with different levels
of expressiveness. Moreover, we highlight an issue with the com-
mon separation quality assessment procedure regarding parts where
targets or predictions are silent and reﬁne a previous contribution
for a more complete evaluation.
Index Terms— informed source separation, singing voice sep-
aration, weak labels, attention, separation evaluation



hal_id    :    hal-02291896



Auditory attention decoding aims at determining which sound
source a subject is “focusing on”. In this work, we address the
problem of EEG-based decoding of auditory attention to a target
instrument in realistic polyphonic music. To this end, we exploit
a stimulus reconstruction model which was proven to decode suc-
cessfully the attention to speech in multi-speaker environments. To
our knowledge, this model was never applied to musical stimuli
for decoding attention. The task we consider here is quite com-
plex as the stimuli used are polyphonic, including duets and trios,
and are reproduced using loudspeakers instead of headphones. We
consider the decoding of three different audio representations and
investigate the inﬂuence on the decoding performance of multiple
variants of musical stimuli, such as the number and type of instru-
ments in the mixture, the spatial rendering, the music genre and
the melody/rhythmical pattern that is played. We obtain promising
results, comparable to those obtained on speech data in previous
works, and conﬁrm that it is possible to correlate the human brain
activity with musically relevant features of the attended source.
Index Terms— Auditory attention decoding, Polyphonic mu-
sic, EEG, Stimulus reconstruction model



hal_id    :    hal-02380780



No abstract found in the PDF.



hal_id    :    hal-02495516



An implementation of acoustic sources is developed in the context of an energetic wave equation derived
from the energy-stress tensor, examined in the one-dimensional case [Dujourdy et al, Acta Acustica
united with Acustica 103:480-491, 2017]. The method efﬁciently models diffuse sound ﬁelds that dom-
inate reverberation at higher frequencies and larger distances. Monopole and dipole electroacoustical
sources are considered. Using loudspeaker models rather than idealized distributions of sound energy
allows for a convenient structure to evaluate directional dependence and frequency dependence for a
variety of source types. Compared to initial condition formulations, an explicit source term enables real-
istic modeling of complex sound sources with the possibility of spatial changes in time. A ﬁnite volume
time domain (FVTD) approach is utilized to lay the groundwork for future extensions to three dimen-
sions. The spatially invariant model parameters are determined iteratively by comparison with in situ
measurements of a long hallway for both the monopole and dipole case in order to verify the validity of
the framework.
Keywords: Room acoustics, ﬁnite difference methods, diffuse ﬁeld
1.



hal_id    :    hal-02166428



. The development of cluster computing frameworks has al-
lowed practitioners to scale out various statistical estimation and ma-
chine learning algorithms with minimal programming eﬀort. This is es-
pecially true for machine learning problems whose objective function
is nicely separable across individual data points, such as classiﬁcation
and regression. In contrast, statistical learning tasks involving pairs (or
more generally tuples) of data points — such as metric learning, clus-
tering or ranking — do not lend themselves as easily to data-parallelism
and in-memory computing. In this paper, we investigate how to bal-
ance between statistical performance and computational eﬃciency in
such distributed tuplewise statistical problems. We ﬁrst propose a sim-
ple strategy based on occasionally repartitioning data across workers
between parallel computation stages, where the number of repartition-
ing steps rules the trade-oﬀbetween accuracy and runtime. We then
present some theoretical results highlighting the beneﬁts brought by the
proposed method in terms of variance reduction, and extend our results
to design distributed stochastic gradient descent algorithms for tuplewise
empirical risk minimization. Our results are supported by numerical ex-
periments in pairwise statistical estimation and learning on synthetic and
real-world datasets.
Keywords: Distributed Machine Learning · Distributed Data Process-
ing · U-Statistics · Stochastic Gradient Descent · AUC Optimization
1



hal_id    :    hal-02291882



We present MAD-EEG, a new, freely available dataset for
studying EEG-based auditory attention decoding considering
the challenging case of subjects attending to a target instrument
in polyphonic music. The dataset represents the ﬁrst music-
related EEG dataset of its kind, enabling, in particular, studies
on single-trial EEG-based attention decoding, while also open-
ing the path for research on other EEG-based music analysis
tasks. MAD-EEG has so far collected 20-channel EEG signals
recorded from 8 subjects listening to solo, duo and trio mu-
sic excerpts and attending to one pre-speciﬁed instrument. The
proposed experimental setting differs from the ones previously
considered as the stimuli are polyphonic and are played to the
subject using speakers instead of headphones. The stimuli were
designed considering variations in terms of number and type of
instruments in the mixture, spatial rendering, music genre and
melody that is played. Preliminary results obtained with a state-
of-the-art stimulus reconstruction algorithm commonly used for
speech stimuli show that the audio representation reconstructed
from the EEG response is more correlated with that of the at-
tended source than with the one of the unattended source, prov-
ing the dataset to be suitable for such kind of studies.
Index Terms: Auditory attention, Polyphonic music, EEG



hal_id    :    hal-02288063



—We propose a semi-supervised multichannel speech
enhancement system based on a probabilistic model which as-
sumes that both speech and noise follow the heavy-tailed multi-
variate complex Cauchy distribution. As we advocate, this allows
handling strong and adverse noisy conditions. Consequently, the
model is parameterized by the source magnitude spectrograms
and the source spatial scatter matrices. To deal with the non-
additivity of scatter matrices, our ﬁrst contribution is to perform
the enhancement on a projected space. Then, our second contri-
bution is to combine a latent variable model for speech, which
is trained by following the variational autoencoder framework,
with a low-rank model for the noise source. At test time, an it-
erative inference algorithm is applied, which produces estimated
parameters to use for separation. The speech latent variables are
estimated ﬁrst from the noisy speech and then updated by a gra-
dient descent method, while a majorization-equalization strategy
is used to update both the noise and the spatial parameters of
both sources. Our experimental results show that the Cauchy
model outperforms the state-of-art methods. The standard devi-
ation scores also reveal that the proposed method is more robust
against non-stationary noise.
Index Terms—Multichannel speech enhancement, multivariate
complex Cauchy distribution, variational autoencoder, nonnega-
tive matrix factorization



hal_id    :    hal-02367908



—In this paper, we investigate machine learning
approaches addressing the problem of geolocation. First, we
review some classical learning methods to build a radio map. In
particular, these methods are splitted in two categories, which we
refer to as likelihood-based methods and ﬁngerprinting methods.
Then, we provide a novel geolocation approach in each of
these two categories. The ﬁrst proposed technique relies on a
semi-parametric Nadaraya-Watson estimator of the likelihood,
followed by a maximum a posteriori (MAP) estimator of the
object’s position. The second technique consists in learning a
proper metric on the dataset, constructed by means of a Gradient
boosting regressor: a k-nearest neighbor algorithm is then used
to estimate the position. Finally, all the proposed methods are
compared on a data set originated from Sigfox network. The
experiments show the interest of the proposed methods, both in
terms of location estimation performance, and of ability to build
radio maps.
Keywords: LPWA Network, localization, maximum
likelihood, metric learning



hal_id    :    hal-02420403



In recent years the task of downbeat tracking has received increasing
attention and the state of the art has been improved with the intro-
duction of deep learning methods. Among proposed solutions, exist-
ing systems exploit short-term musical rules as part of their language
modelling. In this work we show in an oracle scenario how including
longer-term musical rules, in particular music structure, can enhance
downbeat estimation. We introduce a skip-chain conditional random
ﬁeld language model for downbeat tracking designed to include sec-
tion information in an uniﬁed and ﬂexible framework. We combine
this model with a state-of-the-art convolutional-recurrent network
and we contrast the system’s performance to the commonly used
Bar Pointer model. Our experiments on the popular Beatles dataset
show that incorporating structure information in the language model
leads to more consistent and more robust downbeat estimations.
Index Terms— Downbeat Tracking, Music Structure, Deep
Learning, Skip-Chain Conditional Random Fields, Convolutional-
Recurrent Neural Networks.



hal_id    :    hal-02051399



Machine learning and game theory are known to exhibit a
very strong link as they mutually provide each other with so-
lutions and models allowing to study and analyze the optimal
behaviour of a set of agents. In this paper, we take a closer
look at a special class of games, known as fair cost sharing
games, from a machine learning perspective. We show that
this particular kind of games, where agents can choose be-
tween selﬁsh behaviour and cooperation with shared costs,
has a natural link to several machine learning scenarios in-
cluding collaborative learning with homogeneous and het-
erogeneous sources of data. We further demonstrate how the
game-theoretical results bounding the ratio between the best
Nash equilibrium (or its approximate counterpart) and the op-
timal solution of a given game can be used to provide the up-
per bound of the gain achievable by the collaborative learn-
ing expressed as the expected risk and the sample complexity
for homogeneous and heterogeneous cases, respectively. We
believe that the established link can spur many possible fu-
ture implications for other learning scenarios as well, with
privacy-aware learning being among the most noticeable ex-
amples.



hal_id    :    hal-02457728



—Estimation of dominant melody in polyphonic music
remains a difﬁcult task, even though promising breakthroughs
have been done recently with the



hal_id    :    hal-01900037



Popular machine learning estimators involve
regularization parameters that can be chal-
lenging to tune, and standard strategies rely
on grid search for this task. In this paper,
we revisit the techniques of approximating
the regularization path up to predeﬁned tol-
erance ϵ in a uniﬁed framework and show
that its complexity is O(1/ d√ϵ) for uniformly
convex loss of order d > 0 and O(1/√ϵ)
for Generalized Self-Concordant functions.
This framework encompasses least-squares
but also logistic regression (a case that as far
as we know was not handled as precisely by
previous works). We leverage our technique
to provide reﬁned bounds on the validation
error as well as a practical algorithm for hy-
perparameter tuning.
The later has global
convergence guarantee when targeting a pre-
scribed accuracy on the validation set. Last
but not least, our approach helps relieving
the practitioner from the (often neglected)
task of selecting a stopping criterion when
optimizing over the training set: our method
automatically calibrates it based on the tar-
geted accuracy on the validation set.
1



hal_id    :    hal-02019103



Estimating the main melody of a polyphonic audio record-
ing remains a challenging task. We approach the task from
a classiﬁcation perspective and adopt a convolutional re-
current neural network (CRNN) architecture that relies on
a particular form of pretraining by source-ﬁlter nonneg-
ative matrix factorisation (NMF). The source-ﬁlter NMF
decomposition is chosen for its ability to capture the pitch
and timbre content of the leading voice/instrument, pro-
viding a better initial pitch salience than standard time-
frequency representations. Starting from such a musically
motivated representation, we propose to further enhance
the NMF-based salience representations with CNN lay-
ers, then to model the temporal structure by an RNN net-
work and to estimate the dominant melody with a ﬁnal
classiﬁcation layer. The results show that such a system
achieves state-of-the-art performance on the MedleyDB
dataset without any augmentation methods or large train-
ing sets.



hal_id    :    hal-01795319



—In the ﬁeld of room acoustics, it is well known that
reverberation can be characterized statistically in a particular
region of the time-frequency domain (after the transition time
and above Schroeder’s frequency). Since the 1950s, various
formulas have been established, focusing on particular aspects of
reverberation: exponential decay over time, correlations between
frequencies, correlations between sensors at each frequency,
and time-frequency distribution. In this paper, we introduce a
new stochastic reverberation model, that permits us to retrieve
all these well-known results within a common mathematical
framework. To the best of our knowledge, this is the ﬁrst time
that such a uniﬁcation work is presented. The beneﬁts are
multiple: several new formulas generalizing the classical results
are established, that jointly characterize the spatial, temporal
and spectral properties of late reverberation.
Index Terms—Reverberation, room impulse response, room
frequency response, stochastic models, Poisson processes, station-
ary processes, Wigner distribution.



hal_id    :    hal-02943467



Downbeat tracking consists of annotating a piece of mu-
sical audio with the estimated position of the ﬁrst beat of
each bar. In recent years, increasing attention has been paid
to applying deep learning models to this task, and various
architectures have been proposed, leading to a signiﬁcant
improvement in accuracy. However, there are few insights
about the role of the various design choices and the delicate
interactions between them. In this paper we offer a system-
atic investigation of the impact of largely adopted variants.
We study the effects of the temporal granularity of the in-
put representation (i.e. beat-level vs tatum-level) and the
encoding of the networks outputs. We also investigate the
potential of convolutional-recurrent networks, which have
not been explored in previous downbeat tracking systems.
To this end, we exploit a state-of-the-art recurrent neural
network where we introduce those variants, while keeping
the training data, network learning parameters and post-
processing stages ﬁxed. We ﬁnd that temporal granularity
has a signiﬁcant impact on performance, and we analyze
its interaction with the encoding of the networks outputs.



hal_id    :    hal-02912385



Noise-Contrastive Estimation (NCE) is a learning criterion that is regularly used to train neural
language models in place of Maximum Likelihood Estimation, since it avoids the computational
bottleneck caused by the output softmax. In this paper, we analyse and explain some of the
weaknesses of this objective function, linked to the mechanism of self-normalization, by closely
monitoring comparative experiments. We then explore several remedies and modiﬁcations to
propose tractable and efﬁcient NCE training strategies. In particular, we propose to make the
scaling factor a trainable parameter of the model, and to use the noise distribution to initialize the
output bias. These solutions, yet simple, yield stable and competitive performances in either small
and large scale language modelling tasks.
1



hal_id    :    hal-01950907



Motivated by Supervised Opinion Analysis, we
propose a novel framework devoted to Structured
Output Learning with Abstention (SOLA). The
structure prediction model is able to abstain from
predicting some labels in the structured output
at a cost chosen by the user in a ﬂexible way.
For that purpose, we decompose the problem into
the learning of a pair of predictors, one devoted
to structured abstention and the other, to struc-
tured output prediction.
To compare fully la-
beled training data with predictions potentially
containing abstentions, we deﬁne a wide class of
asymmetric abstention-aware losses. Learning is
achieved by surrogate regression in an appropriate
feature space while prediction with abstention is
performed by solving a new pre-image problem.
Thus, SOLA extends recent ideas about Struc-
tured Output Prediction via surrogate problems
and calibration theory and enjoys statistical guar-
antees on the resulting excess risk. Instantiated
on a hierarchical abstention-aware loss, SOLA is
shown to be relevant for ﬁne-grained opinion min-
ing and gives state-of-the-art results on this task.
Moreover, the abstention-aware representations
can be used to competitively predict user-review
ratings based on a sentence-level opinion predic-
tor.



hal_id    :    lirmm-01766795



. This paper introduces a new method for multichannel speech
enhancement based on a versatile modeling of the residual noise spec-
trogram. Such a model has already been presented before in the single
channel case where the noise component is assumed to follow an alpha-
stable distribution for each time-frequency bin, whereas the speech spec-
trogram, supposed to be more regular, is modeled as Gaussian. In this
paper, we describe a multichannel extension of this model, as well as
a Monte Carlo Expectation - Maximisation algorithm for parameter es-
timation. In particular, a multichannel extension of the Itakura-Saito
nonnegative matrix factorization is exploited to estimate the spectral
parameters for speech, and a Metropolis-Hastings algorithm is proposed
to estimate the noise contribution. We evaluate the proposed method in
a challenging multichannel denoising application and compare it to other
state-of-the-art algorithms.
1



hal_id    :    hal-02912471



L’estimation contrastive bruitée (NCE) et l’échantillonage par importance (IS) sont des procédures
d’entraînement basées sur l’échantillonage, que l’on utilise habituellement à la place de l’estimation
du maximum de vraisemblance (MLE) pour éviter le calcul du softmax lorsque l’on entraîne des
modèles de langue neuronaux. Dans cet article, nous cherchons à résumer le fonctionnement de ces
algorithmes, et leur utilisation dans la littérature du TAL. Nous les comparons expérimentalement, et
présentons des manières de faciliter l’entraînement du NCE.
ABSTRACT
Here the title in English.
Noise Contrastive Estimation (NCE) and Importance Sampling (IS) are sampling based algorithms
traditionally used to avoid computing the costly output softmax when training neural language models
with Maximum Likelihood Estimation (MLE). In this work, we attempt to summarize how these
procedures work, and how they have been used in the computational linguistics literature. We then
compare them, and experiment with tricks that ease NCE training.
MOTS-CLÉS : Modèle de langue, Estimation contrastive bruitée, Negative Sampling.
KEYWORDS: Neural Language Model, Noise Contrastive Estimation, Negative Sampling.



hal_id    :    hal-04267897



—Historical documents present many challenges
for ofﬂine handwriting recognition systems, among them, the
segmentation and labeling steps. Carefully annotated text-
lines are needed to train an HTR system. In some scenarios,
transcripts are only available at the paragraph level with no
text-line information. In this work, we demonstrate how to
train an HTR system with few labeled data. Speciﬁcally, we
train a deep convolutional recurrent neural network (CRNN)
system on only 10% of manually labeled text-line data from a
dataset and propose an incremental training procedure that
covers the rest of the data. Performance is further increased
by augmenting the training set with specially crafted multi-
scale data. We also propose a model-based normalization
scheme which considers the variability in the writing scale at
the recognition phase. We apply this approach to the publicly
available READ dataset1. Our system achieved the second
best result during the ICDAR2017 competition [1].
Keywords-CRNN, handwriting recognition, historical docu-
ments, variability, multi-scale training, model-based normal-
ization scheme, limited labeled data



hal_id    :    hal-02369904



The Douglas Rachford algorithm is an algorithm that converges
to a minimizer of a sum of two convex functions. The algo-
rithm consists in ﬁxed point iterations involving computations
of the proximity operators of the two functions separately.
The paper investigates a stochastic version of the algorithm
where both functions are random and the step size is constant.
We establish that the iterates of the algorithm stay close to
the set of solution with high probability when the step size
is small enough. Application to structured regularization is
considered.
Index Terms— Stochastic optimization, proximal me-
thods, Douglas Rachford algorithm, structured regulariza-
tions



hal_id    :    hal-01724272



This paper proposes a patient-speciﬁc supervised classiﬁca-
tion algorithm to detect seizures in long ofﬂine intracranial
electroencephalographic (iEEG) recordings. The main idea
of the proposed algorithm is to combine a set of probabilistic
classiﬁers, trained on a dataset of 1 s epochs, into a weighted
ensemble classiﬁer which can be used to analyze longer 5 s
data segments. The method is trained and evaluated on 24 pa-
tients, all suffering from focal medically intractable epilepsy,
from the Epilepsiae database. The evaluation of the method,
conducted using an average of 113 hours (min: 32 h, max:
229 h) of iEEG data per patient, shows that the proposed al-
gorithm improves upon existing methods for seizure detection
with iEEG.
Index Terms— Seizure detection, intracranial EEG, su-
pervised learning



hal_id    :    hal-01714909



In this study, we propose a novel probabilistic model for sepa-
rating clean speech signals from noisy mixtures by decomposing
the mixture spectrograms into a structured speech part and a more
ﬂexible residual part.
The main novelty in our model is that it
uses a family of heavy-tailed distributions, so called the α-stable
distributions, for modeling the residual signal.
We develop an
expectation-maximization algorithm for parameter estimation and a
Monte Carlo scheme for posterior estimation of the clean speech.
Our experiments show that the proposed method outperforms rele-
vant factorization-based algorithms by a signiﬁcant margin.
Index Terms— Alpha-stable distributions, Audio source sepa-
ration, Speech enhancement, Monte Carlo Expectation-Maximization



hal_id    :    hal-01812011



In high dimension, it is customary to consider
Lasso-type estimators to enforce sparsity. For
standard Lasso theory to hold, the regulariza-
tion parameter should be proportional to the
noise level, which is often unknown in prac-
tice. A remedy is to consider estimators such
as the Concomitant Lasso, which jointly opti-
mize over the regression coeﬃcients and the
noise level. However, when data from diﬀer-
ent sources are pooled to increase sample size,
noise levels diﬀer and new dedicated estima-
tors are needed. We provide new statistical
and computational solutions to perform het-
eroscedastic regression, with an emphasis on
brain imaging with magneto- and electroen-
cephalography (M/EEG). When instantiated
to de-correlated noise, our framework leads to
an eﬃcient algorithm whose computational
cost is not higher than for the Lasso, but ad-
dresses more complex noise structures. Ex-
periments demonstrate improved prediction
and support identiﬁcation with correct esti-
mation of noise levels.
1



hal_id    :    hal-02713307



. Audio-visual representation learning is an important task
from the perspective of designing machines with the ability to understand
complex events. To this end, we propose a novel multimodal framework
that instantiates multiple instance learning. We show that the learnt
representations are useful for classifying events and localizing their char-
acteristic audio-visual elements. The system is trained using only video-
level event labels without any timing information. An important feature
of our method is its capacity to learn from unsynchronized audio-visual
events. We achieve state-of-the-art results on a large-scale dataset of
weakly-labeled audio event videos. Visualizations of localized visual re-
gions and audio segments substantiate our system’s eﬃcacy, especially
when dealing with noisy situations where modality-speciﬁc cues appear
asynchronously.
Keywords: Audio-visual fusion, multimodal deep learning, multiple in-
stance learning, event classiﬁcation, audio-visual localization
1



hal_id    :    hal-01718718



—For audio source separation applications, it is com-
mon to estimate the magnitude of the short-time Fourier trans-
form (STFT) of each source. In order to further synthesizing
time-domain signals, it is necessary to recover the phase of the
corresponding complex-valued STFT. Most authors in this ﬁeld
choose a Wiener-like ﬁltering approach which boils down to
using the phase of the original mixture. In this paper, a different
standpoint is adopted. Many music events are partially composed
of slowly varying sinusoids and the STFT phase increment over
time of those frequency components takes a speciﬁc form. This
allows phase recovery by an unwrapping technique once a short-
term frequency estimate has been obtained. Herein, a novel
iterative source separation procedure is proposed which builds
upon these results. It consists in minimizing the mixing error
by means of the auxiliary function method. This procedure is
initialized by exploiting the unwrapping technique in order to
generate estimates that beneﬁt from a temporal continuity prop-
erty. Experiments conducted on realistic music pieces show that,
given accurate magnitude estimates, this procedure outperforms
the state-of-the-art consistent Wiener ﬁlter.
Index Terms—Phase recovery, sinusoidal modeling, phase un-
wrapping, auxiliary function method, audio source separation.



hal_id    :    hal-01584755



—This paper presents a Bayesian framework for
under-determined audio source separation in multichannel re-
verberant mixtures. We model the source signals as Student’s t
latent random variables in a time-frequency domain. The speciﬁc
structure of musical signals in this domain is exploited by means
of a non-negative matrix factorization model. Conversely, we
design the mixing model in the time domain. In addition to
leading to an exact representation of the convolutive mixing
process, this approach allows us to develop simple probabilistic
priors for the mixing ﬁlters. Indeed, as those ﬁlters correspond to
room responses they exhibit a simple characteristic structure in
the time domain that can be used to guide their estimation. We
also rely on the Student’s t distribution for modeling the impulse
response of the mixing ﬁlters. From this model, we develop a
variational inference algorithm in order to perform source sepa-
ration. The experimental evaluation demonstrates the potential of
this approach for separating multichannel reverberant mixtures.
Index Terms—Audio source separation, multichannel reverber-
ant mixtures, Student’s t distribution, statistical room acoustics,
non-negative matrix factorization, variational inference.



hal_id    :    hal-01269137



. In this contribution we introduce weakly locally stationary time series through
the local approximation of the non-stationary covariance structure by a stationary one.
This allows us to deﬁne autoregression coeﬃcients in a non-stationary context, which, in
the particular case of a locally stationary Time Varying Autoregressive (TVAR) process,
coincide with the generating coeﬃcients. We provide and study an estimator of the time
varying autoregression coeﬃcients in a general setting. The proposed estimator of these
coeﬃcients enjoys an optimal minimax convergence rate under limited smoothness condi-
tions. In a second step, using a bias reduction technique, we derive a minimax-rate estima-
tor for arbitrarily smooth time-evolving coeﬃcients, which outperforms the previous one
for large data sets. In turn, for TVAR processes, the predictor derived from the estimator
exhibits an optimal minimax prediction rate.



hal_id    :    hal-01682750



In this paper, we introduce a training and compensation algorithm of the class-conditioned basis vectors in the non-negative matrix
factorization (NMF) model for single-channel speech enhancement. The main goal is to estimate the basis vectors of different
signal sources in a way that prevents them from representing other sources, in order to reduce the residual noise components that
have features similar to the speech signal. During the proposed training stage, the basis matrices for the clean speech and noises
are estimated jointly by constraining them to belong to different classes. To this end, we employ the probabilistic generative model
(PGM) of classiﬁcation, speciﬁed by class-conditional densities, as an a priori distribution for the basis vectors. The update rules of
the NMF and the PGM parameters of classiﬁcation are jointly obtained by using the variational Bayesian expectation-maximization
(VBEM) algorithm, which guarantees convergence to a stationary point. Another goal of the proposed algorithm is to handle a
mismatch between the characteristics of the training and test data. This is accomplished during the proposed enhancement stage,
where we implement a basis compensation scheme. Speciﬁcally, we use extra free basis vectors to capture the features which are
not included in the training data. Objective experimental results for different combination of speaker and noise types



hal_id    :    hal-01679078



We address the issue of reliably detecting and quantifying cross-frequency coupling (CFC)
in neural time series. Based on non-linear auto-regressive models, the proposed method
provides a generative and parametric model of the time-varying spectral content of the
signals. As this method models the entire spectrum simultaneously, it avoids the pitfalls
related to incorrect filtering or the use of the Hilbert transform on wide-band signals. As the
model is probabilistic, it also provides a score of the model “goodness of fit” via the likeli-
hood, enabling easy and legitimate model selection and parameter comparison; this data-
driven feature is unique to our model-based approach. Using three datasets obtained with
invasive neurophysiological recordings in humans and rodents, we demonstrate that these
models are able to replicate previous results obtained with other metrics, but also reveal
new insights such as the influence of the amplitude of the slow oscillation. Using simulations,
we demonstrate that our parametric method can reveal neural couplings with shorter signals
than non-parametric methods. We also show how the likelihood can be used to find optimal
filtering parameters, suggesting new properties on the spectrum of the driving signal, but
also to estimate the optimal delay between the coupled signals, enabling a directionality esti-
mation in the coupling.
Author summary
Neural oscillations synchronize information across brain areas at



hal_id    :    hal-01362864



—In this paper, we study the usefulness of various
matrix factorization methods for learning features to be used
for the speciﬁc Acoustic Scene Classiﬁcation problem. A com-
mon way of addressing ASC has been to engineer features
capable of capturing the speciﬁcities of acoustic environments.
Instead, we show that better representations of the scenes can
be automatically learned from time-frequency representations
using matrix factorization techniques. We mainly focus on ex-
tensions including sparse, kernel-based, convolutive and a novel
supervised dictionary learning variant of Principal Component
Analysis and Nonnegative Matrix Factorization. An experimental
evaluation is performed on two of the largest ASC datasets
available in order to compare and discuss the usefulness of these
methods for the task. We show that the unsupervised learning
methods provide better representations of acoustic scenes than
the best conventional hand-crafted features on both datasets.
Furthermore, the



hal_id    :    hal-01370542



In this paper we provide a formal justiﬁcation of the use of time-frequency
reassignment techniques on time-frequency transforms of discrete time signals.
State of the art techniques indeed rely on formulae established in the continuous
case which are applied, in a somehow inaccurate manner, to discrete time signals.
Here, we formally derive a general framework for discrete time reassignment. To
illustrate its applicability and generality, this framework is applied to a speciﬁc
transform: the Constant-Q Transform.
Keywords:
Reassigned time-frequency representations, reassigned CQT,
discrete signals, synchrosqueezing



hal_id    :    hal-01404966



No abstract found in the PDF.



hal_id    :    hal-01636627



This paper introduces improvements to nonnegative feature
learning-based methods for acoustic scene classiﬁcation. We start
by introducing modiﬁcations to the task-driven nonnegative ma-
trix factorization algorithm. The proposed adapted scaling algo-
rithm improves the generalization capability of task-driven nonneg-
ative matrix factorization for the task. We then propose to exploit
simple deep neural network architecture to classify both low level
time-frequency representations and unsupervised nonnegative ma-
trix factorization activation features independently. Moreover, we
also propose a deep neural network architecture that exploits jointly
unsupervised nonnegative matrix factorization activation features
and low-level time frequency representations as inputs. Finally, we
present a fusion of proposed systems in order to further improve
performance. The resulting systems are our submission for the task
1 of the DCASE 2017 challenge.
Index Terms— Feature learning, Nonnegative Matrix Factor-
ization, Deep Neural Networks,



hal_id    :    hal-01593459



Leveraging the celebrated support vector regression (SVR) method, we propose a unifying
framework in order to deliver regression machines in reproducing kernel Hilbert spaces
(RKHSs) with data sparsity. The central point is a new deﬁnition of ϵ-insensitivity, valid for
many regression losses (including quantile and expectile regression) and their multivariate
extensions. We show that the dual optimization problem to empirical risk minimization
with ϵ-insensitivity involves a data sparse regularization. We also provide an analysis of
the excess of risk as well as a randomized coordinate descent algorithm for solving the dual.
Numerical experiments validate our approach.
Keywords: Quantile regression, Expectile regression, Operator-valued kernel.



hal_id    :    hal-02365695



—This paper introduces a constant step size adaptive
algorithm for distributed optimization on a graph. The algorithm
is of diffusion-adaptation type and is asynchronous: at every iter-
ation, some randomly selected nodes compute some local variable
by means of a proximity operator involving a locally observed
random variable, and share these variable with neighbors. The
algorithm is built upon a stochastic version of the Douglas-
Rachford algorithm. A practical application to target localization
using measurements from multistatic continuous active sonar
systems is investigated at length.
Index Terms—Adaptive algorithms, stochastic approximation,
distributed optimization, proximal operator, target localization.



hal_id    :    hal-01548475



While most dereverberation methods focus on how to estimate the
magnitude of an anechoic signal in the time-frequency domain, we
propose a method which also takes the phase into account. By ap-
plying a harmonic model to the anechoic signal, we derive a formu-
lation to compute the amplitude and phase of each harmonic. These
parameters are then estimated by our method in presence of rever-
beration. As we jointly estimate the amplitude and phase of the
clean signal, we achieve a very strong dereverberation on synthetic
harmonic signals, resulting in a signiﬁcant improvement of standard
dereverberation objective measures over the state-of-the-art.
Index Terms— dereverberation, phase, sinusoidal modeling,



hal_id    :    hal-01548488



Source separation, which consists in decomposing data into mean-
ingful structured components, is an active research topic in many
ﬁelds including music signal processing. In this paper, we introduce
the Positive α-stable (PαS) distributions to model the latent sources,
which are a subclass of the stable distributions family. They notably
permit us to model random variables that are both nonnegative and
impulsive. Considering the L´evy distribution, the only PαS dis-
tribution whose density is tractable, we propose a mixture model
called L´evy Nonnegative Matrix Factorization (L´evy NMF). This
model accounts for low-rank structures in nonnegative data that pos-
sibly has high variability or is corrupted by very adverse noise. The
model parameters are estimated in a maximum-likelihood sense.
We also derive an estimator of the sources, which extends the valid-
ity of the Wiener ﬁltering to the PαS case. Experiments on synthetic
data and realistic music signals show that L´evy NMF compares fa-
vorably with state-of-the art techniques in terms of robustness to
impulsive noise and highlight its potential for decomposing non-
negative data.
Index Terms— L´evy distribution, Positive alpha-stable distri-
bution, nonnegative matrix factorization, audio source separation.



hal_id    :    hal-01548469



This paper addresses the problem of under-determined audio source
separation in multichannel reverberant mixtures. We target a semi-
blind scenario assuming that the mixing ﬁlters are known. Source
separation is performed from the time-domain mixture signals in or-
der to accurately model the convolutive mixing process. The source
signals are however modeled as latent variables in a time-frequency
domain. In a previous paper we proposed to use the modiﬁed dis-
crete cosine transform. The present paper generalizes the method
to the use of the odd-frequency short-time Fourier transform. In
this domain, the source coefﬁcients are modeled as centered com-
plex Gaussian random variables whose variances are structured by
means of a non-negative matrix factorization model. The inference
procedure relies on a variational expectation-maximization algo-
rithm. In the experiments we discuss the choice of the source repre-
sentation and we show that the proposed approach outperforms two
methods from the literature.
Index Terms— Audio source separation, reverberant mixtures,
non-negative matrix factorization, variational inference.



hal_id    :    hal-01548508



This paper introduces a new method for single-channel denoising
that sheds new light on classical early developments on this topic
that occurred in the 70’s and 80’s with Wiener ﬁltering and spectral
subtraction. Operating both in the short-time Fourier transform
domain, these methods consist in estimating the power spectral
density (PSD) of the noise without speech. Then, the clean speech
signal is obtained by manipulating the corrupted time-frequency
bins thanks to these noise PSD estimates. Theoretically grounded
when using power spectra, these methods were subsequently gener-
alized to magnitude spectra, or shown to yield better performance
by weighting the PSDs in the so-called parameterized Wiener ﬁlter.
Both these strategies were long considered ad-hoc. To the best
of our knowledge, while we recently proposed an interpretation
of magnitude processing, there is still no theoretical result that
would justify the better performance of parameterized Wiener
ﬁlters. Here, we show how the α-stable probabilistic model for
waveforms naturally leads to these weighted ﬁlters and we provide
a grounded and fast algorithm to enhance corrupted audio that
compares favorably with classical denoising methods.
Index Terms—denoising, Wiener ﬁltering, α-stable processes, prob-
ability theory



hal_id    :    hal-01576857



This paper introduces the use of representations based on non-
negative matrix factorization (NMF) to train deep neural net-
works with applications to environmental sound classiﬁca-
tion. Deep learning systems for sound classiﬁcation usually
rely on the network to learn meaningful representations from
spectrograms or hand-crafted features. Instead, we introduce
a NMF-based feature learning stage before training deep net-
works, whose usefulness is highlighted in this paper, espe-
cially for multi-source acoustic environments such as sound
scenes. We rely on two established unsupervised and super-
vised NMF techniques to learn better input representations
for deep neural networks. This will allow us, with simple
architectures, to reach competitive performance with more
complex systems such as convolutional networks for acoustic
scene classiﬁcation. The proposed systems outperform neu-
ral networks trained on time-frequency representations on two
acoustic scene classiﬁcation datasets as well as the best sys-
tems from the 2016 DCASE challenge.
Index Terms— Nonnegative Matrix Factorization, Deep
Neural Networks, Sound Classiﬁcation



hal_id    :    hal-01840082



–
Dans de nombreux domaines tels que la ﬁnance, la géophysique ou les neurosciences, les données se présentent
sous la forme de séries temporelles multivariées. Un enjeu de l’analyse statistique est de prendre en compte cet aspect multivarié,
notamment en raison de phénomènes de phase pouvant être induits par la présence de longue mémoire. Les ondelettes analytiques
sont un outil adapté à ce cadre d’étude. Nous nous intéressons ainsi aux ondelettes quasi-analytiques introduites par Selesnick.
Nous montrons tout d’abord leur existence et nous explicitons ensuite leur qualité analytique. Nous illustrons enﬁn l’avantage de
l’utilisation de ces ondelettes dans un cas simple de processus multivariés à longue mémoire.
Abstract – Multivariate processes with long-range dependent properties are found in a large number of applications including
ﬁnance, geophysics and neuroscience. Statistical analysis of such data is challenging because multivariate time series present phase
phenomenons. Analytic wavelets are well suited to deal with these characteristics. Our starting point is a paper of Selesnick which
introduces quasi-analytic wavelets. We ﬁrst establish the existence of these wavelets. We also give an exact formula quantifying
their analytic quality. We then illustrate on simulations the relevance of quasi-analytic wavelets for multivariate time series analysis.
1



hal_id    :    hal-01540479



– La transformée de Mellin est probablement la transformation intégrale la plus méconnue mais aussi une des plus fondamentales dans
de nombreux domaines. Sa genèse a été fort longue, et il est difﬁcile de donner une référence précise de son



hal_id    :    hal-01540484



– Dans cet article, nous nous intéressons à la séparation robuste de sources non-négatives. Nous introduisons les distributions Positives
α-stables (PαS), un sous-ensemble de la famille des lois stables, qui modélisent les variables latentes non-négatives. Comme ces distributions
sont à queue lourde, elles possèdent naturellement une propriété de robustesse aux valeurs aberrantes. En étudiant plus particulièrement la loi
de Lévy, la seule loi PαS dont la densité s’exprime sous forme analytique, nous mettons au point un modèle de mélange dans lequel nous
structurons les paramètres de dispersion des variables de Lévy par un modèle de factorisations en matrices non-négatives (NMF). Les paramètres
de ce modèle, appelé Lévy NMF, sont estimés au sens du maximum de vraisemblance. Nous obtenons également un estimateur des sources
qui généralise le ﬁltrage de Wiener aux distributions PαS. Des expériences conduites sur des spectrogrammes musicaux et des spectres de
ﬂuorescence démontrent le potentiel de ce modèle pour décomposer des données non-négatives.
Abstract – In this paper, we address the problem of robust source separation of nonnegative data. We introduce the PαS distributions, which are
a subclass of the stable distributions family, to model the nonnegative latent sources. Since those distributions are heavy-tailed, they are expected
to be robust to outliers. Considering the Lévy distribution, the only



hal_id    :    hal-01540481



 Cet article traite du problème de séparation de sources audio sous-déterminé pour les mélanges réverbérants multi-
canaux. Nous visons une application semi-aveugle où les ltres de mélange sont connus. La méthode proposée consiste à travailler
directement avec les signaux temporels du mélange. Cette approche permet de représenter de façon exacte le processus de mé-
lange convolutif, elle est donc adaptée pour la séparation de mélanges fortement réverbérants. Les signaux sources sont quant
à eux représentés dans le domaine de la transformée en cosinus discrète modiée, en utilisant un modèle gaussien basé sur la
factorisation en matrices non-négatives. L'inférence des sources repose sur un algorithme espérance-maximisation variationnel.
Nous montrons expérimentalement l'intérêt d'utiliser conjointement une représentation temporelle du mélange convolutif et un
modèle de source basé sur la factorisation en matrices non-négatives.
Abstract  This paper addresses the problem of multichannel audio source separation in under-determined reverberant mixtures.
We target a semi-blind scenario assuming that the mixing lters are known. The proposed method consists in working directly
with the time-domain mixture signals. This approach makes it possible to accurately represent the convolutive mixing process, it
is therefore suitable for the separation of highly reverberant mixtures. The source signals are represented in the modied discrete
cosine transform domain with a Gaussian model based on



hal_id    :    hal-01725141



– L’algorithme du gradient proximal permet de trouver les minimiseurs d’une somme F + G de deux fonctions convexes propres et
fermées, l’une étant supposée dérivable. Cet article introduit une version stochastique de cet algorithme. Les itérations font intervenir une suite iid
de deux fonctions aléatoires, dont les espérances coïncident respectivement avec F et G, ainsi que des projections aléatoires sur des ensembles
convexes fermés. L’objectif est de fournir une analyse de convergence, dans un contexte adaptatif où le pas de l’algorithme est supposé constant.
On montre que, en moyenne de Césaro, la probabilité pour que les itérées soient hors d’un voisinage des minimiseurs souhaités est arbitrairement
faible lorsque le nombre d’itérations tend vers l’inﬁni, et dans la limite de pas faibles. Le comportement ergodique des itérées est également
étudié. Enﬁn, l’algorithme est étendu au contexte plus général des opérateurs maximaux monotones aléatoires.
Abstract – The proximal gradient algorithm allows to ﬁnd the minimizers of a sum F + G of two proper closed convex functions, one of them
being differentiable. This paper introduces a stochastic version of the proximal gradient algorithm. The iterations involve an iid sequence of two
random functions, whose expectations coincide with F and G respectively, as well as random projections onto closed convex sets.



hal_id    :    hal-01531243



—This paper addresses the problem of multichan-
nel audio source separation in under-determined convolutive
mixtures. We target a semi-blind scenario assuming that the
mixing ﬁlters are known. The convolutive mixing process is
exactly modeled using the time-domain impulse responses of the
mixing ﬁlters. We propose a Student’s t time-frequency source
model based on non-negative matrix factorization (NMF). The
Student’s t distribution being heavy-tailed with respect to the
Gaussian, it provides some ﬂexibility in the modeling of the
sources. We also study a simpler Student’s t sparse source
model within the same general source separation framework.
The inference procedure relies on a variational expectation-
maximization algorithm. Experiments show the advantage of
using an NMF model compared with the sparse source model.
While the Student’s t NMF source model leads to slightly better
results than our previous Gaussian one, we demonstrate the
superiority of our method over two other approaches from the
literature.
Index Terms—Under-determined audio source separation, mul-
tichannel convolutive mixture, Student’s t distribution, non-
negative matrix factorization, variational inference.



hal_id    :    hal-01531238



Hyperparameter estimation is a recurrent problem in the
signal and statistics literature. Popular strategies are cross-
validation or Bayesian inference, yet it remains an active
topic of research in order to offer better or faster algorithms.
The models considered here are sparse regression models
with convex or non-convex group-Lasso-like penalties. Fol-
lowing the recent work of Pereyra et al. [1] we study the
ﬁxed point iteration algorithm they propose and show that,
while it may be suitable for an analysis prior, it suffers from
limitations when using high-dimensional sparse synthesis
models. The ﬁrst contribution of this paper is to show how
to overcome this issue. Secondly, we demonstrate how one
can extend the model to estimate a vector of regulariza-
tion parameters.
We illustrate this on models with group
sparsity reporting improved support recovery and reduced
amplitude bias on the estimated coefﬁcients. This approach
is compared with an alternative method that uses a single
parameter but a non-convex penalty. Results are presented
on simulations and an inverse problem relevant for neuro-
science which is the localization of brain activations using
magneto/electroencephalography.



hal_id    :    hal-02365713



—Image deblurring techniques are effective tools to
obtain high quality image from acquired image degraded by
blur and noise. In applications such as astronomy and satellite
imaging, size of acquired images can be extremely large (up
to gigapixels) covering a wide ﬁeld-of-view suffering from shift-
variant blur. Most of the existing deblurring techniques are
designed to be cost effective on a centralized computing system
having a shared memory and possibly multicore processor. The
largest image they can handle is then conditioned by the memory
capacity of the system. In this paper, we propose a distributed
shift-variant image deblurring algorithm in which several con-
nected processing units (each with reasonable computational
resources) can deblur simultaneously different portions of a
large image while maintaining a certain coherency among them
to ﬁnally obtain a single crisp image. The proposed algorithm
is based on a distributed Douglas-Rachford splitting algorithm
with a speciﬁc structure of the penalty parameters used in
the proximity operator. Numerical experiments show that the
proposed algorithm produces images of similar quality as the
existing centralized techniques while being distributed and being
cost effective for extremely large images.
Index Terms—Distributed optimization, proximal projection,
shift-variant blur, inverse problems, image deblurring.



hal_id    :    hal-01531259



—While most dereverberation methods focus on how
to estimate the amplitude of an anechoic signal, we propose a
method which also takes the phase into account. By applying a
sinusoidal model to the anechoic signal, we derive a formulation
to compute the amplitude and phase of each sinusoid. These
parameters are then estimated by our method in the reverberant
case. As we jointly estimate the amplitude and phase of the clean
signal, we achieve a very strong dereverberation, resulting in a
signiﬁcant improvement of objective dereverberation measures
over the state-of-the-art.



hal_id    :    hal-01531252



In this paper, we focus on the problem of sound source localization
and we propose a technique that exploits the known and arbitrary
geometry of the microphone array. While most probabilistic tech-
niques presented in the past rely on Gaussian models, we go further
in this direction and detail a method for source localization that is
based on the recently proposed α-stable harmonizable processes.
They include Cauchy and Gaussian as special cases and their
remarkable feature is to allow a simple modeling of impulsive
and real world sounds with few parameters. The approach we
present builds on the classical convolutive mixing model and has
the particularities of requiring going through the data only once,
to also work in the underdetermined case of more sources than
microphones and to allow massively parallelizable implementations
operating in the time-frequency domain. We show that the method
yields interesting performance for acoustic imaging in realistic
simulations.
Index Terms—source localization, acoustic modeling, α-
stable random variables, spectral measure, sketching



hal_id    :    hal-01618447



Many applications ﬁelds deal with multivariate long-memory time series. A challenge is to estimate the
long-memory properties together with the coupling between the time series. Real wavelets procedures
present some limitations due to the presence of phase phenomenons. A perspective is to use analytic
wavelets to recover jointly long-memory properties, modulus of long-run covariance between time series
and phases. Approximate wavelets Hilbert pairs of Selesnick (2002) fullﬁlled some of the required prop-
erties. As an extension of Selesnick (2002)’s work, we present some results about existence and quality of
these approximately analytic wavelets.
Keywords: Complex wavelets, multivariate time series



hal_id    :    hal-02912472



Cet article propose une architecture neuronale pour un modèle de langue à vocabulaire ouvert. Les
représentations continues des mots sont calculées à la volée à partir des caractères les composant,
gràce à une couche convolutionnelle suivie d’une couche de regroupement (pooling). Cela permet
au modèle de représenter n’importe quel mot, qu’il fasse partie du contexte ou soit évalué pour la
prédiction. La fonction objectif est dérivée de l’estimation contrastive bruitée (Noise Contrastive
Estimation, ou NCE), calculable dans notre cas sans vocabulaire. Nous évaluons la capacité de
notre modèle à construire des représentations continues de mots inconnus sur la tâche de traduction
automatique IWSLT-2016, de l’Anglais vers le Tchèque, en ré-évaluant les N meilleures hypothèses
(N-best reranking). Les résultats expérimentaux permettent des gains jusqu’à 0,7 point BLEU. Ils
montrent aussi la difﬁculté d’utiliser des représentations dérivées des caractères pour la prédiction.
ABSTRACT
Opening the vocabulary of neural language models with character-level word representations
This paper introduces an architecture for an open-vocabulary neural language model. Word represen-
tations are computed on-the-ﬂy by a convolution network followed by pooling layer. This allows the
model to consider any word, in the context or for the prediction. The training objective is derived from
the Noise-Contrastive Estimation to adapt it the open vocabulary case. We test the ability of our model
to



hal_id    :    hal-02395677



- Parkinson’s disease (PD) is a neurological disorder associated 
with a progressive decline in motor skills, speech, and cognitive processes. 
Since the diagnosis of Parkinson’s disease is difficult, researchers have 
worked to develop a support tool based on algorithms to differentiate 
healthy controls from PD patients. Online handwriting analysis is one of 
the methods that can be used to diagnose PD. The aim of this study is to 
find a subset of handwriting features suitable for efficiently identifying 
subjects with PD. Data was taken from PDMultiMC database collected in 
Lebanon, and consisting of 16 medicated PD patients and 16 age matched 
controls. Seven handwriting tasks were collected such as copying patterns, 
copying words in Arabic, and writing full names. For each task kinematic 
and spatio-temporal, pressure, energy, entropy, and intrinsic features were 
extracted. Feature selection was done in two stages, the first stage selected 
a subset using statistical analysis, and the second step select the most 
relevant features of this subset, by a suboptimal approach. The selected 
features were fed to a support vector machine classifier with RBF kernel, 
whose aim is to identify the subjects suffering from PD. The accuracy of 
the classification of PD was as high as



hal_id    :    hal-02912384



Noise Contrastive Estimation (NCE) is a
learning procedure that is regularly used
to train neural language models, since
it avoids the computational bottleneck
caused by the output softmax. In this pa-
per, we attempt to explain some of the
weaknesses of this objective function, and
to draw directions for further develop-
ments. Experiments on a small task show
the issues raised by the unigram noise
distribution, and that a context dependent
noise distribution, such as the bigram dis-
tribution, can solve these issues and pro-
vide stable and data-efﬁcient learning.
1



hal_id    :    hal-01484744



This paper presents supervised feature learning approaches for
speaker identiﬁcation that rely on nonnegative matrix factorisa-
tion.
Recent studies have shown that group nonnegative matrix
factorisation and task-driven supervised dictionary learning can
help performing effective feature learning for audio classiﬁcation
problems.
This paper proposes to integrate a recent method that relies on
group nonnegative matrix factorisation into a task-driven supervised
framework for speaker identiﬁcation. The goal is to capture both the
speaker variability and the session variability while exploiting the
discriminative learning aspect of the task-driven approach. Results
on a subset of the ESTER corpus prove that the proposed approach
can be competitive with I-vectors.
Index Terms— Nonnegative matrix factorisation, feature learn-
ing, dictionary learning, online learning, speaker identiﬁcation



hal_id    :    hal-01447977



In this paper we tackle the problem of single channel audio source
separation driven by descriptors of the sounding object’s motion.
As opposed to previous approaches, motion is included as a soft-
coupling constraint within the nonnegative matrix factorization
framework. The proposed method is applied to a multimodal dataset
of instruments in string quartet performance recordings where bow
motion information is used for separation of string instruments. We
show that the approach offers better source separation result than
an audio-based baseline and the state-of-the-art multimodal-based
approaches on these very challenging music mixtures.
Index Terms— audio source separation, nonnegative matrix
factorization, motion, multimodal analysis



hal_id    :    hal-01416357



Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) meth-
ods have become popular in modern data analysis problems due to
their computational efﬁciency. Even though they have proved useful
for many statistical models, the application of SG-MCMC to non-
negative matrix factorization (NMF) models has not yet been exten-
sively explored. In this study, we develop two parallel SG-MCMC
algorithms for a broad range of NMF models. We exploit the condi-
tional independence structure of the NMF models and utilize a strat-
iﬁed sub-sampling approach for enabling parallelization. We illus-
trate the proposed algorithms on an image restoration task and report
encouraging results.
Index Terms— Stochastic Gradient MCMC, Non-Negative Ma-
trix Factorization, Tweedie Distribution, Beta Divergence, Richardson-
Romberg Extrapolation.



hal_id    :    hal-01416347



A great number of methods for multichannel audio source separa-
tion are based on probabilistic approaches in which the sources are
modeled as latent random variables in a Time-Frequency (TF) do-
main. For reverberant mixtures, it is common to approximate the
time-domain convolutive mixing process as being instantaneous in
the short-term Fourier transform domain, under a short mixing ﬁl-
ters assumption. The TF latent sources are then inferred from the
TF mixture observations. In this paper we propose to infer the TF
latent sources from the time-domain observations. This approach al-
lows us to exactly model the convolutive mixing process. The infer-
ence procedure relies on a variational expectation-maximization al-
gorithm. In signiﬁcant reverberation conditions, our approach leads
to a signal-to-distortion ratio improvement of 5.5 dB compared with
the usual TF approximation of the convolutive mixing process.
Index Terms— Multichannel audio source separation, time-
domain convolutive model, time-frequency source model, non-
negative matrix factorization, variational EM algorithm.



hal_id    :    hal-01416366



In this paper, we focus on modeling multichannel audio signals in
the short-time Fourier transform domain for the purpose of source
separation. We propose a probabilistic model based on a class of
heavy-tailed distributions, in which the observed mixtures and the
latent sources are jointly modeled by using a certain class of mul-
tivariate alpha-stable distributions. As opposed to the conventional
Gaussian models, where the observations are constrained to lie just
within a few standard deviations from the mean, the proposed heavy-
tailed model allows us to account for spurious data or important un-
certainties in the model. We develop a Monte Carlo Expectation-
Maximization algorithm for inferring the sources from the proposed
model. We show that our approach leads to signiﬁcant performance
improvements in audio source separation under corrupted mixtures
and in spatial audio object coding.
Index Terms— Alpha-stable distributions, Multichannel source
separation, Informed source separation, Monte Carlo Expectation-
Maximization.



hal_id    :    hal-01416355



Phase reconstruction of complex components in the time-frequency
domain is a challenging but necessary task for audio source separa-
tion. While traditional approaches do not exploit phase constraints
that originate from signal modeling, some prior information about
the phase can be obtained from sinusoidal modeling. In this pa-
per, we introduce a probabilistic mixture model which allows us to
incorporate such phase priors within a source separation framework.
While the magnitudes are estimated beforehand, the phases are mod-
eled by Von Mises random variables whose location parameters are
the phase priors. We then approximate this non-tractable model by
an anisotropic Gaussian model, in which the phase dependencies
are preserved. This enables us to derive an MMSE estimator of the
sources which optimally combines Wiener ﬁltering and prior phase
estimates. Experimental results highlight the potential of incorpo-
rating phase priors into mixture models for separating overlapping
components in complex audio mixtures.
Index Terms— Phase reconstruction, Von Mises distribution,
anisotropic Gaussian model, phase unwrapping, source separation



hal_id    :    hal-01401988



. We propose a probabilistic model for acoustic source local-
ization with known but arbitrary geometry of the microphone array. The
approach has several features. First, it relies on a simple nearﬁeld acous-
tic model for wave propagation. Second, it does not require the number
of active sources. On the contrary, it produces a heat map representing
the energy of a large set of candidate locations, thus imaging the acous-
tic ﬁeld. Second, it relies on a heavy-tail α-stable probabilistic model,
whose most important feature is to yield an estimation strategy where
the multichannel signals need to be processed only once in a simple on-
line procedure, called sketching. This sketching produces a ﬁxed-sized
representation of the data that is then analyzed for localization. The
resulting algorithm has a small computational complexity and in this
paper, we demonstrate that it compares favorably with state of the art
for localization in realistic simulations of reverberant environments.
1



hal_id    :    hal-01400965



. In this paper, we consider the underdetermined convolutive
audio source separation (UCASS) problem. In the STFT domain, we con-
sider both source signals and mixing ﬁlters as latent random variables,
and we propose to estimate each source image, i.e. each individual source-
ﬁlter product, by its posterior mean. Although, this is a quite straightfor-
ward application of the Bayesian estimation theory, to our knowledge,
there exist no similar study in the UCASS context. In this paper, we
discuss the interest of this estimator in this context and compare it with
the conventional Wiener ﬁlter in a semi-oracle conﬁguration.3
Keywords: Audio source separation, source image, latent mixing ﬁlters,
MMSE estimator, MCMC sampling.
1



hal_id    :    hal-01497087



— The V˜u-Condat algorithm is a standard method
for ﬁnding a saddle point of a Lagrangian involving a dif-
ferentiable function. Recent works have tried to adapt the
idea of random coordinate descent to this algorithm, with
the aim to efﬁciently solve some regularized or distributed
optimization problems. A drawback of these approaches is
that the admissible step sizes can be small, leading to slow
convergence. In this paper, we introduce a coordinate descent
primal-dual algorithm which is provably convergent for a wider
range of step size values than previous methods. In particular,
the condition on the step-sizes depends on the coordinate-wise
Lipschitz constant of the differentiable function’s gradient. We
discuss the application of our method to distributed optimiza-
tion and large scale support vector machine problems.



hal_id    :    hal-01354064



Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC) algorithms have be-
come increasingly popular for Bayesian inference in large-scale applications. Even
though these methods have proved useful in several scenarios, their performance is
often limited by their bias. In this study, we propose a novel sampling algorithm
that aims to reduce the bias of SG-MCMC while keeping the variance at a reason-
able level. Our approach is based on a numerical sequence acceleration method,
namely the Richardson-Romberg extrapolation, which simply boils down to run-
ning almost the same SG-MCMC algorithm twice in parallel with different step
sizes. We illustrate our framework on the popular Stochastic Gradient Langevin
Dynamics (SGLD) algorithm and propose a novel SG-MCMC algorithm referred to
as Stochastic Gradient Richardson-Romberg Langevin Dynamics (SGRRLD). We
provide formal theoretical analysis and show that SGRRLD is asymptotically con-
sistent, satisﬁes a central limit theorem, and its non-asymptotic bias and the mean
squared-error can be bounded. Our results show that SGRRLD attains higher rates
of convergence than SGLD in both ﬁnite-time and asymptotically, and it achieves
the theoretical accuracy of the methods that are based on higher-order integrators.
We support our ﬁndings using both synthetic and real data experiments.
1



hal_id    :    hal-01272327



Addressing the will to give a more complete picture than an average relationship provided
by standard regression, a novel framework for estimating and predicting simultaneously several
conditional quantiles is introduced. The proposed methodology leverages kernel-based multi-task
learning to curb the embarrassing phenomenon of quantile crossing, with a one-step estimation
procedure and no post-processing. Moreover, this framework comes along with theoretical guaran-
tees and an eﬃcient coordinate descent learning algorithm. Numerical experiments on benchmark
and real datasets highlight the enhancements of our approach regarding the prediction error, the
crossing occurrences and the training time.
1



hal_id    :    hal-01393959



Video is now one of the major sources of information for forensics.
However, video documents can be originating from various record-
ing devices (CCTV, mobile devices...) with inconsistent quality and
can sometimes be recorded in challenging light or motion conditions.
Therefore, the amount of information that can be extracted relying
solely on video image can vary to a great extent. Most of the videos
however generally include audio recording as well. Machine listen-
ing can then become a valuable complement to video image analysis
in challenging scenarios. In this paper, the authors present a brief
overview of some machine listening techniques and their application
to the analysis of video documents for forensics. The applicability of
these techniques to forensics problems is then discussed in the light
of machine listening system performances.
Index Terms— Machine listening, source localisation, event
detection, speaker identiﬁcation, aoustic scene analysis, automatic
speech recognition



hal_id    :    hal-01337860



Most dereverberation methods aim to reconstruct the ane-
choic magnitude spectrogram, given a reverberant signal.
Regardless of the method, the dereverberated signal is sys-
tematically synthesized with the reverberant phase.
This
corrupted phase reintroduces reverberation and distortion in
the signal. This is why we intend to also reconstruct the ane-
choic phase, given a reverberant signal. Before processing
speech signals, we propose in this paper a method for esti-
mating the anechoic phase of reverberant chirp signals. Our
method presents an accurate estimation of the instantaneous
phase and improves objective measures of dereverberation.
Index Terms— Dereverberation, phase, reassignment, si-
nusoidal modeling.



hal_id    :    hal-01393964



Nonnegative matrix factorisation (NMF) with β-divergence is a pop-
ular method to decompose real world data. In this paper we pro-
pose mini-batch stochastic algorithms to perform NMF efﬁciently
on large data matrices. Besides the stochastic aspect, the mini-batch
approach allows exploiting intensive computing devices such as gen-
eral purpose graphical processing units to decrease the processing
time and in some cases outperform coordinate descent approach.
Index Terms— Nonnegative matrix factorisation, GPGPU,
multiplicative rules, online learning



hal_id    :    hal-02943480



This report describes our contribution to the 2016 IEEE AASP
DCASE challenge for the acoustic scene classiﬁcation task. We pro-
pose a feature learning approach following the idea of decomposing
time-frequency representations with nonnegative matrix factoriza-
tion. We aim at learning a common dictionary representing the data
and use projections on this dictionary as features for classiﬁcation.
Our system is based on a novel supervised extension of nonnegative
matrix factorization. In the approach we propose, the dictionary and
the classiﬁer are optimized jointly in order to ﬁnd a suited represen-
tation to minimize the classiﬁcation cost. The proposed method sig-
niﬁcantly outperforms the baseline and provides improved results
compared to unsupervised nonnegative matrix factorization.
Index Terms— Acoustic Scene Classiﬁcation, Feature learn-
ing, Matrix Factorization



hal_id    :    hal-01322937



—In this paper, the late part of a room response is
modeled in the frequency domain as a complex Gaussian random
process. The autocovariance function (ACVF) and power spectral
density (PSD) are theoretically deﬁned from the exponential
decay of the late reverberation power. Furthermore we show
that the ACVF and PSD are accurately parametrized by an
autoregressive moving average (ARMA) model. This leads to
a new generative model of late reverberation in the frequency
domain. The ARMA parameters are easily estimated from the
theoretical ACVF. The statistical characterization is consistent
with empirical results on simulated and real data. This model
could be used to incorporate priors in audio source separation
and dereverberation.
Index Terms—Statistical room acoustics, late reverberation,
Gaussian random process, autoregressive moving average model.



hal_id    :    hal-01316485



We present Vibrato Nonnegative Tensor Factorization, an
algorithm for single-channel unsupervised audio source
separation with an application to separating instrumental or
vocal sources with nonstationary pitch from music record-
ings. Our approach extends Nonnegative Matrix Factor-
ization for audio modeling by including local estimates of
frequency modulation as cues in the separation. This per-
mits the modeling and unsupervised separation of vibrato
or glissando musical sources, which is not possible with
the basic matrix factorization formulation.
The algorithm factorizes a sparse nonnegative tensor
comprising the audio spectrogram and local frequency-
slope-to-frequency ratios, which are estimated at each
time-frequency bin using the Distributed Derivative
Method.
The use of local frequency modulations as
separation cues is motivated by the principle of com-
mon fate partial grouping from Auditory Scene Analysis,
which hypothesizes that each latent source in a mixture
is characterized perceptually by coherent frequency and
amplitude modulations shared by its component partials.
We derive multiplicative factor updates by Minorization-
Maximization, which guarantees convergence to a local
optimum by iteration. We then compare our method to the
baseline on two separation tasks: one considers synthetic
vibrato notes, while the other considers vibrato string in-
strument recordings.



hal_id    :    hal-01418963



We propose an efﬁcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in
presence of pileup from a sample of low-frequency observa-
tions. Based on a functional equation linking the marks’ den-
sity to the characteristic function of the observations and its
derivative, we propose a new time-efﬁcient method using B-
splines to estimate the density of the underlying γ-ray spec-
trum which is able to handle large datasets used in nuclear
physics. A discussion on the numerical computation of the al-
gorithm and its performances on simulated data are provided
to support our ﬁndings.
Index Terms— Shot-noise, nonparametric estimation, B-
splines, γ-spectroscopy, pile-up correction



hal_id    :    hal-01347167



We propose a method that performs anomaly
detection and localisation within heterogeneous
data using a pairwise undirected mixed graphical
model. The data are a mixture of categorical and
quantitative variables, and the model is learned
over a dataset that is supposed not to contain any
anomaly. We then use the model over temporal
data, potentially a data stream, using a version of
the two-sided CUSUM algorithm. The proposed
decision statistic is based on a conditional likeli-
hood ratio computed for each variable given the
others. Our results show that this function allows
to detect anomalies variable by variable, and thus
to localise the variables involved in the anomalies
more precisely than univariate methods based on
simple marginals.



hal_id    :    hal-01306605



—Magnetoencephalography
(MEG)
and
electroen-
cephalography (EEG) source localization is a challenging ill-
posed problem. To identify an appropriate solution out of an
inﬁnite set of possible candidates, the problem requires setting
certain constraints depending on the assumptions or a priori
knowledge about the source distribution. Different constraints
have been proposed so far, including those that impose sparsity
on the source reconstruction in both standard and time-frequency
domains. Source localization in the time-frequency domain has
already been investigated using Gabor dictionary in both a
convex (TF-MxNE) and non-convex way (Iterative Reweighted
TF-MxNE). The iterative reweighted (ir)TF-MxNE solver has
been shown to outperform TF-MxNE in both source recovery
and amplitude bias. However, the choice of an optimal dictionary
remains unsolved. Due to a mixture of signals, i.e. short transient
signals (right after the stimulus onset) and slower brain waves,
the choice of a single dictionary explaining simultaneously both
signals types in a sparse way is difﬁcult. In this work, we
introduce a method to improve the source estimation relying on
a multi-scale dictionary, i.e. multiple dictionaries with different
scales concatenated to ﬁt short transients and slow waves at the
same time. We compare our results with irTF-MxNE on realistic
simulation, then we use somatosensory data to demonstrate the
beneﬁts of the approach on in terms of reduced leakage (time
courses mixture), temporal smoothness and detection of both
signals types.
keywords— Inverse



hal_id    :    hal-01313567



—Magnetoencephalography
(MEG)
and
electroen-
cephalography (EEG) source localization is a challenging ill-
posed problem. To identify an appropriate solution out of an
inﬁnite set of possible candidates, the problem requires setting
certain constraints depending on the assumptions or a priori
knowledge about the source distribution. Different constraints
have been proposed so far, including those that impose sparsity
on the source reconstruction in both standard and time-frequency
domains. Source localization in the time-frequency domain has
already been investigated using Gabor dictionary in both a
convex (TF-MxNE) and non-convex way (Iterative Reweighted
TF-MxNE). The iterative reweighted (ir)TF-MxNE solver has
been shown to outperform TF-MxNE in both source recovery
and amplitude bias. However, the choice of an optimal dictionary
remains unsolved. Due to a mixture of signals, i.e. short transient
signals (right after the stimulus onset) and slower brain waves,
the choice of a single dictionary explaining simultaneously both
signals types in a sparse way is difﬁcult. In this work, we
introduce a method to improve the source estimation relying on
a multi-scale dictionary, i.e. multiple dictionaries with different
scales concatenated to ﬁt short transients and slow waves at the
same time. We compare our results with irTF-MxNE on realistic
simulation, then we use somatosensory data to demonstrate the
beneﬁts of the approach in terms of reduced leakage (time courses
mixture), temporal smoothness and detection of both signals
types.
keywords— Inverse problem;



hal_id    :    hal-01306596



Recently, Stochastic Gradient Markov Chain
Monte Carlo (SG-MCMC) methods have been
proposed for scaling up Monte Carlo compu-
tations to large data problems.
Whilst these
approaches have proven useful in many appli-
cations, vanilla SG-MCMC might suffer from
poor mixing rates when random variables exhibit
strong couplings under the target densities or big
scale differences.
In this study, we propose a
novel SG-MCMC method that takes the local ge-
ometry into account by using ideas from Quasi-
Newton optimization methods.
These second
order methods directly approximate the inverse
Hessian by using a limited history of samples and
their gradients. Our method uses dense approx-
imations of the inverse Hessian while keeping
the time and memory complexities linear with
the dimension of the problem.
We provide a
formal theoretical analysis where we show that
the proposed method is asymptotically unbiased
and consistent with the posterior expectations.
We illustrate the effectiveness of the approach on
both synthetic and real datasets. Our experiments
on two challenging applications show that our
method achieves fast convergence rates similar to
Riemannian approaches while at the same time
having low computational requirements similar
to diagonal preconditioning approaches.



hal_id    :    hal-02287434



. In this paper, we propose an eﬃcient method to estimate in a nonpara-
metric fashion the marks’ density of a shot-noise process in presence of pileup from a
sample of low-frequency observations. Based on a functional equation linking the marks’
density to the characteristic function of the observations and its derivative, we propose a
new time-eﬃcient method using B-splines to estimate the density of the underlying γ-ray
spectrum, which is able to handle large datasets used in nuclear physics. A discussion on
the numerical computation of the algorithm and its performances on simulated data are
provided to support our ﬁndings.
Keywords. Shot-noise, B-splines, inverse problem, γ spectrometry



hal_id    :    hal-01248013



Nonnegative Matrix Factorization (NMF) is a powerful tool for de-
composing mixtures of audio signals in the Time-Frequency (TF)
domain. In the source separation framework, the phase recovery for
each extracted component is necessary for synthesizing time-domain
signals. The Complex NMF (CNMF) model aims to jointly estimate
the spectrogram and the phase of the sources, but requires to con-
strain the phase in order to produce satisfactory sounding results.
We propose to incorporate phase constraints based on signal models
within the CNMF framework: a phase unwrapping constraint that
enforces a form of temporal coherence, and a constraint based on the
repetition of audio events, which models the phases of the sources
within onset frames. We also provide an algorithm for estimating the
model parameters. The experimental results highlight the interest of
including such constraints in the CNMF framework for separating
overlapping components in complex audio mixtures.
Index Terms— Nonnegative matrix factorization, phase recov-
ery, phase unwrapping, repeated audio events, source separation



hal_id    :    hal-01393968



This paper presents a feature learning approach for speaker
identiﬁcation that is based on non-negative matrix factorisa-
tion. Recent studies have shown that in methods such as non-
negative matrix factorisation, the dictionary atoms can repre-
sent well the speaker identity and that Using speaker identity
to induce group similarity can proven to improve further the
performance. However, the approaches proposed so far fo-
cused only on speakers variability and not on sessions vari-
ability. However, this later point is a crucial aspect in the suc-
cess of the I-vector approaches that is now the state-of-the-art
in speaker identiﬁcation.
This paper proposes an approach that relies on group-
NMF and that is inspired that the I-vector training procedure.
By doing so this approach intends to capture both the speaker
variability and the session variability. Results on a small cor-
pus prove the proposed approach to be competitive with the
state-of-the-art I-vector approach.
Index Terms— Non-negative matrix factorisation, group
similarity, spectrogram factorisation, speaker identiﬁcation



hal_id    :    hal-01248010



Room acoustic parameters are key information for dereverberation or speech recognition. Usually, when
one needs to assess the level of reverberation, only the reverberation time RT60 or a direct to reverberant
sounds index Dτ is estimated. Yet, methods which blindly estimate the reverberation time from reverberant
recorded speech do not always diﬀerentiate the RT60 from the Dτ to evaluate the level of reverberation. That
is why we propose a method to jointly blindly estimate these parameters, from the signal energy decay rate
distribution, by means of kernel regression. Evaluation is carried out with real and simulated room impulse
responses to generate noise-free reverberant speech signals. The results show this new method outperforms
baseline approaches in our evaluation.
1.



hal_id    :    hal-01248011



Model selection is a central topic in Bayesian machine learning,
which requires the estimation of the marginal likelihood of the data
under the models to be compared.
During the last decade, con-
ventional model selection methods have lost their charm as they
have high computational requirements. In this study, we propose
a computationally efﬁcient model selection method by integrating
ideas from Stochastic Gradient Markov Chain Monte Carlo (SG-
MCMC) literature and statistical physics. As opposed to conven-
tional methods, the proposed method has very low computational
needs and can be implemented almost without modifying existing
SG-MCMC code. We provide an upper-bound for the bias of the
proposed method. Our experiments show that, our method is 40
times as fast as the baseline method on ﬁnding the optimal model
order in a matrix factorization problem.
Index Terms—
Bayesian model selection, Markov Chain
Monte Carlo, Non-negative matrix factorization



hal_id    :    hal-01248014



We propose a projection-based method for the unmixing of multi-
channel audio signals into their different constituent spatial objects.
Here, spatial objects are modelled using a uniﬁed framework which
handles both point sources and diffuse sources. We then propose
a novel methodology to estimate and take advantage of the spatial
dependencies of an object. Where previous research has processed
the original multichannel mixtures directly and has been principally
focused on the use of inter-channel covariance structures, here we
instead process projections of the multichannel signal on many
different spatial directions. These linear combinations consist of
observations where some spatial objects are cancelled or enhanced.
We then propose an algorithm which takes these projections as
the observations, discarding dependencies between them. Since
each one contains global information regarding all channels of the
original multichannel mixture, this provides an effective means of
learning the parameters of the original audio, while avoiding the
need for joint-processing of all the channels. We further show how
to recover the separated spatial objects and demonstrate the use of
the technique on stereophonic music signals.
Index Terms—Sound Source Separation, α-stable, Spatial
Projection



hal_id    :    hal-01248012



In this paper we present a novel source separation method aiming
to overcome the difﬁculty of modelling non-stationary signals. The
method can be applied to mixtures of musical instruments with fre-
quency and/or amplitude modulation, e.g. typically caused by vi-
brato. It is based on a signal representation that divides the complex
spectrogram into a grid of patches of arbitrary size. These complex
patches are then processed by a two-dimensional discrete Fourier
transform, forming a tensor representation which reveals spectral
and temporal modulation textures. Our representation can be seen
as an alternative to modulation transforms computed on magnitude
spectrograms. An adapted factorization model allows to decompose
different time-varying harmonic sources based on their particular
common modulation proﬁle: hence the name Common Fate Model.
The method is evaluated on musical instrument mixtures playing the
same fundamental frequency (unison), showing improvement over
other state-of-the-art methods.
Index Terms— Sound source separation, Common Fate Model,
Non-Negative tensor factorization.



hal_id    :    hal-01237226



— Based on the idea of randomized coordinate descent
of α-averaged operators, a randomized primal-dual optimization
algorithm is introduced, where a random subset of coordinates is
updated at each iteration. The algorithm builds upon a variant
of a recent (deterministic) algorithm proposed by V˜u and Condat
that includes the well known ADMM as a particular case. The
obtained algorithm is used to solve asynchronously a distributed
optimization problem. A network of agents, each having a
separate cost function containing a differentiable term, seek to
ﬁnd a consensus on the minimum of the aggregate objective. The
method yields an algorithm where at each iteration, a random
subset of agents wake up, update their local estimates, exchange
some data with their neighbors, and go idle. Numerical results
demonstrate the attractive performance of the method.
The general approach can be naturally adapted to other situa-
tions where coordinate descent convex optimization algorithms
are used with a random choice of the coordinates.
Index Terms— Distributed Optimization, Coordinate Descent,
Consensus algorithms, Primal-Dual Algorithm.



hal_id    :    hal-01370051



—Incorporating prior knowledge about the sources
and/or the mixture is a way to improve under-determined audio
source separation performance. A great number of informed
source separation techniques concentrate on taking priors on
the sources into account, but fewer works have focused on con-
straining the mixing model. In this paper we address the problem
of under-determined multichannel audio source separation in re-
verberant conditions. We target a semi-informed scenario where
some room parameters are known. Two probabilistic priors on
the frequency response of the mixing ﬁlters are proposed. Early
reverberation is characterized by an autoregressive model while
according to statistical room acoustics results, late reverberation
is represented by an autoregressive moving average model. Both
reverberation models are deﬁned in the frequency domain. They
aim to transcribe the temporal characteristics of the mixing ﬁlters
into frequency-domain correlations. Our approach leads to a
maximum a posteriori estimation of the mixing ﬁlters which is
achieved thanks to an expectation-maximization algorithm. We
experimentally show the superiority of this approach compared
with a maximum likelihood estimation of the mixing ﬁlters.
Index Terms—Multichannel audio source separation, proba-
bilistic priors, mixing model, MAP estimation, EM algorithm.



hal_id    :    hal-01153882



This paper addresses the generalisation of stationary Hawkes processes in order to allow
for a time-evolving second-order analysis.
Motivated by the concept of locally stationary
autoregressive processes, we apply however inherently diﬀerent techniques to describe the
time-varying dynamics of self-exciting point processes. In particular we derive a stationary
approximation of the Laplace transform of a locally stationary Hawkes process. This allows
us to deﬁne a local intensity function and a local Bartlett spectrum which can be used to
compute approximations of ﬁrst and second order moments of the process. We complete the
paper by some insightful simulation studies.
Keywords:
Locally stationary processes, Hawkes processes, Bartlett spectrum, time
frequency analysis, point processes
2000 MSC: 60G55, 62M15, 46N30



hal_id    :    hal-01260588



—We propose a method to unmix multichannel audio
signals into their different constitutive spatial objects. To achieve
this, we characterize an audio object through both a spatial and
a spectro-temporal modelling. The particularity of the spatial
model we pick is that it neither assumes an object has only one
underlying source point, nor does it attempt to model the complex
room acoustics. Instead, it focuses on a listener perspective, and
takes each object as the superposition of many contributions
with different incoming directions and inter-channel delays. Our
spectro-temporal probabilistic model is based on the recently
proposed α-harmonisable processes, which are adequate for
signals with large dynamics, such as audio. Then, the main
originality of this work is to provide a new way to estimate and
exploit inter-channel dependences of an object for the purpose
of demixing. In the Gaussian α = 2 case, previous research
focused on covariance structures. This approach is no longer
valid for α < 2 where covariances are not deﬁned. Instead, we
show how simple linear combinations of the mixture channels
can be used to learn the model parameters, and the method
we propose consists in pooling the estimates based on many
projections to correctly account for the original multichannel
audio. Intuitively, each such downmix of the mixture provides a
new perspective where some objects are cancelled or



hal_id    :    hal-01080955



. This paper deals with a parametrized family of partially
observed bivariate Markov chains. We establish that, under very mild
assumptions, the limit of the normalized log-likelihood function is max-
imized when the parameters belong to the equivalence class of the true
parameter, which is a key feature for obtaining the consistency of the
maximum likelihood estimators (MLEs) in well-speciﬁed models. This
result is obtained in the general framework of partially dominated mod-
els. We examine two speciﬁc cases of interest, namely, hidden Markov
models (HMMs) and observation-driven time series models. In contrast
with previous approaches, the identiﬁability is addressed by relying on
the uniqueness of the invariant distribution of the Markov chain asso-
ciated to the complete data, regardless its rate of convergence to the
equilibrium.



hal_id    :    hal-01413791



.
In this paper, we introduce a model for drug delivery optimisation in a chronotherapeu-
tics framework. We present a pharmacokinetics and pharmacodynamics model for oxaliplatin and 5-
Fluorouracil, a classic therapeutic association in the treatment of colorectal cancer. We derive the phar-
macokinetics model using law of mass action and enzyme kinetics. We design an age-structured cell cycle
PDE model with drug damage and repair phases to account for the effect of the drugs on proliferating cell
populations, with different parameters for healthy and cancer cell populations focused on their different syn-
chronisation responses to circadian clock triggering. Our goal is to minimise the growth rate of cancerous
cells while maintaining the growth rate of healthy cells above a given toxicity threshold. We numerically
optimise the drug delivery schedules under our model and obtain theoretically efﬁcient infusion schemes
in a chronotherapeutics framework, with as well as without circadian clock involvement in the molecular
pharmacological model.
Keywords and phrases: Cell population dynamics, Age-structured models, Cell division cycle, Phar-
macological models, Drug delivery optimisation
Mathematics Subject Classiﬁcation: 35Q92, 49J20, 92C50



hal_id    :    hal-01183959



The purpose of this paper is to study the dynamical behavior of the sequence (xn)
produced by the forward-backward algorithm
yn+1 ∈B(un+1, xn),
xn+1 = (I + γn+1A(un+1, ·))−1(xn −γn+1yn+1),
where A(ξ) = A(ξ, ·) and B(ξ) = B(ξ, ·) are two functions valued in the set of maximal
monotone operators on RN, (un) is a sequence of independent and identically distributed
random variables, and (γn) is a sequence of vanishing step sizes. Following the approach of
the recent paper [16], we deﬁne the operators A(x) = E[A(u1, x)] and B(x) = E[B(u1, x)],
where the expectations are the set-valued Aumann integrals with respect to the law of
u1, and assume that the monotone operator A + B is maximal (suﬃcient conditions for
maximality are provided). It is shown that with probability one, the interpolated process
obtained from the iterates xn is an asymptotic pseudo trajectory in the sense of Bena¨ım
and Hirsch of the diﬀerential inclusion ˙z(t) ∈−(A + B)(z(t)). The convergence of the
empirical means of the xn’s towards a zero of A + B follows, as well as the convergence of
the sequence (xn) itself to such a zero under a demipositivity assumption. These results
ﬁnd applications in a wide range of optimization or variational inequality problems in
random environments.
Keywords :
Dynamical systems, Random



hal_id    :    hal-01078073



This paper generalizes asymptotic properties obtained in the
observation-driven times series models considered by [7] in the sense
that the conditional law of each observation is also permitted to depend
on the parameter. The existence of ergodic solutions and the consis-
tency of the Maximum Likelihood Estimator (MLE) are derived under
easy-to-check conditions. The obtained conditions appear to apply for a
wide class of models. We illustrate our results with speciﬁc observation-
driven times series, including the recently introduced NBIN-GARCH
and NM-GARCH models, demonstrating the consistency of the MLE
for these two models.
MSC: Primary: 62F12; Secondary: 60J05.
Keywords: consistency, ergodicity, maximum likelihood, observation-driven
models, time series of counts.
1



hal_id    :    hal-01030799



. Consider a non–linear function G(Xt) where Xt is a stationary Gaussian se-
quence with long–range dependence. The usual reduction principle states that the partial
sums of G(Xt) behave asymptotically like the partial sums of the ﬁrst term in the expansion
of G in Hermite polynomials. In the context of the wavelet estimation of the long–range
dependence parameter, one replaces the partial sums of G(Xt) by the wavelet scalogram,
namely the partial sum of squares of the wavelet coeﬃcients. Is there a reduction principle
in the wavelet setting, namely is the asymptotic behavior of the scalogram for G(Xt) the
same as that for the ﬁrst term in the expansion of G in Hermite polynomial? The answer
is negative in general. This paper provides a minimal growth condition on the scales of the
wavelet coeﬃcients which ensures that the reduction principle also holds for the scalogram.
The results are applied to testing the hypothesis that the long-range dependence parameter
takes a speciﬁc value.
Contents
1.



hal_id    :    hal-01164121



In this paper, we consider a nonlinear inverse problem occuring in nu-
clear science. Gamma rays randomly hit a semiconductor detector which
produces an impulse response of electric current. Because the sampling
period of the measured current is larger than the mean interarrival time
of photons, the impulse responses associated to diﬀerent gamma rays can
overlap: this phenomenon is known as pileup.
In this work, it is as-
sumed that the impulse response is an exponentially decaying function.
We propose a novel method to infer the distribution of gamma photon en-
ergies from the indirect measurements obtained from the detector. This
technique is based on a formula linking the characteristic function of the
photon density to a function involving the characteristic function and its
derivative of the observations. We establish that our estimator converges
to the mark density in uniform norm at a polynomial rate.
A limited
Monte-Carlo experiment is provided to support our ﬁndings.
1



hal_id    :    hal-00458648



We consider the problem of estimating the mixing density f from n i.i.d. observations distributed
according to a mixture density with unknown mixing distribution. In contrast with ﬁnite mixtures mod-
els, here the distribution of the hidden variable is not bounded to a ﬁnite set but is spread out over a
given interval. We propose an approach to construct an orthogonal series estimator of the mixing den-
sity f involving Legendre polynomials. The construction of the orthonormal sequence varies from one
mixture model to another. Minimax upper and lower bounds of the mean integrated squared error are
provided which apply in various contexts. In the speciﬁc case of exponential mixtures, it is shown that
the estimator is adaptive over a collection of speciﬁc smoothness classes, more precisely, there exists
a constant A > 0 such that, when the order m of the projection estimator veriﬁes m ∼A log(n), the
estimator achieves the minimax rate over this collection. Other cases are investigated such as Gamma
shape mixtures and scale mixtures of compactly supported densities including Beta mixtures. Finally, a
consistent estimator of the support of the mixing density f is provided.
1. MIXTURE DISTRIBUTIONS
We consider mixture distributions of densities belonging to some parametric collection {πt, t ∈Θ}
of densities with respect to the dominating



hal_id    :    hal-00984064



In this work, we study the problem of aggregating a ﬁnite number of predic-
tors for non stationary sub-linear processes. We provide oracle inequalities relying
essentially on three ingredients: 1) a uniform bound of the ℓ1 norm of the time-
varying sub-linear coeﬃcients, 2) a Lipschitz assumption on the predictors and
3) moment conditions on the noise appearing in the linear representation. Two
kinds of aggregations are considered giving rise to diﬀerent moment conditions
on the noise and more or less sharp oracle inequalities. We apply this approach
for deriving an adaptive predictor for locally stationary time varying autoregres-
sive (TVAR) processes.
It is obtained by aggregating a ﬁnite number of well
chosen predictors, each of them enjoying an optimal minimax convergence rate
under speciﬁc smoothness conditions on the TVAR coeﬃcients. We show that
the obtained aggregated predictor achieves a minimax rate while adapting to the
unknown smoothness. To prove this result, a lower bound is established for the
minimax rate of the prediction risk for the TVAR process. Numerical experiments
complete this study. An important feature of this approach is that the aggregated
predictor can be computed recursively and is thus applicable in an online predic-
tion context.
1



hal_id    :    hal-00755255



We study the convergence of centered and normalized sums of i.i.d. random elements
of the space D of c`adl`ag functions endowed with Skorohod’s J1 topology, to stable distri-
butions in D. Our results are based on the concept of regular variation on metric spaces
and on point process convergence. We provide some applications, in particular to the
empirical process of the renewal-reward process.
1



hal_id    :    hal-01170924



Nonnegative matrix factorization (NMF) is an effective and popular
low-rank model for nonnegative data. It enjoys a rich background,
both from an optimization and probabilistic signal processing view-
point. In this study, we propose a new cost-function for NMF ﬁtting,
which is introduced as arising naturally when adopting a Cauchy
process model for audio waveforms. As we recall, this Cauchy
process model is the only probabilistic framework known to date
that is compatible with having additive magnitude spectrograms
for additive independent audio sources. Similarly to the Gaussian
power-spectral density, this Cauchy model features time-frequency
nonnegative scale parameters, on which an NMF structure may be
imposed. The Cauchy cost function we propose is optimal under
that model in a maximum likelihood sense. It thus appears as
an interesting newcomer in the inventory of useful cost-functions
for NMF in audio. We provide multiplicative updates for Cauchy-
NMF and show that they give good performance in audio source
separation as well as in extracting nonnegative low-rank structures
from data buried in very adverse noise.
Index Terms—NMF, audio, Cauchy distribution, robust esti-
mation, probabilistic modeling



hal_id    :    hal-01219635



In this paper we show that considering early contributions of mixing
ﬁlters through a probabilistic prior can help blind source separation
in reverberant recording conditions. By modeling mixing ﬁlters as
the direct path plus R−1 reﬂections, we represent the propagation
from a source to a mixture channel as an autoregressive process of
order R in the frequency domain. This model is used as a prior to
derive a Maximum A Posteriori (MAP) estimation of the mixing
ﬁlters using the Expectation-Maximization (EM) algorithm. Exper-
imental results over reverberant synthetic mixtures and live record-
ings show that MAP estimation with this prior provides better sep-
aration results than a Maximum Likelihood (ML) estimation.
Index Terms—
Blind audio source separation,
Under-
determined convolutive mixtures, Probabilistic prior, MAP estima-
tion, EM algorithm.



hal_id    :    hal-01219637



Phase recovery of modiﬁed spectrograms is a major issue in au-
dio signal processing applications, such as source separation. This
paper introduces a novel technique for estimating the phases of
components in complex mixtures within onset frames in the Time-
Frequency (TF) domain. We propose to exploit the phase repeti-
tions from one onset frame to another. We introduce a reference
phase which characterizes a component independently of its activa-
tion times. The onset phases of a component are then modeled as
the sum of this reference and an offset which is linearly dependent
on the frequency. We derive a complex mixture model within on-
set frames and we provide two algorithms for the estimation of the
model phase parameters. The model is estimated on experimental
data and this technique is integrated into an audio source separation
framework. The results demonstrate that this model is a promising
tool for exploiting phase repetitions, and point out its potential for
separating overlapping components in complex mixtures.
Index Terms— Phase repetitions, phase reconstruction, audio
source separation, time-frequency analysis



hal_id    :    hal-02437193



– We propose an eﬃcient method to estimate in a nonparametric fashion the marks’ density of a shot-noise process
subject to a high pile-up eﬀect. Based on a formula linking the characteristic function of the mark density to a function involving
the shot-noise characteristic function and its derivative, we construct a “plug-in” estimator which converges to the mark density
in uniform norm at a logarithmic speed. Two limited Monte-Carlo experiments are provided to support our ﬁndings.
1



hal_id    :    hal-01206808



– Dans cet article, nous montrons qu’un a priori probabiliste anéchoïque sur les ﬁltres de mélange permet d’aider
la séparation aveugle et sous-déterminée de sources audio en milieu réverbérant. En considérant un modèle anéchoïque pour les
ﬁltres de mélange, la contribution de chaque source à chaque canal du mélange peut être représentée par un processus aléatoire
suivant un modèle de chaîne de Markov en fréquence. Ce modèle est utilisé comme a priori pour estimer les ﬁltres de mélange
au sens du Maximum A Posteriori (MAP) en utilisant l’algorithme Espérance-Maximisation (EM). Plusieurs séparations sur des
mélanges synthétiques réverbérants et sur des enregistrements réels montrent que l’estimation MAP avec a priori anéchoïque
permet d’obtenir de meilleurs résultats de séparation qu’une estimation au sens du Maximum de Vraisemblance (MV) sans a
priori.
Abstract – In this paper, we show that an anechoic probabilistic prior on mixing ﬁlters can help underdetermined blind source
separation even in reverberant recording conditions. By considering an anechoic model for the mixing ﬁlters, we represent the
contribution of each source to all mixture channels as a random process following a Markov chain model in the frequency domain.
This model is used as a prior to derive a Maximum A Posteriori (MAP) estimation of the mixing ﬁlters using the Expectation-
Maximization (EM)



hal_id    :    hal-02943532



Due to the scarcity of labeled data, most melody extrac-
tion algorithms do not rely on fully data-driven processing
blocks but rather on careful engineering. For example, the
Melodia melody extraction algorithm employs a pitch con-
tour selection stage that relies on a number of heuristics
for selecting the melodic output. In this paper we explore
the use of a discriminative model to perform purely data-
driven melodic contour selection. Speciﬁcally, a discrim-
inative binary classiﬁer is trained to distinguish melodic
from non-melodic contours. This classiﬁer is then used
to predict likelihoods for a track’s extracted contours, and
these scores are decoded to generate a single melody out-
put. The results are compared with the Melodia algorithm
and with a generative model used in a previous study. We
show that the discriminative model outperforms the gen-
erative model in terms of contour classiﬁcation accuracy,
and the melody output from our proposed system performs
comparatively to Melodia. The results are complemented
with error analysis and avenues for future improvements.



hal_id    :    hal-01206804



This paper introduces a novel technique for reconstructing
the phase of modiﬁed spectrograms of audio signals. From
the analysis of mixtures of sinusoids we obtain relation-
ships between phases of successive time frames in the Time-
Frequency (TF) domain. To obtain similar relationships over
frequencies, in particular within onset frames, we study an
impulse model. Instantaneous frequencies and attack times
are estimated locally to encompass the class of non-stationary
signals such as vibratos. These techniques ensure both the
vertical coherence of partials (over frequencies) and the hor-
izontal coherence (over time).
The method is tested on a
variety of data and demonstrates better performance than tra-
ditional consistency-based approaches. We also introduce an
audio restoration framework and observe that our technique
outperforms traditional methods.
Index Terms— Phase reconstruction, sinusoidal model-
ing, linear unwrapping, phase consistency, audio restoration.



hal_id    :    hal-01110035



In this paper, we propose a new method for singing voice detec-
tion based on a Bidirectional Long Short-Term Memory (BLSTM)
Recurrent Neural Network (RNN). This classiﬁer is able to take a
past and future temporal context into account to decide on the pres-
ence/absence of singing voice, thus using the inherent sequential
aspect of a short-term feature extraction in a piece of music. The
BLSTM-RNN contains several hidden layers, so it is able to extract a
simple representation ﬁtted to our task from low-level features. The
results we obtain signiﬁcantly outperform state-of-the-art methods
on a common database.
Index Terms— Singing Voice Detection, Deep Learning, Re-
current Neural Networks, Long Short-Term Memory



hal_id    :    hal-01110028



In the recent years, many studies have focused on the single-
sensor separation of independent waveforms using so-called soft-
masking strategies, where the short term Fourier transform of
the mixture is multiplied element-wise by a ratio of spectrogram
models. When the signals are wide-sense stationary, this strategy
is theoretically justiﬁed as an optimal Wiener ﬁltering: the power
spectrograms of the sources are supposed to add up to yield the
power spectrogram of the mixture. However, experience shows that
using fractional spectrograms instead, such as the amplitude, yields
good performance in practice, because they experimentally better
ﬁt the additivity assumption. To the best of our knowledge, no
probabilistic interpretation of this ﬁltering procedure was available
to date. In this paper, we show that assuming the additivity of frac-
tional spectrograms for the purpose of building soft-masks can be
understood as separating locally stationary α-stable harmonizable
processes, α-harmonizable in short, thus justifying the procedure
theoretically.
Index Terms—audio source separation, probability theory,
harmonizable processes, α-stable random variables, soft-masks



hal_id    :    hal-01110032



Nonnegative Matrix Factorization (NMF) is a powerful tool for de-
composing mixtures of audio signals in the Time-Frequency (TF)
domain. In applications such as source separation, the phase recov-
ery for each extracted component is a major issue since it often leads
to audible artifacts. In this paper, we present a methodology for
evaluating various NMF-based source separation techniques involv-
ing phase reconstruction. For each model considered, a comparison
between two approaches (blind separation without prior information
and oracle separation with supervised model learning) is performed,
in order to inquire about the room for improvement for the estima-
tion methods. Experimental results show that the High Resolution
NMF (HRNMF) model is particularly promising, because it is able
to take phases and correlations over time into account with a great
expressive power.
Index Terms— Nonnegative matrix factorization, audio source
separation, phase reconstruction, time-frequency analysis.